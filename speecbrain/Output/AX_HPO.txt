Requirement already satisfied: librosa in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 1)) (0.11.0)
Requirement already satisfied: pandas in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 2)) (2.2.3)
Requirement already satisfied: transformers in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 3)) (4.49.0)
Requirement already satisfied: torch in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 4)) (2.6.0)
Requirement already satisfied: pyarrow in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 7)) (19.0.1)
Requirement already satisfied: fastparquet in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 8)) (2024.11.0)
Requirement already satisfied: scikit-learn in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 18)) (1.6.1)
Requirement already satisfied: speechbrain in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 21)) (1.0.2)
Requirement already satisfied: datasets in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 23)) (3.6.0)
Requirement already satisfied: matplotlib in /users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages (from -r /users/ach21ag/diss_autml/requirements.txt (line 25)) (3.10.1)
ERROR: Could not find a version that satisfies the requirement libsndfile (from versions: none)
ERROR: No matching distribution found for libsndfile
INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]
INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
[WARNING 06-13 16:28:21] ax.service.utils.with_db_settings_base: Ax currently requires a sqlalchemy version below 2.0. This will be addressed in a future release. Disabling SQL storage in Ax for now, if you would like to use SQL storage please install Ax with mysql extras via `pip install ax-platform[mysql]`.
[INFO 06-13 16:28:23] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.
[WARNING 06-13 16:28:23] ax.service.ax_client: Random seed set to 2002. Note that this setting only affects the Sobol quasi-random generator and BoTorch-powered Bayesian optimization models. For the latter models, setting random seed to the same number for two optimizations will make the generated trials similar, but not exactly the same, and over time the trials will diverge more.
[INFO 06-13 16:28:23] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.
[INFO 06-13 16:28:23] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter max_length. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` "max_length". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.
  return ChoiceParameter(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` "max_length". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.
  return ChoiceParameter(
[INFO 06-13 16:28:23] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='lr', parameter_type=FLOAT, range=[1e-06, 0.001], log_scale=True), RangeParameter(name='num_epochs', parameter_type=INT, range=[1, 10]), RangeParameter(name='unfreeze_epoch', parameter_type=INT, range=[0, 5]), ChoiceParameter(name='max_length', parameter_type=INT, values=[32000, 48000, 64000, 80000, 112000, 160000], is_ordered=True, sort_values=True)], parameter_constraints=[]).
[INFO 06-13 16:28:23] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.
[INFO 06-13 16:28:23] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=4 num_trials=None use_batch_trials=False
[INFO 06-13 16:28:23] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=8
[INFO 06-13 16:28:23] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=8
[INFO 06-13 16:28:23] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.
[INFO 06-13 16:28:23] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 8 trials, BoTorch for subsequent trials]). Iterations after 8 will take longer to generate due to model-fitting.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 16:28:23] ax.service.ax_client: Generated new trial 0 with parameters {'lr': 1.2e-05, 'num_epochs': 9, 'unfreeze_epoch': 5, 'max_length': 160000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder
Label mapping: {np.int64(0): np.int64(0), np.int64(1): np.int64(1), np.int64(2): np.int64(2), np.int64(3): np.int64(3), np.int64(4): np.int64(4), np.int64(5): np.int64(5), np.int64(6): np.int64(6)}

Running trial 0 with config: {'batch_size': 1, 'lr': 1.2358010754486485e-05, 'num_epochs': 9, 'unfreeze_epoch': 5, 'max_length': 160000, 'device': device(type='cpu')}
Epoch [1/9], Batch [1/428], Loss: 5.3194
Epoch [1/9], Batch [2/428], Loss: 6.3499
Epoch [1/9], Batch [3/428], Loss: 3.4710
Epoch [1/9], Batch [4/428], Loss: 2.7741
Epoch [1/9], Batch [5/428], Loss: 6.0477
Epoch [1/9], Batch [6/428], Loss: 5.8080
Epoch [1/9], Batch [7/428], Loss: 6.2584
Epoch [1/9], Batch [8/428], Loss: 1.8122
Epoch [1/9], Batch [9/428], Loss: 5.7955
Epoch [1/9], Batch [10/428], Loss: 1.8660
Epoch [1/9], Batch [11/428], Loss: 0.3425
Epoch [1/9], Batch [12/428], Loss: 2.0566
Epoch [1/9], Batch [13/428], Loss: 3.2923
Epoch [1/9], Batch [14/428], Loss: 3.6659
Epoch [1/9], Batch [15/428], Loss: 2.4438
Epoch [1/9], Batch [16/428], Loss: 4.2111
Epoch [1/9], Batch [17/428], Loss: 1.8836
Epoch [1/9], Batch [18/428], Loss: 4.9928
Epoch [1/9], Batch [19/428], Loss: 2.6649
Epoch [1/9], Batch [20/428], Loss: 2.8718
Epoch [1/9], Batch [21/428], Loss: 2.2460
Epoch [1/9], Batch [22/428], Loss: 1.4095
Epoch [1/9], Batch [23/428], Loss: 2.4373
Epoch [1/9], Batch [24/428], Loss: 3.0119
Epoch [1/9], Batch [25/428], Loss: 2.4217
Epoch [1/9], Batch [26/428], Loss: 5.9366
Epoch [1/9], Batch [27/428], Loss: 5.9054
Epoch [1/9], Batch [28/428], Loss: 6.0059
Epoch [1/9], Batch [29/428], Loss: 2.7352
Epoch [1/9], Batch [30/428], Loss: 3.8986
Epoch [1/9], Batch [31/428], Loss: 2.3961
Epoch [1/9], Batch [32/428], Loss: 5.6452
Epoch [1/9], Batch [33/428], Loss: 2.9993
Epoch [1/9], Batch [34/428], Loss: 3.2034
Epoch [1/9], Batch [35/428], Loss: 2.2799
Epoch [1/9], Batch [36/428], Loss: 2.0158
Epoch [1/9], Batch [37/428], Loss: 5.4539
Epoch [1/9], Batch [38/428], Loss: 6.4575
Epoch [1/9], Batch [39/428], Loss: 0.5185
Epoch [1/9], Batch [40/428], Loss: 0.2747
Epoch [1/9], Batch [41/428], Loss: 0.6118
Epoch [1/9], Batch [42/428], Loss: 5.3084
Epoch [1/9], Batch [43/428], Loss: 0.3132
Epoch [1/9], Batch [44/428], Loss: 2.7933
Epoch [1/9], Batch [45/428], Loss: 3.2099
Epoch [1/9], Batch [46/428], Loss: 2.1263
Epoch [1/9], Batch [47/428], Loss: 0.3423
Epoch [1/9], Batch [48/428], Loss: 4.1201
Epoch [1/9], Batch [49/428], Loss: 5.3629
Epoch [1/9], Batch [50/428], Loss: 2.5036
Epoch [1/9], Batch [51/428], Loss: 5.9470
Epoch [1/9], Batch [52/428], Loss: 2.6464
Epoch [1/9], Batch [53/428], Loss: 5.0284
Epoch [1/9], Batch [54/428], Loss: 2.7780
Epoch [1/9], Batch [55/428], Loss: 5.4361
Epoch [1/9], Batch [56/428], Loss: 2.4743
Epoch [1/9], Batch [57/428], Loss: 4.6988
Epoch [1/9], Batch [58/428], Loss: 0.8870
Epoch [1/9], Batch [59/428], Loss: 3.2416
Epoch [1/9], Batch [60/428], Loss: 5.0061
Epoch [1/9], Batch [61/428], Loss: 4.0770
Epoch [1/9], Batch [62/428], Loss: 6.3985
Epoch [1/9], Batch [63/428], Loss: 4.1928
Epoch [1/9], Batch [64/428], Loss: 5.7785
Epoch [1/9], Batch [65/428], Loss: 4.9992
Epoch [1/9], Batch [66/428], Loss: 2.1360
Epoch [1/9], Batch [67/428], Loss: 2.3185
Epoch [1/9], Batch [68/428], Loss: 4.0808
Epoch [1/9], Batch [69/428], Loss: 2.2697
Epoch [1/9], Batch [70/428], Loss: 3.0375
Epoch [1/9], Batch [71/428], Loss: 5.5669
Epoch [1/9], Batch [72/428], Loss: 3.1097
Epoch [1/9], Batch [73/428], Loss: 5.2628
Epoch [1/9], Batch [74/428], Loss: 2.6800
Epoch [1/9], Batch [75/428], Loss: 0.7743
Epoch [1/9], Batch [76/428], Loss: 4.1720
Epoch [1/9], Batch [77/428], Loss: 3.6600
Epoch [1/9], Batch [78/428], Loss: 1.5839
Epoch [1/9], Batch [79/428], Loss: 5.0229
Epoch [1/9], Batch [80/428], Loss: 6.1305
Epoch [1/9], Batch [81/428], Loss: 5.1749
Epoch [1/9], Batch [82/428], Loss: 3.9940
Epoch [1/9], Batch [83/428], Loss: 5.6192
Epoch [1/9], Batch [84/428], Loss: 4.8404
Epoch [1/9], Batch [85/428], Loss: 5.9472
Epoch [1/9], Batch [86/428], Loss: 5.9441
Epoch [1/9], Batch [87/428], Loss: 2.2589
Epoch [1/9], Batch [88/428], Loss: 0.1510
Epoch [1/9], Batch [89/428], Loss: 3.1106
Epoch [1/9], Batch [90/428], Loss: 3.2666
Epoch [1/9], Batch [91/428], Loss: 2.0111
Epoch [1/9], Batch [92/428], Loss: 3.4166
Epoch [1/9], Batch [93/428], Loss: 1.5516
Epoch [1/9], Batch [94/428], Loss: 2.2280
Epoch [1/9], Batch [95/428], Loss: 0.3507
Epoch [1/9], Batch [96/428], Loss: 5.7785
Epoch [1/9], Batch [97/428], Loss: 0.8217
Epoch [1/9], Batch [98/428], Loss: 3.6412
Epoch [1/9], Batch [99/428], Loss: 5.0435
Epoch [1/9], Batch [100/428], Loss: 2.3021
Epoch [1/9], Batch [101/428], Loss: 6.2969
Epoch [1/9], Batch [102/428], Loss: 0.6276
Epoch [1/9], Batch [103/428], Loss: 2.6483
Epoch [1/9], Batch [104/428], Loss: 5.6183
Epoch [1/9], Batch [105/428], Loss: 0.5622
Epoch [1/9], Batch [106/428], Loss: 2.6089
Epoch [1/9], Batch [107/428], Loss: 2.0652
Epoch [1/9], Batch [108/428], Loss: 2.3771
Epoch [1/9], Batch [109/428], Loss: 6.0936
Epoch [1/9], Batch [110/428], Loss: 2.6993
Epoch [1/9], Batch [111/428], Loss: 0.5148
Epoch [1/9], Batch [112/428], Loss: 0.5206
Epoch [1/9], Batch [113/428], Loss: 3.2085
Epoch [1/9], Batch [114/428], Loss: 3.9747
Epoch [1/9], Batch [115/428], Loss: 2.6597
Epoch [1/9], Batch [116/428], Loss: 3.5788
Epoch [1/9], Batch [117/428], Loss: 3.6370
Epoch [1/9], Batch [118/428], Loss: 3.5979
Epoch [1/9], Batch [119/428], Loss: 5.9341
Epoch [1/9], Batch [120/428], Loss: 1.2506
Epoch [1/9], Batch [121/428], Loss: 6.2216
Epoch [1/9], Batch [122/428], Loss: 0.7099
Epoch [1/9], Batch [123/428], Loss: 2.5172
Epoch [1/9], Batch [124/428], Loss: 0.5605
Epoch [1/9], Batch [125/428], Loss: 2.2904
Epoch [1/9], Batch [126/428], Loss: 2.1773
Epoch [1/9], Batch [127/428], Loss: 5.4586
Epoch [1/9], Batch [128/428], Loss: 1.4739
Epoch [1/9], Batch [129/428], Loss: 5.9962
Epoch [1/9], Batch [130/428], Loss: 5.4382
Epoch [1/9], Batch [131/428], Loss: 2.0699
Epoch [1/9], Batch [132/428], Loss: 2.5392
Epoch [1/9], Batch [133/428], Loss: 5.5909
Epoch [1/9], Batch [134/428], Loss: 2.8915
Epoch [1/9], Batch [135/428], Loss: 1.7327
Epoch [1/9], Batch [136/428], Loss: 4.1571
Epoch [1/9], Batch [137/428], Loss: 5.5162
Epoch [1/9], Batch [138/428], Loss: 5.9102
Epoch [1/9], Batch [139/428], Loss: 5.5713
Epoch [1/9], Batch [140/428], Loss: 3.9824
Epoch [1/9], Batch [141/428], Loss: 6.0408
Epoch [1/9], Batch [142/428], Loss: 3.3172
Epoch [1/9], Batch [143/428], Loss: 3.2100
Epoch [1/9], Batch [144/428], Loss: 0.6992
Epoch [1/9], Batch [145/428], Loss: 2.1783
Epoch [1/9], Batch [146/428], Loss: 0.5650
Epoch [1/9], Batch [147/428], Loss: 5.6928
Epoch [1/9], Batch [148/428], Loss: 2.4217
Epoch [1/9], Batch [149/428], Loss: 4.0174
Epoch [1/9], Batch [150/428], Loss: 5.4071
Epoch [1/9], Batch [151/428], Loss: 2.3330
Epoch [1/9], Batch [152/428], Loss: 2.5928
Epoch [1/9], Batch [153/428], Loss: 2.1444
Epoch [1/9], Batch [154/428], Loss: 3.8959
Epoch [1/9], Batch [155/428], Loss: 2.3436
Epoch [1/9], Batch [156/428], Loss: 2.7992
Epoch [1/9], Batch [157/428], Loss: 4.6973
Epoch [1/9], Batch [158/428], Loss: 2.6386
Epoch [1/9], Batch [159/428], Loss: 2.4821
Epoch [1/9], Batch [160/428], Loss: 2.1931
Epoch [1/9], Batch [161/428], Loss: 5.8235
Epoch [1/9], Batch [162/428], Loss: 2.8119
Epoch [1/9], Batch [163/428], Loss: 2.0451
Epoch [1/9], Batch [164/428], Loss: 0.6960
Epoch [1/9], Batch [165/428], Loss: 5.5635
Epoch [1/9], Batch [166/428], Loss: 2.5146
Epoch [1/9], Batch [167/428], Loss: 3.1514
Epoch [1/9], Batch [168/428], Loss: 2.5940
Epoch [1/9], Batch [169/428], Loss: 2.1922
Epoch [1/9], Batch [170/428], Loss: 2.7363
Epoch [1/9], Batch [171/428], Loss: 1.3112
Epoch [1/9], Batch [172/428], Loss: 2.5971
Epoch [1/9], Batch [173/428], Loss: 2.9727
Epoch [1/9], Batch [174/428], Loss: 3.4299
Epoch [1/9], Batch [175/428], Loss: 2.2218
Epoch [1/9], Batch [176/428], Loss: 2.6060
Epoch [1/9], Batch [177/428], Loss: 2.4719
Epoch [1/9], Batch [178/428], Loss: 0.4236
Epoch [1/9], Batch [179/428], Loss: 2.6395
Epoch [1/9], Batch [180/428], Loss: 4.8679
Epoch [1/9], Batch [181/428], Loss: 2.9497
Epoch [1/9], Batch [182/428], Loss: 3.7265
Epoch [1/9], Batch [183/428], Loss: 1.5103
Epoch [1/9], Batch [184/428], Loss: 4.0698
Epoch [1/9], Batch [185/428], Loss: 2.4383
Epoch [1/9], Batch [186/428], Loss: 2.7768
Epoch [1/9], Batch [187/428], Loss: 2.8697
Epoch [1/9], Batch [188/428], Loss: 5.9907
Epoch [1/9], Batch [189/428], Loss: 2.6410
Epoch [1/9], Batch [190/428], Loss: 5.5270
Epoch [1/9], Batch [191/428], Loss: 3.1304
Epoch [1/9], Batch [192/428], Loss: 5.2486
Epoch [1/9], Batch [193/428], Loss: 0.6876
Epoch [1/9], Batch [194/428], Loss: 2.7011
Epoch [1/9], Batch [195/428], Loss: 0.3623
Epoch [1/9], Batch [196/428], Loss: 3.3179
Epoch [1/9], Batch [197/428], Loss: 3.7518
Epoch [1/9], Batch [198/428], Loss: 4.3783
Epoch [1/9], Batch [199/428], Loss: 2.7542
Epoch [1/9], Batch [200/428], Loss: 2.2673
Epoch [1/9], Batch [201/428], Loss: 2.3101
Epoch [1/9], Batch [202/428], Loss: 1.4172
Epoch [1/9], Batch [203/428], Loss: 0.6566
Epoch [1/9], Batch [204/428], Loss: 3.4663
Epoch [1/9], Batch [205/428], Loss: 2.4220
Epoch [1/9], Batch [206/428], Loss: 1.6556
Epoch [1/9], Batch [207/428], Loss: 4.0596
Epoch [1/9], Batch [208/428], Loss: 6.0814
Epoch [1/9], Batch [209/428], Loss: 0.1783
Epoch [1/9], Batch [210/428], Loss: 4.7604
Epoch [1/9], Batch [211/428], Loss: 3.1382
Epoch [1/9], Batch [212/428], Loss: 1.8418
Epoch [1/9], Batch [213/428], Loss: 1.9048
Epoch [1/9], Batch [214/428], Loss: 0.5026
Epoch [1/9], Batch [215/428], Loss: 5.1016
Epoch [1/9], Batch [216/428], Loss: 0.3357
Epoch [1/9], Batch [217/428], Loss: 0.6572
Epoch [1/9], Batch [218/428], Loss: 4.4674
Epoch [1/9], Batch [219/428], Loss: 5.7291
Epoch [1/9], Batch [220/428], Loss: 5.6515
Epoch [1/9], Batch [221/428], Loss: 6.2102
Epoch [1/9], Batch [222/428], Loss: 2.3440
Epoch [1/9], Batch [223/428], Loss: 5.5291
Epoch [1/9], Batch [224/428], Loss: 5.1987
Epoch [1/9], Batch [225/428], Loss: 2.5421
Epoch [1/9], Batch [226/428], Loss: 3.9277
Epoch [1/9], Batch [227/428], Loss: 1.9519
Epoch [1/9], Batch [228/428], Loss: 2.0215
Epoch [1/9], Batch [229/428], Loss: 2.0773
Epoch [1/9], Batch [230/428], Loss: 5.2710
Epoch [1/9], Batch [231/428], Loss: 2.2127
Epoch [1/9], Batch [232/428], Loss: 2.6018
Epoch [1/9], Batch [233/428], Loss: 1.8846
Epoch [1/9], Batch [234/428], Loss: 1.7681
Epoch [1/9], Batch [235/428], Loss: 0.7836
Epoch [1/9], Batch [236/428], Loss: 1.8228
Epoch [1/9], Batch [237/428], Loss: 5.5156
Epoch [1/9], Batch [238/428], Loss: 3.5431
Epoch [1/9], Batch [239/428], Loss: 5.4752
Epoch [1/9], Batch [240/428], Loss: 1.8367
Epoch [1/9], Batch [241/428], Loss: 5.8903
Epoch [1/9], Batch [242/428], Loss: 3.2548
Epoch [1/9], Batch [243/428], Loss: 1.6264
Epoch [1/9], Batch [244/428], Loss: 3.3545
Epoch [1/9], Batch [245/428], Loss: 0.4623
Epoch [1/9], Batch [246/428], Loss: 4.3116
Epoch [1/9], Batch [247/428], Loss: 1.5639
Epoch [1/9], Batch [248/428], Loss: 3.7128
Epoch [1/9], Batch [249/428], Loss: 2.2069
Epoch [1/9], Batch [250/428], Loss: 4.3130
Epoch [1/9], Batch [251/428], Loss: 1.2257
Epoch [1/9], Batch [252/428], Loss: 1.5702
Epoch [1/9], Batch [253/428], Loss: 4.9862
Epoch [1/9], Batch [254/428], Loss: 1.9271
Epoch [1/9], Batch [255/428], Loss: 2.1438
Epoch [1/9], Batch [256/428], Loss: 2.8113
Epoch [1/9], Batch [257/428], Loss: 0.5909
Epoch [1/9], Batch [258/428], Loss: 5.1947
Epoch [1/9], Batch [259/428], Loss: 5.7679
Epoch [1/9], Batch [260/428], Loss: 1.8193
Epoch [1/9], Batch [261/428], Loss: 2.4997
Epoch [1/9], Batch [262/428], Loss: 2.8946
Epoch [1/9], Batch [263/428], Loss: 5.6340
Epoch [1/9], Batch [264/428], Loss: 5.8182
Epoch [1/9], Batch [265/428], Loss: 3.8325
Epoch [1/9], Batch [266/428], Loss: 3.8530
Epoch [1/9], Batch [267/428], Loss: 5.6258
Epoch [1/9], Batch [268/428], Loss: 4.3760
Epoch [1/9], Batch [269/428], Loss: 5.4516
Epoch [1/9], Batch [270/428], Loss: 2.6646
Epoch [1/9], Batch [271/428], Loss: 5.8991
Epoch [1/9], Batch [272/428], Loss: 2.5200
Epoch [1/9], Batch [273/428], Loss: 2.2913
Epoch [1/9], Batch [274/428], Loss: 2.1415
Epoch [1/9], Batch [275/428], Loss: 3.8524
Epoch [1/9], Batch [276/428], Loss: 5.4702
Epoch [1/9], Batch [277/428], Loss: 5.9014
Epoch [1/9], Batch [278/428], Loss: 5.6410
Epoch [1/9], Batch [279/428], Loss: 2.8356
Epoch [1/9], Batch [280/428], Loss: 3.3127
Epoch [1/9], Batch [281/428], Loss: 1.7962
Epoch [1/9], Batch [282/428], Loss: 3.6388
Epoch [1/9], Batch [283/428], Loss: 5.7011
Epoch [1/9], Batch [284/428], Loss: 1.8978
Epoch [1/9], Batch [285/428], Loss: 0.6276
Epoch [1/9], Batch [286/428], Loss: 0.5787
Epoch [1/9], Batch [287/428], Loss: 5.0628
Epoch [1/9], Batch [288/428], Loss: 2.7300
Epoch [1/9], Batch [289/428], Loss: 3.1638
Epoch [1/9], Batch [290/428], Loss: 5.0818
Epoch [1/9], Batch [291/428], Loss: 4.0578
Epoch [1/9], Batch [292/428], Loss: 5.4074
Epoch [1/9], Batch [293/428], Loss: 1.2754
Epoch [1/9], Batch [294/428], Loss: 1.9828
Epoch [1/9], Batch [295/428], Loss: 2.5749
Epoch [1/9], Batch [296/428], Loss: 1.9524
Epoch [1/9], Batch [297/428], Loss: 3.0556
Epoch [1/9], Batch [298/428], Loss: 4.9072
Epoch [1/9], Batch [299/428], Loss: 5.2704
Epoch [1/9], Batch [300/428], Loss: 1.3335
Epoch [1/9], Batch [301/428], Loss: 2.7663
Epoch [1/9], Batch [302/428], Loss: 2.0124
Epoch [1/9], Batch [303/428], Loss: 5.4088
Epoch [1/9], Batch [304/428], Loss: 2.6334
Epoch [1/9], Batch [305/428], Loss: 2.0500
Epoch [1/9], Batch [306/428], Loss: 1.7136
Epoch [1/9], Batch [307/428], Loss: 0.3119
Epoch [1/9], Batch [308/428], Loss: 4.7594
Epoch [1/9], Batch [309/428], Loss: 3.9932
Epoch [1/9], Batch [310/428], Loss: 0.5479
Epoch [1/9], Batch [311/428], Loss: 1.6615
Epoch [1/9], Batch [312/428], Loss: 1.6254
Epoch [1/9], Batch [313/428], Loss: 5.5350
Epoch [1/9], Batch [314/428], Loss: 5.1935
Epoch [1/9], Batch [315/428], Loss: 2.2096
Epoch [1/9], Batch [316/428], Loss: 0.4247
Epoch [1/9], Batch [317/428], Loss: 2.0747
Epoch [1/9], Batch [318/428], Loss: 3.8197
Epoch [1/9], Batch [319/428], Loss: 4.5608
Epoch [1/9], Batch [320/428], Loss: 2.2387
Epoch [1/9], Batch [321/428], Loss: 3.1476
Epoch [1/9], Batch [322/428], Loss: 3.4648
Epoch [1/9], Batch [323/428], Loss: 5.0092
Epoch [1/9], Batch [324/428], Loss: 5.0902
Epoch [1/9], Batch [325/428], Loss: 4.8882
Epoch [1/9], Batch [326/428], Loss: 4.9566
Epoch [1/9], Batch [327/428], Loss: 5.5925
Epoch [1/9], Batch [328/428], Loss: 0.5105
Epoch [1/9], Batch [329/428], Loss: 0.3311
Epoch [1/9], Batch [330/428], Loss: 1.0079
Epoch [1/9], Batch [331/428], Loss: 5.7442
Epoch [1/9], Batch [332/428], Loss: 4.7954
Epoch [1/9], Batch [333/428], Loss: 5.4005
Epoch [1/9], Batch [334/428], Loss: 1.4335
Epoch [1/9], Batch [335/428], Loss: 2.2402
Epoch [1/9], Batch [336/428], Loss: 4.5539
Epoch [1/9], Batch [337/428], Loss: 4.2658
Epoch [1/9], Batch [338/428], Loss: 0.4316
Epoch [1/9], Batch [339/428], Loss: 5.0508
Epoch [1/9], Batch [340/428], Loss: 4.8677
Epoch [1/9], Batch [341/428], Loss: 2.1748
Epoch [1/9], Batch [342/428], Loss: 3.4039
Epoch [1/9], Batch [343/428], Loss: 2.6763
Epoch [1/9], Batch [344/428], Loss: 5.5754
Epoch [1/9], Batch [345/428], Loss: 2.7869
Epoch [1/9], Batch [346/428], Loss: 0.6822
Epoch [1/9], Batch [347/428], Loss: 5.6135
Epoch [1/9], Batch [348/428], Loss: 2.1225
Epoch [1/9], Batch [349/428], Loss: 2.9132
Epoch [1/9], Batch [350/428], Loss: 4.6742
Epoch [1/9], Batch [351/428], Loss: 5.4659
Epoch [1/9], Batch [352/428], Loss: 3.6680
Epoch [1/9], Batch [353/428], Loss: 4.2446
Epoch [1/9], Batch [354/428], Loss: 0.8116
Epoch [1/9], Batch [355/428], Loss: 2.1281
Epoch [1/9], Batch [356/428], Loss: 2.2276
Epoch [1/9], Batch [357/428], Loss: 4.5993
Epoch [1/9], Batch [358/428], Loss: 2.4194
Epoch [1/9], Batch [359/428], Loss: 1.5486
Epoch [1/9], Batch [360/428], Loss: 2.8955
Epoch [1/9], Batch [361/428], Loss: 2.8982
Epoch [1/9], Batch [362/428], Loss: 2.4865
Epoch [1/9], Batch [363/428], Loss: 3.0338
Epoch [1/9], Batch [364/428], Loss: 3.0516
Epoch [1/9], Batch [365/428], Loss: 3.6328
Epoch [1/9], Batch [366/428], Loss: 5.1067
Epoch [1/9], Batch [367/428], Loss: 2.2567
Epoch [1/9], Batch [368/428], Loss: 5.3979
Epoch [1/9], Batch [369/428], Loss: 4.3318
Epoch [1/9], Batch [370/428], Loss: 4.7018
Epoch [1/9], Batch [371/428], Loss: 5.0266
Epoch [1/9], Batch [372/428], Loss: 5.4766
Epoch [1/9], Batch [373/428], Loss: 3.2400
Epoch [1/9], Batch [374/428], Loss: 2.3328
Epoch [1/9], Batch [375/428], Loss: 5.1017
Epoch [1/9], Batch [376/428], Loss: 4.9109
Epoch [1/9], Batch [377/428], Loss: 0.8344
Epoch [1/9], Batch [378/428], Loss: 5.1464
Epoch [1/9], Batch [379/428], Loss: 2.6343
Epoch [1/9], Batch [380/428], Loss: 4.6349
Epoch [1/9], Batch [381/428], Loss: 5.1728
Epoch [1/9], Batch [382/428], Loss: 2.9143
Epoch [1/9], Batch [383/428], Loss: 5.2783
Epoch [1/9], Batch [384/428], Loss: 0.7126
Epoch [1/9], Batch [385/428], Loss: 3.0367
Epoch [1/9], Batch [386/428], Loss: 0.4837
Epoch [1/9], Batch [387/428], Loss: 2.6357
Epoch [1/9], Batch [388/428], Loss: 5.3724
Epoch [1/9], Batch [389/428], Loss: 3.9012
Epoch [1/9], Batch [390/428], Loss: 1.0021
Epoch [1/9], Batch [391/428], Loss: 4.5456
Epoch [1/9], Batch [392/428], Loss: 1.8597
Epoch [1/9], Batch [393/428], Loss: 1.8492
Epoch [1/9], Batch [394/428], Loss: 0.7372
Epoch [1/9], Batch [395/428], Loss: 4.5834
Epoch [1/9], Batch [396/428], Loss: 1.5675
Epoch [1/9], Batch [397/428], Loss: 5.1622
Epoch [1/9], Batch [398/428], Loss: 4.9022
Epoch [1/9], Batch [399/428], Loss: 2.5856
Epoch [1/9], Batch [400/428], Loss: 0.7823
Epoch [1/9], Batch [401/428], Loss: 4.9096
Epoch [1/9], Batch [402/428], Loss: 2.5607
Epoch [1/9], Batch [403/428], Loss: 3.6546
Epoch [1/9], Batch [404/428], Loss: 0.7978
Epoch [1/9], Batch [405/428], Loss: 2.2945
Epoch [1/9], Batch [406/428], Loss: 0.8339
Epoch [1/9], Batch [407/428], Loss: 1.5711
Epoch [1/9], Batch [408/428], Loss: 5.0268
Epoch [1/9], Batch [409/428], Loss: 2.2732
Epoch [1/9], Batch [410/428], Loss: 3.0872
Epoch [1/9], Batch [411/428], Loss: 4.8875
Epoch [1/9], Batch [412/428], Loss: 5.2838
Epoch [1/9], Batch [413/428], Loss: 4.2582
Epoch [1/9], Batch [414/428], Loss: 2.5136
Epoch [1/9], Batch [415/428], Loss: 1.3011
Epoch [1/9], Batch [416/428], Loss: 3.8880
Epoch [1/9], Batch [417/428], Loss: 0.6498
Epoch [1/9], Batch [418/428], Loss: 2.5664
Epoch [1/9], Batch [419/428], Loss: 1.5436
Epoch [1/9], Batch [420/428], Loss: 3.1975
Epoch [1/9], Batch [421/428], Loss: 3.2844
Epoch [1/9], Batch [422/428], Loss: 5.4751
Epoch [1/9], Batch [423/428], Loss: 2.1373
Epoch [1/9], Batch [424/428], Loss: 4.0987
Epoch [1/9], Batch [425/428], Loss: 4.0880
Epoch [1/9], Batch [426/428], Loss: 4.6952
Epoch [1/9], Batch [427/428], Loss: 1.9271
Epoch [1/9], Batch [428/428], Loss: 2.0904
Epoch [1] Training Time: 368.90 seconds
Epoch [1/9], Average Loss: 3.2706, Training Accuracy: 0.1285
Epoch [1], Validation Loss: 2.7985, Validation Accuracy: 0.1505
Epoch [1] Validation Time: 21.17 seconds
--------------------------------------------------
Epoch [2/9], Batch [1/428], Loss: 0.5947
Epoch [2/9], Batch [2/428], Loss: 3.3844
Epoch [2/9], Batch [3/428], Loss: 4.8607
Epoch [2/9], Batch [4/428], Loss: 0.6374
Epoch [2/9], Batch [5/428], Loss: 5.0030
Epoch [2/9], Batch [6/428], Loss: 4.9145
Epoch [2/9], Batch [7/428], Loss: 2.1411
Epoch [2/9], Batch [8/428], Loss: 5.2431
Epoch [2/9], Batch [9/428], Loss: 5.1012
Epoch [2/9], Batch [10/428], Loss: 5.1537
Epoch [2/9], Batch [11/428], Loss: 4.8517
Epoch [2/9], Batch [12/428], Loss: 5.3599
Epoch [2/9], Batch [13/428], Loss: 1.1999
Epoch [2/9], Batch [14/428], Loss: 2.8438
Epoch [2/9], Batch [15/428], Loss: 4.6996
Epoch [2/9], Batch [16/428], Loss: 2.2769
Epoch [2/9], Batch [17/428], Loss: 1.0743
Epoch [2/9], Batch [18/428], Loss: 5.1124
Epoch [2/9], Batch [19/428], Loss: 4.6886
Epoch [2/9], Batch [20/428], Loss: 4.7773
Epoch [2/9], Batch [21/428], Loss: 2.1268
Epoch [2/9], Batch [22/428], Loss: 3.7241
Epoch [2/9], Batch [23/428], Loss: 0.7758
Epoch [2/9], Batch [24/428], Loss: 2.6760
Epoch [2/9], Batch [25/428], Loss: 4.4381
Epoch [2/9], Batch [26/428], Loss: 1.5485
Epoch [2/9], Batch [27/428], Loss: 2.3131
Epoch [2/9], Batch [28/428], Loss: 2.4630
Epoch [2/9], Batch [29/428], Loss: 4.9650
Epoch [2/9], Batch [30/428], Loss: 5.0090
Epoch [2/9], Batch [31/428], Loss: 2.0394
Epoch [2/9], Batch [32/428], Loss: 1.2154
Epoch [2/9], Batch [33/428], Loss: 1.9802
Epoch [2/9], Batch [34/428], Loss: 4.1203
Epoch [2/9], Batch [35/428], Loss: 4.9054
Epoch [2/9], Batch [36/428], Loss: 2.6285
Epoch [2/9], Batch [37/428], Loss: 5.3779
Epoch [2/9], Batch [38/428], Loss: 4.5823
Epoch [2/9], Batch [39/428], Loss: 1.7220
Epoch [2/9], Batch [40/428], Loss: 2.9495
Epoch [2/9], Batch [41/428], Loss: 3.6349
Epoch [2/9], Batch [42/428], Loss: 1.9501
Epoch [2/9], Batch [43/428], Loss: 2.5184
Epoch [2/9], Batch [44/428], Loss: 1.8754
Epoch [2/9], Batch [45/428], Loss: 1.6246
Epoch [2/9], Batch [46/428], Loss: 3.1721
Epoch [2/9], Batch [47/428], Loss: 2.7048
Epoch [2/9], Batch [48/428], Loss: 4.7037
Epoch [2/9], Batch [49/428], Loss: 2.4519
Epoch [2/9], Batch [50/428], Loss: 1.6202
Epoch [2/9], Batch [51/428], Loss: 3.1846
Epoch [2/9], Batch [52/428], Loss: 1.0677
Epoch [2/9], Batch [53/428], Loss: 2.3387
Epoch [2/9], Batch [54/428], Loss: 2.2561
Epoch [2/9], Batch [55/428], Loss: 1.9846
Epoch [2/9], Batch [56/428], Loss: 3.1445
Epoch [2/9], Batch [57/428], Loss: 2.7264
Epoch [2/9], Batch [58/428], Loss: 3.7124
Epoch [2/9], Batch [59/428], Loss: 1.6569
Epoch [2/9], Batch [60/428], Loss: 2.1713
Epoch [2/9], Batch [61/428], Loss: 0.7901
Epoch [2/9], Batch [62/428], Loss: 4.0316
Epoch [2/9], Batch [63/428], Loss: 3.8421
Epoch [2/9], Batch [64/428], Loss: 4.9261
Epoch [2/9], Batch [65/428], Loss: 4.4224
Epoch [2/9], Batch [66/428], Loss: 2.4270
Epoch [2/9], Batch [67/428], Loss: 4.5504
Epoch [2/9], Batch [68/428], Loss: 1.2751
Epoch [2/9], Batch [69/428], Loss: 4.4915
Epoch [2/9], Batch [70/428], Loss: 5.1177
Epoch [2/9], Batch [71/428], Loss: 4.9074
Epoch [2/9], Batch [72/428], Loss: 1.8122
Epoch [2/9], Batch [73/428], Loss: 0.4578
Epoch [2/9], Batch [74/428], Loss: 0.6614
Epoch [2/9], Batch [75/428], Loss: 2.3745
Epoch [2/9], Batch [76/428], Loss: 4.6587
Epoch [2/9], Batch [77/428], Loss: 2.2047
Epoch [2/9], Batch [78/428], Loss: 1.3037
Epoch [2/9], Batch [79/428], Loss: 2.1384
Epoch [2/9], Batch [80/428], Loss: 3.9109
Epoch [2/9], Batch [81/428], Loss: 2.6886
Epoch [2/9], Batch [82/428], Loss: 2.3132
Epoch [2/9], Batch [83/428], Loss: 2.6564
Epoch [2/9], Batch [84/428], Loss: 3.3546
Epoch [2/9], Batch [85/428], Loss: 2.3062
Epoch [2/9], Batch [86/428], Loss: 0.8622
Epoch [2/9], Batch [87/428], Loss: 4.6875
Epoch [2/9], Batch [88/428], Loss: 3.8893
Epoch [2/9], Batch [89/428], Loss: 4.8622
Epoch [2/9], Batch [90/428], Loss: 1.5434
Epoch [2/9], Batch [91/428], Loss: 0.8817
Epoch [2/9], Batch [92/428], Loss: 4.8231
Epoch [2/9], Batch [93/428], Loss: 1.2944
Epoch [2/9], Batch [94/428], Loss: 1.7902
Epoch [2/9], Batch [95/428], Loss: 3.7558
Epoch [2/9], Batch [96/428], Loss: 3.7315
Epoch [2/9], Batch [97/428], Loss: 4.8397
Epoch [2/9], Batch [98/428], Loss: 4.2101
Epoch [2/9], Batch [99/428], Loss: 2.5010
Epoch [2/9], Batch [100/428], Loss: 4.9088
Epoch [2/9], Batch [101/428], Loss: 1.5455
Epoch [2/9], Batch [102/428], Loss: 2.5689
Epoch [2/9], Batch [103/428], Loss: 1.6573
Epoch [2/9], Batch [104/428], Loss: 1.9121
Epoch [2/9], Batch [105/428], Loss: 0.4444
Epoch [2/9], Batch [106/428], Loss: 1.7627
Epoch [2/9], Batch [107/428], Loss: 3.1851
Epoch [2/9], Batch [108/428], Loss: 1.4729
Epoch [2/9], Batch [109/428], Loss: 4.0959
Epoch [2/9], Batch [110/428], Loss: 0.5550
Epoch [2/9], Batch [111/428], Loss: 2.0303
Epoch [2/9], Batch [112/428], Loss: 4.3293
Epoch [2/9], Batch [113/428], Loss: 4.7779
Epoch [2/9], Batch [114/428], Loss: 1.9855
Epoch [2/9], Batch [115/428], Loss: 2.8645
Epoch [2/9], Batch [116/428], Loss: 4.6711
Epoch [2/9], Batch [117/428], Loss: 3.0636
Epoch [2/9], Batch [118/428], Loss: 1.8062
Epoch [2/9], Batch [119/428], Loss: 0.7783
Epoch [2/9], Batch [120/428], Loss: 0.7310
Epoch [2/9], Batch [121/428], Loss: 4.4483
Epoch [2/9], Batch [122/428], Loss: 2.5985
Epoch [2/9], Batch [123/428], Loss: 2.5157
Epoch [2/9], Batch [124/428], Loss: 2.8746
Epoch [2/9], Batch [125/428], Loss: 1.5719
Epoch [2/9], Batch [126/428], Loss: 2.7486
Epoch [2/9], Batch [127/428], Loss: 2.6343
Epoch [2/9], Batch [128/428], Loss: 0.5465
Epoch [2/9], Batch [129/428], Loss: 1.9836
Epoch [2/9], Batch [130/428], Loss: 4.4547
Epoch [2/9], Batch [131/428], Loss: 4.5608
Epoch [2/9], Batch [132/428], Loss: 3.0070
Epoch [2/9], Batch [133/428], Loss: 4.0537
Epoch [2/9], Batch [134/428], Loss: 5.0012
Epoch [2/9], Batch [135/428], Loss: 1.3899
Epoch [2/9], Batch [136/428], Loss: 4.3648
Epoch [2/9], Batch [137/428], Loss: 3.2709
Epoch [2/9], Batch [138/428], Loss: 5.1597
Epoch [2/9], Batch [139/428], Loss: 2.0847
Epoch [2/9], Batch [140/428], Loss: 1.6193
Epoch [2/9], Batch [141/428], Loss: 2.5137
Epoch [2/9], Batch [142/428], Loss: 2.5111
Epoch [2/9], Batch [143/428], Loss: 2.6101
Epoch [2/9], Batch [144/428], Loss: 2.5612
Epoch [2/9], Batch [145/428], Loss: 2.2504
Epoch [2/9], Batch [146/428], Loss: 4.4033
Epoch [2/9], Batch [147/428], Loss: 4.0291
Epoch [2/9], Batch [148/428], Loss: 2.2602
Epoch [2/9], Batch [149/428], Loss: 1.7859
Epoch [2/9], Batch [150/428], Loss: 1.9797
Epoch [2/9], Batch [151/428], Loss: 4.6014
Epoch [2/9], Batch [152/428], Loss: 1.3773
Epoch [2/9], Batch [153/428], Loss: 2.0633
Epoch [2/9], Batch [154/428], Loss: 1.6473
Epoch [2/9], Batch [155/428], Loss: 2.0162
Epoch [2/9], Batch [156/428], Loss: 2.5605
Epoch [2/9], Batch [157/428], Loss: 4.4371
Epoch [2/9], Batch [158/428], Loss: 5.0579
Epoch [2/9], Batch [159/428], Loss: 1.4178
Epoch [2/9], Batch [160/428], Loss: 4.9309
Epoch [2/9], Batch [161/428], Loss: 2.6064
Epoch [2/9], Batch [162/428], Loss: 4.2716
Epoch [2/9], Batch [163/428], Loss: 2.2860
Epoch [2/9], Batch [164/428], Loss: 1.1660
Epoch [2/9], Batch [165/428], Loss: 2.1240
Epoch [2/9], Batch [166/428], Loss: 4.5983
Epoch [2/9], Batch [167/428], Loss: 2.1868
Epoch [2/9], Batch [168/428], Loss: 4.7091
Epoch [2/9], Batch [169/428], Loss: 3.4053
Epoch [2/9], Batch [170/428], Loss: 1.4775
Epoch [2/9], Batch [171/428], Loss: 3.6770
Epoch [2/9], Batch [172/428], Loss: 0.5849
Epoch [2/9], Batch [173/428], Loss: 3.9922
Epoch [2/9], Batch [174/428], Loss: 2.1049
Epoch [2/9], Batch [175/428], Loss: 3.7098
Epoch [2/9], Batch [176/428], Loss: 2.2393
Epoch [2/9], Batch [177/428], Loss: 0.7996
Epoch [2/9], Batch [178/428], Loss: 3.8908
Epoch [2/9], Batch [179/428], Loss: 2.5853
Epoch [2/9], Batch [180/428], Loss: 4.3700
Epoch [2/9], Batch [181/428], Loss: 3.9357
Epoch [2/9], Batch [182/428], Loss: 3.8920
Epoch [2/9], Batch [183/428], Loss: 4.1309
Epoch [2/9], Batch [184/428], Loss: 3.4529
Epoch [2/9], Batch [185/428], Loss: 3.8462
Epoch [2/9], Batch [186/428], Loss: 3.2848
Epoch [2/9], Batch [187/428], Loss: 1.5274
Epoch [2/9], Batch [188/428], Loss: 5.0282
Epoch [2/9], Batch [189/428], Loss: 4.4206
Epoch [2/9], Batch [190/428], Loss: 3.6083
Epoch [2/9], Batch [191/428], Loss: 0.8883
Epoch [2/9], Batch [192/428], Loss: 1.3528
Epoch [2/9], Batch [193/428], Loss: 1.5744
Epoch [2/9], Batch [194/428], Loss: 2.7085
Epoch [2/9], Batch [195/428], Loss: 1.1974
Epoch [2/9], Batch [196/428], Loss: 2.1625
Epoch [2/9], Batch [197/428], Loss: 3.6210
Epoch [2/9], Batch [198/428], Loss: 0.7815
Epoch [2/9], Batch [199/428], Loss: 2.6402
Epoch [2/9], Batch [200/428], Loss: 2.1814
Epoch [2/9], Batch [201/428], Loss: 4.0422
Epoch [2/9], Batch [202/428], Loss: 1.8100
Epoch [2/9], Batch [203/428], Loss: 0.8171
Epoch [2/9], Batch [204/428], Loss: 4.4226
Epoch [2/9], Batch [205/428], Loss: 0.8847
Epoch [2/9], Batch [206/428], Loss: 4.1009
Epoch [2/9], Batch [207/428], Loss: 0.8449
Epoch [2/9], Batch [208/428], Loss: 1.1443
Epoch [2/9], Batch [209/428], Loss: 2.7885
Epoch [2/9], Batch [210/428], Loss: 3.6150
Epoch [2/9], Batch [211/428], Loss: 1.4269
Epoch [2/9], Batch [212/428], Loss: 1.8670
Epoch [2/9], Batch [213/428], Loss: 1.6714
Epoch [2/9], Batch [214/428], Loss: 1.7493
Epoch [2/9], Batch [215/428], Loss: 1.5947
Epoch [2/9], Batch [216/428], Loss: 1.2087
Epoch [2/9], Batch [217/428], Loss: 0.8415
Epoch [2/9], Batch [218/428], Loss: 2.9912
Epoch [2/9], Batch [219/428], Loss: 1.8474
Epoch [2/9], Batch [220/428], Loss: 1.0971
Epoch [2/9], Batch [221/428], Loss: 3.4284
Epoch [2/9], Batch [222/428], Loss: 0.4338
Epoch [2/9], Batch [223/428], Loss: 0.8526
Epoch [2/9], Batch [224/428], Loss: 1.9513
Epoch [2/9], Batch [225/428], Loss: 1.4501
Epoch [2/9], Batch [226/428], Loss: 3.0166
Epoch [2/9], Batch [227/428], Loss: 2.5434
Epoch [2/9], Batch [228/428], Loss: 2.2725
Epoch [2/9], Batch [229/428], Loss: 3.0826
Epoch [2/9], Batch [230/428], Loss: 1.6937
Epoch [2/9], Batch [231/428], Loss: 1.3860
Epoch [2/9], Batch [232/428], Loss: 1.0964
Epoch [2/9], Batch [233/428], Loss: 3.8998
Epoch [2/9], Batch [234/428], Loss: 0.7197
Epoch [2/9], Batch [235/428], Loss: 2.1827
Epoch [2/9], Batch [236/428], Loss: 2.5397
Epoch [2/9], Batch [237/428], Loss: 3.7920
Epoch [2/9], Batch [238/428], Loss: 3.4407
Epoch [2/9], Batch [239/428], Loss: 2.6752
Epoch [2/9], Batch [240/428], Loss: 4.3677
Epoch [2/9], Batch [241/428], Loss: 4.2699
Epoch [2/9], Batch [242/428], Loss: 4.5605
Epoch [2/9], Batch [243/428], Loss: 2.4049
Epoch [2/9], Batch [244/428], Loss: 4.5228
Epoch [2/9], Batch [245/428], Loss: 2.4828
Epoch [2/9], Batch [246/428], Loss: 4.3578
Epoch [2/9], Batch [247/428], Loss: 2.0501
Epoch [2/9], Batch [248/428], Loss: 4.6289
Epoch [2/9], Batch [249/428], Loss: 3.5973
Epoch [2/9], Batch [250/428], Loss: 3.4013
Epoch [2/9], Batch [251/428], Loss: 2.6636
Epoch [2/9], Batch [252/428], Loss: 4.1568
Epoch [2/9], Batch [253/428], Loss: 3.0206
Epoch [2/9], Batch [254/428], Loss: 1.9965
Epoch [2/9], Batch [255/428], Loss: 3.9739
Epoch [2/9], Batch [256/428], Loss: 4.0087
Epoch [2/9], Batch [257/428], Loss: 4.3225
Epoch [2/9], Batch [258/428], Loss: 3.7991
Epoch [2/9], Batch [259/428], Loss: 1.9797
Epoch [2/9], Batch [260/428], Loss: 1.9597
Epoch [2/9], Batch [261/428], Loss: 3.3565
Epoch [2/9], Batch [262/428], Loss: 2.2981
Epoch [2/9], Batch [263/428], Loss: 3.8364
Epoch [2/9], Batch [264/428], Loss: 1.5099
Epoch [2/9], Batch [265/428], Loss: 4.5095
Epoch [2/9], Batch [266/428], Loss: 0.9033
Epoch [2/9], Batch [267/428], Loss: 2.2477
Epoch [2/9], Batch [268/428], Loss: 3.6020
Epoch [2/9], Batch [269/428], Loss: 1.0114
Epoch [2/9], Batch [270/428], Loss: 2.1824
Epoch [2/9], Batch [271/428], Loss: 4.7429
Epoch [2/9], Batch [272/428], Loss: 4.3949
Epoch [2/9], Batch [273/428], Loss: 4.7122
Epoch [2/9], Batch [274/428], Loss: 3.1930
Epoch [2/9], Batch [275/428], Loss: 1.9302
Epoch [2/9], Batch [276/428], Loss: 1.0309
Epoch [2/9], Batch [277/428], Loss: 3.8467
Epoch [2/9], Batch [278/428], Loss: 1.4257
Epoch [2/9], Batch [279/428], Loss: 2.2593
Epoch [2/9], Batch [280/428], Loss: 0.3619
Epoch [2/9], Batch [281/428], Loss: 4.3610
Epoch [2/9], Batch [282/428], Loss: 2.5454
Epoch [2/9], Batch [283/428], Loss: 2.8267
Epoch [2/9], Batch [284/428], Loss: 3.1686
Epoch [2/9], Batch [285/428], Loss: 4.9609
Epoch [2/9], Batch [286/428], Loss: 2.0060
Epoch [2/9], Batch [287/428], Loss: 3.0930
Epoch [2/9], Batch [288/428], Loss: 2.8245
Epoch [2/9], Batch [289/428], Loss: 0.9697
Epoch [2/9], Batch [290/428], Loss: 4.8050
Epoch [2/9], Batch [291/428], Loss: 0.9681
Epoch [2/9], Batch [292/428], Loss: 1.8247
Epoch [2/9], Batch [293/428], Loss: 4.2190
Epoch [2/9], Batch [294/428], Loss: 3.9781
Epoch [2/9], Batch [295/428], Loss: 4.3489
Epoch [2/9], Batch [296/428], Loss: 2.5121
Epoch [2/9], Batch [297/428], Loss: 1.2273
Epoch [2/9], Batch [298/428], Loss: 1.2815
Epoch [2/9], Batch [299/428], Loss: 3.5813
Epoch [2/9], Batch [300/428], Loss: 3.0563
Epoch [2/9], Batch [301/428], Loss: 4.4199
Epoch [2/9], Batch [302/428], Loss: 1.1747
Epoch [2/9], Batch [303/428], Loss: 1.4752
Epoch [2/9], Batch [304/428], Loss: 4.2922
Epoch [2/9], Batch [305/428], Loss: 0.8788
Epoch [2/9], Batch [306/428], Loss: 4.3407
Epoch [2/9], Batch [307/428], Loss: 2.7161
Epoch [2/9], Batch [308/428], Loss: 2.4322
Epoch [2/9], Batch [309/428], Loss: 2.4509
Epoch [2/9], Batch [310/428], Loss: 3.4677
Epoch [2/9], Batch [311/428], Loss: 4.1114
Epoch [2/9], Batch [312/428], Loss: 4.2395
Epoch [2/9], Batch [313/428], Loss: 3.4480
Epoch [2/9], Batch [314/428], Loss: 2.2514
Epoch [2/9], Batch [315/428], Loss: 2.7838
Epoch [2/9], Batch [316/428], Loss: 3.0567
Epoch [2/9], Batch [317/428], Loss: 4.1555
Epoch [2/9], Batch [318/428], Loss: 4.2574
Epoch [2/9], Batch [319/428], Loss: 2.5648
Epoch [2/9], Batch [320/428], Loss: 1.0418
Epoch [2/9], Batch [321/428], Loss: 2.6222
Epoch [2/9], Batch [322/428], Loss: 3.3201
Epoch [2/9], Batch [323/428], Loss: 1.3119
Epoch [2/9], Batch [324/428], Loss: 1.1947
Epoch [2/9], Batch [325/428], Loss: 1.5947
Epoch [2/9], Batch [326/428], Loss: 0.3472
Epoch [2/9], Batch [327/428], Loss: 1.8730
Epoch [2/9], Batch [328/428], Loss: 3.7627
Epoch [2/9], Batch [329/428], Loss: 2.8510
Epoch [2/9], Batch [330/428], Loss: 4.2876
Epoch [2/9], Batch [331/428], Loss: 3.4599
Epoch [2/9], Batch [332/428], Loss: 4.1257
Epoch [2/9], Batch [333/428], Loss: 2.4301
Epoch [2/9], Batch [334/428], Loss: 4.3582
Epoch [2/9], Batch [335/428], Loss: 0.7444
Epoch [2/9], Batch [336/428], Loss: 1.2279
Epoch [2/9], Batch [337/428], Loss: 2.1931
Epoch [2/9], Batch [338/428], Loss: 0.9856
Epoch [2/9], Batch [339/428], Loss: 1.8900
Epoch [2/9], Batch [340/428], Loss: 3.4597
Epoch [2/9], Batch [341/428], Loss: 0.9737
Epoch [2/9], Batch [342/428], Loss: 0.8882
Epoch [2/9], Batch [343/428], Loss: 1.4741
Epoch [2/9], Batch [344/428], Loss: 0.6707
Epoch [2/9], Batch [345/428], Loss: 0.6801
Epoch [2/9], Batch [346/428], Loss: 3.1406
Epoch [2/9], Batch [347/428], Loss: 1.2879
Epoch [2/9], Batch [348/428], Loss: 3.8045
Epoch [2/9], Batch [349/428], Loss: 1.8362
Epoch [2/9], Batch [350/428], Loss: 1.3255
Epoch [2/9], Batch [351/428], Loss: 4.0917
Epoch [2/9], Batch [352/428], Loss: 2.1762
Epoch [2/9], Batch [353/428], Loss: 2.6441
Epoch [2/9], Batch [354/428], Loss: 1.5208
Epoch [2/9], Batch [355/428], Loss: 2.0725
Epoch [2/9], Batch [356/428], Loss: 1.6344
Epoch [2/9], Batch [357/428], Loss: 3.9477
Epoch [2/9], Batch [358/428], Loss: 2.6070
Epoch [2/9], Batch [359/428], Loss: 4.0373
Epoch [2/9], Batch [360/428], Loss: 3.8555
Epoch [2/9], Batch [361/428], Loss: 2.4266
Epoch [2/9], Batch [362/428], Loss: 4.3092
Epoch [2/9], Batch [363/428], Loss: 3.7783
Epoch [2/9], Batch [364/428], Loss: 1.9994
Epoch [2/9], Batch [365/428], Loss: 3.6081
Epoch [2/9], Batch [366/428], Loss: 4.6508
Epoch [2/9], Batch [367/428], Loss: 0.6413
Epoch [2/9], Batch [368/428], Loss: 1.1546
Epoch [2/9], Batch [369/428], Loss: 2.4484
Epoch [2/9], Batch [370/428], Loss: 3.6072
Epoch [2/9], Batch [371/428], Loss: 3.5441
Epoch [2/9], Batch [372/428], Loss: 3.8004
Epoch [2/9], Batch [373/428], Loss: 2.9917
Epoch [2/9], Batch [374/428], Loss: 1.8331
Epoch [2/9], Batch [375/428], Loss: 3.8176
Epoch [2/9], Batch [376/428], Loss: 1.8823
Epoch [2/9], Batch [377/428], Loss: 4.2327
Epoch [2/9], Batch [378/428], Loss: 2.1307
Epoch [2/9], Batch [379/428], Loss: 2.9692
Epoch [2/9], Batch [380/428], Loss: 2.5697
Epoch [2/9], Batch [381/428], Loss: 3.8211
Epoch [2/9], Batch [382/428], Loss: 3.5201
Epoch [2/9], Batch [383/428], Loss: 2.2696
Epoch [2/9], Batch [384/428], Loss: 2.7734
Epoch [2/9], Batch [385/428], Loss: 2.4133
Epoch [2/9], Batch [386/428], Loss: 2.1679
Epoch [2/9], Batch [387/428], Loss: 2.2310
Epoch [2/9], Batch [388/428], Loss: 3.3078
Epoch [2/9], Batch [389/428], Loss: 1.9252
Epoch [2/9], Batch [390/428], Loss: 0.7939
Epoch [2/9], Batch [391/428], Loss: 3.3385
Epoch [2/9], Batch [392/428], Loss: 2.4701
Epoch [2/9], Batch [393/428], Loss: 2.3096
Epoch [2/9], Batch [394/428], Loss: 1.9341
Epoch [2/9], Batch [395/428], Loss: 2.3400
Epoch [2/9], Batch [396/428], Loss: 3.3646
Epoch [2/9], Batch [397/428], Loss: 4.3664
Epoch [2/9], Batch [398/428], Loss: 2.3759
Epoch [2/9], Batch [399/428], Loss: 0.8799
Epoch [2/9], Batch [400/428], Loss: 1.9177
Epoch [2/9], Batch [401/428], Loss: 1.6969
Epoch [2/9], Batch [402/428], Loss: 1.0280
Epoch [2/9], Batch [403/428], Loss: 3.8481
Epoch [2/9], Batch [404/428], Loss: 0.9986
Epoch [2/9], Batch [405/428], Loss: 2.1760
Epoch [2/9], Batch [406/428], Loss: 3.2031
Epoch [2/9], Batch [407/428], Loss: 2.3485
Epoch [2/9], Batch [408/428], Loss: 0.7416
Epoch [2/9], Batch [409/428], Loss: 0.9715
Epoch [2/9], Batch [410/428], Loss: 3.9543
Epoch [2/9], Batch [411/428], Loss: 2.3173
Epoch [2/9], Batch [412/428], Loss: 0.7696
Epoch [2/9], Batch [413/428], Loss: 0.7354
Epoch [2/9], Batch [414/428], Loss: 0.6527
Epoch [2/9], Batch [415/428], Loss: 1.9658
Epoch [2/9], Batch [416/428], Loss: 3.5098
Epoch [2/9], Batch [417/428], Loss: 1.4049
Epoch [2/9], Batch [418/428], Loss: 3.1464
Epoch [2/9], Batch [419/428], Loss: 1.6383
Epoch [2/9], Batch [420/428], Loss: 2.0849
Epoch [2/9], Batch [421/428], Loss: 2.5969
Epoch [2/9], Batch [422/428], Loss: 0.4234
Epoch [2/9], Batch [423/428], Loss: 3.7042
Epoch [2/9], Batch [424/428], Loss: 2.3400
Epoch [2/9], Batch [425/428], Loss: 2.0661
Epoch [2/9], Batch [426/428], Loss: 1.6214
Epoch [2/9], Batch [427/428], Loss: 3.8709
Epoch [2/9], Batch [428/428], Loss: 3.2654
Epoch [2] Training Time: 368.23 seconds
Epoch [2/9], Average Loss: 2.7413, Training Accuracy: 0.1589
Epoch [2], Validation Loss: 2.3612, Validation Accuracy: 0.2286
Epoch [2] Validation Time: 20.81 seconds
--------------------------------------------------
Epoch [3/9], Batch [1/428], Loss: 3.6449
Epoch [3/9], Batch [2/428], Loss: 3.7338
Epoch [3/9], Batch [3/428], Loss: 3.2784
Epoch [3/9], Batch [4/428], Loss: 4.3891
Epoch [3/9], Batch [5/428], Loss: 2.3167
Epoch [3/9], Batch [6/428], Loss: 3.1601
Epoch [3/9], Batch [7/428], Loss: 3.5475
Epoch [3/9], Batch [8/428], Loss: 1.6911
Epoch [3/9], Batch [9/428], Loss: 3.8885
Epoch [3/9], Batch [10/428], Loss: 3.0407
Epoch [3/9], Batch [11/428], Loss: 3.8478
Epoch [3/9], Batch [12/428], Loss: 2.2078
Epoch [3/9], Batch [13/428], Loss: 1.3347
Epoch [3/9], Batch [14/428], Loss: 3.8298
Epoch [3/9], Batch [15/428], Loss: 1.9049
Epoch [3/9], Batch [16/428], Loss: 3.8917
Epoch [3/9], Batch [17/428], Loss: 2.1211
Epoch [3/9], Batch [18/428], Loss: 2.0347
Epoch [3/9], Batch [19/428], Loss: 2.7719
Epoch [3/9], Batch [20/428], Loss: 1.4070
Epoch [3/9], Batch [21/428], Loss: 0.7805
Epoch [3/9], Batch [22/428], Loss: 1.5943
Epoch [3/9], Batch [23/428], Loss: 3.6633
Epoch [3/9], Batch [24/428], Loss: 3.8143
Epoch [3/9], Batch [25/428], Loss: 0.7217
Epoch [3/9], Batch [26/428], Loss: 3.6702
Epoch [3/9], Batch [27/428], Loss: 3.0176
Epoch [3/9], Batch [28/428], Loss: 2.7075
Epoch [3/9], Batch [29/428], Loss: 2.8698
Epoch [3/9], Batch [30/428], Loss: 3.2531
Epoch [3/9], Batch [31/428], Loss: 1.0740
Epoch [3/9], Batch [32/428], Loss: 1.6211
Epoch [3/9], Batch [33/428], Loss: 3.8583
Epoch [3/9], Batch [34/428], Loss: 1.9457
Epoch [3/9], Batch [35/428], Loss: 4.3854
Epoch [3/9], Batch [36/428], Loss: 1.2490
Epoch [3/9], Batch [37/428], Loss: 4.3524
Epoch [3/9], Batch [38/428], Loss: 4.1836
Epoch [3/9], Batch [39/428], Loss: 1.3462
Epoch [3/9], Batch [40/428], Loss: 2.7035
Epoch [3/9], Batch [41/428], Loss: 3.7266
Epoch [3/9], Batch [42/428], Loss: 3.4554
Epoch [3/9], Batch [43/428], Loss: 3.7172
Epoch [3/9], Batch [44/428], Loss: 1.6849
Epoch [3/9], Batch [45/428], Loss: 2.8662
Epoch [3/9], Batch [46/428], Loss: 2.7802
Epoch [3/9], Batch [47/428], Loss: 2.3351
Epoch [3/9], Batch [48/428], Loss: 3.2250
Epoch [3/9], Batch [49/428], Loss: 2.6932
Epoch [3/9], Batch [50/428], Loss: 3.4947
Epoch [3/9], Batch [51/428], Loss: 2.0683
Epoch [3/9], Batch [52/428], Loss: 3.4507
Epoch [3/9], Batch [53/428], Loss: 2.1507
Epoch [3/9], Batch [54/428], Loss: 2.8955
Epoch [3/9], Batch [55/428], Loss: 1.4547
Epoch [3/9], Batch [56/428], Loss: 4.2976
Epoch [3/9], Batch [57/428], Loss: 4.0412
Epoch [3/9], Batch [58/428], Loss: 2.4301
Epoch [3/9], Batch [59/428], Loss: 3.9719
Epoch [3/9], Batch [60/428], Loss: 3.6612
Epoch [3/9], Batch [61/428], Loss: 4.4497
Epoch [3/9], Batch [62/428], Loss: 2.0206
Epoch [3/9], Batch [63/428], Loss: 2.4240
Epoch [3/9], Batch [64/428], Loss: 0.7849
Epoch [3/9], Batch [65/428], Loss: 4.0405
Epoch [3/9], Batch [66/428], Loss: 2.5201
Epoch [3/9], Batch [67/428], Loss: 1.8837
Epoch [3/9], Batch [68/428], Loss: 1.8464
Epoch [3/9], Batch [69/428], Loss: 2.3363
Epoch [3/9], Batch [70/428], Loss: 4.0809
Epoch [3/9], Batch [71/428], Loss: 1.9768
Epoch [3/9], Batch [72/428], Loss: 1.8868
Epoch [3/9], Batch [73/428], Loss: 0.9896
Epoch [3/9], Batch [74/428], Loss: 1.0781
Epoch [3/9], Batch [75/428], Loss: 1.8126
Epoch [3/9], Batch [76/428], Loss: 3.6212
Epoch [3/9], Batch [77/428], Loss: 1.3490
Epoch [3/9], Batch [78/428], Loss: 1.4949
Epoch [3/9], Batch [79/428], Loss: 2.1795
Epoch [3/9], Batch [80/428], Loss: 2.0994
Epoch [3/9], Batch [81/428], Loss: 3.8342
Epoch [3/9], Batch [82/428], Loss: 2.3991
Epoch [3/9], Batch [83/428], Loss: 1.0429
Epoch [3/9], Batch [84/428], Loss: 1.0855
Epoch [3/9], Batch [85/428], Loss: 3.1899
Epoch [3/9], Batch [86/428], Loss: 3.3640
Epoch [3/9], Batch [87/428], Loss: 3.2858
Epoch [3/9], Batch [88/428], Loss: 1.7159
Epoch [3/9], Batch [89/428], Loss: 1.2020
Epoch [3/9], Batch [90/428], Loss: 0.6110
Epoch [3/9], Batch [91/428], Loss: 3.8978
Epoch [3/9], Batch [92/428], Loss: 3.2934
Epoch [3/9], Batch [93/428], Loss: 2.5381
Epoch [3/9], Batch [94/428], Loss: 3.7156
Epoch [3/9], Batch [95/428], Loss: 2.5677
Epoch [3/9], Batch [96/428], Loss: 3.3161
Epoch [3/9], Batch [97/428], Loss: 3.4628
Epoch [3/9], Batch [98/428], Loss: 2.4697
Epoch [3/9], Batch [99/428], Loss: 2.1503
Epoch [3/9], Batch [100/428], Loss: 2.6407
Epoch [3/9], Batch [101/428], Loss: 1.2474
Epoch [3/9], Batch [102/428], Loss: 1.9961
Epoch [3/9], Batch [103/428], Loss: 1.6294
Epoch [3/9], Batch [104/428], Loss: 0.6677
Epoch [3/9], Batch [105/428], Loss: 1.3239
Epoch [3/9], Batch [106/428], Loss: 1.4295
Epoch [3/9], Batch [107/428], Loss: 2.8605
Epoch [3/9], Batch [108/428], Loss: 0.5644
Epoch [3/9], Batch [109/428], Loss: 2.4218
Epoch [3/9], Batch [110/428], Loss: 3.3746
Epoch [3/9], Batch [111/428], Loss: 3.0865
Epoch [3/9], Batch [112/428], Loss: 0.7170
Epoch [3/9], Batch [113/428], Loss: 2.9523
Epoch [3/9], Batch [114/428], Loss: 2.0336
Epoch [3/9], Batch [115/428], Loss: 1.4515
Epoch [3/9], Batch [116/428], Loss: 0.9061
Epoch [3/9], Batch [117/428], Loss: 0.9305
Epoch [3/9], Batch [118/428], Loss: 3.2219
Epoch [3/9], Batch [119/428], Loss: 1.5717
Epoch [3/9], Batch [120/428], Loss: 2.2056
Epoch [3/9], Batch [121/428], Loss: 2.5588
Epoch [3/9], Batch [122/428], Loss: 1.3482
Epoch [3/9], Batch [123/428], Loss: 0.7796
Epoch [3/9], Batch [124/428], Loss: 3.5092
Epoch [3/9], Batch [125/428], Loss: 3.7563
Epoch [3/9], Batch [126/428], Loss: 2.2181
Epoch [3/9], Batch [127/428], Loss: 1.4474
Epoch [3/9], Batch [128/428], Loss: 2.7950
Epoch [3/9], Batch [129/428], Loss: 1.9388
Epoch [3/9], Batch [130/428], Loss: 3.2273
Epoch [3/9], Batch [131/428], Loss: 2.0811
Epoch [3/9], Batch [132/428], Loss: 0.7834
Epoch [3/9], Batch [133/428], Loss: 1.1457
Epoch [3/9], Batch [134/428], Loss: 3.1781
Epoch [3/9], Batch [135/428], Loss: 3.6907
Epoch [3/9], Batch [136/428], Loss: 2.8783
Epoch [3/9], Batch [137/428], Loss: 0.7321
Epoch [3/9], Batch [138/428], Loss: 3.5173
Epoch [3/9], Batch [139/428], Loss: 3.4993
Epoch [3/9], Batch [140/428], Loss: 1.5200
Epoch [3/9], Batch [141/428], Loss: 3.2854
Epoch [3/9], Batch [142/428], Loss: 2.8932
Epoch [3/9], Batch [143/428], Loss: 2.6808
Epoch [3/9], Batch [144/428], Loss: 2.0571
Epoch [3/9], Batch [145/428], Loss: 1.5404
Epoch [3/9], Batch [146/428], Loss: 1.5882
Epoch [3/9], Batch [147/428], Loss: 0.7361
Epoch [3/9], Batch [148/428], Loss: 0.7227
Epoch [3/9], Batch [149/428], Loss: 3.4944
Epoch [3/9], Batch [150/428], Loss: 3.1948
Epoch [3/9], Batch [151/428], Loss: 1.0995
Epoch [3/9], Batch [152/428], Loss: 2.8685
Epoch [3/9], Batch [153/428], Loss: 1.4478
Epoch [3/9], Batch [154/428], Loss: 2.0212
Epoch [3/9], Batch [155/428], Loss: 1.7877
Epoch [3/9], Batch [156/428], Loss: 3.1065
Epoch [3/9], Batch [157/428], Loss: 4.5801
Epoch [3/9], Batch [158/428], Loss: 0.9758
Epoch [3/9], Batch [159/428], Loss: 2.7907
Epoch [3/9], Batch [160/428], Loss: 2.3976
Epoch [3/9], Batch [161/428], Loss: 0.7533
Epoch [3/9], Batch [162/428], Loss: 2.9200
Epoch [3/9], Batch [163/428], Loss: 1.1614
Epoch [3/9], Batch [164/428], Loss: 0.7157
Epoch [3/9], Batch [165/428], Loss: 3.6204
Epoch [3/9], Batch [166/428], Loss: 4.2266
Epoch [3/9], Batch [167/428], Loss: 0.8279
Epoch [3/9], Batch [168/428], Loss: 3.2778
Epoch [3/9], Batch [169/428], Loss: 0.8185
Epoch [3/9], Batch [170/428], Loss: 3.3513
Epoch [3/9], Batch [171/428], Loss: 3.2258
Epoch [3/9], Batch [172/428], Loss: 2.2870
Epoch [3/9], Batch [173/428], Loss: 1.7028
Epoch [3/9], Batch [174/428], Loss: 4.0028
Epoch [3/9], Batch [175/428], Loss: 1.4706
Epoch [3/9], Batch [176/428], Loss: 1.4524
Epoch [3/9], Batch [177/428], Loss: 2.6424
Epoch [3/9], Batch [178/428], Loss: 1.5544
Epoch [3/9], Batch [179/428], Loss: 2.0362
Epoch [3/9], Batch [180/428], Loss: 2.1198
Epoch [3/9], Batch [181/428], Loss: 1.2507
Epoch [3/9], Batch [182/428], Loss: 0.8415
Epoch [3/9], Batch [183/428], Loss: 1.1356
Epoch [3/9], Batch [184/428], Loss: 2.7747
Epoch [3/9], Batch [185/428], Loss: 3.3329
Epoch [3/9], Batch [186/428], Loss: 2.7599
Epoch [3/9], Batch [187/428], Loss: 2.0612
Epoch [3/9], Batch [188/428], Loss: 2.1322
Epoch [3/9], Batch [189/428], Loss: 3.2080
Epoch [3/9], Batch [190/428], Loss: 1.1924
Epoch [3/9], Batch [191/428], Loss: 4.2469
Epoch [3/9], Batch [192/428], Loss: 3.1488
Epoch [3/9], Batch [193/428], Loss: 0.9447
Epoch [3/9], Batch [194/428], Loss: 3.3634
Epoch [3/9], Batch [195/428], Loss: 1.8716
Epoch [3/9], Batch [196/428], Loss: 2.0963
Epoch [3/9], Batch [197/428], Loss: 1.8249
Epoch [3/9], Batch [198/428], Loss: 2.0012
Epoch [3/9], Batch [199/428], Loss: 1.7116
Epoch [3/9], Batch [200/428], Loss: 0.9353
Epoch [3/9], Batch [201/428], Loss: 1.2903
Epoch [3/9], Batch [202/428], Loss: 3.5673
Epoch [3/9], Batch [203/428], Loss: 0.3879
Epoch [3/9], Batch [204/428], Loss: 2.5234
Epoch [3/9], Batch [205/428], Loss: 3.6774
Epoch [3/9], Batch [206/428], Loss: 1.2168
Epoch [3/9], Batch [207/428], Loss: 0.4953
Epoch [3/9], Batch [208/428], Loss: 0.8703
Epoch [3/9], Batch [209/428], Loss: 3.3272
Epoch [3/9], Batch [210/428], Loss: 1.9608
Epoch [3/9], Batch [211/428], Loss: 1.5134
Epoch [3/9], Batch [212/428], Loss: 1.7753
Epoch [3/9], Batch [213/428], Loss: 1.2435
Epoch [3/9], Batch [214/428], Loss: 1.8629
Epoch [3/9], Batch [215/428], Loss: 3.7046
Epoch [3/9], Batch [216/428], Loss: 3.1695
Epoch [3/9], Batch [217/428], Loss: 2.1712
Epoch [3/9], Batch [218/428], Loss: 4.1652
Epoch [3/9], Batch [219/428], Loss: 3.0000
Epoch [3/9], Batch [220/428], Loss: 3.5772
Epoch [3/9], Batch [221/428], Loss: 2.1797
Epoch [3/9], Batch [222/428], Loss: 2.5190
Epoch [3/9], Batch [223/428], Loss: 3.1413
Epoch [3/9], Batch [224/428], Loss: 2.6505
Epoch [3/9], Batch [225/428], Loss: 0.7921
Epoch [3/9], Batch [226/428], Loss: 1.7232
Epoch [3/9], Batch [227/428], Loss: 2.8791
Epoch [3/9], Batch [228/428], Loss: 2.9626
Epoch [3/9], Batch [229/428], Loss: 3.0213
Epoch [3/9], Batch [230/428], Loss: 3.9894
Epoch [3/9], Batch [231/428], Loss: 1.3648
Epoch [3/9], Batch [232/428], Loss: 1.1935
Epoch [3/9], Batch [233/428], Loss: 3.0741
Epoch [3/9], Batch [234/428], Loss: 1.8473
Epoch [3/9], Batch [235/428], Loss: 2.9243
Epoch [3/9], Batch [236/428], Loss: 0.8215
Epoch [3/9], Batch [237/428], Loss: 2.4100
Epoch [3/9], Batch [238/428], Loss: 2.7978
Epoch [3/9], Batch [239/428], Loss: 1.2036
Epoch [3/9], Batch [240/428], Loss: 0.7403
Epoch [3/9], Batch [241/428], Loss: 2.0304
Epoch [3/9], Batch [242/428], Loss: 2.1647
Epoch [3/9], Batch [243/428], Loss: 2.5872
Epoch [3/9], Batch [244/428], Loss: 2.6062
Epoch [3/9], Batch [245/428], Loss: 1.1252
Epoch [3/9], Batch [246/428], Loss: 0.9444
Epoch [3/9], Batch [247/428], Loss: 2.1020
Epoch [3/9], Batch [248/428], Loss: 2.9947
Epoch [3/9], Batch [249/428], Loss: 2.8198
Epoch [3/9], Batch [250/428], Loss: 1.4636
Epoch [3/9], Batch [251/428], Loss: 4.1817
Epoch [3/9], Batch [252/428], Loss: 2.7509
Epoch [3/9], Batch [253/428], Loss: 2.7415
Epoch [3/9], Batch [254/428], Loss: 2.0318
Epoch [3/9], Batch [255/428], Loss: 2.0454
Epoch [3/9], Batch [256/428], Loss: 1.1653
Epoch [3/9], Batch [257/428], Loss: 1.1321
Epoch [3/9], Batch [258/428], Loss: 2.6542
Epoch [3/9], Batch [259/428], Loss: 2.5905
Epoch [3/9], Batch [260/428], Loss: 2.0172
Epoch [3/9], Batch [261/428], Loss: 2.6047
Epoch [3/9], Batch [262/428], Loss: 1.3732
Epoch [3/9], Batch [263/428], Loss: 2.4982
Epoch [3/9], Batch [264/428], Loss: 1.7063
Epoch [3/9], Batch [265/428], Loss: 2.5093
Epoch [3/9], Batch [266/428], Loss: 2.6539
Epoch [3/9], Batch [267/428], Loss: 1.5605
Epoch [3/9], Batch [268/428], Loss: 1.1248
Epoch [3/9], Batch [269/428], Loss: 2.5772
Epoch [3/9], Batch [270/428], Loss: 3.0977
Epoch [3/9], Batch [271/428], Loss: 2.7680
Epoch [3/9], Batch [272/428], Loss: 2.2056
Epoch [3/9], Batch [273/428], Loss: 1.7876
Epoch [3/9], Batch [274/428], Loss: 2.6124
Epoch [3/9], Batch [275/428], Loss: 2.0631
Epoch [3/9], Batch [276/428], Loss: 3.3802
Epoch [3/9], Batch [277/428], Loss: 2.0599
Epoch [3/9], Batch [278/428], Loss: 2.1262
Epoch [3/9], Batch [279/428], Loss: 2.7094
Epoch [3/9], Batch [280/428], Loss: 0.6938
Epoch [3/9], Batch [281/428], Loss: 3.1283
Epoch [3/9], Batch [282/428], Loss: 2.5637
Epoch [3/9], Batch [283/428], Loss: 3.1783
Epoch [3/9], Batch [284/428], Loss: 2.0175
Epoch [3/9], Batch [285/428], Loss: 1.1315
Epoch [3/9], Batch [286/428], Loss: 1.0750
Epoch [3/9], Batch [287/428], Loss: 1.1769
Epoch [3/9], Batch [288/428], Loss: 0.8847
Epoch [3/9], Batch [289/428], Loss: 1.6314
Epoch [3/9], Batch [290/428], Loss: 4.2768
Epoch [3/9], Batch [291/428], Loss: 0.7217
Epoch [3/9], Batch [292/428], Loss: 3.2564
Epoch [3/9], Batch [293/428], Loss: 2.9490
Epoch [3/9], Batch [294/428], Loss: 2.5193
Epoch [3/9], Batch [295/428], Loss: 1.3166
Epoch [3/9], Batch [296/428], Loss: 1.1661
Epoch [3/9], Batch [297/428], Loss: 2.0786
Epoch [3/9], Batch [298/428], Loss: 3.2814
Epoch [3/9], Batch [299/428], Loss: 2.7333
Epoch [3/9], Batch [300/428], Loss: 2.6762
Epoch [3/9], Batch [301/428], Loss: 2.4514
Epoch [3/9], Batch [302/428], Loss: 3.0593
Epoch [3/9], Batch [303/428], Loss: 3.3523
Epoch [3/9], Batch [304/428], Loss: 1.4868
Epoch [3/9], Batch [305/428], Loss: 3.7943
Epoch [3/9], Batch [306/428], Loss: 1.0330
Epoch [3/9], Batch [307/428], Loss: 0.8873
Epoch [3/9], Batch [308/428], Loss: 3.2475
Epoch [3/9], Batch [309/428], Loss: 1.7780
Epoch [3/9], Batch [310/428], Loss: 2.2410
Epoch [3/9], Batch [311/428], Loss: 1.5620
Epoch [3/9], Batch [312/428], Loss: 2.0999
Epoch [3/9], Batch [313/428], Loss: 1.4496
Epoch [3/9], Batch [314/428], Loss: 0.5252
Epoch [3/9], Batch [315/428], Loss: 2.3038
Epoch [3/9], Batch [316/428], Loss: 1.3181
Epoch [3/9], Batch [317/428], Loss: 2.8036
Epoch [3/9], Batch [318/428], Loss: 0.7537
Epoch [3/9], Batch [319/428], Loss: 0.9848
Epoch [3/9], Batch [320/428], Loss: 1.3532
Epoch [3/9], Batch [321/428], Loss: 3.2585
Epoch [3/9], Batch [322/428], Loss: 3.0918
Epoch [3/9], Batch [323/428], Loss: 1.8165
Epoch [3/9], Batch [324/428], Loss: 2.4094
Epoch [3/9], Batch [325/428], Loss: 0.5209
Epoch [3/9], Batch [326/428], Loss: 2.8456
Epoch [3/9], Batch [327/428], Loss: 1.9300
Epoch [3/9], Batch [328/428], Loss: 2.6058
Epoch [3/9], Batch [329/428], Loss: 2.4112
Epoch [3/9], Batch [330/428], Loss: 0.6992
Epoch [3/9], Batch [331/428], Loss: 2.1133
Epoch [3/9], Batch [332/428], Loss: 2.6302
Epoch [3/9], Batch [333/428], Loss: 3.2309
Epoch [3/9], Batch [334/428], Loss: 3.4685
Epoch [3/9], Batch [335/428], Loss: 0.6398
Epoch [3/9], Batch [336/428], Loss: 1.7485
Epoch [3/9], Batch [337/428], Loss: 2.0634
Epoch [3/9], Batch [338/428], Loss: 2.4095
Epoch [3/9], Batch [339/428], Loss: 2.8691
Epoch [3/9], Batch [340/428], Loss: 3.2130
Epoch [3/9], Batch [341/428], Loss: 3.3434
Epoch [3/9], Batch [342/428], Loss: 2.8355
Epoch [3/9], Batch [343/428], Loss: 1.0484
Epoch [3/9], Batch [344/428], Loss: 2.2005
Epoch [3/9], Batch [345/428], Loss: 2.8215
Epoch [3/9], Batch [346/428], Loss: 1.4526
Epoch [3/9], Batch [347/428], Loss: 3.7044
Epoch [3/9], Batch [348/428], Loss: 1.6628
Epoch [3/9], Batch [349/428], Loss: 1.0207
Epoch [3/9], Batch [350/428], Loss: 1.7890
Epoch [3/9], Batch [351/428], Loss: 1.9527
Epoch [3/9], Batch [352/428], Loss: 3.0765
Epoch [3/9], Batch [353/428], Loss: 1.4781
Epoch [3/9], Batch [354/428], Loss: 2.5818
Epoch [3/9], Batch [355/428], Loss: 1.4620
Epoch [3/9], Batch [356/428], Loss: 3.1536
Epoch [3/9], Batch [357/428], Loss: 3.7402
Epoch [3/9], Batch [358/428], Loss: 2.0511
Epoch [3/9], Batch [359/428], Loss: 3.6384
Epoch [3/9], Batch [360/428], Loss: 2.4276
Epoch [3/9], Batch [361/428], Loss: 2.1030
Epoch [3/9], Batch [362/428], Loss: 1.0591
Epoch [3/9], Batch [363/428], Loss: 3.4316
Epoch [3/9], Batch [364/428], Loss: 0.8738
Epoch [3/9], Batch [365/428], Loss: 3.5301
Epoch [3/9], Batch [366/428], Loss: 2.6374
Epoch [3/9], Batch [367/428], Loss: 2.2483
Epoch [3/9], Batch [368/428], Loss: 3.2285
Epoch [3/9], Batch [369/428], Loss: 2.7294
Epoch [3/9], Batch [370/428], Loss: 1.5426
Epoch [3/9], Batch [371/428], Loss: 2.2856
Epoch [3/9], Batch [372/428], Loss: 1.7020
Epoch [3/9], Batch [373/428], Loss: 4.3116
Epoch [3/9], Batch [374/428], Loss: 0.5761
Epoch [3/9], Batch [375/428], Loss: 2.5707
Epoch [3/9], Batch [376/428], Loss: 3.0653
Epoch [3/9], Batch [377/428], Loss: 0.7131
Epoch [3/9], Batch [378/428], Loss: 1.1771
Epoch [3/9], Batch [379/428], Loss: 3.2782
Epoch [3/9], Batch [380/428], Loss: 0.9291
Epoch [3/9], Batch [381/428], Loss: 1.6055
Epoch [3/9], Batch [382/428], Loss: 2.4002
Epoch [3/9], Batch [383/428], Loss: 3.0579
Epoch [3/9], Batch [384/428], Loss: 0.6152
Epoch [3/9], Batch [385/428], Loss: 1.9575
Epoch [3/9], Batch [386/428], Loss: 1.5818
Epoch [3/9], Batch [387/428], Loss: 1.7916
Epoch [3/9], Batch [388/428], Loss: 1.8682
Epoch [3/9], Batch [389/428], Loss: 0.9972
Epoch [3/9], Batch [390/428], Loss: 2.2384
Epoch [3/9], Batch [391/428], Loss: 1.6515
Epoch [3/9], Batch [392/428], Loss: 1.4178
Epoch [3/9], Batch [393/428], Loss: 2.0888
Epoch [3/9], Batch [394/428], Loss: 1.2694
Epoch [3/9], Batch [395/428], Loss: 1.8573
Epoch [3/9], Batch [396/428], Loss: 3.4965
Epoch [3/9], Batch [397/428], Loss: 3.1206
Epoch [3/9], Batch [398/428], Loss: 0.8681
Epoch [3/9], Batch [399/428], Loss: 1.7642
Epoch [3/9], Batch [400/428], Loss: 2.1783
Epoch [3/9], Batch [401/428], Loss: 1.6848
Epoch [3/9], Batch [402/428], Loss: 2.5438
Epoch [3/9], Batch [403/428], Loss: 1.4593
Epoch [3/9], Batch [404/428], Loss: 1.7154
Epoch [3/9], Batch [405/428], Loss: 3.2024
Epoch [3/9], Batch [406/428], Loss: 3.1152
Epoch [3/9], Batch [407/428], Loss: 1.5296
Epoch [3/9], Batch [408/428], Loss: 0.6024
Epoch [3/9], Batch [409/428], Loss: 1.2715
Epoch [3/9], Batch [410/428], Loss: 1.8184
Epoch [3/9], Batch [411/428], Loss: 2.6800
Epoch [3/9], Batch [412/428], Loss: 3.5582
Epoch [3/9], Batch [413/428], Loss: 0.6529
Epoch [3/9], Batch [414/428], Loss: 3.3930
Epoch [3/9], Batch [415/428], Loss: 2.7250
Epoch [3/9], Batch [416/428], Loss: 2.9378
Epoch [3/9], Batch [417/428], Loss: 2.9415
Epoch [3/9], Batch [418/428], Loss: 0.5961
Epoch [3/9], Batch [419/428], Loss: 3.8517
Epoch [3/9], Batch [420/428], Loss: 2.8723
Epoch [3/9], Batch [421/428], Loss: 2.1270
Epoch [3/9], Batch [422/428], Loss: 2.3441
Epoch [3/9], Batch [423/428], Loss: 1.7479
Epoch [3/9], Batch [424/428], Loss: 2.9644
Epoch [3/9], Batch [425/428], Loss: 0.9567
Epoch [3/9], Batch [426/428], Loss: 1.0861
Epoch [3/9], Batch [427/428], Loss: 1.8214
Epoch [3/9], Batch [428/428], Loss: 2.5524
Epoch [3] Training Time: 372.96 seconds
Epoch [3/9], Average Loss: 2.2888, Training Accuracy: 0.2126
Epoch [3], Validation Loss: 2.0740, Validation Accuracy: 0.2653
Epoch [3] Validation Time: 21.21 seconds
--------------------------------------------------
Epoch [4/9], Batch [1/428], Loss: 0.7620
Epoch [4/9], Batch [2/428], Loss: 3.0883
Epoch [4/9], Batch [3/428], Loss: 0.8690
Epoch [4/9], Batch [4/428], Loss: 2.4910
Epoch [4/9], Batch [5/428], Loss: 4.0640
Epoch [4/9], Batch [6/428], Loss: 1.9456
Epoch [4/9], Batch [7/428], Loss: 2.3165
Epoch [4/9], Batch [8/428], Loss: 1.8822
Epoch [4/9], Batch [9/428], Loss: 1.9560
Epoch [4/9], Batch [10/428], Loss: 1.8309
Epoch [4/9], Batch [11/428], Loss: 1.7275
Epoch [4/9], Batch [12/428], Loss: 1.2777
Epoch [4/9], Batch [13/428], Loss: 2.0722
Epoch [4/9], Batch [14/428], Loss: 3.2029
Epoch [4/9], Batch [15/428], Loss: 2.4285
Epoch [4/9], Batch [16/428], Loss: 4.3253
Epoch [4/9], Batch [17/428], Loss: 3.4671
Epoch [4/9], Batch [18/428], Loss: 1.6459
Epoch [4/9], Batch [19/428], Loss: 1.9088
Epoch [4/9], Batch [20/428], Loss: 1.8415
Epoch [4/9], Batch [21/428], Loss: 3.3157
Epoch [4/9], Batch [22/428], Loss: 1.4826
Epoch [4/9], Batch [23/428], Loss: 2.0314
Epoch [4/9], Batch [24/428], Loss: 3.0590
Epoch [4/9], Batch [25/428], Loss: 2.0822
Epoch [4/9], Batch [26/428], Loss: 1.7839
Epoch [4/9], Batch [27/428], Loss: 1.0982
Epoch [4/9], Batch [28/428], Loss: 1.2866
Epoch [4/9], Batch [29/428], Loss: 3.6871
Epoch [4/9], Batch [30/428], Loss: 2.9382
Epoch [4/9], Batch [31/428], Loss: 1.5201
Epoch [4/9], Batch [32/428], Loss: 0.9085
Epoch [4/9], Batch [33/428], Loss: 1.9529
Epoch [4/9], Batch [34/428], Loss: 2.5375
Epoch [4/9], Batch [35/428], Loss: 1.6532
Epoch [4/9], Batch [36/428], Loss: 1.7662
Epoch [4/9], Batch [37/428], Loss: 2.4327
Epoch [4/9], Batch [38/428], Loss: 2.2437
Epoch [4/9], Batch [39/428], Loss: 2.8373
Epoch [4/9], Batch [40/428], Loss: 2.6142
Epoch [4/9], Batch [41/428], Loss: 1.2928
Epoch [4/9], Batch [42/428], Loss: 3.2711
Epoch [4/9], Batch [43/428], Loss: 3.0103
Epoch [4/9], Batch [44/428], Loss: 2.2922
Epoch [4/9], Batch [45/428], Loss: 3.0518
Epoch [4/9], Batch [46/428], Loss: 1.0014
Epoch [4/9], Batch [47/428], Loss: 2.6715
Epoch [4/9], Batch [48/428], Loss: 0.8892
Epoch [4/9], Batch [49/428], Loss: 3.1502
Epoch [4/9], Batch [50/428], Loss: 1.1131
Epoch [4/9], Batch [51/428], Loss: 2.3654
Epoch [4/9], Batch [52/428], Loss: 1.9685
Epoch [4/9], Batch [53/428], Loss: 2.5375
Epoch [4/9], Batch [54/428], Loss: 2.6307
Epoch [4/9], Batch [55/428], Loss: 1.1076
Epoch [4/9], Batch [56/428], Loss: 2.8095
Epoch [4/9], Batch [57/428], Loss: 2.7572
Epoch [4/9], Batch [58/428], Loss: 2.0736
Epoch [4/9], Batch [59/428], Loss: 2.3913
Epoch [4/9], Batch [60/428], Loss: 2.4469
Epoch [4/9], Batch [61/428], Loss: 2.6105
Epoch [4/9], Batch [62/428], Loss: 1.4499
Epoch [4/9], Batch [63/428], Loss: 1.3402
Epoch [4/9], Batch [64/428], Loss: 1.7543
Epoch [4/9], Batch [65/428], Loss: 0.7156
Epoch [4/9], Batch [66/428], Loss: 2.8901
Epoch [4/9], Batch [67/428], Loss: 1.9261
Epoch [4/9], Batch [68/428], Loss: 3.0018
Epoch [4/9], Batch [69/428], Loss: 3.7877
Epoch [4/9], Batch [70/428], Loss: 2.0619
Epoch [4/9], Batch [71/428], Loss: 2.3000
Epoch [4/9], Batch [72/428], Loss: 1.4649
Epoch [4/9], Batch [73/428], Loss: 1.8802
Epoch [4/9], Batch [74/428], Loss: 2.8611
Epoch [4/9], Batch [75/428], Loss: 3.6715
Epoch [4/9], Batch [76/428], Loss: 1.3679
Epoch [4/9], Batch [77/428], Loss: 2.4857
Epoch [4/9], Batch [78/428], Loss: 2.4258
Epoch [4/9], Batch [79/428], Loss: 2.6838
Epoch [4/9], Batch [80/428], Loss: 1.8327
Epoch [4/9], Batch [81/428], Loss: 1.8058
Epoch [4/9], Batch [82/428], Loss: 1.7914
Epoch [4/9], Batch [83/428], Loss: 0.6591
Epoch [4/9], Batch [84/428], Loss: 1.2241
Epoch [4/9], Batch [85/428], Loss: 2.9309
Epoch [4/9], Batch [86/428], Loss: 3.2600
Epoch [4/9], Batch [87/428], Loss: 3.3546
Epoch [4/9], Batch [88/428], Loss: 0.7926
Epoch [4/9], Batch [89/428], Loss: 1.9032
Epoch [4/9], Batch [90/428], Loss: 2.0114
Epoch [4/9], Batch [91/428], Loss: 3.4465
Epoch [4/9], Batch [92/428], Loss: 2.6387
Epoch [4/9], Batch [93/428], Loss: 1.4104
Epoch [4/9], Batch [94/428], Loss: 2.5078
Epoch [4/9], Batch [95/428], Loss: 1.7146
Epoch [4/9], Batch [96/428], Loss: 3.2431
Epoch [4/9], Batch [97/428], Loss: 1.1390
Epoch [4/9], Batch [98/428], Loss: 3.3187
Epoch [4/9], Batch [99/428], Loss: 2.1176
Epoch [4/9], Batch [100/428], Loss: 1.1250
Epoch [4/9], Batch [101/428], Loss: 2.5632
Epoch [4/9], Batch [102/428], Loss: 3.1165
Epoch [4/9], Batch [103/428], Loss: 3.9597
Epoch [4/9], Batch [104/428], Loss: 1.1050
Epoch [4/9], Batch [105/428], Loss: 1.8462
Epoch [4/9], Batch [106/428], Loss: 2.7623
Epoch [4/9], Batch [107/428], Loss: 0.8573
Epoch [4/9], Batch [108/428], Loss: 3.2571
Epoch [4/9], Batch [109/428], Loss: 2.3961
Epoch [4/9], Batch [110/428], Loss: 0.5728
Epoch [4/9], Batch [111/428], Loss: 2.2020
Epoch [4/9], Batch [112/428], Loss: 2.2293
Epoch [4/9], Batch [113/428], Loss: 2.8866
Epoch [4/9], Batch [114/428], Loss: 2.8928
Epoch [4/9], Batch [115/428], Loss: 1.7134
Epoch [4/9], Batch [116/428], Loss: 4.0597
Epoch [4/9], Batch [117/428], Loss: 2.3752
Epoch [4/9], Batch [118/428], Loss: 2.4350
Epoch [4/9], Batch [119/428], Loss: 1.3536
Epoch [4/9], Batch [120/428], Loss: 0.8853
Epoch [4/9], Batch [121/428], Loss: 2.2083
Epoch [4/9], Batch [122/428], Loss: 1.9572
Epoch [4/9], Batch [123/428], Loss: 1.4247
Epoch [4/9], Batch [124/428], Loss: 2.0984
Epoch [4/9], Batch [125/428], Loss: 2.8152
Epoch [4/9], Batch [126/428], Loss: 2.9219
Epoch [4/9], Batch [127/428], Loss: 1.7163
Epoch [4/9], Batch [128/428], Loss: 0.9244
Epoch [4/9], Batch [129/428], Loss: 2.7520
Epoch [4/9], Batch [130/428], Loss: 1.5919
Epoch [4/9], Batch [131/428], Loss: 2.9177
Epoch [4/9], Batch [132/428], Loss: 0.7578
Epoch [4/9], Batch [133/428], Loss: 1.7375
Epoch [4/9], Batch [134/428], Loss: 1.2261
Epoch [4/9], Batch [135/428], Loss: 2.4317
Epoch [4/9], Batch [136/428], Loss: 3.1016
Epoch [4/9], Batch [137/428], Loss: 2.0723
Epoch [4/9], Batch [138/428], Loss: 2.2436
Epoch [4/9], Batch [139/428], Loss: 2.1286
Epoch [4/9], Batch [140/428], Loss: 2.5436
Epoch [4/9], Batch [141/428], Loss: 2.4644
Epoch [4/9], Batch [142/428], Loss: 1.4381
Epoch [4/9], Batch [143/428], Loss: 1.3571
Epoch [4/9], Batch [144/428], Loss: 2.3235
Epoch [4/9], Batch [145/428], Loss: 2.1419
Epoch [4/9], Batch [146/428], Loss: 2.3717
Epoch [4/9], Batch [147/428], Loss: 3.3721
Epoch [4/9], Batch [148/428], Loss: 2.0106
Epoch [4/9], Batch [149/428], Loss: 2.2020
Epoch [4/9], Batch [150/428], Loss: 0.6321
Epoch [4/9], Batch [151/428], Loss: 1.1669
Epoch [4/9], Batch [152/428], Loss: 2.3372
Epoch [4/9], Batch [153/428], Loss: 3.0161
Epoch [4/9], Batch [154/428], Loss: 2.2785
Epoch [4/9], Batch [155/428], Loss: 3.3244
Epoch [4/9], Batch [156/428], Loss: 1.5174
Epoch [4/9], Batch [157/428], Loss: 2.8748
Epoch [4/9], Batch [158/428], Loss: 1.0791
Epoch [4/9], Batch [159/428], Loss: 1.5808
Epoch [4/9], Batch [160/428], Loss: 2.7596
Epoch [4/9], Batch [161/428], Loss: 2.7235
Epoch [4/9], Batch [162/428], Loss: 1.8448
Epoch [4/9], Batch [163/428], Loss: 2.8523
Epoch [4/9], Batch [164/428], Loss: 1.7096
Epoch [4/9], Batch [165/428], Loss: 1.8982
Epoch [4/9], Batch [166/428], Loss: 3.8618
Epoch [4/9], Batch [167/428], Loss: 1.9902
Epoch [4/9], Batch [168/428], Loss: 3.6065
Epoch [4/9], Batch [169/428], Loss: 2.8760
Epoch [4/9], Batch [170/428], Loss: 1.9243
Epoch [4/9], Batch [171/428], Loss: 0.9224
Epoch [4/9], Batch [172/428], Loss: 1.4079
Epoch [4/9], Batch [173/428], Loss: 2.4206
Epoch [4/9], Batch [174/428], Loss: 3.8707
Epoch [4/9], Batch [175/428], Loss: 2.3737
Epoch [4/9], Batch [176/428], Loss: 1.0167
Epoch [4/9], Batch [177/428], Loss: 2.7757
Epoch [4/9], Batch [178/428], Loss: 2.2268
Epoch [4/9], Batch [179/428], Loss: 2.3511
Epoch [4/9], Batch [180/428], Loss: 2.5046
Epoch [4/9], Batch [181/428], Loss: 1.1616
Epoch [4/9], Batch [182/428], Loss: 1.6092
Epoch [4/9], Batch [183/428], Loss: 1.2012
Epoch [4/9], Batch [184/428], Loss: 1.5890
Epoch [4/9], Batch [185/428], Loss: 1.3849
Epoch [4/9], Batch [186/428], Loss: 2.5233
Epoch [4/9], Batch [187/428], Loss: 2.4858
Epoch [4/9], Batch [188/428], Loss: 3.8338
Epoch [4/9], Batch [189/428], Loss: 2.2835
Epoch [4/9], Batch [190/428], Loss: 1.4663
Epoch [4/9], Batch [191/428], Loss: 2.8435
Epoch [4/9], Batch [192/428], Loss: 2.0077
Epoch [4/9], Batch [193/428], Loss: 1.0052
Epoch [4/9], Batch [194/428], Loss: 1.3860
Epoch [4/9], Batch [195/428], Loss: 2.4684
Epoch [4/9], Batch [196/428], Loss: 0.4931
Epoch [4/9], Batch [197/428], Loss: 1.4170
Epoch [4/9], Batch [198/428], Loss: 1.4652
Epoch [4/9], Batch [199/428], Loss: 2.2268
Epoch [4/9], Batch [200/428], Loss: 1.5948
Epoch [4/9], Batch [201/428], Loss: 1.9059
Epoch [4/9], Batch [202/428], Loss: 2.2979
Epoch [4/9], Batch [203/428], Loss: 0.5891
Epoch [4/9], Batch [204/428], Loss: 0.5195
Epoch [4/9], Batch [205/428], Loss: 2.5089
Epoch [4/9], Batch [206/428], Loss: 1.1366
Epoch [4/9], Batch [207/428], Loss: 2.2313
Epoch [4/9], Batch [208/428], Loss: 2.6886
Epoch [4/9], Batch [209/428], Loss: 0.5954
Epoch [4/9], Batch [210/428], Loss: 2.4386
Epoch [4/9], Batch [211/428], Loss: 2.0357
Epoch [4/9], Batch [212/428], Loss: 2.3817
Epoch [4/9], Batch [213/428], Loss: 1.2033
Epoch [4/9], Batch [214/428], Loss: 2.4667
Epoch [4/9], Batch [215/428], Loss: 3.6469
Epoch [4/9], Batch [216/428], Loss: 2.3619
Epoch [4/9], Batch [217/428], Loss: 3.3540
Epoch [4/9], Batch [218/428], Loss: 1.2252
Epoch [4/9], Batch [219/428], Loss: 1.2085
Epoch [4/9], Batch [220/428], Loss: 3.2230
Epoch [4/9], Batch [221/428], Loss: 1.1036
Epoch [4/9], Batch [222/428], Loss: 1.4378
Epoch [4/9], Batch [223/428], Loss: 1.4510
Epoch [4/9], Batch [224/428], Loss: 1.4982
Epoch [4/9], Batch [225/428], Loss: 2.1428
Epoch [4/9], Batch [226/428], Loss: 0.8668
Epoch [4/9], Batch [227/428], Loss: 0.7809
Epoch [4/9], Batch [228/428], Loss: 2.4014
Epoch [4/9], Batch [229/428], Loss: 2.0908
Epoch [4/9], Batch [230/428], Loss: 0.7607
Epoch [4/9], Batch [231/428], Loss: 0.9899
Epoch [4/9], Batch [232/428], Loss: 0.5057
Epoch [4/9], Batch [233/428], Loss: 2.9116
Epoch [4/9], Batch [234/428], Loss: 1.6899
Epoch [4/9], Batch [235/428], Loss: 2.7363
Epoch [4/9], Batch [236/428], Loss: 3.1792
Epoch [4/9], Batch [237/428], Loss: 2.5421
Epoch [4/9], Batch [238/428], Loss: 1.1765
Epoch [4/9], Batch [239/428], Loss: 1.0170
Epoch [4/9], Batch [240/428], Loss: 3.5530
Epoch [4/9], Batch [241/428], Loss: 1.9845
Epoch [4/9], Batch [242/428], Loss: 2.2530
Epoch [4/9], Batch [243/428], Loss: 2.5191
Epoch [4/9], Batch [244/428], Loss: 3.6950
Epoch [4/9], Batch [245/428], Loss: 2.1385
Epoch [4/9], Batch [246/428], Loss: 1.2280
Epoch [4/9], Batch [247/428], Loss: 0.8368
Epoch [4/9], Batch [248/428], Loss: 1.8752
Epoch [4/9], Batch [249/428], Loss: 1.7107
Epoch [4/9], Batch [250/428], Loss: 2.8710
Epoch [4/9], Batch [251/428], Loss: 1.8182
Epoch [4/9], Batch [252/428], Loss: 2.4863
Epoch [4/9], Batch [253/428], Loss: 2.6524
Epoch [4/9], Batch [254/428], Loss: 0.8689
Epoch [4/9], Batch [255/428], Loss: 0.8756
Epoch [4/9], Batch [256/428], Loss: 0.8904
Epoch [4/9], Batch [257/428], Loss: 1.2675
Epoch [4/9], Batch [258/428], Loss: 2.2302
Epoch [4/9], Batch [259/428], Loss: 0.8123
Epoch [4/9], Batch [260/428], Loss: 2.3733
Epoch [4/9], Batch [261/428], Loss: 2.8778
Epoch [4/9], Batch [262/428], Loss: 2.4135
Epoch [4/9], Batch [263/428], Loss: 2.4019
Epoch [4/9], Batch [264/428], Loss: 2.2030
Epoch [4/9], Batch [265/428], Loss: 1.0800
Epoch [4/9], Batch [266/428], Loss: 2.0646
Epoch [4/9], Batch [267/428], Loss: 2.6879
Epoch [4/9], Batch [268/428], Loss: 1.4263
Epoch [4/9], Batch [269/428], Loss: 2.6226
Epoch [4/9], Batch [270/428], Loss: 0.5236
Epoch [4/9], Batch [271/428], Loss: 3.1775
Epoch [4/9], Batch [272/428], Loss: 1.5093
Epoch [4/9], Batch [273/428], Loss: 3.5924
Epoch [4/9], Batch [274/428], Loss: 2.4754
Epoch [4/9], Batch [275/428], Loss: 1.8564
Epoch [4/9], Batch [276/428], Loss: 1.9592
Epoch [4/9], Batch [277/428], Loss: 1.9488
Epoch [4/9], Batch [278/428], Loss: 3.7850
Epoch [4/9], Batch [279/428], Loss: 1.4646
Epoch [4/9], Batch [280/428], Loss: 2.4154
Epoch [4/9], Batch [281/428], Loss: 0.5422
Epoch [4/9], Batch [282/428], Loss: 1.3043
Epoch [4/9], Batch [283/428], Loss: 3.0686
Epoch [4/9], Batch [284/428], Loss: 3.0523
Epoch [4/9], Batch [285/428], Loss: 0.9536
Epoch [4/9], Batch [286/428], Loss: 1.2015
Epoch [4/9], Batch [287/428], Loss: 2.0980
Epoch [4/9], Batch [288/428], Loss: 0.5157
Epoch [4/9], Batch [289/428], Loss: 1.5165
Epoch [4/9], Batch [290/428], Loss: 0.5916
Epoch [4/9], Batch [291/428], Loss: 2.1249
Epoch [4/9], Batch [292/428], Loss: 2.2994
Epoch [4/9], Batch [293/428], Loss: 1.1812
Epoch [4/9], Batch [294/428], Loss: 2.2717
Epoch [4/9], Batch [295/428], Loss: 2.0104
Epoch [4/9], Batch [296/428], Loss: 1.8039
Epoch [4/9], Batch [297/428], Loss: 1.2309
Epoch [4/9], Batch [298/428], Loss: 2.7460
Epoch [4/9], Batch [299/428], Loss: 2.9956
Epoch [4/9], Batch [300/428], Loss: 1.7173
Epoch [4/9], Batch [301/428], Loss: 1.2449
Epoch [4/9], Batch [302/428], Loss: 3.3473
Epoch [4/9], Batch [303/428], Loss: 1.6832
Epoch [4/9], Batch [304/428], Loss: 2.0257
Epoch [4/9], Batch [305/428], Loss: 2.7910
Epoch [4/9], Batch [306/428], Loss: 1.9437
Epoch [4/9], Batch [307/428], Loss: 0.6255
Epoch [4/9], Batch [308/428], Loss: 1.4563
Epoch [4/9], Batch [309/428], Loss: 1.2545
Epoch [4/9], Batch [310/428], Loss: 1.6087
Epoch [4/9], Batch [311/428], Loss: 1.0160
Epoch [4/9], Batch [312/428], Loss: 2.1128
Epoch [4/9], Batch [313/428], Loss: 1.6082
Epoch [4/9], Batch [314/428], Loss: 0.8870
Epoch [4/9], Batch [315/428], Loss: 2.0865
Epoch [4/9], Batch [316/428], Loss: 1.3535
Epoch [4/9], Batch [317/428], Loss: 1.0258
Epoch [4/9], Batch [318/428], Loss: 1.9568
Epoch [4/9], Batch [319/428], Loss: 1.7872
Epoch [4/9], Batch [320/428], Loss: 1.9789
Epoch [4/9], Batch [321/428], Loss: 0.4274
Epoch [4/9], Batch [322/428], Loss: 2.4630
Epoch [4/9], Batch [323/428], Loss: 2.0257
Epoch [4/9], Batch [324/428], Loss: 1.1740
Epoch [4/9], Batch [325/428], Loss: 2.7077
Epoch [4/9], Batch [326/428], Loss: 2.3261
Epoch [4/9], Batch [327/428], Loss: 1.2878
Epoch [4/9], Batch [328/428], Loss: 0.7672
Epoch [4/9], Batch [329/428], Loss: 1.2838
Epoch [4/9], Batch [330/428], Loss: 2.3111
Epoch [4/9], Batch [331/428], Loss: 2.6738
Epoch [4/9], Batch [332/428], Loss: 1.3534
Epoch [4/9], Batch [333/428], Loss: 1.8667
Epoch [4/9], Batch [334/428], Loss: 1.1791
Epoch [4/9], Batch [335/428], Loss: 1.9900
Epoch [4/9], Batch [336/428], Loss: 2.2333
Epoch [4/9], Batch [337/428], Loss: 1.9989
Epoch [4/9], Batch [338/428], Loss: 2.0522
Epoch [4/9], Batch [339/428], Loss: 2.6063
Epoch [4/9], Batch [340/428], Loss: 2.1504
Epoch [4/9], Batch [341/428], Loss: 2.4250
Epoch [4/9], Batch [342/428], Loss: 2.0556
Epoch [4/9], Batch [343/428], Loss: 2.1227
Epoch [4/9], Batch [344/428], Loss: 1.9129
Epoch [4/9], Batch [345/428], Loss: 2.4772
Epoch [4/9], Batch [346/428], Loss: 2.5560
Epoch [4/9], Batch [347/428], Loss: 2.5990
Epoch [4/9], Batch [348/428], Loss: 1.9020
Epoch [4/9], Batch [349/428], Loss: 2.4341
Epoch [4/9], Batch [350/428], Loss: 2.6634
Epoch [4/9], Batch [351/428], Loss: 2.4511
Epoch [4/9], Batch [352/428], Loss: 1.1377
Epoch [4/9], Batch [353/428], Loss: 2.4821
Epoch [4/9], Batch [354/428], Loss: 1.7708
Epoch [4/9], Batch [355/428], Loss: 2.1822
Epoch [4/9], Batch [356/428], Loss: 2.0610
Epoch [4/9], Batch [357/428], Loss: 1.1010
Epoch [4/9], Batch [358/428], Loss: 1.6220
Epoch [4/9], Batch [359/428], Loss: 1.4496
Epoch [4/9], Batch [360/428], Loss: 1.1022
Epoch [4/9], Batch [361/428], Loss: 2.0716
Epoch [4/9], Batch [362/428], Loss: 0.8948
Epoch [4/9], Batch [363/428], Loss: 2.5128
Epoch [4/9], Batch [364/428], Loss: 1.8092
Epoch [4/9], Batch [365/428], Loss: 1.5855
Epoch [4/9], Batch [366/428], Loss: 1.2347
Epoch [4/9], Batch [367/428], Loss: 2.2211
Epoch [4/9], Batch [368/428], Loss: 2.3526
Epoch [4/9], Batch [369/428], Loss: 0.5746
Epoch [4/9], Batch [370/428], Loss: 0.4059
Epoch [4/9], Batch [371/428], Loss: 0.5555
Epoch [4/9], Batch [372/428], Loss: 1.9885
Epoch [4/9], Batch [373/428], Loss: 0.6750
Epoch [4/9], Batch [374/428], Loss: 1.1039
Epoch [4/9], Batch [375/428], Loss: 2.0214
Epoch [4/9], Batch [376/428], Loss: 2.0813
Epoch [4/9], Batch [377/428], Loss: 2.4115
Epoch [4/9], Batch [378/428], Loss: 1.3177
Epoch [4/9], Batch [379/428], Loss: 3.5117
Epoch [4/9], Batch [380/428], Loss: 1.7254
Epoch [4/9], Batch [381/428], Loss: 1.5101
Epoch [4/9], Batch [382/428], Loss: 1.6018
Epoch [4/9], Batch [383/428], Loss: 1.8129
Epoch [4/9], Batch [384/428], Loss: 1.2503
Epoch [4/9], Batch [385/428], Loss: 2.0724
Epoch [4/9], Batch [386/428], Loss: 0.5445
Epoch [4/9], Batch [387/428], Loss: 0.7698
Epoch [4/9], Batch [388/428], Loss: 1.4633
Epoch [4/9], Batch [389/428], Loss: 1.0445
Epoch [4/9], Batch [390/428], Loss: 1.3593
Epoch [4/9], Batch [391/428], Loss: 2.1868
Epoch [4/9], Batch [392/428], Loss: 1.0916
Epoch [4/9], Batch [393/428], Loss: 1.1680
Epoch [4/9], Batch [394/428], Loss: 1.4517
Epoch [4/9], Batch [395/428], Loss: 1.3413
Epoch [4/9], Batch [396/428], Loss: 2.5553
Epoch [4/9], Batch [397/428], Loss: 1.9024
Epoch [4/9], Batch [398/428], Loss: 1.4752
Epoch [4/9], Batch [399/428], Loss: 1.8620
Epoch [4/9], Batch [400/428], Loss: 2.5886
Epoch [4/9], Batch [401/428], Loss: 1.7614
Epoch [4/9], Batch [402/428], Loss: 2.1601
Epoch [4/9], Batch [403/428], Loss: 0.9707
Epoch [4/9], Batch [404/428], Loss: 1.9221
Epoch [4/9], Batch [405/428], Loss: 2.0956
Epoch [4/9], Batch [406/428], Loss: 1.3548
Epoch [4/9], Batch [407/428], Loss: 3.1955
Epoch [4/9], Batch [408/428], Loss: 1.6096
Epoch [4/9], Batch [409/428], Loss: 1.7920
Epoch [4/9], Batch [410/428], Loss: 3.2332
Epoch [4/9], Batch [411/428], Loss: 0.8192
Epoch [4/9], Batch [412/428], Loss: 1.7460
Epoch [4/9], Batch [413/428], Loss: 1.8101
Epoch [4/9], Batch [414/428], Loss: 2.5098
Epoch [4/9], Batch [415/428], Loss: 1.6063
Epoch [4/9], Batch [416/428], Loss: 2.3284
Epoch [4/9], Batch [417/428], Loss: 0.7631
Epoch [4/9], Batch [418/428], Loss: 2.3693
Epoch [4/9], Batch [419/428], Loss: 3.5559
Epoch [4/9], Batch [420/428], Loss: 0.8004
Epoch [4/9], Batch [421/428], Loss: 2.3506
Epoch [4/9], Batch [422/428], Loss: 1.3979
Epoch [4/9], Batch [423/428], Loss: 1.1248
Epoch [4/9], Batch [424/428], Loss: 2.8222
Epoch [4/9], Batch [425/428], Loss: 1.6041
Epoch [4/9], Batch [426/428], Loss: 1.7371
Epoch [4/9], Batch [427/428], Loss: 2.7272
Epoch [4/9], Batch [428/428], Loss: 0.3919
Epoch [4] Training Time: 374.24 seconds
Epoch [4/9], Average Loss: 1.9924, Training Accuracy: 0.2430
Epoch [4], Validation Loss: 1.8981, Validation Accuracy: 0.2789
Epoch [4] Validation Time: 21.26 seconds
--------------------------------------------------
Epoch [5/9], Batch [1/428], Loss: 0.8258
Epoch [5/9], Batch [2/428], Loss: 0.9961
Epoch [5/9], Batch [3/428], Loss: 1.5345
Epoch [5/9], Batch [4/428], Loss: 0.5770
Epoch [5/9], Batch [5/428], Loss: 3.3101
Epoch [5/9], Batch [6/428], Loss: 1.3947
Epoch [5/9], Batch [7/428], Loss: 1.0576
Epoch [5/9], Batch [8/428], Loss: 2.0542
Epoch [5/9], Batch [9/428], Loss: 2.0737
Epoch [5/9], Batch [10/428], Loss: 0.8849
Epoch [5/9], Batch [11/428], Loss: 1.3835
Epoch [5/9], Batch [12/428], Loss: 0.6053
Epoch [5/9], Batch [13/428], Loss: 1.8885
Epoch [5/9], Batch [14/428], Loss: 3.3225
Epoch [5/9], Batch [15/428], Loss: 2.5446
Epoch [5/9], Batch [16/428], Loss: 1.9163
Epoch [5/9], Batch [17/428], Loss: 1.9730
Epoch [5/9], Batch [18/428], Loss: 1.5864
Epoch [5/9], Batch [19/428], Loss: 2.0653
Epoch [5/9], Batch [20/428], Loss: 2.5543
Epoch [5/9], Batch [21/428], Loss: 1.5913
Epoch [5/9], Batch [22/428], Loss: 1.4883
Epoch [5/9], Batch [23/428], Loss: 0.6754
Epoch [5/9], Batch [24/428], Loss: 1.7231
Epoch [5/9], Batch [25/428], Loss: 1.4984
Epoch [5/9], Batch [26/428], Loss: 0.6474
Epoch [5/9], Batch [27/428], Loss: 1.5482
Epoch [5/9], Batch [28/428], Loss: 0.8422
Epoch [5/9], Batch [29/428], Loss: 1.1913
Epoch [5/9], Batch [30/428], Loss: 0.5285
Epoch [5/9], Batch [31/428], Loss: 1.6822
Epoch [5/9], Batch [32/428], Loss: 2.5684
Epoch [5/9], Batch [33/428], Loss: 1.9888
Epoch [5/9], Batch [34/428], Loss: 3.5746
Epoch [5/9], Batch [35/428], Loss: 1.4482
Epoch [5/9], Batch [36/428], Loss: 1.8507
Epoch [5/9], Batch [37/428], Loss: 1.3216
Epoch [5/9], Batch [38/428], Loss: 2.6540
Epoch [5/9], Batch [39/428], Loss: 1.5834
Epoch [5/9], Batch [40/428], Loss: 3.1482
Epoch [5/9], Batch [41/428], Loss: 1.1884
Epoch [5/9], Batch [42/428], Loss: 2.8671
Epoch [5/9], Batch [43/428], Loss: 1.5089
Epoch [5/9], Batch [44/428], Loss: 2.8946
Epoch [5/9], Batch [45/428], Loss: 2.0342
Epoch [5/9], Batch [46/428], Loss: 2.9339
Epoch [5/9], Batch [47/428], Loss: 2.8941
Epoch [5/9], Batch [48/428], Loss: 0.9392
Epoch [5/9], Batch [49/428], Loss: 1.1765
Epoch [5/9], Batch [50/428], Loss: 1.2384
Epoch [5/9], Batch [51/428], Loss: 2.2772
Epoch [5/9], Batch [52/428], Loss: 2.4594
Epoch [5/9], Batch [53/428], Loss: 2.1983
Epoch [5/9], Batch [54/428], Loss: 1.7975
Epoch [5/9], Batch [55/428], Loss: 1.0683
Epoch [5/9], Batch [56/428], Loss: 2.1890
Epoch [5/9], Batch [57/428], Loss: 1.3795
Epoch [5/9], Batch [58/428], Loss: 1.8599
Epoch [5/9], Batch [59/428], Loss: 2.6600
Epoch [5/9], Batch [60/428], Loss: 2.4192
Epoch [5/9], Batch [61/428], Loss: 1.2113
Epoch [5/9], Batch [62/428], Loss: 2.2135
Epoch [5/9], Batch [63/428], Loss: 1.5616
Epoch [5/9], Batch [64/428], Loss: 2.4330
Epoch [5/9], Batch [65/428], Loss: 1.1977
Epoch [5/9], Batch [66/428], Loss: 2.4283
Epoch [5/9], Batch [67/428], Loss: 3.7147
Epoch [5/9], Batch [68/428], Loss: 2.2588
Epoch [5/9], Batch [69/428], Loss: 1.8872
Epoch [5/9], Batch [70/428], Loss: 1.1882
Epoch [5/9], Batch [71/428], Loss: 2.2300
Epoch [5/9], Batch [72/428], Loss: 1.4691
Epoch [5/9], Batch [73/428], Loss: 0.9261
Epoch [5/9], Batch [74/428], Loss: 2.5546
Epoch [5/9], Batch [75/428], Loss: 2.0327
Epoch [5/9], Batch [76/428], Loss: 1.6483
Epoch [5/9], Batch [77/428], Loss: 0.5829
Epoch [5/9], Batch [78/428], Loss: 2.3596
Epoch [5/9], Batch [79/428], Loss: 1.7356
Epoch [5/9], Batch [80/428], Loss: 1.6227
Epoch [5/9], Batch [81/428], Loss: 1.9935
Epoch [5/9], Batch [82/428], Loss: 3.3485
Epoch [5/9], Batch [83/428], Loss: 1.8311
Epoch [5/9], Batch [84/428], Loss: 1.8466
Epoch [5/9], Batch [85/428], Loss: 1.7299
Epoch [5/9], Batch [86/428], Loss: 2.1750
Epoch [5/9], Batch [87/428], Loss: 0.5224
Epoch [5/9], Batch [88/428], Loss: 1.4620
Epoch [5/9], Batch [89/428], Loss: 1.3674
Epoch [5/9], Batch [90/428], Loss: 0.6442
Epoch [5/9], Batch [91/428], Loss: 1.6726
Epoch [5/9], Batch [92/428], Loss: 2.4296
Epoch [5/9], Batch [93/428], Loss: 1.5916
Epoch [5/9], Batch [94/428], Loss: 0.3821
Epoch [5/9], Batch [95/428], Loss: 1.5643
Epoch [5/9], Batch [96/428], Loss: 1.9312
Epoch [5/9], Batch [97/428], Loss: 2.3809
Epoch [5/9], Batch [98/428], Loss: 2.2976
Epoch [5/9], Batch [99/428], Loss: 2.1074
Epoch [5/9], Batch [100/428], Loss: 1.2786
Epoch [5/9], Batch [101/428], Loss: 2.1556
Epoch [5/9], Batch [102/428], Loss: 1.6128
Epoch [5/9], Batch [103/428], Loss: 1.8178
Epoch [5/9], Batch [104/428], Loss: 0.8365
Epoch [5/9], Batch [105/428], Loss: 0.4572
Epoch [5/9], Batch [106/428], Loss: 1.6303
Epoch [5/9], Batch [107/428], Loss: 1.6530
Epoch [5/9], Batch [108/428], Loss: 1.3475
Epoch [5/9], Batch [109/428], Loss: 2.1657
Epoch [5/9], Batch [110/428], Loss: 2.4071
Epoch [5/9], Batch [111/428], Loss: 0.6907
Epoch [5/9], Batch [112/428], Loss: 1.8969
Epoch [5/9], Batch [113/428], Loss: 2.0423
Epoch [5/9], Batch [114/428], Loss: 0.7141
Epoch [5/9], Batch [115/428], Loss: 2.8962
Epoch [5/9], Batch [116/428], Loss: 2.5053
Epoch [5/9], Batch [117/428], Loss: 0.6111
Epoch [5/9], Batch [118/428], Loss: 3.0571
Epoch [5/9], Batch [119/428], Loss: 1.5348
Epoch [5/9], Batch [120/428], Loss: 2.3897
Epoch [5/9], Batch [121/428], Loss: 1.0758
Epoch [5/9], Batch [122/428], Loss: 2.5321
Epoch [5/9], Batch [123/428], Loss: 2.3705
Epoch [5/9], Batch [124/428], Loss: 0.8912
Epoch [5/9], Batch [125/428], Loss: 0.6668
Epoch [5/9], Batch [126/428], Loss: 2.7025
Epoch [5/9], Batch [127/428], Loss: 0.8621
Epoch [5/9], Batch [128/428], Loss: 1.4507
Epoch [5/9], Batch [129/428], Loss: 2.5355
Epoch [5/9], Batch [130/428], Loss: 1.1746
Epoch [5/9], Batch [131/428], Loss: 2.2013
Epoch [5/9], Batch [132/428], Loss: 3.3715
Epoch [5/9], Batch [133/428], Loss: 2.3151
Epoch [5/9], Batch [134/428], Loss: 1.3526
Epoch [5/9], Batch [135/428], Loss: 2.3390
Epoch [5/9], Batch [136/428], Loss: 1.1339
Epoch [5/9], Batch [137/428], Loss: 1.4882
Epoch [5/9], Batch [138/428], Loss: 1.9447
Epoch [5/9], Batch [139/428], Loss: 1.9783
Epoch [5/9], Batch [140/428], Loss: 2.5813
Epoch [5/9], Batch [141/428], Loss: 1.6051
Epoch [5/9], Batch [142/428], Loss: 0.9681
Epoch [5/9], Batch [143/428], Loss: 1.9921
Epoch [5/9], Batch [144/428], Loss: 2.1256
Epoch [5/9], Batch [145/428], Loss: 1.8805
Epoch [5/9], Batch [146/428], Loss: 2.1020
Epoch [5/9], Batch [147/428], Loss: 2.3187
Epoch [5/9], Batch [148/428], Loss: 2.5504
Epoch [5/9], Batch [149/428], Loss: 1.6411
Epoch [5/9], Batch [150/428], Loss: 3.3776
Epoch [5/9], Batch [151/428], Loss: 2.1267
Epoch [5/9], Batch [152/428], Loss: 2.2900
Epoch [5/9], Batch [153/428], Loss: 1.5865
Epoch [5/9], Batch [154/428], Loss: 2.2172
Epoch [5/9], Batch [155/428], Loss: 2.1639
Epoch [5/9], Batch [156/428], Loss: 1.9077
Epoch [5/9], Batch [157/428], Loss: 0.3094
Epoch [5/9], Batch [158/428], Loss: 1.8908
Epoch [5/9], Batch [159/428], Loss: 1.1826
Epoch [5/9], Batch [160/428], Loss: 1.4600
Epoch [5/9], Batch [161/428], Loss: 1.3963
Epoch [5/9], Batch [162/428], Loss: 1.5749
Epoch [5/9], Batch [163/428], Loss: 1.7017
Epoch [5/9], Batch [164/428], Loss: 1.1984
Epoch [5/9], Batch [165/428], Loss: 1.3489
Epoch [5/9], Batch [166/428], Loss: 0.2919
Epoch [5/9], Batch [167/428], Loss: 1.8469
Epoch [5/9], Batch [168/428], Loss: 1.3642
Epoch [5/9], Batch [169/428], Loss: 2.8270
Epoch [5/9], Batch [170/428], Loss: 1.4318
Epoch [5/9], Batch [171/428], Loss: 2.5065
Epoch [5/9], Batch [172/428], Loss: 2.0401
Epoch [5/9], Batch [173/428], Loss: 1.7866
Epoch [5/9], Batch [174/428], Loss: 1.8103
Epoch [5/9], Batch [175/428], Loss: 2.0125
Epoch [5/9], Batch [176/428], Loss: 1.5700
Epoch [5/9], Batch [177/428], Loss: 0.4738
Epoch [5/9], Batch [178/428], Loss: 0.7474
Epoch [5/9], Batch [179/428], Loss: 1.2357
Epoch [5/9], Batch [180/428], Loss: 3.1023
Epoch [5/9], Batch [181/428], Loss: 2.2645
Epoch [5/9], Batch [182/428], Loss: 2.1236
Epoch [5/9], Batch [183/428], Loss: 1.7214
Epoch [5/9], Batch [184/428], Loss: 2.3907
Epoch [5/9], Batch [185/428], Loss: 1.1498
Epoch [5/9], Batch [186/428], Loss: 2.8002
Epoch [5/9], Batch [187/428], Loss: 3.1363
Epoch [5/9], Batch [188/428], Loss: 0.7348
Epoch [5/9], Batch [189/428], Loss: 1.3172
Epoch [5/9], Batch [190/428], Loss: 1.4266
Epoch [5/9], Batch [191/428], Loss: 1.8176
Epoch [5/9], Batch [192/428], Loss: 1.8529
Epoch [5/9], Batch [193/428], Loss: 1.5541
Epoch [5/9], Batch [194/428], Loss: 1.2452
Epoch [5/9], Batch [195/428], Loss: 1.8636
Epoch [5/9], Batch [196/428], Loss: 0.7890
Epoch [5/9], Batch [197/428], Loss: 2.4240
Epoch [5/9], Batch [198/428], Loss: 2.1684
Epoch [5/9], Batch [199/428], Loss: 1.7390
Epoch [5/9], Batch [200/428], Loss: 1.5444
Epoch [5/9], Batch [201/428], Loss: 2.5019
Epoch [5/9], Batch [202/428], Loss: 0.9402
Epoch [5/9], Batch [203/428], Loss: 1.8816
Epoch [5/9], Batch [204/428], Loss: 2.6892
Epoch [5/9], Batch [205/428], Loss: 1.0979
Epoch [5/9], Batch [206/428], Loss: 2.1353
Epoch [5/9], Batch [207/428], Loss: 1.6084
Epoch [5/9], Batch [208/428], Loss: 2.1905
Epoch [5/9], Batch [209/428], Loss: 2.3469
Epoch [5/9], Batch [210/428], Loss: 1.6097
Epoch [5/9], Batch [211/428], Loss: 3.1137
Epoch [5/9], Batch [212/428], Loss: 1.6785
Epoch [5/9], Batch [213/428], Loss: 2.0653
Epoch [5/9], Batch [214/428], Loss: 0.3585
Epoch [5/9], Batch [215/428], Loss: 2.4162
Epoch [5/9], Batch [216/428], Loss: 0.3512
Epoch [5/9], Batch [217/428], Loss: 2.4700
Epoch [5/9], Batch [218/428], Loss: 1.4993
Epoch [5/9], Batch [219/428], Loss: 1.1707
Epoch [5/9], Batch [220/428], Loss: 2.4028
Epoch [5/9], Batch [221/428], Loss: 1.3293
Epoch [5/9], Batch [222/428], Loss: 2.0150
Epoch [5/9], Batch [223/428], Loss: 1.9074
Epoch [5/9], Batch [224/428], Loss: 1.5066
Epoch [5/9], Batch [225/428], Loss: 1.4829
Epoch [5/9], Batch [226/428], Loss: 1.5496
Epoch [5/9], Batch [227/428], Loss: 1.0293
Epoch [5/9], Batch [228/428], Loss: 0.8624
Epoch [5/9], Batch [229/428], Loss: 3.4969
Epoch [5/9], Batch [230/428], Loss: 1.8530
Epoch [5/9], Batch [231/428], Loss: 2.5016
Epoch [5/9], Batch [232/428], Loss: 1.1689
Epoch [5/9], Batch [233/428], Loss: 1.8384
Epoch [5/9], Batch [234/428], Loss: 1.4437
Epoch [5/9], Batch [235/428], Loss: 2.1986
Epoch [5/9], Batch [236/428], Loss: 2.4456
Epoch [5/9], Batch [237/428], Loss: 2.7667
Epoch [5/9], Batch [238/428], Loss: 1.3516
Epoch [5/9], Batch [239/428], Loss: 1.8309
Epoch [5/9], Batch [240/428], Loss: 1.4664
Epoch [5/9], Batch [241/428], Loss: 0.5994
Epoch [5/9], Batch [242/428], Loss: 1.9659
Epoch [5/9], Batch [243/428], Loss: 1.9323
Epoch [5/9], Batch [244/428], Loss: 2.8670
Epoch [5/9], Batch [245/428], Loss: 2.3413
Epoch [5/9], Batch [246/428], Loss: 1.8017
Epoch [5/9], Batch [247/428], Loss: 1.5336
Epoch [5/9], Batch [248/428], Loss: 1.9711
Epoch [5/9], Batch [249/428], Loss: 2.4759
Epoch [5/9], Batch [250/428], Loss: 1.7569
Epoch [5/9], Batch [251/428], Loss: 1.4011
Epoch [5/9], Batch [252/428], Loss: 2.0999
Epoch [5/9], Batch [253/428], Loss: 1.1373
Epoch [5/9], Batch [254/428], Loss: 1.4783
Epoch [5/9], Batch [255/428], Loss: 3.1632
Epoch [5/9], Batch [256/428], Loss: 3.2543
Epoch [5/9], Batch [257/428], Loss: 1.5998
Epoch [5/9], Batch [258/428], Loss: 1.8310
Epoch [5/9], Batch [259/428], Loss: 2.1055
Epoch [5/9], Batch [260/428], Loss: 1.1421
Epoch [5/9], Batch [261/428], Loss: 0.5215
Epoch [5/9], Batch [262/428], Loss: 1.6891
Epoch [5/9], Batch [263/428], Loss: 2.5727
Epoch [5/9], Batch [264/428], Loss: 3.0311
Epoch [5/9], Batch [265/428], Loss: 2.3888
Epoch [5/9], Batch [266/428], Loss: 1.7886
Epoch [5/9], Batch [267/428], Loss: 0.6780
Epoch [5/9], Batch [268/428], Loss: 0.5102
Epoch [5/9], Batch [269/428], Loss: 2.9969
Epoch [5/9], Batch [270/428], Loss: 1.7861
Epoch [5/9], Batch [271/428], Loss: 1.0713
Epoch [5/9], Batch [272/428], Loss: 3.4464
Epoch [5/9], Batch [273/428], Loss: 1.0667
Epoch [5/9], Batch [274/428], Loss: 1.8983
Epoch [5/9], Batch [275/428], Loss: 0.9525
Epoch [5/9], Batch [276/428], Loss: 1.1534
Epoch [5/9], Batch [277/428], Loss: 3.0722
Epoch [5/9], Batch [278/428], Loss: 3.1107
Epoch [5/9], Batch [279/428], Loss: 1.5628
Epoch [5/9], Batch [280/428], Loss: 0.9624
Epoch [5/9], Batch [281/428], Loss: 0.9262
Epoch [5/9], Batch [282/428], Loss: 2.8483
Epoch [5/9], Batch [283/428], Loss: 1.6110
Epoch [5/9], Batch [284/428], Loss: 0.9343
Epoch [5/9], Batch [285/428], Loss: 1.6074
Epoch [5/9], Batch [286/428], Loss: 2.8325
Epoch [5/9], Batch [287/428], Loss: 1.3972
Epoch [5/9], Batch [288/428], Loss: 1.6331
Epoch [5/9], Batch [289/428], Loss: 2.5267
Epoch [5/9], Batch [290/428], Loss: 3.5530
Epoch [5/9], Batch [291/428], Loss: 2.7534
Epoch [5/9], Batch [292/428], Loss: 1.4167
Epoch [5/9], Batch [293/428], Loss: 2.0771
Epoch [5/9], Batch [294/428], Loss: 2.4188
Epoch [5/9], Batch [295/428], Loss: 1.7944
Epoch [5/9], Batch [296/428], Loss: 1.2924
Epoch [5/9], Batch [297/428], Loss: 1.8032
Epoch [5/9], Batch [298/428], Loss: 2.2976
Epoch [5/9], Batch [299/428], Loss: 1.4124
Epoch [5/9], Batch [300/428], Loss: 2.6249
Epoch [5/9], Batch [301/428], Loss: 0.8744
Epoch [5/9], Batch [302/428], Loss: 2.4908
Epoch [5/9], Batch [303/428], Loss: 1.8227
Epoch [5/9], Batch [304/428], Loss: 1.5173
Epoch [5/9], Batch [305/428], Loss: 1.1267
Epoch [5/9], Batch [306/428], Loss: 1.6021
Epoch [5/9], Batch [307/428], Loss: 3.3507
Epoch [5/9], Batch [308/428], Loss: 2.3949
Epoch [5/9], Batch [309/428], Loss: 0.6601
Epoch [5/9], Batch [310/428], Loss: 2.2558
Epoch [5/9], Batch [311/428], Loss: 3.8150
Epoch [5/9], Batch [312/428], Loss: 1.1828
Epoch [5/9], Batch [313/428], Loss: 0.9878
Epoch [5/9], Batch [314/428], Loss: 1.9218
Epoch [5/9], Batch [315/428], Loss: 2.2879
Epoch [5/9], Batch [316/428], Loss: 2.5549
Epoch [5/9], Batch [317/428], Loss: 0.7660
Epoch [5/9], Batch [318/428], Loss: 1.5908
Epoch [5/9], Batch [319/428], Loss: 1.0576
Epoch [5/9], Batch [320/428], Loss: 2.0603
Epoch [5/9], Batch [321/428], Loss: 1.1884
Epoch [5/9], Batch [322/428], Loss: 2.1888
Epoch [5/9], Batch [323/428], Loss: 1.9556
Epoch [5/9], Batch [324/428], Loss: 1.3146
Epoch [5/9], Batch [325/428], Loss: 1.8083
Epoch [5/9], Batch [326/428], Loss: 0.3792
Epoch [5/9], Batch [327/428], Loss: 2.3306
Epoch [5/9], Batch [328/428], Loss: 1.6627
Epoch [5/9], Batch [329/428], Loss: 1.3058
Epoch [5/9], Batch [330/428], Loss: 1.7203
Epoch [5/9], Batch [331/428], Loss: 2.4435
Epoch [5/9], Batch [332/428], Loss: 1.9614
Epoch [5/9], Batch [333/428], Loss: 1.3498
Epoch [5/9], Batch [334/428], Loss: 0.7143
Epoch [5/9], Batch [335/428], Loss: 1.2744
Epoch [5/9], Batch [336/428], Loss: 1.5867
Epoch [5/9], Batch [337/428], Loss: 0.4170
Epoch [5/9], Batch [338/428], Loss: 1.8496
Epoch [5/9], Batch [339/428], Loss: 1.3934
Epoch [5/9], Batch [340/428], Loss: 1.8987
Epoch [5/9], Batch [341/428], Loss: 2.0991
Epoch [5/9], Batch [342/428], Loss: 1.1569
Epoch [5/9], Batch [343/428], Loss: 2.3535
Epoch [5/9], Batch [344/428], Loss: 1.4379
Epoch [5/9], Batch [345/428], Loss: 0.6104
Epoch [5/9], Batch [346/428], Loss: 1.0964
Epoch [5/9], Batch [347/428], Loss: 1.1873
Epoch [5/9], Batch [348/428], Loss: 1.7448
Epoch [5/9], Batch [349/428], Loss: 1.0360
Epoch [5/9], Batch [350/428], Loss: 1.4481
Epoch [5/9], Batch [351/428], Loss: 1.3737
Epoch [5/9], Batch [352/428], Loss: 2.1703
Epoch [5/9], Batch [353/428], Loss: 1.9557
Epoch [5/9], Batch [354/428], Loss: 1.9122
Epoch [5/9], Batch [355/428], Loss: 3.1096
Epoch [5/9], Batch [356/428], Loss: 1.8614
Epoch [5/9], Batch [357/428], Loss: 2.7297
Epoch [5/9], Batch [358/428], Loss: 3.3132
Epoch [5/9], Batch [359/428], Loss: 1.1245
Epoch [5/9], Batch [360/428], Loss: 2.8684
Epoch [5/9], Batch [361/428], Loss: 2.0801
Epoch [5/9], Batch [362/428], Loss: 1.8085
Epoch [5/9], Batch [363/428], Loss: 2.7309
Epoch [5/9], Batch [364/428], Loss: 1.0983
Epoch [5/9], Batch [365/428], Loss: 1.5233
Epoch [5/9], Batch [366/428], Loss: 2.1342
Epoch [5/9], Batch [367/428], Loss: 1.1440
Epoch [5/9], Batch [368/428], Loss: 3.3427
Epoch [5/9], Batch [369/428], Loss: 1.8613
Epoch [5/9], Batch [370/428], Loss: 1.7981
Epoch [5/9], Batch [371/428], Loss: 2.0633
Epoch [5/9], Batch [372/428], Loss: 1.1128
Epoch [5/9], Batch [373/428], Loss: 3.9814
Epoch [5/9], Batch [374/428], Loss: 1.1937
Epoch [5/9], Batch [375/428], Loss: 1.8049
Epoch [5/9], Batch [376/428], Loss: 0.4144
Epoch [5/9], Batch [377/428], Loss: 2.0783
Epoch [5/9], Batch [378/428], Loss: 0.9680
Epoch [5/9], Batch [379/428], Loss: 2.1055
Epoch [5/9], Batch [380/428], Loss: 2.1517
Epoch [5/9], Batch [381/428], Loss: 1.8985
Epoch [5/9], Batch [382/428], Loss: 1.3676
Epoch [5/9], Batch [383/428], Loss: 2.0032
Epoch [5/9], Batch [384/428], Loss: 1.8092
Epoch [5/9], Batch [385/428], Loss: 1.6698
Epoch [5/9], Batch [386/428], Loss: 0.9400
Epoch [5/9], Batch [387/428], Loss: 0.4088
Epoch [5/9], Batch [388/428], Loss: 1.9794
Epoch [5/9], Batch [389/428], Loss: 1.4990
Epoch [5/9], Batch [390/428], Loss: 2.3723
Epoch [5/9], Batch [391/428], Loss: 3.5589
Epoch [5/9], Batch [392/428], Loss: 2.4191
Epoch [5/9], Batch [393/428], Loss: 1.9568
Epoch [5/9], Batch [394/428], Loss: 1.3677
Epoch [5/9], Batch [395/428], Loss: 0.8658
Epoch [5/9], Batch [396/428], Loss: 2.7237
Epoch [5/9], Batch [397/428], Loss: 1.7570
Epoch [5/9], Batch [398/428], Loss: 1.4449
Epoch [5/9], Batch [399/428], Loss: 1.3214
Epoch [5/9], Batch [400/428], Loss: 1.9421
Epoch [5/9], Batch [401/428], Loss: 1.8830
Epoch [5/9], Batch [402/428], Loss: 1.8725
Epoch [5/9], Batch [403/428], Loss: 1.4024
Epoch [5/9], Batch [404/428], Loss: 0.8261
Epoch [5/9], Batch [405/428], Loss: 1.4853
Epoch [5/9], Batch [406/428], Loss: 1.6323
Epoch [5/9], Batch [407/428], Loss: 2.1072
Epoch [5/9], Batch [408/428], Loss: 2.3739
Epoch [5/9], Batch [409/428], Loss: 2.3300
Epoch [5/9], Batch [410/428], Loss: 1.8530
Epoch [5/9], Batch [411/428], Loss: 0.8009
Epoch [5/9], Batch [412/428], Loss: 1.2291
Epoch [5/9], Batch [413/428], Loss: 3.6701
Epoch [5/9], Batch [414/428], Loss: 2.1720
Epoch [5/9], Batch [415/428], Loss: 1.4178
Epoch [5/9], Batch [416/428], Loss: 2.1179
Epoch [5/9], Batch [417/428], Loss: 2.2429
Epoch [5/9], Batch [418/428], Loss: 1.0078
Epoch [5/9], Batch [419/428], Loss: 1.7661
Epoch [5/9], Batch [420/428], Loss: 1.5636
Epoch [5/9], Batch [421/428], Loss: 1.1281
Epoch [5/9], Batch [422/428], Loss: 1.7910
Epoch [5/9], Batch [423/428], Loss: 1.6618
Epoch [5/9], Batch [424/428], Loss: 1.8842
Epoch [5/9], Batch [425/428], Loss: 1.6386
Epoch [5/9], Batch [426/428], Loss: 2.8848
Epoch [5/9], Batch [427/428], Loss: 2.8824
Epoch [5/9], Batch [428/428], Loss: 2.7673
Epoch [5] Training Time: 376.68 seconds
Epoch [5/9], Average Loss: 1.8063, Training Accuracy: 0.2640
Epoch [5], Validation Loss: 1.7925, Validation Accuracy: 0.2925
Epoch [5] Validation Time: 21.34 seconds
--------------------------------------------------
Epoch 6: Unfreezing feature extractor layers...
Epoch [6/9], Batch [1/428], Loss: 1.5885
Epoch [6/9], Batch [2/428], Loss: 0.5627
Epoch [6/9], Batch [3/428], Loss: 2.0271
Epoch [6/9], Batch [4/428], Loss: 1.8644
Epoch [6/9], Batch [5/428], Loss: 1.0449
Epoch [6/9], Batch [6/428], Loss: 4.2443
Epoch [6/9], Batch [7/428], Loss: 1.3182
Epoch [6/9], Batch [8/428], Loss: 1.7205
Epoch [6/9], Batch [9/428], Loss: 5.0085
Epoch [6/9], Batch [10/428], Loss: 0.8574
Epoch [6/9], Batch [11/428], Loss: 0.8151
Epoch [6/9], Batch [12/428], Loss: 0.8556
Epoch [6/9], Batch [13/428], Loss: 0.0444
Epoch [6/9], Batch [14/428], Loss: 2.0245
Epoch [6/9], Batch [15/428], Loss: 3.1099
Epoch [6/9], Batch [16/428], Loss: 0.2276
Epoch [6/9], Batch [17/428], Loss: 3.9476
Epoch [6/9], Batch [18/428], Loss: 3.5324
Epoch [6/9], Batch [19/428], Loss: 0.3755
Epoch [6/9], Batch [20/428], Loss: 2.0067
Epoch [6/9], Batch [21/428], Loss: 0.5231
Epoch [6/9], Batch [22/428], Loss: 0.6480
Epoch [6/9], Batch [23/428], Loss: 0.4894
Epoch [6/9], Batch [24/428], Loss: 3.8780
Epoch [6/9], Batch [25/428], Loss: 0.3996
Epoch [6/9], Batch [26/428], Loss: 0.4169
Epoch [6/9], Batch [27/428], Loss: 0.1221
Epoch [6/9], Batch [28/428], Loss: 5.3933
Epoch [6/9], Batch [29/428], Loss: 0.0834
Epoch [6/9], Batch [30/428], Loss: 2.9752
Epoch [6/9], Batch [31/428], Loss: 0.0588
Epoch [6/9], Batch [32/428], Loss: 3.6668
Epoch [6/9], Batch [33/428], Loss: 0.0269
Epoch [6/9], Batch [34/428], Loss: 4.3439
Epoch [6/9], Batch [35/428], Loss: 0.0159
Epoch [6/9], Batch [36/428], Loss: 2.8864
Epoch [6/9], Batch [37/428], Loss: 3.6750
Epoch [6/9], Batch [38/428], Loss: 4.3735
Epoch [6/9], Batch [39/428], Loss: 4.4659
Epoch [6/9], Batch [40/428], Loss: 0.0312
Epoch [6/9], Batch [41/428], Loss: 0.0221
Epoch [6/9], Batch [42/428], Loss: 7.5469
Epoch [6/9], Batch [43/428], Loss: 5.6141
Epoch [6/9], Batch [44/428], Loss: 2.7934
Epoch [6/9], Batch [45/428], Loss: 2.3494
Epoch [6/9], Batch [46/428], Loss: 0.0016
Epoch [6/9], Batch [47/428], Loss: 0.0008
Epoch [6/9], Batch [48/428], Loss: 0.0148
Epoch [6/9], Batch [49/428], Loss: 5.6552
Epoch [6/9], Batch [50/428], Loss: 8.5997
Epoch [6/9], Batch [51/428], Loss: 6.8754
Epoch [6/9], Batch [52/428], Loss: 0.0006
Epoch [6/9], Batch [53/428], Loss: 1.9394
Epoch [6/9], Batch [54/428], Loss: 0.0008
Epoch [6/9], Batch [55/428], Loss: 2.1099
Epoch [6/9], Batch [56/428], Loss: 0.8711
Epoch [6/9], Batch [57/428], Loss: 6.9013
Epoch [6/9], Batch [58/428], Loss: 0.4881
Epoch [6/9], Batch [59/428], Loss: 0.0157
Epoch [6/9], Batch [60/428], Loss: 0.0037
Epoch [6/9], Batch [61/428], Loss: 2.8673
Epoch [6/9], Batch [62/428], Loss: 4.4525
Epoch [6/9], Batch [63/428], Loss: 2.0860
Epoch [6/9], Batch [64/428], Loss: 5.7838
Epoch [6/9], Batch [65/428], Loss: 0.0071
Epoch [6/9], Batch [66/428], Loss: 1.4494
Epoch [6/9], Batch [67/428], Loss: 0.0080
Epoch [6/9], Batch [68/428], Loss: 0.0093
Epoch [6/9], Batch [69/428], Loss: 4.1205
Epoch [6/9], Batch [70/428], Loss: 0.5414
Epoch [6/9], Batch [71/428], Loss: 2.4392
Epoch [6/9], Batch [72/428], Loss: 4.1793
Epoch [6/9], Batch [73/428], Loss: 5.3469
Epoch [6/9], Batch [74/428], Loss: 0.5388
Epoch [6/9], Batch [75/428], Loss: 0.0021
Epoch [6/9], Batch [76/428], Loss: 2.9828
Epoch [6/9], Batch [77/428], Loss: 2.1344
Epoch [6/9], Batch [78/428], Loss: 0.3300
Epoch [6/9], Batch [79/428], Loss: 1.2499
Epoch [6/9], Batch [80/428], Loss: 1.3256
Epoch [6/9], Batch [81/428], Loss: 4.7302
Epoch [6/9], Batch [82/428], Loss: 0.0034
Epoch [6/9], Batch [83/428], Loss: 1.1131
Epoch [6/9], Batch [84/428], Loss: 1.0938
Epoch [6/9], Batch [85/428], Loss: 0.6010
Epoch [6/9], Batch [86/428], Loss: 2.5963
Epoch [6/9], Batch [87/428], Loss: 3.4344
Epoch [6/9], Batch [88/428], Loss: 0.0047
Epoch [6/9], Batch [89/428], Loss: 1.8504
Epoch [6/9], Batch [90/428], Loss: 1.2522
Epoch [6/9], Batch [91/428], Loss: 0.7271
Epoch [6/9], Batch [92/428], Loss: 1.2693
Epoch [6/9], Batch [93/428], Loss: 3.0646
Epoch [6/9], Batch [94/428], Loss: 0.9419
Epoch [6/9], Batch [95/428], Loss: 0.0010
Epoch [6/9], Batch [96/428], Loss: 1.1871
Epoch [6/9], Batch [97/428], Loss: 1.6304
Epoch [6/9], Batch [98/428], Loss: 4.1068
Epoch [6/9], Batch [99/428], Loss: 0.0011
Epoch [6/9], Batch [100/428], Loss: 0.8225
Epoch [6/9], Batch [101/428], Loss: 0.2172
Epoch [6/9], Batch [102/428], Loss: 1.8164
Epoch [6/9], Batch [103/428], Loss: 2.7311
Epoch [6/9], Batch [104/428], Loss: 0.0804
Epoch [6/9], Batch [105/428], Loss: 0.0020
Epoch [6/9], Batch [106/428], Loss: 2.6829
Epoch [6/9], Batch [107/428], Loss: 1.5366
Epoch [6/9], Batch [108/428], Loss: 0.0007
Epoch [6/9], Batch [109/428], Loss: 0.0490
Epoch [6/9], Batch [110/428], Loss: 0.0007
Epoch [6/9], Batch [111/428], Loss: 0.0006
Epoch [6/9], Batch [112/428], Loss: 1.9128
Epoch [6/9], Batch [113/428], Loss: 7.9417
Epoch [6/9], Batch [114/428], Loss: 0.0007
Epoch [6/9], Batch [115/428], Loss: 0.0007
Epoch [6/9], Batch [116/428], Loss: 0.0009
Epoch [6/9], Batch [117/428], Loss: 0.0015
Epoch [6/9], Batch [118/428], Loss: 4.5129
Epoch [6/9], Batch [119/428], Loss: 0.0549
Epoch [6/9], Batch [120/428], Loss: 4.8419
Epoch [6/9], Batch [121/428], Loss: 0.0021
Epoch [6/9], Batch [122/428], Loss: 0.0031
Epoch [6/9], Batch [123/428], Loss: 0.0376
Epoch [6/9], Batch [124/428], Loss: 3.4018
Epoch [6/9], Batch [125/428], Loss: 0.0007
Epoch [6/9], Batch [126/428], Loss: 3.9582
Epoch [6/9], Batch [127/428], Loss: 1.1487
Epoch [6/9], Batch [128/428], Loss: 6.2638
Epoch [6/9], Batch [129/428], Loss: 0.0088
Epoch [6/9], Batch [130/428], Loss: 0.0314
Epoch [6/9], Batch [131/428], Loss: 0.5193
Epoch [6/9], Batch [132/428], Loss: 0.0171
Epoch [6/9], Batch [133/428], Loss: 0.0052
Epoch [6/9], Batch [134/428], Loss: 3.0241
Epoch [6/9], Batch [135/428], Loss: 0.0024
Epoch [6/9], Batch [136/428], Loss: 0.0011
Epoch [6/9], Batch [137/428], Loss: 2.2068
Epoch [6/9], Batch [138/428], Loss: 1.6616
Epoch [6/9], Batch [139/428], Loss: 0.1428
Epoch [6/9], Batch [140/428], Loss: 0.2082
Epoch [6/9], Batch [141/428], Loss: 1.4826
Epoch [6/9], Batch [142/428], Loss: 0.0016
Epoch [6/9], Batch [143/428], Loss: 7.1474
Epoch [6/9], Batch [144/428], Loss: 0.0009
Epoch [6/9], Batch [145/428], Loss: 1.8924
Epoch [6/9], Batch [146/428], Loss: 5.0765
Epoch [6/9], Batch [147/428], Loss: 3.8335
Epoch [6/9], Batch [148/428], Loss: 0.0004
Epoch [6/9], Batch [149/428], Loss: 0.3641
Epoch [6/9], Batch [150/428], Loss: 1.7418
Epoch [6/9], Batch [151/428], Loss: 6.0956
Epoch [6/9], Batch [152/428], Loss: 1.4983
Epoch [6/9], Batch [153/428], Loss: 0.0008
Epoch [6/9], Batch [154/428], Loss: 2.3137
Epoch [6/9], Batch [155/428], Loss: 7.5321
Epoch [6/9], Batch [156/428], Loss: 7.9098
Epoch [6/9], Batch [157/428], Loss: 1.8493
Epoch [6/9], Batch [158/428], Loss: 1.6287
Epoch [6/9], Batch [159/428], Loss: 4.5706
Epoch [6/9], Batch [160/428], Loss: 2.7211
Epoch [6/9], Batch [161/428], Loss: 0.3495
Epoch [6/9], Batch [162/428], Loss: 2.6227
Epoch [6/9], Batch [163/428], Loss: 0.0469
Epoch [6/9], Batch [164/428], Loss: 1.7743
Epoch [6/9], Batch [165/428], Loss: 0.7016
Epoch [6/9], Batch [166/428], Loss: 1.2823
Epoch [6/9], Batch [167/428], Loss: 0.1530
Epoch [6/9], Batch [168/428], Loss: 1.1259
Epoch [6/9], Batch [169/428], Loss: 2.4442
Epoch [6/9], Batch [170/428], Loss: 0.6090
Epoch [6/9], Batch [171/428], Loss: 0.0706
Epoch [6/9], Batch [172/428], Loss: 1.2551
Epoch [6/9], Batch [173/428], Loss: 0.0014
Epoch [6/9], Batch [174/428], Loss: 7.6208
Epoch [6/9], Batch [175/428], Loss: 2.5678
Epoch [6/9], Batch [176/428], Loss: 0.0049
Epoch [6/9], Batch [177/428], Loss: 0.3528
Epoch [6/9], Batch [178/428], Loss: 0.1591
Epoch [6/9], Batch [179/428], Loss: 0.0013
Epoch [6/9], Batch [180/428], Loss: 3.1327
Epoch [6/9], Batch [181/428], Loss: 0.0773
Epoch [6/9], Batch [182/428], Loss: 0.0107
Epoch [6/9], Batch [183/428], Loss: 0.6417
Epoch [6/9], Batch [184/428], Loss: 0.0264
Epoch [6/9], Batch [185/428], Loss: 6.8874
Epoch [6/9], Batch [186/428], Loss: 0.0034
Epoch [6/9], Batch [187/428], Loss: 2.2914
Epoch [6/9], Batch [188/428], Loss: 6.5501
Epoch [6/9], Batch [189/428], Loss: 6.8511
Epoch [6/9], Batch [190/428], Loss: 3.1965
Epoch [6/9], Batch [191/428], Loss: 6.4590
Epoch [6/9], Batch [192/428], Loss: 0.0036
Epoch [6/9], Batch [193/428], Loss: 0.0048
Epoch [6/9], Batch [194/428], Loss: 0.0054
Epoch [6/9], Batch [195/428], Loss: 6.0243
Epoch [6/9], Batch [196/428], Loss: 0.0056
Epoch [6/9], Batch [197/428], Loss: 8.3183
Epoch [6/9], Batch [198/428], Loss: 0.0058
Epoch [6/9], Batch [199/428], Loss: 0.0015
Epoch [6/9], Batch [200/428], Loss: 0.3274
Epoch [6/9], Batch [201/428], Loss: 0.4832
Epoch [6/9], Batch [202/428], Loss: 0.2744
Epoch [6/9], Batch [203/428], Loss: 6.3767
Epoch [6/9], Batch [204/428], Loss: 7.1540
Epoch [6/9], Batch [205/428], Loss: 0.0070
Epoch [6/9], Batch [206/428], Loss: 0.0052
Epoch [6/9], Batch [207/428], Loss: 0.0023
Epoch [6/9], Batch [208/428], Loss: 5.1684
Epoch [6/9], Batch [209/428], Loss: 0.0822
Epoch [6/9], Batch [210/428], Loss: 5.1136
Epoch [6/9], Batch [211/428], Loss: 0.0037
Epoch [6/9], Batch [212/428], Loss: 0.0016
Epoch [6/9], Batch [213/428], Loss: 0.0219
Epoch [6/9], Batch [214/428], Loss: 0.0015
Epoch [6/9], Batch [215/428], Loss: 5.7836
Epoch [6/9], Batch [216/428], Loss: 0.0052
Epoch [6/9], Batch [217/428], Loss: 0.0013
Epoch [6/9], Batch [218/428], Loss: 4.9126
Epoch [6/9], Batch [219/428], Loss: 0.0150
Epoch [6/9], Batch [220/428], Loss: 3.6253
Epoch [6/9], Batch [221/428], Loss: 0.0057
Epoch [6/9], Batch [222/428], Loss: 0.0009
Epoch [6/9], Batch [223/428], Loss: 1.1349
Epoch [6/9], Batch [224/428], Loss: 6.5939
Epoch [6/9], Batch [225/428], Loss: 0.0330
Epoch [6/9], Batch [226/428], Loss: 0.0012
Epoch [6/9], Batch [227/428], Loss: 0.0193
Epoch [6/9], Batch [228/428], Loss: 0.4829
Epoch [6/9], Batch [229/428], Loss: 1.8952
Epoch [6/9], Batch [230/428], Loss: 0.0005
Epoch [6/9], Batch [231/428], Loss: 0.0004
Epoch [6/9], Batch [232/428], Loss: 0.0002
Epoch [6/9], Batch [233/428], Loss: 5.5028
Epoch [6/9], Batch [234/428], Loss: 2.6117
Epoch [6/9], Batch [235/428], Loss: 0.3907
Epoch [6/9], Batch [236/428], Loss: 8.5676
Epoch [6/9], Batch [237/428], Loss: 8.2630
Epoch [6/9], Batch [238/428], Loss: 2.3990
Epoch [6/9], Batch [239/428], Loss: 0.3201
Epoch [6/9], Batch [240/428], Loss: 0.0005
Epoch [6/9], Batch [241/428], Loss: 3.7959
Epoch [6/9], Batch [242/428], Loss: 0.0014
Epoch [6/9], Batch [243/428], Loss: 3.1169
Epoch [6/9], Batch [244/428], Loss: 4.3474
Epoch [6/9], Batch [245/428], Loss: 0.0018
Epoch [6/9], Batch [246/428], Loss: 0.4923
Epoch [6/9], Batch [247/428], Loss: 0.0254
Epoch [6/9], Batch [248/428], Loss: 3.2091
Epoch [6/9], Batch [249/428], Loss: 0.7695
Epoch [6/9], Batch [250/428], Loss: 4.2879
Epoch [6/9], Batch [251/428], Loss: 4.5786
Epoch [6/9], Batch [252/428], Loss: 7.0498
Epoch [6/9], Batch [253/428], Loss: 0.0025
Epoch [6/9], Batch [254/428], Loss: 0.0003
Epoch [6/9], Batch [255/428], Loss: 0.0022
Epoch [6/9], Batch [256/428], Loss: 0.0020
Epoch [6/9], Batch [257/428], Loss: 0.7467
Epoch [6/9], Batch [258/428], Loss: 0.0014
Epoch [6/9], Batch [259/428], Loss: 1.5147
Epoch [6/9], Batch [260/428], Loss: 2.2740
Epoch [6/9], Batch [261/428], Loss: 3.7803
Epoch [6/9], Batch [262/428], Loss: 0.9192
Epoch [6/9], Batch [263/428], Loss: 3.8904
Epoch [6/9], Batch [264/428], Loss: 3.3070
Epoch [6/9], Batch [265/428], Loss: 1.5219
Epoch [6/9], Batch [266/428], Loss: 0.1154
Epoch [6/9], Batch [267/428], Loss: 0.0194
Epoch [6/9], Batch [268/428], Loss: 1.1657
Epoch [6/9], Batch [269/428], Loss: 1.4391
Epoch [6/9], Batch [270/428], Loss: 0.3347
Epoch [6/9], Batch [271/428], Loss: 0.0207
Epoch [6/9], Batch [272/428], Loss: 0.2052
Epoch [6/9], Batch [273/428], Loss: 0.0050
Epoch [6/9], Batch [274/428], Loss: 0.0007
Epoch [6/9], Batch [275/428], Loss: 1.1154
Epoch [6/9], Batch [276/428], Loss: 0.0015
Epoch [6/9], Batch [277/428], Loss: 3.9805
Epoch [6/9], Batch [278/428], Loss: 3.8140
Epoch [6/9], Batch [279/428], Loss: 0.1887
Epoch [6/9], Batch [280/428], Loss: 3.0450
Epoch [6/9], Batch [281/428], Loss: 0.5475
Epoch [6/9], Batch [282/428], Loss: 0.9921
Epoch [6/9], Batch [283/428], Loss: 1.1162
Epoch [6/9], Batch [284/428], Loss: 0.0004
Epoch [6/9], Batch [285/428], Loss: 0.4957
Epoch [6/9], Batch [286/428], Loss: 2.4535
Epoch [6/9], Batch [287/428], Loss: 0.0003
Epoch [6/9], Batch [288/428], Loss: 0.0005
Epoch [6/9], Batch [289/428], Loss: 3.2334
Epoch [6/9], Batch [290/428], Loss: 1.9154
Epoch [6/9], Batch [291/428], Loss: 0.6076
Epoch [6/9], Batch [292/428], Loss: 0.0727
Epoch [6/9], Batch [293/428], Loss: 0.0004
Epoch [6/9], Batch [294/428], Loss: 3.8209
Epoch [6/9], Batch [295/428], Loss: 7.7587
Epoch [6/9], Batch [296/428], Loss: 0.4278
Epoch [6/9], Batch [297/428], Loss: 0.0894
Epoch [6/9], Batch [298/428], Loss: 0.0007
Epoch [6/9], Batch [299/428], Loss: 0.9023
Epoch [6/9], Batch [300/428], Loss: 0.0577
Epoch [6/9], Batch [301/428], Loss: 0.0107
Epoch [6/9], Batch [302/428], Loss: 5.3040
Epoch [6/9], Batch [303/428], Loss: 1.9378
Epoch [6/9], Batch [304/428], Loss: 0.0056
Epoch [6/9], Batch [305/428], Loss: 0.9073
Epoch [6/9], Batch [306/428], Loss: 0.1645
Epoch [6/9], Batch [307/428], Loss: 0.0518
Epoch [6/9], Batch [308/428], Loss: 3.6711
Epoch [6/9], Batch [309/428], Loss: 6.4538
Epoch [6/9], Batch [310/428], Loss: 1.6665
Epoch [6/9], Batch [311/428], Loss: 2.2531
Epoch [6/9], Batch [312/428], Loss: 1.2228
Epoch [6/9], Batch [313/428], Loss: 0.0010
Epoch [6/9], Batch [314/428], Loss: 1.0624
Epoch [6/9], Batch [315/428], Loss: 0.0495
Epoch [6/9], Batch [316/428], Loss: 0.0014
Epoch [6/9], Batch [317/428], Loss: 0.1740
Epoch [6/9], Batch [318/428], Loss: 0.4484
Epoch [6/9], Batch [319/428], Loss: 0.4595
Epoch [6/9], Batch [320/428], Loss: 0.0338
Epoch [6/9], Batch [321/428], Loss: 0.7294
Epoch [6/9], Batch [322/428], Loss: 0.0021
Epoch [6/9], Batch [323/428], Loss: 0.0025
Epoch [6/9], Batch [324/428], Loss: 2.3625
Epoch [6/9], Batch [325/428], Loss: 0.0605
Epoch [6/9], Batch [326/428], Loss: 0.0029
Epoch [6/9], Batch [327/428], Loss: 0.0009
Epoch [6/9], Batch [328/428], Loss: 0.0006
Epoch [6/9], Batch [329/428], Loss: 0.0006
Epoch [6/9], Batch [330/428], Loss: 5.1339
Epoch [6/9], Batch [331/428], Loss: 6.2480
Epoch [6/9], Batch [332/428], Loss: 0.0003
Epoch [6/9], Batch [333/428], Loss: 0.0012
Epoch [6/9], Batch [334/428], Loss: 7.4744
Epoch [6/9], Batch [335/428], Loss: 1.4214
Epoch [6/9], Batch [336/428], Loss: 4.3516
Epoch [6/9], Batch [337/428], Loss: 2.2269
Epoch [6/9], Batch [338/428], Loss: 0.0003
Epoch [6/9], Batch [339/428], Loss: 0.0003
Epoch [6/9], Batch [340/428], Loss: 0.0003
Epoch [6/9], Batch [341/428], Loss: 0.0563
Epoch [6/9], Batch [342/428], Loss: 0.0004
Epoch [6/9], Batch [343/428], Loss: 0.2771
Epoch [6/9], Batch [344/428], Loss: 0.2981
Epoch [6/9], Batch [345/428], Loss: 6.2368
Epoch [6/9], Batch [346/428], Loss: 0.7494
Epoch [6/9], Batch [347/428], Loss: 0.0317
Epoch [6/9], Batch [348/428], Loss: 0.0001
Epoch [6/9], Batch [349/428], Loss: 2.8937
Epoch [6/9], Batch [350/428], Loss: 4.5355
Epoch [6/9], Batch [351/428], Loss: 0.0015
Epoch [6/9], Batch [352/428], Loss: 0.0031
Epoch [6/9], Batch [353/428], Loss: 1.9554
Epoch [6/9], Batch [354/428], Loss: 0.0007
Epoch [6/9], Batch [355/428], Loss: 1.9297
Epoch [6/9], Batch [356/428], Loss: 0.0460
Epoch [6/9], Batch [357/428], Loss: 0.0002
Epoch [6/9], Batch [358/428], Loss: 1.4138
Epoch [6/9], Batch [359/428], Loss: 0.0005
Epoch [6/9], Batch [360/428], Loss: 0.0029
Epoch [6/9], Batch [361/428], Loss: 0.0003
Epoch [6/9], Batch [362/428], Loss: 0.4640
Epoch [6/9], Batch [363/428], Loss: 0.0022
Epoch [6/9], Batch [364/428], Loss: 4.2916
Epoch [6/9], Batch [365/428], Loss: 2.6699
Epoch [6/9], Batch [366/428], Loss: 0.0004
Epoch [6/9], Batch [367/428], Loss: 0.0003
Epoch [6/9], Batch [368/428], Loss: 3.9596
Epoch [6/9], Batch [369/428], Loss: 0.6103
Epoch [6/9], Batch [370/428], Loss: 0.0002
Epoch [6/9], Batch [371/428], Loss: 0.0001
Epoch [6/9], Batch [372/428], Loss: 5.5968
Epoch [6/9], Batch [373/428], Loss: 0.0723
Epoch [6/9], Batch [374/428], Loss: 5.5790
Epoch [6/9], Batch [375/428], Loss: 0.1858
Epoch [6/9], Batch [376/428], Loss: 0.0004
Epoch [6/9], Batch [377/428], Loss: 0.0001
Epoch [6/9], Batch [378/428], Loss: 0.0381
Epoch [6/9], Batch [379/428], Loss: 0.0938
Epoch [6/9], Batch [380/428], Loss: 0.0017
Epoch [6/9], Batch [381/428], Loss: 0.5784
Epoch [6/9], Batch [382/428], Loss: 0.5222
Epoch [6/9], Batch [383/428], Loss: 0.0002
Epoch [6/9], Batch [384/428], Loss: 3.6367
Epoch [6/9], Batch [385/428], Loss: 0.0002
Epoch [6/9], Batch [386/428], Loss: 2.1586
Epoch [6/9], Batch [387/428], Loss: 4.0132
Epoch [6/9], Batch [388/428], Loss: 0.0003
Epoch [6/9], Batch [389/428], Loss: 0.0001
Epoch [6/9], Batch [390/428], Loss: 1.7391
Epoch [6/9], Batch [391/428], Loss: 1.2000
Epoch [6/9], Batch [392/428], Loss: 5.2976
Epoch [6/9], Batch [393/428], Loss: 0.0003
Epoch [6/9], Batch [394/428], Loss: 0.0002
Epoch [6/9], Batch [395/428], Loss: 0.1547
Epoch [6/9], Batch [396/428], Loss: 1.8210
Epoch [6/9], Batch [397/428], Loss: 0.0002
Epoch [6/9], Batch [398/428], Loss: 0.0002
Epoch [6/9], Batch [399/428], Loss: 0.0002
Epoch [6/9], Batch [400/428], Loss: 8.7546
Epoch [6/9], Batch [401/428], Loss: 1.6952
Epoch [6/9], Batch [402/428], Loss: 0.0821
Epoch [6/9], Batch [403/428], Loss: 0.7005
Epoch [6/9], Batch [404/428], Loss: 0.0004
Epoch [6/9], Batch [405/428], Loss: 0.0006
Epoch [6/9], Batch [406/428], Loss: 3.5818
Epoch [6/9], Batch [407/428], Loss: 2.8413
Epoch [6/9], Batch [408/428], Loss: 0.0008
Epoch [6/9], Batch [409/428], Loss: 7.1105
Epoch [6/9], Batch [410/428], Loss: 0.7998
Epoch [6/9], Batch [411/428], Loss: 0.0011
Epoch [6/9], Batch [412/428], Loss: 3.4149
Epoch [6/9], Batch [413/428], Loss: 0.0010
Epoch [6/9], Batch [414/428], Loss: 0.0010
Epoch [6/9], Batch [415/428], Loss: 0.3339
Epoch [6/9], Batch [416/428], Loss: 0.0337
Epoch [6/9], Batch [417/428], Loss: 0.3499
Epoch [6/9], Batch [418/428], Loss: 0.7387
Epoch [6/9], Batch [419/428], Loss: 0.4256
Epoch [6/9], Batch [420/428], Loss: 0.0008
Epoch [6/9], Batch [421/428], Loss: 6.8267
Epoch [6/9], Batch [422/428], Loss: 0.1539
Epoch [6/9], Batch [423/428], Loss: 0.0143
Epoch [6/9], Batch [424/428], Loss: 0.0927
Epoch [6/9], Batch [425/428], Loss: 0.0019
Epoch [6/9], Batch [426/428], Loss: 0.0446
Epoch [6/9], Batch [427/428], Loss: 0.0027
Epoch [6/9], Batch [428/428], Loss: 3.8500
Epoch [6] Training Time: 534.37 seconds
Epoch [6/9], Average Loss: 1.6638, Training Accuracy: 0.5654
Epoch [6], Validation Loss: 1.1117, Validation Accuracy: 0.6512
Epoch [6] Validation Time: 23.03 seconds
--------------------------------------------------
Epoch [7/9], Batch [1/428], Loss: 2.3725
Epoch [7/9], Batch [2/428], Loss: 0.0044
Epoch [7/9], Batch [3/428], Loss: 0.0031
Epoch [7/9], Batch [4/428], Loss: 0.0030
Epoch [7/9], Batch [5/428], Loss: 2.6326
Epoch [7/9], Batch [6/428], Loss: 0.3692
Epoch [7/9], Batch [7/428], Loss: 0.0088
Epoch [7/9], Batch [8/428], Loss: 0.0405
Epoch [7/9], Batch [9/428], Loss: 0.0010
Epoch [7/9], Batch [10/428], Loss: 0.0002
Epoch [7/9], Batch [11/428], Loss: 1.4399
Epoch [7/9], Batch [12/428], Loss: 0.0013
Epoch [7/9], Batch [13/428], Loss: 0.0001
Epoch [7/9], Batch [14/428], Loss: 0.0014
Epoch [7/9], Batch [15/428], Loss: 0.0003
Epoch [7/9], Batch [16/428], Loss: 5.1918
Epoch [7/9], Batch [17/428], Loss: 0.0006
Epoch [7/9], Batch [18/428], Loss: 0.0014
Epoch [7/9], Batch [19/428], Loss: 2.9997
Epoch [7/9], Batch [20/428], Loss: 5.7930
Epoch [7/9], Batch [21/428], Loss: 3.0372
Epoch [7/9], Batch [22/428], Loss: 1.7009
Epoch [7/9], Batch [23/428], Loss: 0.0317
Epoch [7/9], Batch [24/428], Loss: 0.0001
Epoch [7/9], Batch [25/428], Loss: 1.4137
Epoch [7/9], Batch [26/428], Loss: 0.0003
Epoch [7/9], Batch [27/428], Loss: 0.0035
Epoch [7/9], Batch [28/428], Loss: 2.3855
Epoch [7/9], Batch [29/428], Loss: 0.0004
Epoch [7/9], Batch [30/428], Loss: 1.8368
Epoch [7/9], Batch [31/428], Loss: 0.1411
Epoch [7/9], Batch [32/428], Loss: 0.2079
Epoch [7/9], Batch [33/428], Loss: 0.2270
Epoch [7/9], Batch [34/428], Loss: 0.0587
Epoch [7/9], Batch [35/428], Loss: 0.0051
Epoch [7/9], Batch [36/428], Loss: 0.0101
Epoch [7/9], Batch [37/428], Loss: 0.0830
Epoch [7/9], Batch [38/428], Loss: 0.0023
Epoch [7/9], Batch [39/428], Loss: 3.4294
Epoch [7/9], Batch [40/428], Loss: 2.1961
Epoch [7/9], Batch [41/428], Loss: 0.0024
Epoch [7/9], Batch [42/428], Loss: 0.0012
Epoch [7/9], Batch [43/428], Loss: 0.0009
Epoch [7/9], Batch [44/428], Loss: 0.0010
Epoch [7/9], Batch [45/428], Loss: 0.0006
Epoch [7/9], Batch [46/428], Loss: 0.0009
Epoch [7/9], Batch [47/428], Loss: 0.0037
Epoch [7/9], Batch [48/428], Loss: 1.6225
Epoch [7/9], Batch [49/428], Loss: 0.0005
Epoch [7/9], Batch [50/428], Loss: 0.0864
Epoch [7/9], Batch [51/428], Loss: 0.0138
Epoch [7/9], Batch [52/428], Loss: 0.0852
Epoch [7/9], Batch [53/428], Loss: 0.0003
Epoch [7/9], Batch [54/428], Loss: 4.0381
Epoch [7/9], Batch [55/428], Loss: 0.9095
Epoch [7/9], Batch [56/428], Loss: 0.0015
Epoch [7/9], Batch [57/428], Loss: 0.0926
Epoch [7/9], Batch [58/428], Loss: 0.4926
Epoch [7/9], Batch [59/428], Loss: 8.1797
Epoch [7/9], Batch [60/428], Loss: 0.0335
Epoch [7/9], Batch [61/428], Loss: 0.0013
Epoch [7/9], Batch [62/428], Loss: 0.0027
Epoch [7/9], Batch [63/428], Loss: 0.0002
Epoch [7/9], Batch [64/428], Loss: 3.5067
Epoch [7/9], Batch [65/428], Loss: 2.3233
Epoch [7/9], Batch [66/428], Loss: 0.0008
Epoch [7/9], Batch [67/428], Loss: 0.0003
Epoch [7/9], Batch [68/428], Loss: 0.0753
Epoch [7/9], Batch [69/428], Loss: 0.0013
Epoch [7/9], Batch [70/428], Loss: 0.0001
Epoch [7/9], Batch [71/428], Loss: 0.1162
Epoch [7/9], Batch [72/428], Loss: 1.6330
Epoch [7/9], Batch [73/428], Loss: 3.0749
Epoch [7/9], Batch [74/428], Loss: 0.9729
Epoch [7/9], Batch [75/428], Loss: 0.0093
Epoch [7/9], Batch [76/428], Loss: 0.0914
Epoch [7/9], Batch [77/428], Loss: 0.0007
Epoch [7/9], Batch [78/428], Loss: 0.6489
Epoch [7/9], Batch [79/428], Loss: 0.0002
Epoch [7/9], Batch [80/428], Loss: 1.4846
Epoch [7/9], Batch [81/428], Loss: 0.4493
Epoch [7/9], Batch [82/428], Loss: 0.0010
Epoch [7/9], Batch [83/428], Loss: 0.0010
Epoch [7/9], Batch [84/428], Loss: 0.1874
Epoch [7/9], Batch [85/428], Loss: 0.0005
Epoch [7/9], Batch [86/428], Loss: 0.2661
Epoch [7/9], Batch [87/428], Loss: 0.0002
Epoch [7/9], Batch [88/428], Loss: 0.8264
Epoch [7/9], Batch [89/428], Loss: 0.0086
Epoch [7/9], Batch [90/428], Loss: 0.0003
Epoch [7/9], Batch [91/428], Loss: 0.0003
Epoch [7/9], Batch [92/428], Loss: 0.0008
Epoch [7/9], Batch [93/428], Loss: 5.3714
Epoch [7/9], Batch [94/428], Loss: 3.9208
Epoch [7/9], Batch [95/428], Loss: 0.0003
Epoch [7/9], Batch [96/428], Loss: 3.2825
Epoch [7/9], Batch [97/428], Loss: 0.0008
Epoch [7/9], Batch [98/428], Loss: 0.7070
Epoch [7/9], Batch [99/428], Loss: 0.0028
Epoch [7/9], Batch [100/428], Loss: 1.6053
Epoch [7/9], Batch [101/428], Loss: 0.1189
Epoch [7/9], Batch [102/428], Loss: 0.0004
Epoch [7/9], Batch [103/428], Loss: 1.0067
Epoch [7/9], Batch [104/428], Loss: 1.4443
Epoch [7/9], Batch [105/428], Loss: 0.0704
Epoch [7/9], Batch [106/428], Loss: 0.0006
Epoch [7/9], Batch [107/428], Loss: 0.6068
Epoch [7/9], Batch [108/428], Loss: 1.2552
Epoch [7/9], Batch [109/428], Loss: 0.0212
Epoch [7/9], Batch [110/428], Loss: 0.0002
Epoch [7/9], Batch [111/428], Loss: 0.1111
Epoch [7/9], Batch [112/428], Loss: 0.0078
Epoch [7/9], Batch [113/428], Loss: 0.0002
Epoch [7/9], Batch [114/428], Loss: 1.2197
Epoch [7/9], Batch [115/428], Loss: 0.0002
Epoch [7/9], Batch [116/428], Loss: 0.0351
Epoch [7/9], Batch [117/428], Loss: 0.0001
Epoch [7/9], Batch [118/428], Loss: 0.0001
Epoch [7/9], Batch [119/428], Loss: 0.0001
Epoch [7/9], Batch [120/428], Loss: 2.4834
Epoch [7/9], Batch [121/428], Loss: 6.4609
Epoch [7/9], Batch [122/428], Loss: 1.7402
Epoch [7/9], Batch [123/428], Loss: 0.0004
Epoch [7/9], Batch [124/428], Loss: 1.1273
Epoch [7/9], Batch [125/428], Loss: 4.4201
Epoch [7/9], Batch [126/428], Loss: 6.4819
Epoch [7/9], Batch [127/428], Loss: 0.0171
Epoch [7/9], Batch [128/428], Loss: 0.0004
Epoch [7/9], Batch [129/428], Loss: 0.0002
Epoch [7/9], Batch [130/428], Loss: 4.1899
Epoch [7/9], Batch [131/428], Loss: 0.0006
Epoch [7/9], Batch [132/428], Loss: 0.0158
Epoch [7/9], Batch [133/428], Loss: 0.1802
Epoch [7/9], Batch [134/428], Loss: 0.0427
Epoch [7/9], Batch [135/428], Loss: 0.0002
Epoch [7/9], Batch [136/428], Loss: 0.0060
Epoch [7/9], Batch [137/428], Loss: 0.0005
Epoch [7/9], Batch [138/428], Loss: 0.0080
Epoch [7/9], Batch [139/428], Loss: 0.0019
Epoch [7/9], Batch [140/428], Loss: 0.0027
Epoch [7/9], Batch [141/428], Loss: 0.0049
Epoch [7/9], Batch [142/428], Loss: 0.0459
Epoch [7/9], Batch [143/428], Loss: 0.0875
Epoch [7/9], Batch [144/428], Loss: 0.0003
Epoch [7/9], Batch [145/428], Loss: 0.3168
Epoch [7/9], Batch [146/428], Loss: 0.6332
Epoch [7/9], Batch [147/428], Loss: 0.0073
Epoch [7/9], Batch [148/428], Loss: 0.1006
Epoch [7/9], Batch [149/428], Loss: 0.0001
Epoch [7/9], Batch [150/428], Loss: 0.0001
Epoch [7/9], Batch [151/428], Loss: 0.0099
Epoch [7/9], Batch [152/428], Loss: 0.0295
Epoch [7/9], Batch [153/428], Loss: 0.0001
Epoch [7/9], Batch [154/428], Loss: 0.0000
Epoch [7/9], Batch [155/428], Loss: 0.0037
Epoch [7/9], Batch [156/428], Loss: 3.5681
Epoch [7/9], Batch [157/428], Loss: 0.0001
Epoch [7/9], Batch [158/428], Loss: 0.0000
Epoch [7/9], Batch [159/428], Loss: 0.0001
Epoch [7/9], Batch [160/428], Loss: 4.3051
Epoch [7/9], Batch [161/428], Loss: 0.0000
Epoch [7/9], Batch [162/428], Loss: 0.0001
Epoch [7/9], Batch [163/428], Loss: 0.0001
Epoch [7/9], Batch [164/428], Loss: 0.1700
Epoch [7/9], Batch [165/428], Loss: 0.0004
Epoch [7/9], Batch [166/428], Loss: 0.0000
Epoch [7/9], Batch [167/428], Loss: 0.0001
Epoch [7/9], Batch [168/428], Loss: 0.0001
Epoch [7/9], Batch [169/428], Loss: 0.0001
Epoch [7/9], Batch [170/428], Loss: 0.0002
Epoch [7/9], Batch [171/428], Loss: 0.0001
Epoch [7/9], Batch [172/428], Loss: 0.0001
Epoch [7/9], Batch [173/428], Loss: 0.0652
Epoch [7/9], Batch [174/428], Loss: 0.0001
Epoch [7/9], Batch [175/428], Loss: 0.0005
Epoch [7/9], Batch [176/428], Loss: 0.0026
Epoch [7/9], Batch [177/428], Loss: 2.7221
Epoch [7/9], Batch [178/428], Loss: 1.3688
Epoch [7/9], Batch [179/428], Loss: 1.2678
Epoch [7/9], Batch [180/428], Loss: 1.6109
Epoch [7/9], Batch [181/428], Loss: 0.1016
Epoch [7/9], Batch [182/428], Loss: 0.0011
Epoch [7/9], Batch [183/428], Loss: 0.0017
Epoch [7/9], Batch [184/428], Loss: 0.0003
Epoch [7/9], Batch [185/428], Loss: 0.0000
Epoch [7/9], Batch [186/428], Loss: 0.1144
Epoch [7/9], Batch [187/428], Loss: 3.8842
Epoch [7/9], Batch [188/428], Loss: 0.1222
Epoch [7/9], Batch [189/428], Loss: 0.0131
Epoch [7/9], Batch [190/428], Loss: 1.0162
Epoch [7/9], Batch [191/428], Loss: 0.1720
Epoch [7/9], Batch [192/428], Loss: 0.0230
Epoch [7/9], Batch [193/428], Loss: 0.0001
Epoch [7/9], Batch [194/428], Loss: 0.0017
Epoch [7/9], Batch [195/428], Loss: 0.0230
Epoch [7/9], Batch [196/428], Loss: 1.0797
Epoch [7/9], Batch [197/428], Loss: 0.0000
Epoch [7/9], Batch [198/428], Loss: 0.0002
Epoch [7/9], Batch [199/428], Loss: 0.0001
Epoch [7/9], Batch [200/428], Loss: 0.0000
Epoch [7/9], Batch [201/428], Loss: 0.0226
Epoch [7/9], Batch [202/428], Loss: 0.0005
Epoch [7/9], Batch [203/428], Loss: 0.0058
Epoch [7/9], Batch [204/428], Loss: 0.0008
Epoch [7/9], Batch [205/428], Loss: 1.0574
Epoch [7/9], Batch [206/428], Loss: 0.0184
Epoch [7/9], Batch [207/428], Loss: 0.0008
Epoch [7/9], Batch [208/428], Loss: 1.7174
Epoch [7/9], Batch [209/428], Loss: 2.8056
Epoch [7/9], Batch [210/428], Loss: 0.0001
Epoch [7/9], Batch [211/428], Loss: 0.1860
Epoch [7/9], Batch [212/428], Loss: 0.0001
Epoch [7/9], Batch [213/428], Loss: 0.0001
Epoch [7/9], Batch [214/428], Loss: 0.0000
Epoch [7/9], Batch [215/428], Loss: 0.0022
Epoch [7/9], Batch [216/428], Loss: 0.4292
Epoch [7/9], Batch [217/428], Loss: 0.0001
Epoch [7/9], Batch [218/428], Loss: 0.0008
Epoch [7/9], Batch [219/428], Loss: 0.4104
Epoch [7/9], Batch [220/428], Loss: 0.0114
Epoch [7/9], Batch [221/428], Loss: 0.2693
Epoch [7/9], Batch [222/428], Loss: 0.2706
Epoch [7/9], Batch [223/428], Loss: 0.7886
Epoch [7/9], Batch [224/428], Loss: 0.0001
Epoch [7/9], Batch [225/428], Loss: 0.5083
Epoch [7/9], Batch [226/428], Loss: 0.2362
Epoch [7/9], Batch [227/428], Loss: 0.0001
Epoch [7/9], Batch [228/428], Loss: 0.0001
Epoch [7/9], Batch [229/428], Loss: 0.0082
Epoch [7/9], Batch [230/428], Loss: 0.0036
Epoch [7/9], Batch [231/428], Loss: 0.0585
Epoch [7/9], Batch [232/428], Loss: 0.7803
Epoch [7/9], Batch [233/428], Loss: 0.0001
Epoch [7/9], Batch [234/428], Loss: 0.0007
Epoch [7/9], Batch [235/428], Loss: 0.0001
Epoch [7/9], Batch [236/428], Loss: 0.0002
Epoch [7/9], Batch [237/428], Loss: 0.0001
Epoch [7/9], Batch [238/428], Loss: 0.0009
Epoch [7/9], Batch [239/428], Loss: 0.0003
Epoch [7/9], Batch [240/428], Loss: 0.0001
Epoch [7/9], Batch [241/428], Loss: 5.9333
Epoch [7/9], Batch [242/428], Loss: 3.1349
Epoch [7/9], Batch [243/428], Loss: 0.0071
Epoch [7/9], Batch [244/428], Loss: 0.0001
Epoch [7/9], Batch [245/428], Loss: 0.0001
Epoch [7/9], Batch [246/428], Loss: 0.0007
Epoch [7/9], Batch [247/428], Loss: 0.0009
Epoch [7/9], Batch [248/428], Loss: 0.0003
Epoch [7/9], Batch [249/428], Loss: 0.7316
Epoch [7/9], Batch [250/428], Loss: 0.3612
Epoch [7/9], Batch [251/428], Loss: 0.0001
Epoch [7/9], Batch [252/428], Loss: 0.0034
Epoch [7/9], Batch [253/428], Loss: 0.0001
Epoch [7/9], Batch [254/428], Loss: 0.0001
Epoch [7/9], Batch [255/428], Loss: 0.0001
Epoch [7/9], Batch [256/428], Loss: 0.0001
Epoch [7/9], Batch [257/428], Loss: 0.0001
Epoch [7/9], Batch [258/428], Loss: 0.0258
Epoch [7/9], Batch [259/428], Loss: 0.0002
Epoch [7/9], Batch [260/428], Loss: 0.0002
Epoch [7/9], Batch [261/428], Loss: 0.0001
Epoch [7/9], Batch [262/428], Loss: 2.3971
Epoch [7/9], Batch [263/428], Loss: 0.0003
Epoch [7/9], Batch [264/428], Loss: 1.8856
Epoch [7/9], Batch [265/428], Loss: 0.0001
Epoch [7/9], Batch [266/428], Loss: 0.0001
Epoch [7/9], Batch [267/428], Loss: 0.6167
Epoch [7/9], Batch [268/428], Loss: 0.0001
Epoch [7/9], Batch [269/428], Loss: 0.0001
Epoch [7/9], Batch [270/428], Loss: 0.0000
Epoch [7/9], Batch [271/428], Loss: 0.0009
Epoch [7/9], Batch [272/428], Loss: 2.3164
Epoch [7/9], Batch [273/428], Loss: 0.0123
Epoch [7/9], Batch [274/428], Loss: 0.0001
Epoch [7/9], Batch [275/428], Loss: 0.1719
Epoch [7/9], Batch [276/428], Loss: 0.0004
Epoch [7/9], Batch [277/428], Loss: 0.0003
Epoch [7/9], Batch [278/428], Loss: 0.0010
Epoch [7/9], Batch [279/428], Loss: 0.0001
Epoch [7/9], Batch [280/428], Loss: 0.0001
Epoch [7/9], Batch [281/428], Loss: 0.0010
Epoch [7/9], Batch [282/428], Loss: 0.4523
Epoch [7/9], Batch [283/428], Loss: 0.0001
Epoch [7/9], Batch [284/428], Loss: 0.0001
Epoch [7/9], Batch [285/428], Loss: 0.0001
Epoch [7/9], Batch [286/428], Loss: 0.0117
Epoch [7/9], Batch [287/428], Loss: 0.0004
Epoch [7/9], Batch [288/428], Loss: 0.0001
Epoch [7/9], Batch [289/428], Loss: 2.4947
Epoch [7/9], Batch [290/428], Loss: 0.4047
Epoch [7/9], Batch [291/428], Loss: 0.0268
Epoch [7/9], Batch [292/428], Loss: 3.0803
Epoch [7/9], Batch [293/428], Loss: 0.0001
Epoch [7/9], Batch [294/428], Loss: 0.0001
Epoch [7/9], Batch [295/428], Loss: 0.0000
Epoch [7/9], Batch [296/428], Loss: 0.0189
Epoch [7/9], Batch [297/428], Loss: 0.0001
Epoch [7/9], Batch [298/428], Loss: 0.0037
Epoch [7/9], Batch [299/428], Loss: 0.0016
Epoch [7/9], Batch [300/428], Loss: 0.0003
Epoch [7/9], Batch [301/428], Loss: 0.0002
Epoch [7/9], Batch [302/428], Loss: 8.8424
Epoch [7/9], Batch [303/428], Loss: 0.0001
Epoch [7/9], Batch [304/428], Loss: 0.0001
Epoch [7/9], Batch [305/428], Loss: 0.0052
Epoch [7/9], Batch [306/428], Loss: 0.0080
Epoch [7/9], Batch [307/428], Loss: 0.0011
Epoch [7/9], Batch [308/428], Loss: 0.0047
Epoch [7/9], Batch [309/428], Loss: 0.0006
Epoch [7/9], Batch [310/428], Loss: 0.0001
Epoch [7/9], Batch [311/428], Loss: 0.0002
Epoch [7/9], Batch [312/428], Loss: 0.0000
Epoch [7/9], Batch [313/428], Loss: 0.2092
Epoch [7/9], Batch [314/428], Loss: 7.0642
Epoch [7/9], Batch [315/428], Loss: 0.0006
Epoch [7/9], Batch [316/428], Loss: 0.0003
Epoch [7/9], Batch [317/428], Loss: 3.0780
Epoch [7/9], Batch [318/428], Loss: 0.0003
Epoch [7/9], Batch [319/428], Loss: 9.4122
Epoch [7/9], Batch [320/428], Loss: 0.0002
Epoch [7/9], Batch [321/428], Loss: 0.0022
Epoch [7/9], Batch [322/428], Loss: 0.0037
Epoch [7/9], Batch [323/428], Loss: 0.0010
Epoch [7/9], Batch [324/428], Loss: 0.0497
Epoch [7/9], Batch [325/428], Loss: 0.0001
Epoch [7/9], Batch [326/428], Loss: 0.0000
Epoch [7/9], Batch [327/428], Loss: 0.0043
Epoch [7/9], Batch [328/428], Loss: 0.0002
Epoch [7/9], Batch [329/428], Loss: 0.0005
Epoch [7/9], Batch [330/428], Loss: 0.0001
Epoch [7/9], Batch [331/428], Loss: 0.0018
Epoch [7/9], Batch [332/428], Loss: 1.4838
Epoch [7/9], Batch [333/428], Loss: 0.0001
Epoch [7/9], Batch [334/428], Loss: 0.0005
Epoch [7/9], Batch [335/428], Loss: 0.0005
Epoch [7/9], Batch [336/428], Loss: 0.0001
Epoch [7/9], Batch [337/428], Loss: 0.0000
Epoch [7/9], Batch [338/428], Loss: 0.2713
Epoch [7/9], Batch [339/428], Loss: 0.0004
Epoch [7/9], Batch [340/428], Loss: 0.0000
Epoch [7/9], Batch [341/428], Loss: 0.0004
Epoch [7/9], Batch [342/428], Loss: 0.0003
Epoch [7/9], Batch [343/428], Loss: 0.0020
Epoch [7/9], Batch [344/428], Loss: 0.0001
Epoch [7/9], Batch [345/428], Loss: 0.0110
Epoch [7/9], Batch [346/428], Loss: 0.0002
Epoch [7/9], Batch [347/428], Loss: 4.8425
Epoch [7/9], Batch [348/428], Loss: 6.3137
Epoch [7/9], Batch [349/428], Loss: 0.0000
Epoch [7/9], Batch [350/428], Loss: 0.0002
Epoch [7/9], Batch [351/428], Loss: 0.7314
Epoch [7/9], Batch [352/428], Loss: 0.0019
Epoch [7/9], Batch [353/428], Loss: 0.0275
Epoch [7/9], Batch [354/428], Loss: 0.0331
Epoch [7/9], Batch [355/428], Loss: 0.0006
Epoch [7/9], Batch [356/428], Loss: 2.5696
Epoch [7/9], Batch [357/428], Loss: 0.0001
Epoch [7/9], Batch [358/428], Loss: 0.0001
Epoch [7/9], Batch [359/428], Loss: 0.0001
Epoch [7/9], Batch [360/428], Loss: 0.0086
Epoch [7/9], Batch [361/428], Loss: 0.0531
Epoch [7/9], Batch [362/428], Loss: 0.0001
Epoch [7/9], Batch [363/428], Loss: 4.9155
Epoch [7/9], Batch [364/428], Loss: 0.0001
Epoch [7/9], Batch [365/428], Loss: 0.0001
Epoch [7/9], Batch [366/428], Loss: 0.0002
Epoch [7/9], Batch [367/428], Loss: 0.0001
Epoch [7/9], Batch [368/428], Loss: 0.0001
Epoch [7/9], Batch [369/428], Loss: 0.0922
Epoch [7/9], Batch [370/428], Loss: 0.0004
Epoch [7/9], Batch [371/428], Loss: 0.0000
Epoch [7/9], Batch [372/428], Loss: 0.0001
Epoch [7/9], Batch [373/428], Loss: 0.0001
Epoch [7/9], Batch [374/428], Loss: 0.0000
Epoch [7/9], Batch [375/428], Loss: 0.0061
Epoch [7/9], Batch [376/428], Loss: 0.0001
Epoch [7/9], Batch [377/428], Loss: 0.0001
Epoch [7/9], Batch [378/428], Loss: 0.0042
Epoch [7/9], Batch [379/428], Loss: 0.0003
Epoch [7/9], Batch [380/428], Loss: 0.0015
Epoch [7/9], Batch [381/428], Loss: 0.0000
Epoch [7/9], Batch [382/428], Loss: 0.0002
Epoch [7/9], Batch [383/428], Loss: 7.0981
Epoch [7/9], Batch [384/428], Loss: 0.0000
Epoch [7/9], Batch [385/428], Loss: 0.2120
Epoch [7/9], Batch [386/428], Loss: 0.0001
Epoch [7/9], Batch [387/428], Loss: 0.0001
Epoch [7/9], Batch [388/428], Loss: 0.0000
Epoch [7/9], Batch [389/428], Loss: 0.0000
Epoch [7/9], Batch [390/428], Loss: 0.0001
Epoch [7/9], Batch [391/428], Loss: 0.2682
Epoch [7/9], Batch [392/428], Loss: 0.0035
Epoch [7/9], Batch [393/428], Loss: 0.0001
Epoch [7/9], Batch [394/428], Loss: 0.0012
Epoch [7/9], Batch [395/428], Loss: 0.0001
Epoch [7/9], Batch [396/428], Loss: 0.0003
Epoch [7/9], Batch [397/428], Loss: 1.2584
Epoch [7/9], Batch [398/428], Loss: 0.0001
Epoch [7/9], Batch [399/428], Loss: 0.0000
Epoch [7/9], Batch [400/428], Loss: 5.8777
Epoch [7/9], Batch [401/428], Loss: 0.0000
Epoch [7/9], Batch [402/428], Loss: 0.0001
Epoch [7/9], Batch [403/428], Loss: 0.0001
Epoch [7/9], Batch [404/428], Loss: 0.3189
Epoch [7/9], Batch [405/428], Loss: 0.0000
Epoch [7/9], Batch [406/428], Loss: 0.0016
Epoch [7/9], Batch [407/428], Loss: 0.0001
Epoch [7/9], Batch [408/428], Loss: 0.0031
Epoch [7/9], Batch [409/428], Loss: 0.0001
Epoch [7/9], Batch [410/428], Loss: 0.1839
Epoch [7/9], Batch [411/428], Loss: 0.0001
Epoch [7/9], Batch [412/428], Loss: 0.0000
Epoch [7/9], Batch [413/428], Loss: 0.0000
Epoch [7/9], Batch [414/428], Loss: 0.0001
Epoch [7/9], Batch [415/428], Loss: 8.6405
Epoch [7/9], Batch [416/428], Loss: 1.7545
Epoch [7/9], Batch [417/428], Loss: 0.1069
Epoch [7/9], Batch [418/428], Loss: 0.0002
Epoch [7/9], Batch [419/428], Loss: 5.4408
Epoch [7/9], Batch [420/428], Loss: 0.0003
Epoch [7/9], Batch [421/428], Loss: 0.0002
Epoch [7/9], Batch [422/428], Loss: 0.0014
Epoch [7/9], Batch [423/428], Loss: 0.0001
Epoch [7/9], Batch [424/428], Loss: 0.0115
Epoch [7/9], Batch [425/428], Loss: 0.0002
Epoch [7/9], Batch [426/428], Loss: 0.0004
Epoch [7/9], Batch [427/428], Loss: 0.0005
Epoch [7/9], Batch [428/428], Loss: 0.0002
Epoch [7] Training Time: 512.07 seconds
Epoch [7/9], Average Loss: 0.5951, Training Accuracy: 0.8224
Epoch [7], Validation Loss: 0.1938, Validation Accuracy: 0.9492
Epoch [7] Validation Time: 23.01 seconds
--------------------------------------------------
Epoch [8/9], Batch [1/428], Loss: 0.0004
Epoch [8/9], Batch [2/428], Loss: 0.0000
Epoch [8/9], Batch [3/428], Loss: 0.0007
Epoch [8/9], Batch [4/428], Loss: 0.0003
Epoch [8/9], Batch [5/428], Loss: 0.0003
Epoch [8/9], Batch [6/428], Loss: 0.0003
Epoch [8/9], Batch [7/428], Loss: 0.0003
Epoch [8/9], Batch [8/428], Loss: 0.0002
Epoch [8/9], Batch [9/428], Loss: 0.0002
Epoch [8/9], Batch [10/428], Loss: 0.0002
Epoch [8/9], Batch [11/428], Loss: 0.0000
Epoch [8/9], Batch [12/428], Loss: 0.0000
Epoch [8/9], Batch [13/428], Loss: 0.0001
Epoch [8/9], Batch [14/428], Loss: 0.0001
Epoch [8/9], Batch [15/428], Loss: 0.0002
Epoch [8/9], Batch [16/428], Loss: 0.0002
Epoch [8/9], Batch [17/428], Loss: 0.0000
Epoch [8/9], Batch [18/428], Loss: 0.0000
Epoch [8/9], Batch [19/428], Loss: 0.0372
Epoch [8/9], Batch [20/428], Loss: 0.0001
Epoch [8/9], Batch [21/428], Loss: 0.0000
Epoch [8/9], Batch [22/428], Loss: 0.0003
Epoch [8/9], Batch [23/428], Loss: 0.0001
Epoch [8/9], Batch [24/428], Loss: 0.0001
Epoch [8/9], Batch [25/428], Loss: 0.0002
Epoch [8/9], Batch [26/428], Loss: 0.0000
Epoch [8/9], Batch [27/428], Loss: 0.0006
Epoch [8/9], Batch [28/428], Loss: 0.0001
Epoch [8/9], Batch [29/428], Loss: 0.0002
Epoch [8/9], Batch [30/428], Loss: 0.0000
Epoch [8/9], Batch [31/428], Loss: 0.0007
Epoch [8/9], Batch [32/428], Loss: 0.0106
Epoch [8/9], Batch [33/428], Loss: 0.0002
Epoch [8/9], Batch [34/428], Loss: 0.0000
Epoch [8/9], Batch [35/428], Loss: 0.0000
Epoch [8/9], Batch [36/428], Loss: 0.0002
Epoch [8/9], Batch [37/428], Loss: 0.0001
Epoch [8/9], Batch [38/428], Loss: 0.0000
Epoch [8/9], Batch [39/428], Loss: 0.0000
Epoch [8/9], Batch [40/428], Loss: 0.1046
Epoch [8/9], Batch [41/428], Loss: 0.0001
Epoch [8/9], Batch [42/428], Loss: 0.0000
Epoch [8/9], Batch [43/428], Loss: 0.0000
Epoch [8/9], Batch [44/428], Loss: 0.0024
Epoch [8/9], Batch [45/428], Loss: 0.6432
Epoch [8/9], Batch [46/428], Loss: 0.0001
Epoch [8/9], Batch [47/428], Loss: 0.0001
Epoch [8/9], Batch [48/428], Loss: 0.0003
Epoch [8/9], Batch [49/428], Loss: 0.0000
Epoch [8/9], Batch [50/428], Loss: 0.0001
Epoch [8/9], Batch [51/428], Loss: 0.0001
Epoch [8/9], Batch [52/428], Loss: 0.0004
Epoch [8/9], Batch [53/428], Loss: 0.0000
Epoch [8/9], Batch [54/428], Loss: 0.0001
Epoch [8/9], Batch [55/428], Loss: 0.0001
Epoch [8/9], Batch [56/428], Loss: 0.0001
Epoch [8/9], Batch [57/428], Loss: 0.0002
Epoch [8/9], Batch [58/428], Loss: 0.0001
Epoch [8/9], Batch [59/428], Loss: 0.0000
Epoch [8/9], Batch [60/428], Loss: 0.0000
Epoch [8/9], Batch [61/428], Loss: 0.0000
Epoch [8/9], Batch [62/428], Loss: 0.0038
Epoch [8/9], Batch [63/428], Loss: 0.6092
Epoch [8/9], Batch [64/428], Loss: 0.0001
Epoch [8/9], Batch [65/428], Loss: 0.0010
Epoch [8/9], Batch [66/428], Loss: 0.0002
Epoch [8/9], Batch [67/428], Loss: 0.0012
Epoch [8/9], Batch [68/428], Loss: 0.0001
Epoch [8/9], Batch [69/428], Loss: 0.0000
Epoch [8/9], Batch [70/428], Loss: 0.0023
Epoch [8/9], Batch [71/428], Loss: 0.0000
Epoch [8/9], Batch [72/428], Loss: 0.0001
Epoch [8/9], Batch [73/428], Loss: 0.0001
Epoch [8/9], Batch [74/428], Loss: 0.0001
Epoch [8/9], Batch [75/428], Loss: 0.0001
Epoch [8/9], Batch [76/428], Loss: 0.0000
Epoch [8/9], Batch [77/428], Loss: 0.0004
Epoch [8/9], Batch [78/428], Loss: 0.0000
Epoch [8/9], Batch [79/428], Loss: 0.6731
Epoch [8/9], Batch [80/428], Loss: 0.0003
Epoch [8/9], Batch [81/428], Loss: 0.0059
Epoch [8/9], Batch [82/428], Loss: 0.0001
Epoch [8/9], Batch [83/428], Loss: 0.0225
Epoch [8/9], Batch [84/428], Loss: 0.0001
Epoch [8/9], Batch [85/428], Loss: 0.0000
Epoch [8/9], Batch [86/428], Loss: 0.0001
Epoch [8/9], Batch [87/428], Loss: 0.0001
Epoch [8/9], Batch [88/428], Loss: 0.0001
Epoch [8/9], Batch [89/428], Loss: 0.0418
Epoch [8/9], Batch [90/428], Loss: 0.0000
Epoch [8/9], Batch [91/428], Loss: 0.0001
Epoch [8/9], Batch [92/428], Loss: 0.0000
Epoch [8/9], Batch [93/428], Loss: 0.0001
Epoch [8/9], Batch [94/428], Loss: 0.0000
Epoch [8/9], Batch [95/428], Loss: 0.0001
Epoch [8/9], Batch [96/428], Loss: 0.0001
Epoch [8/9], Batch [97/428], Loss: 0.0002
Epoch [8/9], Batch [98/428], Loss: 0.0001
Epoch [8/9], Batch [99/428], Loss: 0.0005
Epoch [8/9], Batch [100/428], Loss: 0.0001
Epoch [8/9], Batch [101/428], Loss: 0.0001
Epoch [8/9], Batch [102/428], Loss: 0.0000
Epoch [8/9], Batch [103/428], Loss: 0.0000
Epoch [8/9], Batch [104/428], Loss: 0.0664
Epoch [8/9], Batch [105/428], Loss: 0.0000
Epoch [8/9], Batch [106/428], Loss: 0.0000
Epoch [8/9], Batch [107/428], Loss: 0.0001
Epoch [8/9], Batch [108/428], Loss: 0.0000
Epoch [8/9], Batch [109/428], Loss: 0.0001
Epoch [8/9], Batch [110/428], Loss: 0.0001
Epoch [8/9], Batch [111/428], Loss: 0.0000
Epoch [8/9], Batch [112/428], Loss: 0.0002
Epoch [8/9], Batch [113/428], Loss: 0.0001
Epoch [8/9], Batch [114/428], Loss: 0.0003
Epoch [8/9], Batch [115/428], Loss: 0.0001
Epoch [8/9], Batch [116/428], Loss: 0.0003
Epoch [8/9], Batch [117/428], Loss: 0.0001
Epoch [8/9], Batch [118/428], Loss: 0.0000
Epoch [8/9], Batch [119/428], Loss: 0.0001
Epoch [8/9], Batch [120/428], Loss: 0.0000
Epoch [8/9], Batch [121/428], Loss: 0.0000
Epoch [8/9], Batch [122/428], Loss: 0.0001
Epoch [8/9], Batch [123/428], Loss: 0.0001
Epoch [8/9], Batch [124/428], Loss: 0.0000
Epoch [8/9], Batch [125/428], Loss: 0.0015
Epoch [8/9], Batch [126/428], Loss: 0.0001
Epoch [8/9], Batch [127/428], Loss: 0.0001
Epoch [8/9], Batch [128/428], Loss: 0.0000
Epoch [8/9], Batch [129/428], Loss: 0.0002
Epoch [8/9], Batch [130/428], Loss: 0.0001
Epoch [8/9], Batch [131/428], Loss: 0.0007
Epoch [8/9], Batch [132/428], Loss: 0.0000
Epoch [8/9], Batch [133/428], Loss: 0.0001
Epoch [8/9], Batch [134/428], Loss: 0.0001
Epoch [8/9], Batch [135/428], Loss: 0.0000
Epoch [8/9], Batch [136/428], Loss: 0.0002
Epoch [8/9], Batch [137/428], Loss: 0.0001
Epoch [8/9], Batch [138/428], Loss: 0.0002
Epoch [8/9], Batch [139/428], Loss: 0.0117
Epoch [8/9], Batch [140/428], Loss: 0.0000
Epoch [8/9], Batch [141/428], Loss: 0.0000
Epoch [8/9], Batch [142/428], Loss: 0.0002
Epoch [8/9], Batch [143/428], Loss: 0.0017
Epoch [8/9], Batch [144/428], Loss: 0.0000
Epoch [8/9], Batch [145/428], Loss: 0.0000
Epoch [8/9], Batch [146/428], Loss: 0.0001
Epoch [8/9], Batch [147/428], Loss: 0.0001
Epoch [8/9], Batch [148/428], Loss: 0.0000
Epoch [8/9], Batch [149/428], Loss: 0.0033
Epoch [8/9], Batch [150/428], Loss: 0.0001
Epoch [8/9], Batch [151/428], Loss: 0.0016
Epoch [8/9], Batch [152/428], Loss: 2.3644
Epoch [8/9], Batch [153/428], Loss: 0.0002
Epoch [8/9], Batch [154/428], Loss: 0.0000
Epoch [8/9], Batch [155/428], Loss: 0.0006
Epoch [8/9], Batch [156/428], Loss: 0.0000
Epoch [8/9], Batch [157/428], Loss: 0.3674
Epoch [8/9], Batch [158/428], Loss: 0.0000
Epoch [8/9], Batch [159/428], Loss: 0.0000
Epoch [8/9], Batch [160/428], Loss: 0.0000
Epoch [8/9], Batch [161/428], Loss: 0.0007
Epoch [8/9], Batch [162/428], Loss: 0.0000
Epoch [8/9], Batch [163/428], Loss: 0.0000
Epoch [8/9], Batch [164/428], Loss: 1.9548
Epoch [8/9], Batch [165/428], Loss: 0.0000
Epoch [8/9], Batch [166/428], Loss: 0.0000
Epoch [8/9], Batch [167/428], Loss: 0.0001
Epoch [8/9], Batch [168/428], Loss: 0.0001
Epoch [8/9], Batch [169/428], Loss: 0.2222
Epoch [8/9], Batch [170/428], Loss: 0.0000
Epoch [8/9], Batch [171/428], Loss: 0.0002
Epoch [8/9], Batch [172/428], Loss: 0.0000
Epoch [8/9], Batch [173/428], Loss: 0.0000
Epoch [8/9], Batch [174/428], Loss: 0.0000
Epoch [8/9], Batch [175/428], Loss: 0.0000
Epoch [8/9], Batch [176/428], Loss: 0.0000
Epoch [8/9], Batch [177/428], Loss: 0.0000
Epoch [8/9], Batch [178/428], Loss: 0.0000
Epoch [8/9], Batch [179/428], Loss: 0.0000
Epoch [8/9], Batch [180/428], Loss: 0.0000
Epoch [8/9], Batch [181/428], Loss: 0.0000
Epoch [8/9], Batch [182/428], Loss: 0.0003
Epoch [8/9], Batch [183/428], Loss: 0.0001
Epoch [8/9], Batch [184/428], Loss: 0.0001
Epoch [8/9], Batch [185/428], Loss: 0.0001
Epoch [8/9], Batch [186/428], Loss: 0.0000
Epoch [8/9], Batch [187/428], Loss: 0.0001
Epoch [8/9], Batch [188/428], Loss: 0.2057
Epoch [8/9], Batch [189/428], Loss: 0.0003
Epoch [8/9], Batch [190/428], Loss: 0.0000
Epoch [8/9], Batch [191/428], Loss: 0.0004
Epoch [8/9], Batch [192/428], Loss: 0.0008
Epoch [8/9], Batch [193/428], Loss: 0.0000
Epoch [8/9], Batch [194/428], Loss: 0.0000
Epoch [8/9], Batch [195/428], Loss: 0.0000
Epoch [8/9], Batch [196/428], Loss: 0.0000
Epoch [8/9], Batch [197/428], Loss: 0.4351
Epoch [8/9], Batch [198/428], Loss: 0.0004
Epoch [8/9], Batch [199/428], Loss: 0.0000
Epoch [8/9], Batch [200/428], Loss: 0.0000
Epoch [8/9], Batch [201/428], Loss: 0.0000
Epoch [8/9], Batch [202/428], Loss: 0.0000
Epoch [8/9], Batch [203/428], Loss: 0.0000
Epoch [8/9], Batch [204/428], Loss: 0.2133
Epoch [8/9], Batch [205/428], Loss: 5.3320
Epoch [8/9], Batch [206/428], Loss: 0.0002
Epoch [8/9], Batch [207/428], Loss: 0.0001
Epoch [8/9], Batch [208/428], Loss: 0.0001
Epoch [8/9], Batch [209/428], Loss: 0.0000
Epoch [8/9], Batch [210/428], Loss: 0.0225
Epoch [8/9], Batch [211/428], Loss: 0.0000
Epoch [8/9], Batch [212/428], Loss: 0.0000
Epoch [8/9], Batch [213/428], Loss: 0.0000
Epoch [8/9], Batch [214/428], Loss: 0.0000
Epoch [8/9], Batch [215/428], Loss: 0.0000
Epoch [8/9], Batch [216/428], Loss: 0.0000
Epoch [8/9], Batch [217/428], Loss: 0.0000
Epoch [8/9], Batch [218/428], Loss: 0.5996
Epoch [8/9], Batch [219/428], Loss: 0.0001
Epoch [8/9], Batch [220/428], Loss: 0.0000
Epoch [8/9], Batch [221/428], Loss: 0.0108
Epoch [8/9], Batch [222/428], Loss: 0.0000
Epoch [8/9], Batch [223/428], Loss: 0.0001
Epoch [8/9], Batch [224/428], Loss: 0.0000
Epoch [8/9], Batch [225/428], Loss: 0.0005
Epoch [8/9], Batch [226/428], Loss: 2.3826
Epoch [8/9], Batch [227/428], Loss: 0.0951
Epoch [8/9], Batch [228/428], Loss: 0.0000
Epoch [8/9], Batch [229/428], Loss: 0.0001
Epoch [8/9], Batch [230/428], Loss: 0.0001
Epoch [8/9], Batch [231/428], Loss: 0.0000
Epoch [8/9], Batch [232/428], Loss: 0.0087
Epoch [8/9], Batch [233/428], Loss: 0.0000
Epoch [8/9], Batch [234/428], Loss: 0.0002
Epoch [8/9], Batch [235/428], Loss: 0.0000
Epoch [8/9], Batch [236/428], Loss: 0.0002
Epoch [8/9], Batch [237/428], Loss: 0.0001
Epoch [8/9], Batch [238/428], Loss: 0.0000
Epoch [8/9], Batch [239/428], Loss: 0.0001
Epoch [8/9], Batch [240/428], Loss: 0.0000
Epoch [8/9], Batch [241/428], Loss: 0.0000
Epoch [8/9], Batch [242/428], Loss: 0.0001
Epoch [8/9], Batch [243/428], Loss: 0.0000
Epoch [8/9], Batch [244/428], Loss: 0.0000
Epoch [8/9], Batch [245/428], Loss: 0.0000
Epoch [8/9], Batch [246/428], Loss: 0.0006
Epoch [8/9], Batch [247/428], Loss: 0.0000
Epoch [8/9], Batch [248/428], Loss: 0.0000
Epoch [8/9], Batch [249/428], Loss: 0.0006
Epoch [8/9], Batch [250/428], Loss: 0.0000
Epoch [8/9], Batch [251/428], Loss: 0.0006
Epoch [8/9], Batch [252/428], Loss: 0.0001
Epoch [8/9], Batch [253/428], Loss: 0.0000
Epoch [8/9], Batch [254/428], Loss: 0.0001
Epoch [8/9], Batch [255/428], Loss: 0.0001
Epoch [8/9], Batch [256/428], Loss: 0.0001
Epoch [8/9], Batch [257/428], Loss: 0.0000
Epoch [8/9], Batch [258/428], Loss: 0.0002
Epoch [8/9], Batch [259/428], Loss: 0.0003
Epoch [8/9], Batch [260/428], Loss: 0.0032
Epoch [8/9], Batch [261/428], Loss: 0.0000
Epoch [8/9], Batch [262/428], Loss: 0.0001
Epoch [8/9], Batch [263/428], Loss: 0.0000
Epoch [8/9], Batch [264/428], Loss: 0.0251
Epoch [8/9], Batch [265/428], Loss: 0.0001
Epoch [8/9], Batch [266/428], Loss: 0.0000
Epoch [8/9], Batch [267/428], Loss: 0.0017
Epoch [8/9], Batch [268/428], Loss: 0.0000
Epoch [8/9], Batch [269/428], Loss: 0.0000
Epoch [8/9], Batch [270/428], Loss: 1.8807
Epoch [8/9], Batch [271/428], Loss: 0.0001
Epoch [8/9], Batch [272/428], Loss: 0.0238
Epoch [8/9], Batch [273/428], Loss: 0.0000
Epoch [8/9], Batch [274/428], Loss: 0.0001
Epoch [8/9], Batch [275/428], Loss: 0.0000
Epoch [8/9], Batch [276/428], Loss: 0.0000
Epoch [8/9], Batch [277/428], Loss: 0.0001
Epoch [8/9], Batch [278/428], Loss: 0.0000
Epoch [8/9], Batch [279/428], Loss: 0.0002
Epoch [8/9], Batch [280/428], Loss: 0.0000
Epoch [8/9], Batch [281/428], Loss: 0.0001
Epoch [8/9], Batch [282/428], Loss: 0.0000
Epoch [8/9], Batch [283/428], Loss: 0.0000
Epoch [8/9], Batch [284/428], Loss: 0.0000
Epoch [8/9], Batch [285/428], Loss: 0.0000
Epoch [8/9], Batch [286/428], Loss: 0.0001
Epoch [8/9], Batch [287/428], Loss: 0.0000
Epoch [8/9], Batch [288/428], Loss: 0.0004
Epoch [8/9], Batch [289/428], Loss: 0.0009
Epoch [8/9], Batch [290/428], Loss: 0.0000
Epoch [8/9], Batch [291/428], Loss: 0.0000
Epoch [8/9], Batch [292/428], Loss: 0.0000
Epoch [8/9], Batch [293/428], Loss: 0.0001
Epoch [8/9], Batch [294/428], Loss: 0.0000
Epoch [8/9], Batch [295/428], Loss: 0.0714
Epoch [8/9], Batch [296/428], Loss: 0.0000
Epoch [8/9], Batch [297/428], Loss: 0.0000
Epoch [8/9], Batch [298/428], Loss: 0.0001
Epoch [8/9], Batch [299/428], Loss: 0.7952
Epoch [8/9], Batch [300/428], Loss: 0.0028
Epoch [8/9], Batch [301/428], Loss: 0.0000
Epoch [8/9], Batch [302/428], Loss: 0.0000
Epoch [8/9], Batch [303/428], Loss: 0.0000
Epoch [8/9], Batch [304/428], Loss: 0.0002
Epoch [8/9], Batch [305/428], Loss: 0.0001
Epoch [8/9], Batch [306/428], Loss: 0.0001
Epoch [8/9], Batch [307/428], Loss: 0.0009
Epoch [8/9], Batch [308/428], Loss: 0.0015
Epoch [8/9], Batch [309/428], Loss: 0.0000
Epoch [8/9], Batch [310/428], Loss: 0.0000
Epoch [8/9], Batch [311/428], Loss: 0.0000
Epoch [8/9], Batch [312/428], Loss: 0.4151
Epoch [8/9], Batch [313/428], Loss: 0.0000
Epoch [8/9], Batch [314/428], Loss: 0.0002
Epoch [8/9], Batch [315/428], Loss: 0.0016
Epoch [8/9], Batch [316/428], Loss: 0.0000
Epoch [8/9], Batch [317/428], Loss: 0.0001
Epoch [8/9], Batch [318/428], Loss: 0.0000
Epoch [8/9], Batch [319/428], Loss: 0.0005
Epoch [8/9], Batch [320/428], Loss: 0.4149
Epoch [8/9], Batch [321/428], Loss: 0.0001
Epoch [8/9], Batch [322/428], Loss: 0.0224
Epoch [8/9], Batch [323/428], Loss: 0.0000
Epoch [8/9], Batch [324/428], Loss: 0.0000
Epoch [8/9], Batch [325/428], Loss: 0.0000
Epoch [8/9], Batch [326/428], Loss: 0.0000
Epoch [8/9], Batch [327/428], Loss: 0.0001
Epoch [8/9], Batch [328/428], Loss: 0.0000
Epoch [8/9], Batch [329/428], Loss: 0.0260
Epoch [8/9], Batch [330/428], Loss: 0.0005
Epoch [8/9], Batch [331/428], Loss: 0.0000
Epoch [8/9], Batch [332/428], Loss: 0.0000
Epoch [8/9], Batch [333/428], Loss: 0.0000
Epoch [8/9], Batch [334/428], Loss: 0.0000
Epoch [8/9], Batch [335/428], Loss: 0.0000
Epoch [8/9], Batch [336/428], Loss: 0.0156
Epoch [8/9], Batch [337/428], Loss: 0.1047
Epoch [8/9], Batch [338/428], Loss: 0.0000
Epoch [8/9], Batch [339/428], Loss: 0.0000
Epoch [8/9], Batch [340/428], Loss: 0.0002
Epoch [8/9], Batch [341/428], Loss: 0.0000
Epoch [8/9], Batch [342/428], Loss: 0.0027
Epoch [8/9], Batch [343/428], Loss: 0.0000
Epoch [8/9], Batch [344/428], Loss: 0.0001
Epoch [8/9], Batch [345/428], Loss: 0.0000
Epoch [8/9], Batch [346/428], Loss: 0.0008
Epoch [8/9], Batch [347/428], Loss: 0.0000
Epoch [8/9], Batch [348/428], Loss: 0.0000
Epoch [8/9], Batch [349/428], Loss: 0.0001
Epoch [8/9], Batch [350/428], Loss: 0.0000
Epoch [8/9], Batch [351/428], Loss: 0.0000
Epoch [8/9], Batch [352/428], Loss: 3.1566
Epoch [8/9], Batch [353/428], Loss: 0.0001
Epoch [8/9], Batch [354/428], Loss: 0.0000
Epoch [8/9], Batch [355/428], Loss: 0.0000
Epoch [8/9], Batch [356/428], Loss: 0.3983
Epoch [8/9], Batch [357/428], Loss: 0.0009
Epoch [8/9], Batch [358/428], Loss: 0.8363
Epoch [8/9], Batch [359/428], Loss: 0.0000
Epoch [8/9], Batch [360/428], Loss: 0.0000
Epoch [8/9], Batch [361/428], Loss: 0.0000
Epoch [8/9], Batch [362/428], Loss: 0.0000
Epoch [8/9], Batch [363/428], Loss: 0.0918
Epoch [8/9], Batch [364/428], Loss: 0.0000
Epoch [8/9], Batch [365/428], Loss: 0.0000
Epoch [8/9], Batch [366/428], Loss: 0.0001
Epoch [8/9], Batch [367/428], Loss: 0.0007
Epoch [8/9], Batch [368/428], Loss: 0.0001
Epoch [8/9], Batch [369/428], Loss: 0.0000
Epoch [8/9], Batch [370/428], Loss: 0.0000
Epoch [8/9], Batch [371/428], Loss: 0.0001
Epoch [8/9], Batch [372/428], Loss: 0.0029
Epoch [8/9], Batch [373/428], Loss: 0.0000
Epoch [8/9], Batch [374/428], Loss: 0.0000
Epoch [8/9], Batch [375/428], Loss: 0.0001
Epoch [8/9], Batch [376/428], Loss: 0.0064
Epoch [8/9], Batch [377/428], Loss: 0.0001
Epoch [8/9], Batch [378/428], Loss: 0.0000
Epoch [8/9], Batch [379/428], Loss: 0.0283
Epoch [8/9], Batch [380/428], Loss: 0.1240
Epoch [8/9], Batch [381/428], Loss: 0.0000
Epoch [8/9], Batch [382/428], Loss: 0.0000
Epoch [8/9], Batch [383/428], Loss: 0.0000
Epoch [8/9], Batch [384/428], Loss: 0.0000
Epoch [8/9], Batch [385/428], Loss: 0.0000
Epoch [8/9], Batch [386/428], Loss: 0.0000
Epoch [8/9], Batch [387/428], Loss: 0.0000
Epoch [8/9], Batch [388/428], Loss: 0.0000
Epoch [8/9], Batch [389/428], Loss: 0.0000
Epoch [8/9], Batch [390/428], Loss: 0.0001
Epoch [8/9], Batch [391/428], Loss: 0.0000
Epoch [8/9], Batch [392/428], Loss: 0.0000
Epoch [8/9], Batch [393/428], Loss: 0.0000
Epoch [8/9], Batch [394/428], Loss: 0.0000
Epoch [8/9], Batch [395/428], Loss: 0.0001
Epoch [8/9], Batch [396/428], Loss: 10.8221
Epoch [8/9], Batch [397/428], Loss: 0.0012
Epoch [8/9], Batch [398/428], Loss: 0.0001
Epoch [8/9], Batch [399/428], Loss: 0.0000
Epoch [8/9], Batch [400/428], Loss: 0.0001
Epoch [8/9], Batch [401/428], Loss: 0.0007
Epoch [8/9], Batch [402/428], Loss: 0.0001
Epoch [8/9], Batch [403/428], Loss: 0.0000
Epoch [8/9], Batch [404/428], Loss: 0.0000
Epoch [8/9], Batch [405/428], Loss: 0.0000
Epoch [8/9], Batch [406/428], Loss: 0.0000
Epoch [8/9], Batch [407/428], Loss: 0.0021
Epoch [8/9], Batch [408/428], Loss: 0.0000
Epoch [8/9], Batch [409/428], Loss: 0.0000
Epoch [8/9], Batch [410/428], Loss: 0.0000[INFO 06-13 17:37:08] ax.service.ax_client: Completed trial 0 with data: {'objective': (np.float64(-0.949206), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 17:37:08] ax.service.ax_client: Generated new trial 1 with parameters {'lr': 0.000131, 'num_epochs': 1, 'unfreeze_epoch': 0, 'max_length': 48000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [8/9], Batch [411/428], Loss: 0.0001
Epoch [8/9], Batch [412/428], Loss: 0.0005
Epoch [8/9], Batch [413/428], Loss: 0.0000
Epoch [8/9], Batch [414/428], Loss: 0.0001
Epoch [8/9], Batch [415/428], Loss: 0.0000
Epoch [8/9], Batch [416/428], Loss: 0.0000
Epoch [8/9], Batch [417/428], Loss: 0.0001
Epoch [8/9], Batch [418/428], Loss: 0.0000
Epoch [8/9], Batch [419/428], Loss: 0.0000
Epoch [8/9], Batch [420/428], Loss: 0.0000
Epoch [8/9], Batch [421/428], Loss: 0.0000
Epoch [8/9], Batch [422/428], Loss: 0.0000
Epoch [8/9], Batch [423/428], Loss: 0.0000
Epoch [8/9], Batch [424/428], Loss: 0.0000
Epoch [8/9], Batch [425/428], Loss: 0.0000
Epoch [8/9], Batch [426/428], Loss: 0.0000
Epoch [8/9], Batch [427/428], Loss: 0.0000
Epoch [8/9], Batch [428/428], Loss: 0.0001
Epoch [8] Training Time: 509.68 seconds
Epoch [8/9], Average Loss: 0.0836, Training Accuracy: 0.9790
Epoch [8], Validation Loss: 0.6106, Validation Accuracy: 0.8865
Epoch [8] Validation Time: 20.74 seconds
--------------------------------------------------
Epoch [9/9], Batch [1/428], Loss: 0.0000
Epoch [9/9], Batch [2/428], Loss: 0.0000
Epoch [9/9], Batch [3/428], Loss: 0.0000
Epoch [9/9], Batch [4/428], Loss: 0.0001
Epoch [9/9], Batch [5/428], Loss: 0.0000
Epoch [9/9], Batch [6/428], Loss: 0.0002
Epoch [9/9], Batch [7/428], Loss: 0.0000
Epoch [9/9], Batch [8/428], Loss: 0.0000
Epoch [9/9], Batch [9/428], Loss: 0.0000
Epoch [9/9], Batch [10/428], Loss: 0.0000
Epoch [9/9], Batch [11/428], Loss: 0.0000
Epoch [9/9], Batch [12/428], Loss: 0.0003
Epoch [9/9], Batch [13/428], Loss: 0.0002
Epoch [9/9], Batch [14/428], Loss: 0.0000
Epoch [9/9], Batch [15/428], Loss: 0.0000
Epoch [9/9], Batch [16/428], Loss: 0.0000
Epoch [9/9], Batch [17/428], Loss: 0.0000
Epoch [9/9], Batch [18/428], Loss: 0.0000
Epoch [9/9], Batch [19/428], Loss: 0.0000
Epoch [9/9], Batch [20/428], Loss: 0.0000
Epoch [9/9], Batch [21/428], Loss: 0.0000
Epoch [9/9], Batch [22/428], Loss: 0.0000
Epoch [9/9], Batch [23/428], Loss: 0.0001
Epoch [9/9], Batch [24/428], Loss: 0.0000
Epoch [9/9], Batch [25/428], Loss: 0.0000
Epoch [9/9], Batch [26/428], Loss: 0.0000
Epoch [9/9], Batch [27/428], Loss: 0.0000
Epoch [9/9], Batch [28/428], Loss: 0.0000
Epoch [9/9], Batch [29/428], Loss: 0.0000
Epoch [9/9], Batch [30/428], Loss: 0.0000
Epoch [9/9], Batch [31/428], Loss: 0.0001
Epoch [9/9], Batch [32/428], Loss: 0.0001
Epoch [9/9], Batch [33/428], Loss: 0.0000
Epoch [9/9], Batch [34/428], Loss: 0.0000
Epoch [9/9], Batch [35/428], Loss: 0.0000
Epoch [9/9], Batch [36/428], Loss: 0.0000
Epoch [9/9], Batch [37/428], Loss: 0.0000
Epoch [9/9], Batch [38/428], Loss: 0.0000
Epoch [9/9], Batch [39/428], Loss: 0.0029
Epoch [9/9], Batch [40/428], Loss: 0.0001
Epoch [9/9], Batch [41/428], Loss: 0.0001
Epoch [9/9], Batch [42/428], Loss: 0.0000
Epoch [9/9], Batch [43/428], Loss: 0.0000
Epoch [9/9], Batch [44/428], Loss: 0.0002
Epoch [9/9], Batch [45/428], Loss: 0.0000
Epoch [9/9], Batch [46/428], Loss: 0.0000
Epoch [9/9], Batch [47/428], Loss: 0.0001
Epoch [9/9], Batch [48/428], Loss: 0.0004
Epoch [9/9], Batch [49/428], Loss: 0.0000
Epoch [9/9], Batch [50/428], Loss: 0.0000
Epoch [9/9], Batch [51/428], Loss: 0.0000
Epoch [9/9], Batch [52/428], Loss: 0.0000
Epoch [9/9], Batch [53/428], Loss: 0.0000
Epoch [9/9], Batch [54/428], Loss: 0.0000
Epoch [9/9], Batch [55/428], Loss: 0.0000
Epoch [9/9], Batch [56/428], Loss: 0.0000
Epoch [9/9], Batch [57/428], Loss: 0.0000
Epoch [9/9], Batch [58/428], Loss: 0.0000
Epoch [9/9], Batch [59/428], Loss: 0.0000
Epoch [9/9], Batch [60/428], Loss: 0.0000
Epoch [9/9], Batch [61/428], Loss: 0.0001
Epoch [9/9], Batch [62/428], Loss: 0.0000
Epoch [9/9], Batch [63/428], Loss: 0.0000
Epoch [9/9], Batch [64/428], Loss: 0.0000
Epoch [9/9], Batch [65/428], Loss: 0.0000
Epoch [9/9], Batch [66/428], Loss: 0.0000
Epoch [9/9], Batch [67/428], Loss: 0.0000
Epoch [9/9], Batch [68/428], Loss: 0.0000
Epoch [9/9], Batch [69/428], Loss: 0.0000
Epoch [9/9], Batch [70/428], Loss: 0.0000
Epoch [9/9], Batch [71/428], Loss: 0.0000
Epoch [9/9], Batch [72/428], Loss: 0.0001
Epoch [9/9], Batch [73/428], Loss: 0.0000
Epoch [9/9], Batch [74/428], Loss: 0.0000
Epoch [9/9], Batch [75/428], Loss: 0.0000
Epoch [9/9], Batch [76/428], Loss: 0.0000
Epoch [9/9], Batch [77/428], Loss: 0.0000
Epoch [9/9], Batch [78/428], Loss: 0.9872
Epoch [9/9], Batch [79/428], Loss: 0.0000
Epoch [9/9], Batch [80/428], Loss: 0.0000
Epoch [9/9], Batch [81/428], Loss: 0.0000
Epoch [9/9], Batch [82/428], Loss: 0.0002
Epoch [9/9], Batch [83/428], Loss: 3.8507
Epoch [9/9], Batch [84/428], Loss: 0.0001
Epoch [9/9], Batch [85/428], Loss: 0.0000
Epoch [9/9], Batch [86/428], Loss: 0.0000
Epoch [9/9], Batch [87/428], Loss: 0.0000
Epoch [9/9], Batch [88/428], Loss: 0.0003
Epoch [9/9], Batch [89/428], Loss: 0.0000
Epoch [9/9], Batch [90/428], Loss: 0.0000
Epoch [9/9], Batch [91/428], Loss: 0.0000
Epoch [9/9], Batch [92/428], Loss: 0.0000
Epoch [9/9], Batch [93/428], Loss: 0.0000
Epoch [9/9], Batch [94/428], Loss: 0.0001
Epoch [9/9], Batch [95/428], Loss: 0.0000
Epoch [9/9], Batch [96/428], Loss: 0.0003
Epoch [9/9], Batch [97/428], Loss: 0.0000
Epoch [9/9], Batch [98/428], Loss: 0.0000
Epoch [9/9], Batch [99/428], Loss: 0.0000
Epoch [9/9], Batch [100/428], Loss: 0.0001
Epoch [9/9], Batch [101/428], Loss: 0.0001
Epoch [9/9], Batch [102/428], Loss: 0.0000
Epoch [9/9], Batch [103/428], Loss: 0.0001
Epoch [9/9], Batch [104/428], Loss: 0.0000
Epoch [9/9], Batch [105/428], Loss: 0.0000
Epoch [9/9], Batch [106/428], Loss: 0.0000
Epoch [9/9], Batch [107/428], Loss: 0.0000
Epoch [9/9], Batch [108/428], Loss: 0.0000
Epoch [9/9], Batch [109/428], Loss: 0.0000
Epoch [9/9], Batch [110/428], Loss: 0.0000
Epoch [9/9], Batch [111/428], Loss: 0.0001
Epoch [9/9], Batch [112/428], Loss: 0.0000
Epoch [9/9], Batch [113/428], Loss: 0.0000
Epoch [9/9], Batch [114/428], Loss: 0.0000
Epoch [9/9], Batch [115/428], Loss: 0.0000
Epoch [9/9], Batch [116/428], Loss: 0.0001
Epoch [9/9], Batch [117/428], Loss: 0.0000
Epoch [9/9], Batch [118/428], Loss: 0.0000
Epoch [9/9], Batch [119/428], Loss: 0.0006
Epoch [9/9], Batch [120/428], Loss: 0.0643
Epoch [9/9], Batch [121/428], Loss: 0.0000
Epoch [9/9], Batch [122/428], Loss: 0.0000
Epoch [9/9], Batch [123/428], Loss: 0.0001
Epoch [9/9], Batch [124/428], Loss: 0.0000
Epoch [9/9], Batch [125/428], Loss: 0.0000
Epoch [9/9], Batch [126/428], Loss: 0.0000
Epoch [9/9], Batch [127/428], Loss: 0.0002
Epoch [9/9], Batch [128/428], Loss: 0.0006
Epoch [9/9], Batch [129/428], Loss: 0.0000
Epoch [9/9], Batch [130/428], Loss: 0.0000
Epoch [9/9], Batch [131/428], Loss: 0.0002
Epoch [9/9], Batch [132/428], Loss: 0.0000
Epoch [9/9], Batch [133/428], Loss: 0.0000
Epoch [9/9], Batch [134/428], Loss: 0.0000
Epoch [9/9], Batch [135/428], Loss: 0.0000
Epoch [9/9], Batch [136/428], Loss: 0.0001
Epoch [9/9], Batch [137/428], Loss: 0.0000
Epoch [9/9], Batch [138/428], Loss: 0.0000
Epoch [9/9], Batch [139/428], Loss: 0.0000
Epoch [9/9], Batch [140/428], Loss: 0.0000
Epoch [9/9], Batch [141/428], Loss: 0.0000
Epoch [9/9], Batch [142/428], Loss: 0.0000
Epoch [9/9], Batch [143/428], Loss: 0.0063
Epoch [9/9], Batch [144/428], Loss: 0.0001
Epoch [9/9], Batch [145/428], Loss: 0.0013
Epoch [9/9], Batch [146/428], Loss: 0.0000
Epoch [9/9], Batch [147/428], Loss: 0.5351
Epoch [9/9], Batch [148/428], Loss: 0.0000
Epoch [9/9], Batch [149/428], Loss: 0.0000
Epoch [9/9], Batch [150/428], Loss: 0.0001
Epoch [9/9], Batch [151/428], Loss: 0.0001
Epoch [9/9], Batch [152/428], Loss: 0.0000
Epoch [9/9], Batch [153/428], Loss: 0.0000
Epoch [9/9], Batch [154/428], Loss: 0.0000
Epoch [9/9], Batch [155/428], Loss: 0.0001
Epoch [9/9], Batch [156/428], Loss: 0.0000
Epoch [9/9], Batch [157/428], Loss: 0.0007
Epoch [9/9], Batch [158/428], Loss: 0.0001
Epoch [9/9], Batch [159/428], Loss: 0.0000
Epoch [9/9], Batch [160/428], Loss: 0.0129
Epoch [9/9], Batch [161/428], Loss: 0.0000
Epoch [9/9], Batch [162/428], Loss: 0.0009
Epoch [9/9], Batch [163/428], Loss: 0.0000
Epoch [9/9], Batch [164/428], Loss: 0.0000
Epoch [9/9], Batch [165/428], Loss: 0.0000
Epoch [9/9], Batch [166/428], Loss: 0.0000
Epoch [9/9], Batch [167/428], Loss: 0.0000
Epoch [9/9], Batch [168/428], Loss: 0.0001
Epoch [9/9], Batch [169/428], Loss: 0.0000
Epoch [9/9], Batch [170/428], Loss: 0.0000
Epoch [9/9], Batch [171/428], Loss: 0.0000
Epoch [9/9], Batch [172/428], Loss: 0.0000
Epoch [9/9], Batch [173/428], Loss: 0.0000
Epoch [9/9], Batch [174/428], Loss: 0.0000
Epoch [9/9], Batch [175/428], Loss: 0.0000
Epoch [9/9], Batch [176/428], Loss: 0.0002
Epoch [9/9], Batch [177/428], Loss: 0.0000
Epoch [9/9], Batch [178/428], Loss: 0.0000
Epoch [9/9], Batch [179/428], Loss: 0.0000
Epoch [9/9], Batch [180/428], Loss: 0.0000
Epoch [9/9], Batch [181/428], Loss: 0.0001
Epoch [9/9], Batch [182/428], Loss: 0.0000
Epoch [9/9], Batch [183/428], Loss: 0.0000
Epoch [9/9], Batch [184/428], Loss: 0.0000
Epoch [9/9], Batch [185/428], Loss: 0.0000
Epoch [9/9], Batch [186/428], Loss: 0.0000
Epoch [9/9], Batch [187/428], Loss: 0.0000
Epoch [9/9], Batch [188/428], Loss: 0.0000
Epoch [9/9], Batch [189/428], Loss: 0.0000
Epoch [9/9], Batch [190/428], Loss: 0.0000
Epoch [9/9], Batch [191/428], Loss: 0.0001
Epoch [9/9], Batch [192/428], Loss: 0.0010
Epoch [9/9], Batch [193/428], Loss: 0.0000
Epoch [9/9], Batch [194/428], Loss: 0.0000
Epoch [9/9], Batch [195/428], Loss: 0.0001
Epoch [9/9], Batch [196/428], Loss: 0.0000
Epoch [9/9], Batch [197/428], Loss: 0.0000
Epoch [9/9], Batch [198/428], Loss: 0.0000
Epoch [9/9], Batch [199/428], Loss: 0.0000
Epoch [9/9], Batch [200/428], Loss: 0.0000
Epoch [9/9], Batch [201/428], Loss: 0.0000
Epoch [9/9], Batch [202/428], Loss: 0.0001
Epoch [9/9], Batch [203/428], Loss: 0.0000
Epoch [9/9], Batch [204/428], Loss: 0.0001
Epoch [9/9], Batch [205/428], Loss: 0.0001
Epoch [9/9], Batch [206/428], Loss: 0.0000
Epoch [9/9], Batch [207/428], Loss: 0.0000
Epoch [9/9], Batch [208/428], Loss: 0.0000
Epoch [9/9], Batch [209/428], Loss: 0.0000
Epoch [9/9], Batch [210/428], Loss: 0.0000
Epoch [9/9], Batch [211/428], Loss: 0.0000
Epoch [9/9], Batch [212/428], Loss: 0.0006
Epoch [9/9], Batch [213/428], Loss: 0.0000
Epoch [9/9], Batch [214/428], Loss: 0.0000
Epoch [9/9], Batch [215/428], Loss: 0.0001
Epoch [9/9], Batch [216/428], Loss: 0.0000
Epoch [9/9], Batch [217/428], Loss: 0.0014
Epoch [9/9], Batch [218/428], Loss: 0.0000
Epoch [9/9], Batch [219/428], Loss: 0.0000
Epoch [9/9], Batch [220/428], Loss: 0.0000
Epoch [9/9], Batch [221/428], Loss: 0.0000
Epoch [9/9], Batch [222/428], Loss: 0.0000
Epoch [9/9], Batch [223/428], Loss: 0.0000
Epoch [9/9], Batch [224/428], Loss: 0.0000
Epoch [9/9], Batch [225/428], Loss: 0.0000
Epoch [9/9], Batch [226/428], Loss: 0.0000
Epoch [9/9], Batch [227/428], Loss: 0.0000
Epoch [9/9], Batch [228/428], Loss: 0.0000
Epoch [9/9], Batch [229/428], Loss: 0.0000
Epoch [9/9], Batch [230/428], Loss: 0.0000
Epoch [9/9], Batch [231/428], Loss: 0.0000
Epoch [9/9], Batch [232/428], Loss: 0.0000
Epoch [9/9], Batch [233/428], Loss: 0.0000
Epoch [9/9], Batch [234/428], Loss: 0.0000
Epoch [9/9], Batch [235/428], Loss: 0.0000
Epoch [9/9], Batch [236/428], Loss: 0.0000
Epoch [9/9], Batch [237/428], Loss: 0.0001
Epoch [9/9], Batch [238/428], Loss: 0.0000
Epoch [9/9], Batch [239/428], Loss: 0.0000
Epoch [9/9], Batch [240/428], Loss: 0.0000
Epoch [9/9], Batch [241/428], Loss: 0.0006
Epoch [9/9], Batch [242/428], Loss: 0.0000
Epoch [9/9], Batch [243/428], Loss: 0.0001
Epoch [9/9], Batch [244/428], Loss: 0.0000
Epoch [9/9], Batch [245/428], Loss: 0.0000
Epoch [9/9], Batch [246/428], Loss: 0.0000
Epoch [9/9], Batch [247/428], Loss: 0.0015
Epoch [9/9], Batch [248/428], Loss: 0.0000
Epoch [9/9], Batch [249/428], Loss: 0.0000
Epoch [9/9], Batch [250/428], Loss: 0.0000
Epoch [9/9], Batch [251/428], Loss: 0.0000
Epoch [9/9], Batch [252/428], Loss: 0.0000
Epoch [9/9], Batch [253/428], Loss: 0.0001
Epoch [9/9], Batch [254/428], Loss: 0.0000
Epoch [9/9], Batch [255/428], Loss: 0.0000
Epoch [9/9], Batch [256/428], Loss: 0.0000
Epoch [9/9], Batch [257/428], Loss: 0.0000
Epoch [9/9], Batch [258/428], Loss: 0.0001
Epoch [9/9], Batch [259/428], Loss: 0.0000
Epoch [9/9], Batch [260/428], Loss: 0.0000
Epoch [9/9], Batch [261/428], Loss: 0.0000
Epoch [9/9], Batch [262/428], Loss: 0.0000
Epoch [9/9], Batch [263/428], Loss: 0.0000
Epoch [9/9], Batch [264/428], Loss: 0.0000
Epoch [9/9], Batch [265/428], Loss: 0.0000
Epoch [9/9], Batch [266/428], Loss: 0.0019
Epoch [9/9], Batch [267/428], Loss: 0.0001
Epoch [9/9], Batch [268/428], Loss: 0.0001
Epoch [9/9], Batch [269/428], Loss: 0.0001
Epoch [9/9], Batch [270/428], Loss: 0.0000
Epoch [9/9], Batch [271/428], Loss: 0.0000
Epoch [9/9], Batch [272/428], Loss: 0.0000
Epoch [9/9], Batch [273/428], Loss: 0.0000
Epoch [9/9], Batch [274/428], Loss: 0.0017
Epoch [9/9], Batch [275/428], Loss: 0.0000
Epoch [9/9], Batch [276/428], Loss: 0.0000
Epoch [9/9], Batch [277/428], Loss: 0.0000
Epoch [9/9], Batch [278/428], Loss: 0.0000
Epoch [9/9], Batch [279/428], Loss: 0.0001
Epoch [9/9], Batch [280/428], Loss: 0.0001
Epoch [9/9], Batch [281/428], Loss: 0.0000
Epoch [9/9], Batch [282/428], Loss: 0.0000
Epoch [9/9], Batch [283/428], Loss: 0.0005
Epoch [9/9], Batch [284/428], Loss: 0.0000
Epoch [9/9], Batch [285/428], Loss: 0.0000
Epoch [9/9], Batch [286/428], Loss: 0.0000
Epoch [9/9], Batch [287/428], Loss: 0.0000
Epoch [9/9], Batch [288/428], Loss: 0.0000
Epoch [9/9], Batch [289/428], Loss: 0.0000
Epoch [9/9], Batch [290/428], Loss: 0.0000
Epoch [9/9], Batch [291/428], Loss: 0.0000
Epoch [9/9], Batch [292/428], Loss: 0.0000
Epoch [9/9], Batch [293/428], Loss: 0.0000
Epoch [9/9], Batch [294/428], Loss: 0.0000
Epoch [9/9], Batch [295/428], Loss: 0.0000
Epoch [9/9], Batch [296/428], Loss: 0.0000
Epoch [9/9], Batch [297/428], Loss: 0.0000
Epoch [9/9], Batch [298/428], Loss: 0.0000
Epoch [9/9], Batch [299/428], Loss: 0.0001
Epoch [9/9], Batch [300/428], Loss: 0.0072
Epoch [9/9], Batch [301/428], Loss: 0.0002
Epoch [9/9], Batch [302/428], Loss: 0.0000
Epoch [9/9], Batch [303/428], Loss: 0.0008
Epoch [9/9], Batch [304/428], Loss: 0.0019
Epoch [9/9], Batch [305/428], Loss: 0.0000
Epoch [9/9], Batch [306/428], Loss: 0.0000
Epoch [9/9], Batch [307/428], Loss: 0.0000
Epoch [9/9], Batch [308/428], Loss: 0.0000
Epoch [9/9], Batch [309/428], Loss: 0.0000
Epoch [9/9], Batch [310/428], Loss: 0.0000
Epoch [9/9], Batch [311/428], Loss: 0.0000
Epoch [9/9], Batch [312/428], Loss: 0.0000
Epoch [9/9], Batch [313/428], Loss: 0.0000
Epoch [9/9], Batch [314/428], Loss: 0.0026
Epoch [9/9], Batch [315/428], Loss: 0.0000
Epoch [9/9], Batch [316/428], Loss: 0.0000
Epoch [9/9], Batch [317/428], Loss: 0.0000
Epoch [9/9], Batch [318/428], Loss: 0.0000
Epoch [9/9], Batch [319/428], Loss: 0.0000
Epoch [9/9], Batch [320/428], Loss: 0.0000
Epoch [9/9], Batch [321/428], Loss: 0.0000
Epoch [9/9], Batch [322/428], Loss: 0.0000
Epoch [9/9], Batch [323/428], Loss: 0.0000
Epoch [9/9], Batch [324/428], Loss: 0.0000
Epoch [9/9], Batch [325/428], Loss: 0.0007
Epoch [9/9], Batch [326/428], Loss: 0.0000
Epoch [9/9], Batch [327/428], Loss: 0.0000
Epoch [9/9], Batch [328/428], Loss: 0.0001
Epoch [9/9], Batch [329/428], Loss: 0.0001
Epoch [9/9], Batch [330/428], Loss: 0.0001
Epoch [9/9], Batch [331/428], Loss: 0.0000
Epoch [9/9], Batch [332/428], Loss: 0.0000
Epoch [9/9], Batch [333/428], Loss: 0.0000
Epoch [9/9], Batch [334/428], Loss: 0.0000
Epoch [9/9], Batch [335/428], Loss: 0.0000
Epoch [9/9], Batch [336/428], Loss: 0.0000
Epoch [9/9], Batch [337/428], Loss: 0.0000
Epoch [9/9], Batch [338/428], Loss: 0.0000
Epoch [9/9], Batch [339/428], Loss: 0.0000
Epoch [9/9], Batch [340/428], Loss: 0.0002
Epoch [9/9], Batch [341/428], Loss: 0.0001
Epoch [9/9], Batch [342/428], Loss: 0.0000
Epoch [9/9], Batch [343/428], Loss: 0.0000
Epoch [9/9], Batch [344/428], Loss: 0.0003
Epoch [9/9], Batch [345/428], Loss: 0.0000
Epoch [9/9], Batch [346/428], Loss: 0.0000
Epoch [9/9], Batch [347/428], Loss: 0.0000
Epoch [9/9], Batch [348/428], Loss: 0.0000
Epoch [9/9], Batch [349/428], Loss: 0.0000
Epoch [9/9], Batch [350/428], Loss: 0.0000
Epoch [9/9], Batch [351/428], Loss: 0.0000
Epoch [9/9], Batch [352/428], Loss: 0.0000
Epoch [9/9], Batch [353/428], Loss: 0.0000
Epoch [9/9], Batch [354/428], Loss: 0.0000
Epoch [9/9], Batch [355/428], Loss: 0.0000
Epoch [9/9], Batch [356/428], Loss: 0.0000
Epoch [9/9], Batch [357/428], Loss: 0.0000
Epoch [9/9], Batch [358/428], Loss: 0.0000
Epoch [9/9], Batch [359/428], Loss: 0.0000
Epoch [9/9], Batch [360/428], Loss: 0.0000
Epoch [9/9], Batch [361/428], Loss: 0.0002
Epoch [9/9], Batch [362/428], Loss: 0.0000
Epoch [9/9], Batch [363/428], Loss: 0.0000
Epoch [9/9], Batch [364/428], Loss: 0.0000
Epoch [9/9], Batch [365/428], Loss: 0.0000
Epoch [9/9], Batch [366/428], Loss: 0.0000
Epoch [9/9], Batch [367/428], Loss: 0.0000
Epoch [9/9], Batch [368/428], Loss: 0.0000
Epoch [9/9], Batch [369/428], Loss: 0.0000
Epoch [9/9], Batch [370/428], Loss: 0.0000
Epoch [9/9], Batch [371/428], Loss: 0.0000
Epoch [9/9], Batch [372/428], Loss: 0.0000
Epoch [9/9], Batch [373/428], Loss: 0.0000
Epoch [9/9], Batch [374/428], Loss: 0.0000
Epoch [9/9], Batch [375/428], Loss: 0.0000
Epoch [9/9], Batch [376/428], Loss: 0.0000
Epoch [9/9], Batch [377/428], Loss: 0.0000
Epoch [9/9], Batch [378/428], Loss: 0.0000
Epoch [9/9], Batch [379/428], Loss: 0.0000
Epoch [9/9], Batch [380/428], Loss: 0.0000
Epoch [9/9], Batch [381/428], Loss: 0.0000
Epoch [9/9], Batch [382/428], Loss: 0.0000
Epoch [9/9], Batch [383/428], Loss: 0.0001
Epoch [9/9], Batch [384/428], Loss: 0.0001
Epoch [9/9], Batch [385/428], Loss: 0.0000
Epoch [9/9], Batch [386/428], Loss: 0.0000
Epoch [9/9], Batch [387/428], Loss: 0.0000
Epoch [9/9], Batch [388/428], Loss: 0.0000
Epoch [9/9], Batch [389/428], Loss: 0.0000
Epoch [9/9], Batch [390/428], Loss: 0.0020
Epoch [9/9], Batch [391/428], Loss: 0.0000
Epoch [9/9], Batch [392/428], Loss: 0.0144
Epoch [9/9], Batch [393/428], Loss: 0.9406
Epoch [9/9], Batch [394/428], Loss: 0.0000
Epoch [9/9], Batch [395/428], Loss: 0.0000
Epoch [9/9], Batch [396/428], Loss: 0.0000
Epoch [9/9], Batch [397/428], Loss: 0.0000
Epoch [9/9], Batch [398/428], Loss: 0.0001
Epoch [9/9], Batch [399/428], Loss: 0.0000
Epoch [9/9], Batch [400/428], Loss: 0.0000
Epoch [9/9], Batch [401/428], Loss: 0.0000
Epoch [9/9], Batch [402/428], Loss: 0.0000
Epoch [9/9], Batch [403/428], Loss: 0.0000
Epoch [9/9], Batch [404/428], Loss: 0.0001
Epoch [9/9], Batch [405/428], Loss: 0.0000
Epoch [9/9], Batch [406/428], Loss: 0.0000
Epoch [9/9], Batch [407/428], Loss: 0.0000
Epoch [9/9], Batch [408/428], Loss: 0.0000
Epoch [9/9], Batch [409/428], Loss: 0.0000
Epoch [9/9], Batch [410/428], Loss: 0.0000
Epoch [9/9], Batch [411/428], Loss: 0.0000
Epoch [9/9], Batch [412/428], Loss: 0.0000
Epoch [9/9], Batch [413/428], Loss: 0.0000
Epoch [9/9], Batch [414/428], Loss: 0.0000
Epoch [9/9], Batch [415/428], Loss: 0.0000
Epoch [9/9], Batch [416/428], Loss: 0.0000
Epoch [9/9], Batch [417/428], Loss: 0.0000
Epoch [9/9], Batch [418/428], Loss: 0.0000
Epoch [9/9], Batch [419/428], Loss: 0.0000
Epoch [9/9], Batch [420/428], Loss: 0.0000
Epoch [9/9], Batch [421/428], Loss: 0.0000
Epoch [9/9], Batch [422/428], Loss: 0.0000
Epoch [9/9], Batch [423/428], Loss: 0.0001
Epoch [9/9], Batch [424/428], Loss: 0.0000
Epoch [9/9], Batch [425/428], Loss: 0.0000
Epoch [9/9], Batch [426/428], Loss: 0.0000
Epoch [9/9], Batch [427/428], Loss: 0.0000
Epoch [9/9], Batch [428/428], Loss: 0.0000
Epoch [9] Training Time: 512.19 seconds
Epoch [9/9], Average Loss: 0.0151, Training Accuracy: 0.9930
Epoch [9], Validation Loss: 0.2438, Validation Accuracy: 0.9492
Epoch [9] Validation Time: 20.80 seconds
--------------------------------------------------

Running trial 1 with config: {'batch_size': 1, 'lr': 0.000131365565907626, 'num_epochs': 1, 'unfreeze_epoch': 0, 'max_length': 48000, 'device': device(type='cpu')}
Epoch 1: Unfreezing feature extractor layers...
Epoch [1/1], Batch [1/428], Loss: 4.6423
Epoch [1/1], Batch [2/428], Loss: 2.5604
Epoch [1/1], Batch [3/428], Loss: 4.8447
Epoch [1/1], Batch [4/428], Loss: 6.3065
Epoch [1/1], Batch [5/428], Loss: 0.5183
Epoch [1/1], Batch [6/428], Loss: 0.4315
Epoch [1/1], Batch [7/428], Loss: 6.9820
Epoch [1/1], Batch [8/428], Loss: 6.0386
Epoch [1/1], Batch [9/428], Loss: 6.5244
Epoch [1/1], Batch [10/428], Loss: 1.1561
Epoch [1/1], Batch [11/428], Loss: 3.6422
Epoch [1/1], Batch [12/428], Loss: 0.1220
Epoch [1/1], Batch [13/428], Loss: 0.0360
Epoch [1/1], Batch [14/428], Loss: 0.0051
Epoch [1/1], Batch [15/428], Loss: 11.9808
Epoch [1/1], Batch [16/428], Loss: 10.0978
Epoch [1/1], Batch [17/428], Loss: 10.3743
Epoch [1/1], Batch [18/428], Loss: 9.1532
Epoch [1/1], Batch [19/428], Loss: 6.4263
Epoch [1/1], Batch [20/428], Loss: 3.9597
Epoch [1/1], Batch [21/428], Loss: 3.4515
Epoch [1/1], Batch [22/428], Loss: 0.7058
Epoch [1/1], Batch [23/428], Loss: 3.7380
Epoch [1/1], Batch [24/428], Loss: 6.7915
Epoch [1/1], Batch [25/428], Loss: 2.4648
Epoch [1/1], Batch [26/428], Loss: 2.0439
Epoch [1/1], Batch [27/428], Loss: 2.3797
Epoch [1/1], Batch [28/428], Loss: 1.5889
Epoch [1/1], Batch [29/428], Loss: 4.6477
Epoch [1/1], Batch [30/428], Loss: 4.3348
Epoch [1/1], Batch [31/428], Loss: 1.1983
Epoch [1/1], Batch [32/428], Loss: 3.3873
Epoch [1/1], Batch [33/428], Loss: 2.8876
Epoch [1/1], Batch [34/428], Loss: 1.9672
Epoch [1/1], Batch [35/428], Loss: 2.6716
Epoch [1/1], Batch [36/428], Loss: 5.8738
Epoch [1/1], Batch [37/428], Loss: 2.8195
Epoch [1/1], Batch [38/428], Loss: 5.3047
Epoch [1/1], Batch [39/428], Loss: 2.0368
Epoch [1/1], Batch [40/428], Loss: 1.3640
Epoch [1/1], Batch [41/428], Loss: 5.0207
Epoch [1/1], Batch [42/428], Loss: 2.2054
Epoch [1/1], Batch [43/428], Loss: 5.1910
Epoch [1/1], Batch [44/428], Loss: 2.3534
Epoch [1/1], Batch [45/428], Loss: 5.8602
Epoch [1/1], Batch [46/428], Loss: 1.1025
Epoch [1/1], Batch [47/428], Loss: 4.8167
Epoch [1/1], Batch [48/428], Loss: 2.6692
Epoch [1/1], Batch [49/428], Loss: 2.5918
Epoch [1/1], Batch [50/428], Loss: 4.1700
Epoch [1/1], Batch [51/428], Loss: 5.3762
Epoch [1/1], Batch [52/428], Loss: 0.5788
Epoch [1/1], Batch [53/428], Loss: 1.7047
Epoch [1/1], Batch [54/428], Loss: 1.3921
Epoch [1/1], Batch [55/428], Loss: 2.2089
Epoch [1/1], Batch [56/428], Loss: 3.2621
Epoch [1/1], Batch [57/428], Loss: 1.6169
Epoch [1/1], Batch [58/428], Loss: 3.2089
Epoch [1/1], Batch [59/428], Loss: 1.1951
Epoch [1/1], Batch [60/428], Loss: 3.2264
Epoch [1/1], Batch [61/428], Loss: 0.7654
Epoch [1/1], Batch [62/428], Loss: 2.8313
Epoch [1/1], Batch [63/428], Loss: 1.6230
Epoch [1/1], Batch [64/428], Loss: 3.3883
Epoch [1/1], Batch [65/428], Loss: 0.8547
Epoch [1/1], Batch [66/428], Loss: 2.6816
Epoch [1/1], Batch [67/428], Loss: 1.6853
Epoch [1/1], Batch [68/428], Loss: 2.1971
Epoch [1/1], Batch [69/428], Loss: 1.6461
Epoch [1/1], Batch [70/428], Loss: 1.6455
Epoch [1/1], Batch [71/428], Loss: 1.7514
Epoch [1/1], Batch [72/428], Loss: 2.3845
Epoch [1/1], Batch [73/428], Loss: 0.7068
Epoch [1/1], Batch [74/428], Loss: 2.5819
Epoch [1/1], Batch [75/428], Loss: 5.4902
Epoch [1/1], Batch [76/428], Loss: 1.1448
Epoch [1/1], Batch [77/428], Loss: 0.8668
Epoch [1/1], Batch [78/428], Loss: 0.5123
Epoch [1/1], Batch [79/428], Loss: 2.3024
Epoch [1/1], Batch [80/428], Loss: 5.3204
Epoch [1/1], Batch [81/428], Loss: 5.6406
Epoch [1/1], Batch [82/428], Loss: 4.2260
Epoch [1/1], Batch [83/428], Loss: 8.2435
Epoch [1/1], Batch [84/428], Loss: 4.0621
Epoch [1/1], Batch [85/428], Loss: 3.9332
Epoch [1/1], Batch [86/428], Loss: 1.1375
Epoch [1/1], Batch [87/428], Loss: 0.9335
Epoch [1/1], Batch [88/428], Loss: 6.1379
Epoch [1/1], Batch [89/428], Loss: 1.4424
Epoch [1/1], Batch [90/428], Loss: 2.5624
Epoch [1/1], Batch [91/428], Loss: 1.0569
Epoch [1/1], Batch [92/428], Loss: 3.2268
Epoch [1/1], Batch [93/428], Loss: 2.7807
Epoch [1/1], Batch [94/428], Loss: 1.5266
Epoch [1/1], Batch [95/428], Loss: 3.3473
Epoch [1/1], Batch [96/428], Loss: 3.6183
Epoch [1/1], Batch [97/428], Loss: 2.7440
Epoch [1/1], Batch [98/428], Loss: 2.3521
Epoch [1/1], Batch [99/428], Loss: 1.8055
Epoch [1/1], Batch [100/428], Loss: 2.9169
Epoch [1/1], Batch [101/428], Loss: 2.9163
Epoch [1/1], Batch [102/428], Loss: 2.2704
Epoch [1/1], Batch [103/428], Loss: 2.2726
Epoch [1/1], Batch [104/428], Loss: 4.3174
Epoch [1/1], Batch [105/428], Loss: 1.8965
Epoch [1/1], Batch [106/428], Loss: 2.7967
Epoch [1/1], Batch [107/428], Loss: 1.1256
Epoch [1/1], Batch [108/428], Loss: 2.7644
Epoch [1/1], Batch [109/428], Loss: 1.7286
Epoch [1/1], Batch [110/428], Loss: 1.5480
Epoch [1/1], Batch [111/428], Loss: 2.1748
Epoch [1/1], Batch [112/428], Loss: 1.0041
Epoch [1/1], Batch [113/428], Loss: 4.0044
Epoch [1/1], Batch [114/428], Loss: 2.8569
Epoch [1/1], Batch [115/428], Loss: 3.9618
[INFO 06-13 17:40:49] ax.service.ax_client: Completed trial 1 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 17:40:49] ax.service.ax_client: Generated new trial 2 with parameters {'lr': 0.000408, 'num_epochs': 6, 'unfreeze_epoch': 3, 'max_length': 80000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder
Epoch [1/1], Batch [116/428], Loss: 5.4120
Epoch [1/1], Batch [117/428], Loss: 1.3872
Epoch [1/1], Batch [118/428], Loss: 2.8037
Epoch [1/1], Batch [119/428], Loss: 2.6524
Epoch [1/1], Batch [120/428], Loss: 2.7950
Epoch [1/1], Batch [121/428], Loss: 1.9984
Epoch [1/1], Batch [122/428], Loss: 1.6060
Epoch [1/1], Batch [123/428], Loss: 3.6875
Epoch [1/1], Batch [124/428], Loss: 2.0368
Epoch [1/1], Batch [125/428], Loss: 1.8368
Epoch [1/1], Batch [126/428], Loss: 3.8150
Epoch [1/1], Batch [127/428], Loss: 3.2643
Epoch [1/1], Batch [128/428], Loss: 3.9686
Epoch [1/1], Batch [129/428], Loss: 2.4773
Epoch [1/1], Batch [130/428], Loss: 2.3594
Epoch [1/1], Batch [131/428], Loss: 1.5367
Epoch [1/1], Batch [132/428], Loss: 1.4398
Epoch [1/1], Batch [133/428], Loss: 2.2426
Epoch [1/1], Batch [134/428], Loss: 1.0676
Epoch [1/1], Batch [135/428], Loss: 2.6301
Epoch [1/1], Batch [136/428], Loss: 2.2153
Epoch [1/1], Batch [137/428], Loss: 4.0967
Epoch [1/1], Batch [138/428], Loss: 0.7187
Epoch [1/1], Batch [139/428], Loss: 2.3015
Epoch [1/1], Batch [140/428], Loss: 2.6884
Epoch [1/1], Batch [141/428], Loss: 0.6454
Epoch [1/1], Batch [142/428], Loss: 0.5958
Epoch [1/1], Batch [143/428], Loss: 3.5345
Epoch [1/1], Batch [144/428], Loss: 0.4068
Epoch [1/1], Batch [145/428], Loss: 2.2731
Epoch [1/1], Batch [146/428], Loss: 3.2326
Epoch [1/1], Batch [147/428], Loss: 3.8193
Epoch [1/1], Batch [148/428], Loss: 3.7396
Epoch [1/1], Batch [149/428], Loss: 2.7562
Epoch [1/1], Batch [150/428], Loss: 3.1361
Epoch [1/1], Batch [151/428], Loss: 5.7587
Epoch [1/1], Batch [152/428], Loss: 1.7135
Epoch [1/1], Batch [153/428], Loss: 1.2025
Epoch [1/1], Batch [154/428], Loss: 1.3809
Epoch [1/1], Batch [155/428], Loss: 5.2801
Epoch [1/1], Batch [156/428], Loss: 1.4291
Epoch [1/1], Batch [157/428], Loss: 1.8263
Epoch [1/1], Batch [158/428], Loss: 1.7003
Epoch [1/1], Batch [159/428], Loss: 2.9455
Epoch [1/1], Batch [160/428], Loss: 1.2839
Epoch [1/1], Batch [161/428], Loss: 1.9543
Epoch [1/1], Batch [162/428], Loss: 0.7661
Epoch [1/1], Batch [163/428], Loss: 2.9343
Epoch [1/1], Batch [164/428], Loss: 2.2377
Epoch [1/1], Batch [165/428], Loss: 2.3172
Epoch [1/1], Batch [166/428], Loss: 3.4570
Epoch [1/1], Batch [167/428], Loss: 2.4181
Epoch [1/1], Batch [168/428], Loss: 4.2568
Epoch [1/1], Batch [169/428], Loss: 1.9260
Epoch [1/1], Batch [170/428], Loss: 3.5696
Epoch [1/1], Batch [171/428], Loss: 1.5187
Epoch [1/1], Batch [172/428], Loss: 1.1605
Epoch [1/1], Batch [173/428], Loss: 3.1906
Epoch [1/1], Batch [174/428], Loss: 2.9365
Epoch [1/1], Batch [175/428], Loss: 0.6919
Epoch [1/1], Batch [176/428], Loss: 2.1589
Epoch [1/1], Batch [177/428], Loss: 2.4726
Epoch [1/1], Batch [178/428], Loss: 3.3104
Epoch [1/1], Batch [179/428], Loss: 2.2799
Epoch [1/1], Batch [180/428], Loss: 2.0316
Epoch [1/1], Batch [181/428], Loss: 3.1341
Epoch [1/1], Batch [182/428], Loss: 1.1893
Epoch [1/1], Batch [183/428], Loss: 1.4700
Epoch [1/1], Batch [184/428], Loss: 2.8785
Epoch [1/1], Batch [185/428], Loss: 2.7814
Epoch [1/1], Batch [186/428], Loss: 0.9855
Epoch [1/1], Batch [187/428], Loss: 0.7899
Epoch [1/1], Batch [188/428], Loss: 1.9340
Epoch [1/1], Batch [189/428], Loss: 2.0452
Epoch [1/1], Batch [190/428], Loss: 3.2053
Epoch [1/1], Batch [191/428], Loss: 2.7948
Epoch [1/1], Batch [192/428], Loss: 4.0964
Epoch [1/1], Batch [193/428], Loss: 3.3206
Epoch [1/1], Batch [194/428], Loss: 2.4412
Epoch [1/1], Batch [195/428], Loss: 2.2635
Epoch [1/1], Batch [196/428], Loss: 2.5518
Epoch [1/1], Batch [197/428], Loss: 2.2999
Epoch [1/1], Batch [198/428], Loss: 1.7911
Epoch [1/1], Batch [199/428], Loss: 1.2779
Epoch [1/1], Batch [200/428], Loss: 1.5165
Epoch [1/1], Batch [201/428], Loss: 1.0340
Epoch [1/1], Batch [202/428], Loss: 3.2757
Epoch [1/1], Batch [203/428], Loss: 0.8729
Epoch [1/1], Batch [204/428], Loss: 0.6439
Epoch [1/1], Batch [205/428], Loss: 4.0285
Epoch [1/1], Batch [206/428], Loss: 4.0188
Epoch [1/1], Batch [207/428], Loss: 4.5664
Epoch [1/1], Batch [208/428], Loss: 3.8193
Epoch [1/1], Batch [209/428], Loss: 0.2834
Epoch [1/1], Batch [210/428], Loss: 4.5463
Epoch [1/1], Batch [211/428], Loss: 4.3179
Epoch [1/1], Batch [212/428], Loss: 4.0143
Epoch [1/1], Batch [213/428], Loss: 0.3000
Epoch [1/1], Batch [214/428], Loss: 3.8214
Epoch [1/1], Batch [215/428], Loss: 2.8008
Epoch [1/1], Batch [216/428], Loss: 0.4600
Epoch [1/1], Batch [217/428], Loss: 3.3177
Epoch [1/1], Batch [218/428], Loss: 3.2863
Epoch [1/1], Batch [219/428], Loss: 2.9182
Epoch [1/1], Batch [220/428], Loss: 1.3355
Epoch [1/1], Batch [221/428], Loss: 4.3990
Epoch [1/1], Batch [222/428], Loss: 4.2115
Epoch [1/1], Batch [223/428], Loss: 2.2876
Epoch [1/1], Batch [224/428], Loss: 2.1365
Epoch [1/1], Batch [225/428], Loss: 0.7608
Epoch [1/1], Batch [226/428], Loss: 1.8508
Epoch [1/1], Batch [227/428], Loss: 3.9797
Epoch [1/1], Batch [228/428], Loss: 3.9904
Epoch [1/1], Batch [229/428], Loss: 1.7095
Epoch [1/1], Batch [230/428], Loss: 1.1975
Epoch [1/1], Batch [231/428], Loss: 4.0421
Epoch [1/1], Batch [232/428], Loss: 4.0333
Epoch [1/1], Batch [233/428], Loss: 2.8439
Epoch [1/1], Batch [234/428], Loss: 1.3703
Epoch [1/1], Batch [235/428], Loss: 2.4094
Epoch [1/1], Batch [236/428], Loss: 2.1013
Epoch [1/1], Batch [237/428], Loss: 1.2014
Epoch [1/1], Batch [238/428], Loss: 1.2977
Epoch [1/1], Batch [239/428], Loss: 1.2643
Epoch [1/1], Batch [240/428], Loss: 3.1792
Epoch [1/1], Batch [241/428], Loss: 3.3549
Epoch [1/1], Batch [242/428], Loss: 3.3845
Epoch [1/1], Batch [243/428], Loss: 1.1324
Epoch [1/1], Batch [244/428], Loss: 2.3157
Epoch [1/1], Batch [245/428], Loss: 1.0536
Epoch [1/1], Batch [246/428], Loss: 4.6462
Epoch [1/1], Batch [247/428], Loss: 2.9174
Epoch [1/1], Batch [248/428], Loss: 0.7199
Epoch [1/1], Batch [249/428], Loss: 4.2055
Epoch [1/1], Batch [250/428], Loss: 1.9837
Epoch [1/1], Batch [251/428], Loss: 2.0518
Epoch [1/1], Batch [252/428], Loss: 2.2528
Epoch [1/1], Batch [253/428], Loss: 2.4532
Epoch [1/1], Batch [254/428], Loss: 1.7826
Epoch [1/1], Batch [255/428], Loss: 3.2597
Epoch [1/1], Batch [256/428], Loss: 1.5018
Epoch [1/1], Batch [257/428], Loss: 2.6405
Epoch [1/1], Batch [258/428], Loss: 1.8094
Epoch [1/1], Batch [259/428], Loss: 1.0545
Epoch [1/1], Batch [260/428], Loss: 0.9447
Epoch [1/1], Batch [261/428], Loss: 2.4523
Epoch [1/1], Batch [262/428], Loss: 2.1506
Epoch [1/1], Batch [263/428], Loss: 3.5986
Epoch [1/1], Batch [264/428], Loss: 3.5829
Epoch [1/1], Batch [265/428], Loss: 0.7291
Epoch [1/1], Batch [266/428], Loss: 0.6709
Epoch [1/1], Batch [267/428], Loss: 1.7818
Epoch [1/1], Batch [268/428], Loss: 0.5632
Epoch [1/1], Batch [269/428], Loss: 0.4648
Epoch [1/1], Batch [270/428], Loss: 3.3130
Epoch [1/1], Batch [271/428], Loss: 0.2978
Epoch [1/1], Batch [272/428], Loss: 0.2225
Epoch [1/1], Batch [273/428], Loss: 4.5837
Epoch [1/1], Batch [274/428], Loss: 3.6212
Epoch [1/1], Batch [275/428], Loss: 0.1044
Epoch [1/1], Batch [276/428], Loss: 0.0750
Epoch [1/1], Batch [277/428], Loss: 5.5578
Epoch [1/1], Batch [278/428], Loss: 5.7555
Epoch [1/1], Batch [279/428], Loss: 0.0380
Epoch [1/1], Batch [280/428], Loss: 5.7003
Epoch [1/1], Batch [281/428], Loss: 6.2598
Epoch [1/1], Batch [282/428], Loss: 6.2006
Epoch [1/1], Batch [283/428], Loss: 0.0322
Epoch [1/1], Batch [284/428], Loss: 4.9171
Epoch [1/1], Batch [285/428], Loss: 5.5265
Epoch [1/1], Batch [286/428], Loss: 6.0004
Epoch [1/1], Batch [287/428], Loss: 6.0514
Epoch [1/1], Batch [288/428], Loss: 3.2620
Epoch [1/1], Batch [289/428], Loss: 2.8694
Epoch [1/1], Batch [290/428], Loss: 2.1597
Epoch [1/1], Batch [291/428], Loss: 1.4991
Epoch [1/1], Batch [292/428], Loss: 0.7636
Epoch [1/1], Batch [293/428], Loss: 3.3444
Epoch [1/1], Batch [294/428], Loss: 0.4396
Epoch [1/1], Batch [295/428], Loss: 0.2641
Epoch [1/1], Batch [296/428], Loss: 3.7291
Epoch [1/1], Batch [297/428], Loss: 5.7936
Epoch [1/1], Batch [298/428], Loss: 3.6541
Epoch [1/1], Batch [299/428], Loss: 3.6978
Epoch [1/1], Batch [300/428], Loss: 5.1902
Epoch [1/1], Batch [301/428], Loss: 3.8913
Epoch [1/1], Batch [302/428], Loss: 3.3268
Epoch [1/1], Batch [303/428], Loss: 3.5331
Epoch [1/1], Batch [304/428], Loss: 2.0554
Epoch [1/1], Batch [305/428], Loss: 3.6542
Epoch [1/1], Batch [306/428], Loss: 2.6440
Epoch [1/1], Batch [307/428], Loss: 4.0352
Epoch [1/1], Batch [308/428], Loss: 3.8416
Epoch [1/1], Batch [309/428], Loss: 0.8820
Epoch [1/1], Batch [310/428], Loss: 2.3779
Epoch [1/1], Batch [311/428], Loss: 3.0677
Epoch [1/1], Batch [312/428], Loss: 1.9971
Epoch [1/1], Batch [313/428], Loss: 2.2900
Epoch [1/1], Batch [314/428], Loss: 1.8994
Epoch [1/1], Batch [315/428], Loss: 2.3590
Epoch [1/1], Batch [316/428], Loss: 4.6172
Epoch [1/1], Batch [317/428], Loss: 1.7200
Epoch [1/1], Batch [318/428], Loss: 2.3449
Epoch [1/1], Batch [319/428], Loss: 2.4762
Epoch [1/1], Batch [320/428], Loss: 5.0506
Epoch [1/1], Batch [321/428], Loss: 2.0000
Epoch [1/1], Batch [322/428], Loss: 2.7175
Epoch [1/1], Batch [323/428], Loss: 1.3322
Epoch [1/1], Batch [324/428], Loss: 1.2919
Epoch [1/1], Batch [325/428], Loss: 1.4107
Epoch [1/1], Batch [326/428], Loss: 4.5504
Epoch [1/1], Batch [327/428], Loss: 4.3691
Epoch [1/1], Batch [328/428], Loss: 2.2780
Epoch [1/1], Batch [329/428], Loss: 1.0559
Epoch [1/1], Batch [330/428], Loss: 2.6088
Epoch [1/1], Batch [331/428], Loss: 3.0708
Epoch [1/1], Batch [332/428], Loss: 2.2162
Epoch [1/1], Batch [333/428], Loss: 0.8573
Epoch [1/1], Batch [334/428], Loss: 2.9523
Epoch [1/1], Batch [335/428], Loss: 1.7770
Epoch [1/1], Batch [336/428], Loss: 2.6752
Epoch [1/1], Batch [337/428], Loss: 1.8263
Epoch [1/1], Batch [338/428], Loss: 1.8928
Epoch [1/1], Batch [339/428], Loss: 1.7345
Epoch [1/1], Batch [340/428], Loss: 1.2874
Epoch [1/1], Batch [341/428], Loss: 2.5709
Epoch [1/1], Batch [342/428], Loss: 2.0564
Epoch [1/1], Batch [343/428], Loss: 1.2165
Epoch [1/1], Batch [344/428], Loss: 2.3347
Epoch [1/1], Batch [345/428], Loss: 2.4565
Epoch [1/1], Batch [346/428], Loss: 2.0687
Epoch [1/1], Batch [347/428], Loss: 4.2939
Epoch [1/1], Batch [348/428], Loss: 2.2645
Epoch [1/1], Batch [349/428], Loss: 4.1101
Epoch [1/1], Batch [350/428], Loss: 1.2349
Epoch [1/1], Batch [351/428], Loss: 2.2342
Epoch [1/1], Batch [352/428], Loss: 2.1813
Epoch [1/1], Batch [353/428], Loss: 3.3064
Epoch [1/1], Batch [354/428], Loss: 2.7598
Epoch [1/1], Batch [355/428], Loss: 2.7918
Epoch [1/1], Batch [356/428], Loss: 1.7062
Epoch [1/1], Batch [357/428], Loss: 1.7898
Epoch [1/1], Batch [358/428], Loss: 2.7723
Epoch [1/1], Batch [359/428], Loss: 2.0528
Epoch [1/1], Batch [360/428], Loss: 2.6032
Epoch [1/1], Batch [361/428], Loss: 2.5272
Epoch [1/1], Batch [362/428], Loss: 2.8878
Epoch [1/1], Batch [363/428], Loss: 2.2460
Epoch [1/1], Batch [364/428], Loss: 2.0581
Epoch [1/1], Batch [365/428], Loss: 2.7509
Epoch [1/1], Batch [366/428], Loss: 2.0383
Epoch [1/1], Batch [367/428], Loss: 2.5480
Epoch [1/1], Batch [368/428], Loss: 1.2007
Epoch [1/1], Batch [369/428], Loss: 2.6214
Epoch [1/1], Batch [370/428], Loss: 2.5697
Epoch [1/1], Batch [371/428], Loss: 2.9100
Epoch [1/1], Batch [372/428], Loss: 0.8010
Epoch [1/1], Batch [373/428], Loss: 0.7038
Epoch [1/1], Batch [374/428], Loss: 2.1021
Epoch [1/1], Batch [375/428], Loss: 0.5175
Epoch [1/1], Batch [376/428], Loss: 0.4370
Epoch [1/1], Batch [377/428], Loss: 3.3292
Epoch [1/1], Batch [378/428], Loss: 3.5055
Epoch [1/1], Batch [379/428], Loss: 3.4204
Epoch [1/1], Batch [380/428], Loss: 3.5625
Epoch [1/1], Batch [381/428], Loss: 2.5955
Epoch [1/1], Batch [382/428], Loss: 0.2875
Epoch [1/1], Batch [383/428], Loss: 3.0656
Epoch [1/1], Batch [384/428], Loss: 3.2515
Epoch [1/1], Batch [385/428], Loss: 0.3542
Epoch [1/1], Batch [386/428], Loss: 2.3627
Epoch [1/1], Batch [387/428], Loss: 2.8108
Epoch [1/1], Batch [388/428], Loss: 0.4486
Epoch [1/1], Batch [389/428], Loss: 2.5119
Epoch [1/1], Batch [390/428], Loss: 0.5010
Epoch [1/1], Batch [391/428], Loss: 4.8935
Epoch [1/1], Batch [392/428], Loss: 4.7669
Epoch [1/1], Batch [393/428], Loss: 4.7409
Epoch [1/1], Batch [394/428], Loss: 0.5609
Epoch [1/1], Batch [395/428], Loss: 0.5405
Epoch [1/1], Batch [396/428], Loss: 0.4969
Epoch [1/1], Batch [397/428], Loss: 0.4139
Epoch [1/1], Batch [398/428], Loss: 2.6037
Epoch [1/1], Batch [399/428], Loss: 0.2888
Epoch [1/1], Batch [400/428], Loss: 0.2180
Epoch [1/1], Batch [401/428], Loss: 0.1542
Epoch [1/1], Batch [402/428], Loss: 4.6339
Epoch [1/1], Batch [403/428], Loss: 0.0821
Epoch [1/1], Batch [404/428], Loss: 4.5625
Epoch [1/1], Batch [405/428], Loss: 5.0692
Epoch [1/1], Batch [406/428], Loss: 4.6878
Epoch [1/1], Batch [407/428], Loss: 4.6349
Epoch [1/1], Batch [408/428], Loss: 6.1922
Epoch [1/1], Batch [409/428], Loss: 4.3624
Epoch [1/1], Batch [410/428], Loss: 3.9831
Epoch [1/1], Batch [411/428], Loss: 5.2619
Epoch [1/1], Batch [412/428], Loss: 0.1012
Epoch [1/1], Batch [413/428], Loss: 0.1172
Epoch [1/1], Batch [414/428], Loss: 5.1386
Epoch [1/1], Batch [415/428], Loss: 2.6490
Epoch [1/1], Batch [416/428], Loss: 4.6389
Epoch [1/1], Batch [417/428], Loss: 4.0869
Epoch [1/1], Batch [418/428], Loss: 3.8745
Epoch [1/1], Batch [419/428], Loss: 3.6203
Epoch [1/1], Batch [420/428], Loss: 3.3336
Epoch [1/1], Batch [421/428], Loss: 0.6685
Epoch [1/1], Batch [422/428], Loss: 0.7639
Epoch [1/1], Batch [423/428], Loss: 1.3666
Epoch [1/1], Batch [424/428], Loss: 2.1566
Epoch [1/1], Batch [425/428], Loss: 1.2557
Epoch [1/1], Batch [426/428], Loss: 3.0731
Epoch [1/1], Batch [427/428], Loss: 3.0262
Epoch [1/1], Batch [428/428], Loss: 1.0937
Epoch [1] Training Time: 212.30 seconds
Epoch [1/1], Average Loss: 2.6848, Training Accuracy: 0.1869
Epoch [1], Validation Loss: 2.4212, Validation Accuracy: 0.1429
Epoch [1] Validation Time: 7.47 seconds
--------------------------------------------------

Running trial 2 with config: {'batch_size': 1, 'lr': 0.0004076675739931088, 'num_epochs': 6, 'unfreeze_epoch': 3, 'max_length': 80000, 'device': device(type='cpu')}
Epoch [1/6], Batch [1/428], Loss: 3.4847
Epoch [1/6], Batch [2/428], Loss: 1.8887
Epoch [1/6], Batch [3/428], Loss: 2.8205
Epoch [1/6], Batch [4/428], Loss: 0.8439
Epoch [1/6], Batch [5/428], Loss: 2.1467
Epoch [1/6], Batch [6/428], Loss: 3.3566
Epoch [1/6], Batch [7/428], Loss: 4.1810
Epoch [1/6], Batch [8/428], Loss: 4.0147
Epoch [1/6], Batch [9/428], Loss: 0.8698
Epoch [1/6], Batch [10/428], Loss: 0.5193
Epoch [1/6], Batch [11/428], Loss: 2.6212
Epoch [1/6], Batch [12/428], Loss: 2.7567
Epoch [1/6], Batch [13/428], Loss: 1.0236
Epoch [1/6], Batch [14/428], Loss: 1.0202
Epoch [1/6], Batch [15/428], Loss: 3.0662
Epoch [1/6], Batch [16/428], Loss: 2.4754
Epoch [1/6], Batch [17/428], Loss: 0.8716
Epoch [1/6], Batch [18/428], Loss: 1.8769
Epoch [1/6], Batch [19/428], Loss: 0.8125
Epoch [1/6], Batch [20/428], Loss: 2.4237
Epoch [1/6], Batch [21/428], Loss: 2.8002
Epoch [1/6], Batch [22/428], Loss: 3.9117
Epoch [1/6], Batch [23/428], Loss: 0.2428
Epoch [1/6], Batch [24/428], Loss: 0.5850
Epoch [1/6], Batch [25/428], Loss: 0.5429
Epoch [1/6], Batch [26/428], Loss: 1.5798
Epoch [1/6], Batch [27/428], Loss: 1.3582
Epoch [1/6], Batch [28/428], Loss: 0.8853
Epoch [1/6], Batch [29/428], Loss: 0.9402
Epoch [1/6], Batch [30/428], Loss: 1.2070
Epoch [1/6], Batch [31/428], Loss: 3.3309
Epoch [1/6], Batch [32/428], Loss: 0.5337
Epoch [1/6], Batch [33/428], Loss: 0.8850
Epoch [1/6], Batch [34/428], Loss: 2.2089
Epoch [1/6], Batch [35/428], Loss: 0.2855
Epoch [1/6], Batch [36/428], Loss: 0.0432
Epoch [1/6], Batch [37/428], Loss: 2.6898
Epoch [1/6], Batch [38/428], Loss: 1.9134
Epoch [1/6], Batch [39/428], Loss: 1.9711
Epoch [1/6], Batch [40/428], Loss: 1.1270
Epoch [1/6], Batch [41/428], Loss: 2.2236
Epoch [1/6], Batch [42/428], Loss: 1.6570
Epoch [1/6], Batch [43/428], Loss: 0.7198
Epoch [1/6], Batch [44/428], Loss: 1.3957
Epoch [1/6], Batch [45/428], Loss: 2.4106
Epoch [1/6], Batch [46/428], Loss: 0.6030
Epoch [1/6], Batch [47/428], Loss: 0.0207
Epoch [1/6], Batch [48/428], Loss: 2.8587
Epoch [1/6], Batch [49/428], Loss: 1.5905
Epoch [1/6], Batch [50/428], Loss: 0.5492
Epoch [1/6], Batch [51/428], Loss: 1.1376
Epoch [1/6], Batch [52/428], Loss: 0.0083
Epoch [1/6], Batch [53/428], Loss: 0.9839
Epoch [1/6], Batch [54/428], Loss: 2.5316
Epoch [1/6], Batch [55/428], Loss: 0.1987
Epoch [1/6], Batch [56/428], Loss: 2.0623
Epoch [1/6], Batch [57/428], Loss: 2.4927
Epoch [1/6], Batch [58/428], Loss: 0.0268
Epoch [1/6], Batch [59/428], Loss: 2.3406
Epoch [1/6], Batch [60/428], Loss: 2.2808
Epoch [1/6], Batch [61/428], Loss: 1.2770
Epoch [1/6], Batch [62/428], Loss: 1.9917
Epoch [1/6], Batch [63/428], Loss: 0.0028
Epoch [1/6], Batch [64/428], Loss: 0.5603
Epoch [1/6], Batch [65/428], Loss: 0.1321
Epoch [1/6], Batch [66/428], Loss: 1.1968
Epoch [1/6], Batch [67/428], Loss: 2.4628
Epoch [1/6], Batch [68/428], Loss: 1.5461
Epoch [1/6], Batch [69/428], Loss: 1.4351
Epoch [1/6], Batch [70/428], Loss: 1.1391
Epoch [1/6], Batch [71/428], Loss: 1.2871
Epoch [1/6], Batch [72/428], Loss: 0.8121
Epoch [1/6], Batch [73/428], Loss: 3.2835
Epoch [1/6], Batch [74/428], Loss: 1.5280
Epoch [1/6], Batch [75/428], Loss: 3.0608
Epoch [1/6], Batch [76/428], Loss: 1.9440
Epoch [1/6], Batch [77/428], Loss: 1.1689
Epoch [1/6], Batch [78/428], Loss: 3.8893
Epoch [1/6], Batch [79/428], Loss: 2.3663
Epoch [1/6], Batch [80/428], Loss: 0.2233
Epoch [1/6], Batch [81/428], Loss: 1.3196
Epoch [1/6], Batch [82/428], Loss: 1.4799
Epoch [1/6], Batch [83/428], Loss: 0.4440
Epoch [1/6], Batch [84/428], Loss: 1.1821
Epoch [1/6], Batch [85/428], Loss: 2.8636
Epoch [1/6], Batch [86/428], Loss: 1.0583
Epoch [1/6], Batch [87/428], Loss: 0.5544
Epoch [1/6], Batch [88/428], Loss: 0.5912
Epoch [1/6], Batch [89/428], Loss: 0.6025
Epoch [1/6], Batch [90/428], Loss: 1.9677
Epoch [1/6], Batch [91/428], Loss: 0.2584
Epoch [1/6], Batch [92/428], Loss: 2.8699
Epoch [1/6], Batch [93/428], Loss: 1.9237
Epoch [1/6], Batch [94/428], Loss: 0.6317
Epoch [1/6], Batch [95/428], Loss: 0.5985
Epoch [1/6], Batch [96/428], Loss: 1.1008
Epoch [1/6], Batch [97/428], Loss: 0.0012
Epoch [1/6], Batch [98/428], Loss: 1.4323
Epoch [1/6], Batch [99/428], Loss: 2.4087
Epoch [1/6], Batch [100/428], Loss: 1.8711
Epoch [1/6], Batch [101/428], Loss: 3.7116
Epoch [1/6], Batch [102/428], Loss: 2.5200
Epoch [1/6], Batch [103/428], Loss: 0.0011
Epoch [1/6], Batch [104/428], Loss: 2.0238
Epoch [1/6], Batch [105/428], Loss: 0.0008
Epoch [1/6], Batch [106/428], Loss: 0.8886
Epoch [1/6], Batch [107/428], Loss: 0.6237
Epoch [1/6], Batch [108/428], Loss: 0.9944
Epoch [1/6], Batch [109/428], Loss: 0.0028
Epoch [1/6], Batch [110/428], Loss: 1.2705
Epoch [1/6], Batch [111/428], Loss: 4.0182
Epoch [1/6], Batch [112/428], Loss: 0.0024
Epoch [1/6], Batch [113/428], Loss: 0.0004
Epoch [1/6], Batch [114/428], Loss: 0.7027
Epoch [1/6], Batch [115/428], Loss: 0.9839
Epoch [1/6], Batch [116/428], Loss: 0.0012
Epoch [1/6], Batch [117/428], Loss: 0.4662
Epoch [1/6], Batch [118/428], Loss: 1.7481
Epoch [1/6], Batch [119/428], Loss: 0.3168
Epoch [1/6], Batch [120/428], Loss: 0.4835
Epoch [1/6], Batch [121/428], Loss: 0.5248
Epoch [1/6], Batch [122/428], Loss: 1.7881
Epoch [1/6], Batch [123/428], Loss: 0.2099
Epoch [1/6], Batch [124/428], Loss: 3.6257
Epoch [1/6], Batch [125/428], Loss: 1.0706
Epoch [1/6], Batch [126/428], Loss: 0.0063
Epoch [1/6], Batch [127/428], Loss: 0.0867
Epoch [1/6], Batch [128/428], Loss: 0.9967
Epoch [1/6], Batch [129/428], Loss: 0.9850
Epoch [1/6], Batch [130/428], Loss: 2.6280
Epoch [1/6], Batch [131/428], Loss: 2.8605
Epoch [1/6], Batch [132/428], Loss: 0.9837
Epoch [1/6], Batch [133/428], Loss: 0.2180
Epoch [1/6], Batch [134/428], Loss: 0.6982
Epoch [1/6], Batch [135/428], Loss: 0.4264
Epoch [1/6], Batch [136/428], Loss: 1.1683
Epoch [1/6], Batch [137/428], Loss: 3.3974
Epoch [1/6], Batch [138/428], Loss: 0.1982
Epoch [1/6], Batch [139/428], Loss: 0.2182
Epoch [1/6], Batch [140/428], Loss: 4.9441
Epoch [1/6], Batch [141/428], Loss: 0.2162
Epoch [1/6], Batch [142/428], Loss: 1.7826
Epoch [1/6], Batch [143/428], Loss: 0.8096
Epoch [1/6], Batch [144/428], Loss: 3.2937
Epoch [1/6], Batch [145/428], Loss: 0.0002
Epoch [1/6], Batch [146/428], Loss: 0.2179
Epoch [1/6], Batch [147/428], Loss: 3.7664
Epoch [1/6], Batch [148/428], Loss: 2.0522
Epoch [1/6], Batch [149/428], Loss: 1.6123
Epoch [1/6], Batch [150/428], Loss: 0.7915
Epoch [1/6], Batch [151/428], Loss: 0.2980
Epoch [1/6], Batch [152/428], Loss: 3.8577
Epoch [1/6], Batch [153/428], Loss: 4.4655
Epoch [1/6], Batch [154/428], Loss: 0.0044
Epoch [1/6], Batch [155/428], Loss: 0.0020
Epoch [1/6], Batch [156/428], Loss: 0.2395
Epoch [1/6], Batch [157/428], Loss: 2.3335
Epoch [1/6], Batch [158/428], Loss: 2.8480
Epoch [1/6], Batch [159/428], Loss: 0.0968
Epoch [1/6], Batch [160/428], Loss: 0.2789
Epoch [1/6], Batch [161/428], Loss: 5.1694
Epoch [1/6], Batch [162/428], Loss: 2.0002
Epoch [1/6], Batch [163/428], Loss: 0.0041
Epoch [1/6], Batch [164/428], Loss: 0.0778
Epoch [1/6], Batch [165/428], Loss: 1.5396
Epoch [1/6], Batch [166/428], Loss: 0.1450
Epoch [1/6], Batch [167/428], Loss: 2.0840
Epoch [1/6], Batch [168/428], Loss: 0.5251
Epoch [1/6], Batch [169/428], Loss: 1.0777
Epoch [1/6], Batch [170/428], Loss: 2.5270
Epoch [1/6], Batch [171/428], Loss: 0.4343
Epoch [1/6], Batch [172/428], Loss: 0.5488
Epoch [1/6], Batch [173/428], Loss: 1.7694
Epoch [1/6], Batch [174/428], Loss: 3.2925
Epoch [1/6], Batch [175/428], Loss: 4.2561
Epoch [1/6], Batch [176/428], Loss: 1.3092
Epoch [1/6], Batch [177/428], Loss: 4.7305
Epoch [1/6], Batch [178/428], Loss: 0.0063
Epoch [1/6], Batch [179/428], Loss: 1.6553
Epoch [1/6], Batch [180/428], Loss: 0.0580
Epoch [1/6], Batch [181/428], Loss: 2.2367
Epoch [1/6], Batch [182/428], Loss: 0.1334
Epoch [1/6], Batch [183/428], Loss: 0.9852
Epoch [1/6], Batch [184/428], Loss: 3.4587
Epoch [1/6], Batch [185/428], Loss: 0.5118
Epoch [1/6], Batch [186/428], Loss: 2.0671
Epoch [1/6], Batch [187/428], Loss: 2.2716
Epoch [1/6], Batch [188/428], Loss: 0.6633
Epoch [1/6], Batch [189/428], Loss: 1.0166
Epoch [1/6], Batch [190/428], Loss: 1.5270
Epoch [1/6], Batch [191/428], Loss: 1.5985
Epoch [1/6], Batch [192/428], Loss: 0.6630
Epoch [1/6], Batch [193/428], Loss: 0.6816
Epoch [1/6], Batch [194/428], Loss: 0.0021
Epoch [1/6], Batch [195/428], Loss: 2.4899
Epoch [1/6], Batch [196/428], Loss: 2.2370
Epoch [1/6], Batch [197/428], Loss: 2.1874
Epoch [1/6], Batch [198/428], Loss: 0.8590
Epoch [1/6], Batch [199/428], Loss: 0.9910
Epoch [1/6], Batch [200/428], Loss: 2.4752
Epoch [1/6], Batch [201/428], Loss: 0.1295
Epoch [1/6], Batch [202/428], Loss: 2.2750
Epoch [1/6], Batch [203/428], Loss: 0.0016
Epoch [1/6], Batch [204/428], Loss: 0.0040
Epoch [1/6], Batch [205/428], Loss: 2.5140
Epoch [1/6], Batch [206/428], Loss: 0.0103
Epoch [1/6], Batch [207/428], Loss: 4.4064
Epoch [1/6], Batch [208/428], Loss: 0.0017
Epoch [1/6], Batch [209/428], Loss: 2.6610
Epoch [1/6], Batch [210/428], Loss: 1.5175
Epoch [1/6], Batch [211/428], Loss: 2.1232
Epoch [1/6], Batch [212/428], Loss: 0.0009
Epoch [1/6], Batch [213/428], Loss: 1.3076
Epoch [1/6], Batch [214/428], Loss: 0.0042
Epoch [1/6], Batch [215/428], Loss: 0.0975
Epoch [1/6], Batch [216/428], Loss: 2.4374
Epoch [1/6], Batch [217/428], Loss: 2.7933
Epoch [1/6], Batch [218/428], Loss: 1.0078
Epoch [1/6], Batch [219/428], Loss: 1.2394
Epoch [1/6], Batch [220/428], Loss: 1.9934
Epoch [1/6], Batch [221/428], Loss: 2.4287
Epoch [1/6], Batch [222/428], Loss: 1.7335
Epoch [1/6], Batch [223/428], Loss: 0.2491
Epoch [1/6], Batch [224/428], Loss: 0.0020
Epoch [1/6], Batch [225/428], Loss: 0.0024
Epoch [1/6], Batch [226/428], Loss: 0.0585
Epoch [1/6], Batch [227/428], Loss: 1.0672
Epoch [1/6], Batch [228/428], Loss: 1.4846
Epoch [1/6], Batch [229/428], Loss: 0.0811
Epoch [1/6], Batch [230/428], Loss: 0.0675
Epoch [1/6], Batch [231/428], Loss: 0.5886
Epoch [1/6], Batch [232/428], Loss: 4.9059
Epoch [1/6], Batch [233/428], Loss: 0.0010
Epoch [1/6], Batch [234/428], Loss: 0.0007
Epoch [1/6], Batch [235/428], Loss: 0.0244
Epoch [1/6], Batch [236/428], Loss: 2.2930
Epoch [1/6], Batch [237/428], Loss: 0.0028
Epoch [1/6], Batch [238/428], Loss: 0.0006
Epoch [1/6], Batch [239/428], Loss: 2.0537
Epoch [1/6], Batch [240/428], Loss: 2.6792
Epoch [1/6], Batch [241/428], Loss: 0.5953
Epoch [1/6], Batch [242/428], Loss: 8.1870
Epoch [1/6], Batch [243/428], Loss: 1.4437
Epoch [1/6], Batch [244/428], Loss: 0.4976
Epoch [1/6], Batch [245/428], Loss: 1.2151
Epoch [1/6], Batch [246/428], Loss: 0.1010
Epoch [1/6], Batch [247/428], Loss: 1.4961
Epoch [1/6], Batch [248/428], Loss: 3.7908
Epoch [1/6], Batch [249/428], Loss: 1.3505
Epoch [1/6], Batch [250/428], Loss: 0.1057
Epoch [1/6], Batch [251/428], Loss: 0.0778
Epoch [1/6], Batch [252/428], Loss: 0.7602
Epoch [1/6], Batch [253/428], Loss: 0.0504
Epoch [1/6], Batch [254/428], Loss: 1.8473
Epoch [1/6], Batch [255/428], Loss: 4.4860
Epoch [1/6], Batch [256/428], Loss: 3.2370
Epoch [1/6], Batch [257/428], Loss: 0.0005
Epoch [1/6], Batch [258/428], Loss: 0.6018
Epoch [1/6], Batch [259/428], Loss: 0.9531
Epoch [1/6], Batch [260/428], Loss: 3.1987
Epoch [1/6], Batch [261/428], Loss: 0.0090
Epoch [1/6], Batch [262/428], Loss: 1.6614
Epoch [1/6], Batch [263/428], Loss: 1.9303
Epoch [1/6], Batch [264/428], Loss: 2.1288
Epoch [1/6], Batch [265/428], Loss: 0.0006
Epoch [1/6], Batch [266/428], Loss: 5.7258
Epoch [1/6], Batch [267/428], Loss: 0.0006
Epoch [1/6], Batch [268/428], Loss: 2.5758
Epoch [1/6], Batch [269/428], Loss: 0.0324
Epoch [1/6], Batch [270/428], Loss: 0.0015
Epoch [1/6], Batch [271/428], Loss: 0.0003
Epoch [1/6], Batch [272/428], Loss: 0.0055
Epoch [1/6], Batch [273/428], Loss: 1.6893
Epoch [1/6], Batch [274/428], Loss: 0.4968
Epoch [1/6], Batch [275/428], Loss: 1.9402
Epoch [1/6], Batch [276/428], Loss: 1.9069
Epoch [1/6], Batch [277/428], Loss: 6.7747
Epoch [1/6], Batch [278/428], Loss: 1.7131
Epoch [1/6], Batch [279/428], Loss: 1.4548
Epoch [1/6], Batch [280/428], Loss: 1.0001
Epoch [1/6], Batch [281/428], Loss: 0.5175
Epoch [1/6], Batch [282/428], Loss: 2.6809
Epoch [1/6], Batch [283/428], Loss: 1.5894
Epoch [1/6], Batch [284/428], Loss: 0.2962
Epoch [1/6], Batch [285/428], Loss: 0.6743
Epoch [1/6], Batch [286/428], Loss: 1.8018
Epoch [1/6], Batch [287/428], Loss: 1.8388
Epoch [1/6], Batch [288/428], Loss: 1.3306
Epoch [1/6], Batch [289/428], Loss: 2.4464
Epoch [1/6], Batch [290/428], Loss: 0.0947
Epoch [1/6], Batch [291/428], Loss: 0.0007
Epoch [1/6], Batch [292/428], Loss: 0.4893
Epoch [1/6], Batch [293/428], Loss: 1.2023
Epoch [1/6], Batch [294/428], Loss: 1.2903
Epoch [1/6], Batch [295/428], Loss: 1.2048
Epoch [1/6], Batch [296/428], Loss: 1.8404
Epoch [1/6], Batch [297/428], Loss: 1.0052
Epoch [1/6], Batch [298/428], Loss: 0.1358
Epoch [1/6], Batch [299/428], Loss: 0.6851
Epoch [1/6], Batch [300/428], Loss: 0.0714
Epoch [1/6], Batch [301/428], Loss: 0.7141
Epoch [1/6], Batch [302/428], Loss: 1.8952
Epoch [1/6], Batch [303/428], Loss: 0.9737
Epoch [1/6], Batch [304/428], Loss: 1.2988
Epoch [1/6], Batch [305/428], Loss: 2.4446
Epoch [1/6], Batch [306/428], Loss: 1.5827
Epoch [1/6], Batch [307/428], Loss: 1.1677
Epoch [1/6], Batch [308/428], Loss: 1.7954
Epoch [1/6], Batch [309/428], Loss: 3.5498
Epoch [1/6], Batch [310/428], Loss: 1.1660
Epoch [1/6], Batch [311/428], Loss: 1.0226
Epoch [1/6], Batch [312/428], Loss: 2.6746
Epoch [1/6], Batch [313/428], Loss: 1.7175
Epoch [1/6], Batch [314/428], Loss: 1.1215
Epoch [1/6], Batch [315/428], Loss: 1.8928
Epoch [1/6], Batch [316/428], Loss: 1.2010
Epoch [1/6], Batch [317/428], Loss: 0.8681
Epoch [1/6], Batch [318/428], Loss: 2.2898
Epoch [1/6], Batch [319/428], Loss: 3.9353
Epoch [1/6], Batch [320/428], Loss: 3.2722
Epoch [1/6], Batch [321/428], Loss: 0.0008
Epoch [1/6], Batch [322/428], Loss: 0.0554
Epoch [1/6], Batch [323/428], Loss: 2.4855
Epoch [1/6], Batch [324/428], Loss: 1.5094
Epoch [1/6], Batch [325/428], Loss: 0.0403
Epoch [1/6], Batch [326/428], Loss: 0.0062
Epoch [1/6], Batch [327/428], Loss: 1.4239
Epoch [1/6], Batch [328/428], Loss: 0.4816
Epoch [1/6], Batch [329/428], Loss: 0.6971
Epoch [1/6], Batch [330/428], Loss: 4.5300
Epoch [1/6], Batch [331/428], Loss: 0.9675
Epoch [1/6], Batch [332/428], Loss: 0.0009
Epoch [1/6], Batch [333/428], Loss: 0.0521
Epoch [1/6], Batch [334/428], Loss: 0.5238
Epoch [1/6], Batch [335/428], Loss: 0.6619
Epoch [1/6], Batch [336/428], Loss: 2.1734
Epoch [1/6], Batch [337/428], Loss: 2.5410
Epoch [1/6], Batch [338/428], Loss: 0.8953
Epoch [1/6], Batch [339/428], Loss: 3.2670
Epoch [1/6], Batch [340/428], Loss: 1.5739
Epoch [1/6], Batch [341/428], Loss: 0.0300
Epoch [1/6], Batch [342/428], Loss: 0.6851
Epoch [1/6], Batch [343/428], Loss: 2.8076
Epoch [1/6], Batch [344/428], Loss: 0.0962
Epoch [1/6], Batch [345/428], Loss: 0.0022
Epoch [1/6], Batch [346/428], Loss: 1.1655
Epoch [1/6], Batch [347/428], Loss: 0.8733
Epoch [1/6], Batch [348/428], Loss: 0.1962
Epoch [1/6], Batch [349/428], Loss: 1.4193
Epoch [1/6], Batch [350/428], Loss: 1.7935
Epoch [1/6], Batch [351/428], Loss: 0.0367
Epoch [1/6], Batch [352/428], Loss: 0.0045
Epoch [1/6], Batch [353/428], Loss: 0.0156
Epoch [1/6], Batch [354/428], Loss: 3.2275
Epoch [1/6], Batch [355/428], Loss: 0.6825
Epoch [1/6], Batch [356/428], Loss: 0.0315
Epoch [1/6], Batch [357/428], Loss: 0.0022
Epoch [1/6], Batch [358/428], Loss: 0.0382
Epoch [1/6], Batch [359/428], Loss: 2.0271
Epoch [1/6], Batch [360/428], Loss: 3.8312
Epoch [1/6], Batch [361/428], Loss: 2.0624
Epoch [1/6], Batch [362/428], Loss: 0.1378
Epoch [1/6], Batch [363/428], Loss: 1.2214
Epoch [1/6], Batch [364/428], Loss: 2.1587
Epoch [1/6], Batch [365/428], Loss: 0.0006
Epoch [1/6], Batch [366/428], Loss: 0.0065
Epoch [1/6], Batch [367/428], Loss: 0.0579
Epoch [1/6], Batch [368/428], Loss: 4.9096
Epoch [1/6], Batch [369/428], Loss: 1.7077
Epoch [1/6], Batch [370/428], Loss: 0.8156
Epoch [1/6], Batch [371/428], Loss: 0.5984
Epoch [1/6], Batch [372/428], Loss: 5.1041
Epoch [1/6], Batch [373/428], Loss: 0.5457
Epoch [1/6], Batch [374/428], Loss: 1.5959
Epoch [1/6], Batch [375/428], Loss: 0.0578
Epoch [1/6], Batch [376/428], Loss: 0.7456
Epoch [1/6], Batch [377/428], Loss: 0.0061
Epoch [1/6], Batch [378/428], Loss: 8.3124
Epoch [1/6], Batch [379/428], Loss: 2.0351
Epoch [1/6], Batch [380/428], Loss: 1.9017
Epoch [1/6], Batch [381/428], Loss: 3.3642
Epoch [1/6], Batch [382/428], Loss: 0.4771
Epoch [1/6], Batch [383/428], Loss: 2.1110
Epoch [1/6], Batch [384/428], Loss: 2.1749
Epoch [1/6], Batch [385/428], Loss: 0.7583
Epoch [1/6], Batch [386/428], Loss: 0.0002
Epoch [1/6], Batch [387/428], Loss: 0.1536
Epoch [1/6], Batch [388/428], Loss: 0.0014
Epoch [1/6], Batch [389/428], Loss: 4.5346
Epoch [1/6], Batch [390/428], Loss: 2.2858
Epoch [1/6], Batch [391/428], Loss: 1.1995
Epoch [1/6], Batch [392/428], Loss: 0.0817
Epoch [1/6], Batch [393/428], Loss: 0.9310
Epoch [1/6], Batch [394/428], Loss: 0.1059
Epoch [1/6], Batch [395/428], Loss: 3.0250
Epoch [1/6], Batch [396/428], Loss: 0.0011
Epoch [1/6], Batch [397/428], Loss: 0.5420
Epoch [1/6], Batch [398/428], Loss: 3.0308
Epoch [1/6], Batch [399/428], Loss: 0.0082
Epoch [1/6], Batch [400/428], Loss: 2.5377
Epoch [1/6], Batch [401/428], Loss: 1.6120
Epoch [1/6], Batch [402/428], Loss: 0.0157
Epoch [1/6], Batch [403/428], Loss: 0.0055
Epoch [1/6], Batch [404/428], Loss: 2.2107
Epoch [1/6], Batch [405/428], Loss: 0.2752
Epoch [1/6], Batch [406/428], Loss: 3.1022
Epoch [1/6], Batch [407/428], Loss: 2.5477
Epoch [1/6], Batch [408/428], Loss: 0.0004
Epoch [1/6], Batch [409/428], Loss: 0.0070
Epoch [1/6], Batch [410/428], Loss: 1.4429
Epoch [1/6], Batch [411/428], Loss: 0.0561
Epoch [1/6], Batch [412/428], Loss: 0.0501
Epoch [1/6], Batch [413/428], Loss: 2.7848
Epoch [1/6], Batch [414/428], Loss: 1.3710
Epoch [1/6], Batch [415/428], Loss: 0.5734
Epoch [1/6], Batch [416/428], Loss: 1.1999
Epoch [1/6], Batch [417/428], Loss: 0.4956
Epoch [1/6], Batch [418/428], Loss: 1.3613
Epoch [1/6], Batch [419/428], Loss: 1.8949
Epoch [1/6], Batch [420/428], Loss: 1.7216
Epoch [1/6], Batch [421/428], Loss: 2.1160
Epoch [1/6], Batch [422/428], Loss: 0.0003
Epoch [1/6], Batch [423/428], Loss: 1.8478
Epoch [1/6], Batch [424/428], Loss: 0.2936
Epoch [1/6], Batch [425/428], Loss: 1.1855
Epoch [1/6], Batch [426/428], Loss: 4.9690
Epoch [1/6], Batch [427/428], Loss: 0.0002
Epoch [1/6], Batch [428/428], Loss: 4.3541
Epoch [1] Training Time: 171.41 seconds
Epoch [1/6], Average Loss: 1.4169, Training Accuracy: 0.5047
Epoch [1], Validation Loss: 1.7642, Validation Accuracy: 0.4977
Epoch [1] Validation Time: 10.91 seconds
--------------------------------------------------
Epoch [2/6], Batch [1/428], Loss: 0.0005
Epoch [2/6], Batch [2/428], Loss: 0.0450
Epoch [2/6], Batch [3/428], Loss: 0.6608
Epoch [2/6], Batch [4/428], Loss: 0.0002
Epoch [2/6], Batch [5/428], Loss: 2.5406
Epoch [2/6], Batch [6/428], Loss: 1.6773
Epoch [2/6], Batch [7/428], Loss: 0.0669
Epoch [2/6], Batch [8/428], Loss: 0.0005
Epoch [2/6], Batch [9/428], Loss: 0.6520
Epoch [2/6], Batch [10/428], Loss: 1.5241
Epoch [2/6], Batch [11/428], Loss: 0.0489
Epoch [2/6], Batch [12/428], Loss: 0.0009
Epoch [2/6], Batch [13/428], Loss: 1.0072
Epoch [2/6], Batch [14/428], Loss: 1.0410
Epoch [2/6], Batch [15/428], Loss: 1.0569
Epoch [2/6], Batch [16/428], Loss: 1.4351
Epoch [2/6], Batch [17/428], Loss: 2.0356
Epoch [2/6], Batch [18/428], Loss: 0.0002
Epoch [2/6], Batch [19/428], Loss: 0.0005
Epoch [2/6], Batch [20/428], Loss: 1.3468
Epoch [2/6], Batch [21/428], Loss: 2.3991
Epoch [2/6], Batch [22/428], Loss: 1.9377
Epoch [2/6], Batch [23/428], Loss: 1.7341
Epoch [2/6], Batch [24/428], Loss: 0.0002
Epoch [2/6], Batch [25/428], Loss: 0.0004
Epoch [2/6], Batch [26/428], Loss: 0.0002
Epoch [2/6], Batch [27/428], Loss: 1.2607
Epoch [2/6], Batch [28/428], Loss: 1.9331
Epoch [2/6], Batch [29/428], Loss: 1.3617
Epoch [2/6], Batch [30/428], Loss: 1.9565
Epoch [2/6], Batch [31/428], Loss: 0.8197
Epoch [2/6], Batch [32/428], Loss: 0.6816
Epoch [2/6], Batch [33/428], Loss: 0.4183
Epoch [2/6], Batch [34/428], Loss: 1.3827
Epoch [2/6], Batch [35/428], Loss: 0.0152
Epoch [2/6], Batch [36/428], Loss: 2.1312
Epoch [2/6], Batch [37/428], Loss: 2.2022
Epoch [2/6], Batch [38/428], Loss: 0.0014
Epoch [2/6], Batch [39/428], Loss: 3.6758
Epoch [2/6], Batch [40/428], Loss: 0.6841
Epoch [2/6], Batch [41/428], Loss: 1.0799
Epoch [2/6], Batch [42/428], Loss: 0.7843
Epoch [2/6], Batch [43/428], Loss: 0.9952
Epoch [2/6], Batch [44/428], Loss: 1.4956
Epoch [2/6], Batch [45/428], Loss: 3.0351
Epoch [2/6], Batch [46/428], Loss: 0.1738
Epoch [2/6], Batch [47/428], Loss: 0.6951
Epoch [2/6], Batch [48/428], Loss: 2.1302
Epoch [2/6], Batch [49/428], Loss: 1.0039
Epoch [2/6], Batch [50/428], Loss: 1.9657
Epoch [2/6], Batch [51/428], Loss: 0.1547
Epoch [2/6], Batch [52/428], Loss: 3.5121
Epoch [2/6], Batch [53/428], Loss: 1.6953
Epoch [2/6], Batch [54/428], Loss: 2.7601
Epoch [2/6], Batch [55/428], Loss: 0.0702
Epoch [2/6], Batch [56/428], Loss: 1.4454
Epoch [2/6], Batch [57/428], Loss: 0.0003
Epoch [2/6], Batch [58/428], Loss: 1.2776
Epoch [2/6], Batch [59/428], Loss: 1.4741
Epoch [2/6], Batch [60/428], Loss: 1.0256
Epoch [2/6], Batch [61/428], Loss: 1.3050
Epoch [2/6], Batch [62/428], Loss: 0.0195
Epoch [2/6], Batch [63/428], Loss: 1.2714
Epoch [2/6], Batch [64/428], Loss: 0.5738
Epoch [2/6], Batch [65/428], Loss: 0.0365
Epoch [2/6], Batch [66/428], Loss: 0.1627
Epoch [2/6], Batch [67/428], Loss: 1.6053
Epoch [2/6], Batch [68/428], Loss: 1.2729
Epoch [2/6], Batch [69/428], Loss: 0.0014
Epoch [2/6], Batch [70/428], Loss: 4.0330
Epoch [2/6], Batch [71/428], Loss: 1.1833
Epoch [2/6], Batch [72/428], Loss: 1.4929
Epoch [2/6], Batch [73/428], Loss: 1.3753
Epoch [2/6], Batch [74/428], Loss: 0.3326
Epoch [2/6], Batch [75/428], Loss: 0.0021
Epoch [2/6], Batch [76/428], Loss: 1.4267
Epoch [2/6], Batch [77/428], Loss: 0.6795
Epoch [2/6], Batch [78/428], Loss: 1.2382
Epoch [2/6], Batch [79/428], Loss: 0.0693
Epoch [2/6], Batch [80/428], Loss: 0.0457
Epoch [2/6], Batch [81/428], Loss: 0.7420
Epoch [2/6], Batch [82/428], Loss: 1.1733
Epoch [2/6], Batch [83/428], Loss: 0.7329
Epoch [2/6], Batch [84/428], Loss: 3.0033
Epoch [2/6], Batch [85/428], Loss: 1.1311
Epoch [2/6], Batch [86/428], Loss: 0.0033
Epoch [2/6], Batch [87/428], Loss: 0.6988
Epoch [2/6], Batch [88/428], Loss: 0.3299
Epoch [2/6], Batch [89/428], Loss: 0.6811
Epoch [2/6], Batch [90/428], Loss: 0.8227
Epoch [2/6], Batch [91/428], Loss: 2.5873
Epoch [2/6], Batch [92/428], Loss: 1.4070
Epoch [2/6], Batch [93/428], Loss: 2.1539
Epoch [2/6], Batch [94/428], Loss: 0.6379
Epoch [2/6], Batch [95/428], Loss: 0.8197
Epoch [2/6], Batch [96/428], Loss: 0.6154
Epoch [2/6], Batch [97/428], Loss: 1.1987
Epoch [2/6], Batch [98/428], Loss: 1.8310
Epoch [2/6], Batch [99/428], Loss: 0.3876
Epoch [2/6], Batch [100/428], Loss: 1.4237
Epoch [2/6], Batch [101/428], Loss: 2.2746
Epoch [2/6], Batch [102/428], Loss: 2.2507
Epoch [2/6], Batch [103/428], Loss: 0.0044
Epoch [2/6], Batch [104/428], Loss: 0.1592
Epoch [2/6], Batch [105/428], Loss: 2.1640
Epoch [2/6], Batch [106/428], Loss: 3.2340
Epoch [2/6], Batch [107/428], Loss: 1.3019
Epoch [2/6], Batch [108/428], Loss: 0.7652
Epoch [2/6], Batch [109/428], Loss: 1.6919
Epoch [2/6], Batch [110/428], Loss: 1.2067
Epoch [2/6], Batch [111/428], Loss: 0.5009
Epoch [2/6], Batch [112/428], Loss: 2.2722
Epoch [2/6], Batch [113/428], Loss: 0.6644
Epoch [2/6], Batch [114/428], Loss: 0.1217
Epoch [2/6], Batch [115/428], Loss: 1.6298
Epoch [2/6], Batch [116/428], Loss: 0.3698
Epoch [2/6], Batch [117/428], Loss: 0.4586
Epoch [2/6], Batch [118/428], Loss: 0.8908
Epoch [2/6], Batch [119/428], Loss: 1.1833
Epoch [2/6], Batch [120/428], Loss: 0.0070
Epoch [2/6], Batch [121/428], Loss: 1.7387
Epoch [2/6], Batch [122/428], Loss: 0.0275
Epoch [2/6], Batch [123/428], Loss: 0.0852
Epoch [2/6], Batch [124/428], Loss: 0.0000
Epoch [2/6], Batch [125/428], Loss: 0.8416
Epoch [2/6], Batch [126/428], Loss: 1.1853
Epoch [2/6], Batch [127/428], Loss: 0.0120
Epoch [2/6], Batch [128/428], Loss: 0.4111
Epoch [2/6], Batch [129/428], Loss: 0.5682
Epoch [2/6], Batch [130/428], Loss: 1.1435
Epoch [2/6], Batch [131/428], Loss: 1.2162
Epoch [2/6], Batch [132/428], Loss: 2.7789
Epoch [2/6], Batch [133/428], Loss: 0.8089
Epoch [2/6], Batch [134/428], Loss: 0.5951
Epoch [2/6], Batch [135/428], Loss: 1.2687
Epoch [2/6], Batch [136/428], Loss: 1.1700
Epoch [2/6], Batch [137/428], Loss: 2.5800
Epoch [2/6], Batch [138/428], Loss: 0.0074
Epoch [2/6], Batch [139/428], Loss: 0.0535
Epoch [2/6], Batch [140/428], Loss: 0.6126
Epoch [2/6], Batch [141/428], Loss: 0.0986
Epoch [2/6], Batch [142/428], Loss: 1.4456
Epoch [2/6], Batch [143/428], Loss: 2.6347
Epoch [2/6], Batch [144/428], Loss: 1.0071
Epoch [2/6], Batch [145/428], Loss: 0.5946
Epoch [2/6], Batch [146/428], Loss: 0.0001
Epoch [2/6], Batch [147/428], Loss: 0.0029
Epoch [2/6], Batch [148/428], Loss: 0.2855
Epoch [2/6], Batch [149/428], Loss: 2.7439
Epoch [2/6], Batch [150/428], Loss: 0.4965
Epoch [2/6], Batch [151/428], Loss: 0.0000
Epoch [2/6], Batch [152/428], Loss: 2.6168
Epoch [2/6], Batch [153/428], Loss: 0.7649
Epoch [2/6], Batch [154/428], Loss: 1.7627
Epoch [2/6], Batch [155/428], Loss: 0.1314
Epoch [2/6], Batch [156/428], Loss: 2.3284
Epoch [2/6], Batch [157/428], Loss: 1.4010
Epoch [2/6], Batch [158/428], Loss: 1.5215
Epoch [2/6], Batch [159/428], Loss: 0.2544
Epoch [2/6], Batch [160/428], Loss: 0.1191
Epoch [2/6], Batch [161/428], Loss: 0.9532
Epoch [2/6], Batch [162/428], Loss: 2.3304
Epoch [2/6], Batch [163/428], Loss: 1.3721
Epoch [2/6], Batch [164/428], Loss: 1.9042
Epoch [2/6], Batch [165/428], Loss: 3.6680
Epoch [2/6], Batch [166/428], Loss: 1.3683
Epoch [2/6], Batch [167/428], Loss: 1.9371
Epoch [2/6], Batch [168/428], Loss: 0.0703
Epoch [2/6], Batch [169/428], Loss: 1.1850
Epoch [2/6], Batch [170/428], Loss: 0.5416
Epoch [2/6], Batch [171/428], Loss: 2.6373
Epoch [2/6], Batch [172/428], Loss: 1.0211
Epoch [2/6], Batch [173/428], Loss: 1.9220
Epoch [2/6], Batch [174/428], Loss: 1.0780
Epoch [2/6], Batch [175/428], Loss: 0.8509
Epoch [2/6], Batch [176/428], Loss: 0.2168
Epoch [2/6], Batch [177/428], Loss: 1.0819
Epoch [2/6], Batch [178/428], Loss: 2.3277
Epoch [2/6], Batch [179/428], Loss: 0.1435
Epoch [2/6], Batch [180/428], Loss: 0.6981
Epoch [2/6], Batch [181/428], Loss: 0.1276
Epoch [2/6], Batch [182/428], Loss: 0.6387
Epoch [2/6], Batch [183/428], Loss: 0.0095
Epoch [2/6], Batch [184/428], Loss: 0.0516
Epoch [2/6], Batch [185/428], Loss: 0.0701
Epoch [2/6], Batch [186/428], Loss: 0.0000
Epoch [2/6], Batch [187/428], Loss: 1.4396
Epoch [2/6], Batch [188/428], Loss: 1.0475
Epoch [2/6], Batch [189/428], Loss: 1.0906
Epoch [2/6], Batch [190/428], Loss: 0.0001
Epoch [2/6], Batch [191/428], Loss: 0.4319
Epoch [2/6], Batch [192/428], Loss: 1.0344
Epoch [2/6], Batch [193/428], Loss: 0.5388
Epoch [2/6], Batch [194/428], Loss: 0.4515
Epoch [2/6], Batch [195/428], Loss: 1.0423
Epoch [2/6], Batch [196/428], Loss: 0.1425
Epoch [2/6], Batch [197/428], Loss: 1.5432
Epoch [2/6], Batch [198/428], Loss: 1.9535
Epoch [2/6], Batch [199/428], Loss: 1.2648
Epoch [2/6], Batch [200/428], Loss: 0.1033
Epoch [2/6], Batch [201/428], Loss: 1.3597
Epoch [2/6], Batch [202/428], Loss: 0.1085
Epoch [2/6], Batch [203/428], Loss: 2.6134
Epoch [2/6], Batch [204/428], Loss: 0.6601
Epoch [2/6], Batch [205/428], Loss: 0.0055
Epoch [2/6], Batch [206/428], Loss: 2.7710
Epoch [2/6], Batch [207/428], Loss: 0.1736
Epoch [2/6], Batch [208/428], Loss: 1.8897
Epoch [2/6], Batch [209/428], Loss: 0.0000
Epoch [2/6], Batch [210/428], Loss: 0.4208
Epoch [2/6], Batch [211/428], Loss: 2.2093
Epoch [2/6], Batch [212/428], Loss: 0.0000
Epoch [2/6], Batch [213/428], Loss: 0.0026
Epoch [2/6], Batch [214/428], Loss: 2.2945
Epoch [2/6], Batch [215/428], Loss: 0.1541
Epoch [2/6], Batch [216/428], Loss: 0.1747
Epoch [2/6], Batch [217/428], Loss: 0.9752
Epoch [2/6], Batch [218/428], Loss: 2.0421
Epoch [2/6], Batch [219/428], Loss: 0.2089
Epoch [2/6], Batch [220/428], Loss: 3.3773
Epoch [2/6], Batch [221/428], Loss: 1.5934
Epoch [2/6], Batch [222/428], Loss: 1.1671
Epoch [2/6], Batch [223/428], Loss: 1.1273
Epoch [2/6], Batch [224/428], Loss: 0.7942
Epoch [2/6], Batch [225/428], Loss: 0.2416
Epoch [2/6], Batch [226/428], Loss: 0.8425
Epoch [2/6], Batch [227/428], Loss: 0.0008
Epoch [2/6], Batch [228/428], Loss: 3.9551
Epoch [2/6], Batch [229/428], Loss: 0.0001
Epoch [2/6], Batch [230/428], Loss: 0.4038
Epoch [2/6], Batch [231/428], Loss: 0.0001
Epoch [2/6], Batch [232/428], Loss: 0.5195
Epoch [2/6], Batch [233/428], Loss: 0.0013
Epoch [2/6], Batch [234/428], Loss: 2.9649
Epoch [2/6], Batch [235/428], Loss: 2.1108
Epoch [2/6], Batch [236/428], Loss: 0.0159
Epoch [2/6], Batch [237/428], Loss: 0.3763
Epoch [2/6], Batch [238/428], Loss: 0.1631
Epoch [2/6], Batch [239/428], Loss: 4.4455
Epoch [2/6], Batch [240/428], Loss: 4.1125
Epoch [2/6], Batch [241/428], Loss: 2.8414
Epoch [2/6], Batch [242/428], Loss: 0.0411
Epoch [2/6], Batch [243/428], Loss: 2.2551
Epoch [2/6], Batch [244/428], Loss: 3.3718
Epoch [2/6], Batch [245/428], Loss: 0.0004
Epoch [2/6], Batch [246/428], Loss: 0.0465
Epoch [2/6], Batch [247/428], Loss: 2.9327
Epoch [2/6], Batch [248/428], Loss: 0.9472
Epoch [2/6], Batch [249/428], Loss: 2.7604
Epoch [2/6], Batch [250/428], Loss: 1.3353
Epoch [2/6], Batch [251/428], Loss: 3.7945
Epoch [2/6], Batch [252/428], Loss: 2.4183
Epoch [2/6], Batch [253/428], Loss: 1.1499
Epoch [2/6], Batch [254/428], Loss: 0.0002
Epoch [2/6], Batch [255/428], Loss: 1.0052
Epoch [2/6], Batch [256/428], Loss: 0.0002
Epoch [2/6], Batch [257/428], Loss: 0.2520
Epoch [2/6], Batch [258/428], Loss: 1.3028
Epoch [2/6], Batch [259/428], Loss: 0.8955
Epoch [2/6], Batch [260/428], Loss: 1.2318
Epoch [2/6], Batch [261/428], Loss: 0.4619
Epoch [2/6], Batch [262/428], Loss: 0.6529
Epoch [2/6], Batch [263/428], Loss: 0.3209
Epoch [2/6], Batch [264/428], Loss: 0.3945
Epoch [2/6], Batch [265/428], Loss: 0.1029
Epoch [2/6], Batch [266/428], Loss: 0.7994
Epoch [2/6], Batch [267/428], Loss: 0.1460
Epoch [2/6], Batch [268/428], Loss: 0.1796
Epoch [2/6], Batch [269/428], Loss: 1.1379
Epoch [2/6], Batch [270/428], Loss: 3.1048
Epoch [2/6], Batch [271/428], Loss: 0.0158
Epoch [2/6], Batch [272/428], Loss: 0.3104
Epoch [2/6], Batch [273/428], Loss: 0.0016
Epoch [2/6], Batch [274/428], Loss: 0.0571
Epoch [2/6], Batch [275/428], Loss: 0.9459
Epoch [2/6], Batch [276/428], Loss: 0.1823
Epoch [2/6], Batch [277/428], Loss: 0.1569
Epoch [2/6], Batch [278/428], Loss: 0.0000
Epoch [2/6], Batch [279/428], Loss: 1.4815
Epoch [2/6], Batch [280/428], Loss: 3.0072
Epoch [2/6], Batch [281/428], Loss: 5.4580
Epoch [2/6], Batch [282/428], Loss: 0.0632
Epoch [2/6], Batch [283/428], Loss: 0.0004
Epoch [2/6], Batch [284/428], Loss: 1.3563
Epoch [2/6], Batch [285/428], Loss: 1.0940
Epoch [2/6], Batch [286/428], Loss: 0.6850
Epoch [2/6], Batch [287/428], Loss: 0.4649
Epoch [2/6], Batch [288/428], Loss: 0.0001
Epoch [2/6], Batch [289/428], Loss: 0.0938
Epoch [2/6], Batch [290/428], Loss: 0.1385
Epoch [2/6], Batch [291/428], Loss: 0.0097
Epoch [2/6], Batch [292/428], Loss: 0.0002
Epoch [2/6], Batch [293/428], Loss: 5.3593
Epoch [2/6], Batch [294/428], Loss: 0.1848
Epoch [2/6], Batch [295/428], Loss: 2.4214
Epoch [2/6], Batch [296/428], Loss: 3.9863
Epoch [2/6], Batch [297/428], Loss: 0.3161
Epoch [2/6], Batch [298/428], Loss: 1.2442
Epoch [2/6], Batch [299/428], Loss: 0.0194
Epoch [2/6], Batch [300/428], Loss: 1.1594
Epoch [2/6], Batch [301/428], Loss: 0.1138
Epoch [2/6], Batch [302/428], Loss: 0.4110
Epoch [2/6], Batch [303/428], Loss: 2.6625
Epoch [2/6], Batch [304/428], Loss: 0.0958
Epoch [2/6], Batch [305/428], Loss: 3.1434
Epoch [2/6], Batch [306/428], Loss: 2.8745
Epoch [2/6], Batch [307/428], Loss: 0.0342
Epoch [2/6], Batch [308/428], Loss: 0.1671
Epoch [2/6], Batch [309/428], Loss: 0.0003
Epoch [2/6], Batch [310/428], Loss: 0.1116
Epoch [2/6], Batch [311/428], Loss: 0.1956
Epoch [2/6], Batch [312/428], Loss: 0.0016
Epoch [2/6], Batch [313/428], Loss: 0.0028
Epoch [2/6], Batch [314/428], Loss: 0.1010
Epoch [2/6], Batch [315/428], Loss: 0.2718
Epoch [2/6], Batch [316/428], Loss: 4.0517
Epoch [2/6], Batch [317/428], Loss: 0.8702
Epoch [2/6], Batch [318/428], Loss: 4.3557
Epoch [2/6], Batch [319/428], Loss: 3.7778
Epoch [2/6], Batch [320/428], Loss: 0.0014
Epoch [2/6], Batch [321/428], Loss: 0.0020
Epoch [2/6], Batch [322/428], Loss: 0.8970
Epoch [2/6], Batch [323/428], Loss: 2.0604
Epoch [2/6], Batch [324/428], Loss: 0.0046
Epoch [2/6], Batch [325/428], Loss: 0.3444
Epoch [2/6], Batch [326/428], Loss: 0.0147
Epoch [2/6], Batch [327/428], Loss: 0.0104
Epoch [2/6], Batch [328/428], Loss: 3.0405
Epoch [2/6], Batch [329/428], Loss: 0.0174
Epoch [2/6], Batch [330/428], Loss: 0.0826
Epoch [2/6], Batch [331/428], Loss: 0.6017
Epoch [2/6], Batch [332/428], Loss: 0.0435
Epoch [2/6], Batch [333/428], Loss: 0.0061
Epoch [2/6], Batch [334/428], Loss: 0.0000
Epoch [2/6], Batch [335/428], Loss: 1.5013
Epoch [2/6], Batch [336/428], Loss: 0.0023
Epoch [2/6], Batch [337/428], Loss: 0.0026
Epoch [2/6], Batch [338/428], Loss: 3.6864
Epoch [2/6], Batch [339/428], Loss: 0.9594
Epoch [2/6], Batch [340/428], Loss: 0.1279
Epoch [2/6], Batch [341/428], Loss: 0.0009
Epoch [2/6], Batch [342/428], Loss: 0.0000
Epoch [2/6], Batch [343/428], Loss: 3.3437
Epoch [2/6], Batch [344/428], Loss: 0.0000
Epoch [2/6], Batch [345/428], Loss: 0.0839
Epoch [2/6], Batch [346/428], Loss: 3.0331
Epoch [2/6], Batch [347/428], Loss: 0.2392
Epoch [2/6], Batch [348/428], Loss: 3.9329
Epoch [2/6], Batch [349/428], Loss: 1.1178
Epoch [2/6], Batch [350/428], Loss: 0.0127
Epoch [2/6], Batch [351/428], Loss: 0.0050
Epoch [2/6], Batch [352/428], Loss: 0.5057
Epoch [2/6], Batch [353/428], Loss: 0.0981
Epoch [2/6], Batch [354/428], Loss: 0.0628
Epoch [2/6], Batch [355/428], Loss: 0.0089
Epoch [2/6], Batch [356/428], Loss: 0.0131
Epoch [2/6], Batch [357/428], Loss: 0.0000
Epoch [2/6], Batch [358/428], Loss: 4.4735
Epoch [2/6], Batch [359/428], Loss: 0.4032
Epoch [2/6], Batch [360/428], Loss: 4.8047
Epoch [2/6], Batch [361/428], Loss: 3.7293
Epoch [2/6], Batch [362/428], Loss: 0.6365
Epoch [2/6], Batch [363/428], Loss: 0.0003
Epoch [2/6], Batch [364/428], Loss: 3.8534
Epoch [2/6], Batch [365/428], Loss: 0.6612
Epoch [2/6], Batch [366/428], Loss: 1.7134
Epoch [2/6], Batch [367/428], Loss: 0.0000
Epoch [2/6], Batch [368/428], Loss: 2.5933
Epoch [2/6], Batch [369/428], Loss: 0.7122
Epoch [2/6], Batch [370/428], Loss: 0.0001
Epoch [2/6], Batch [371/428], Loss: 1.9162
Epoch [2/6], Batch [372/428], Loss: 0.0005
Epoch [2/6], Batch [373/428], Loss: 0.0000
Epoch [2/6], Batch [374/428], Loss: 2.4212
Epoch [2/6], Batch [375/428], Loss: 0.0789
Epoch [2/6], Batch [376/428], Loss: 0.0597
Epoch [2/6], Batch [377/428], Loss: 0.2693
Epoch [2/6], Batch [378/428], Loss: 0.0002
Epoch [2/6], Batch [379/428], Loss: 1.5623
Epoch [2/6], Batch [380/428], Loss: 2.1804
Epoch [2/6], Batch [381/428], Loss: 0.0407
Epoch [2/6], Batch [382/428], Loss: 0.0478
Epoch [2/6], Batch [383/428], Loss: 0.1277
Epoch [2/6], Batch [384/428], Loss: 1.9271
Epoch [2/6], Batch [385/428], Loss: 2.0598
Epoch [2/6], Batch [386/428], Loss: 0.0013
Epoch [2/6], Batch [387/428], Loss: 0.0000
Epoch [2/6], Batch [388/428], Loss: 9.6374
Epoch [2/6], Batch [389/428], Loss: 0.4168
Epoch [2/6], Batch [390/428], Loss: 0.6002
Epoch [2/6], Batch [391/428], Loss: 0.0352
Epoch [2/6], Batch [392/428], Loss: 0.4430
Epoch [2/6], Batch [393/428], Loss: 1.6327
Epoch [2/6], Batch [394/428], Loss: 0.0029
Epoch [2/6], Batch [395/428], Loss: 0.0001
Epoch [2/6], Batch [396/428], Loss: 0.5558
Epoch [2/6], Batch [397/428], Loss: 0.0182
Epoch [2/6], Batch [398/428], Loss: 0.1066
Epoch [2/6], Batch [399/428], Loss: 0.4630
Epoch [2/6], Batch [400/428], Loss: 0.0132
Epoch [2/6], Batch [401/428], Loss: 1.6852
Epoch [2/6], Batch [402/428], Loss: 0.9126
Epoch [2/6], Batch [403/428], Loss: 2.6890
Epoch [2/6], Batch [404/428], Loss: 1.6441
Epoch [2/6], Batch [405/428], Loss: 0.0749
Epoch [2/6], Batch [406/428], Loss: 0.2311
Epoch [2/6], Batch [407/428], Loss: 0.5896
Epoch [2/6], Batch [408/428], Loss: 0.0821
Epoch [2/6], Batch [409/428], Loss: 1.2292
Epoch [2/6], Batch [410/428], Loss: 0.7147
Epoch [2/6], Batch [411/428], Loss: 0.4190
Epoch [2/6], Batch [412/428], Loss: 1.1813
Epoch [2/6], Batch [413/428], Loss: 0.0797
Epoch [2/6], Batch [414/428], Loss: 0.0004
Epoch [2/6], Batch [415/428], Loss: 0.0536
Epoch [2/6], Batch [416/428], Loss: 0.6959
Epoch [2/6], Batch [417/428], Loss: 0.0145
Epoch [2/6], Batch [418/428], Loss: 0.0001
Epoch [2/6], Batch [419/428], Loss: 0.0324
Epoch [2/6], Batch [420/428], Loss: 0.1928
Epoch [2/6], Batch [421/428], Loss: 1.9935
Epoch [2/6], Batch [422/428], Loss: 1.8886
Epoch [2/6], Batch [423/428], Loss: 0.4479
Epoch [2/6], Batch [424/428], Loss: 1.1748
Epoch [2/6], Batch [425/428], Loss: 1.3116
Epoch [2/6], Batch [426/428], Loss: 8.6761
Epoch [2/6], Batch [427/428], Loss: 4.7286
Epoch [2/6], Batch [428/428], Loss: 1.2353
Epoch [2] Training Time: 172.76 seconds
Epoch [2/6], Average Loss: 1.0594, Training Accuracy: 0.5981
Epoch [2], Validation Loss: 1.7939, Validation Accuracy: 0.4738
Epoch [2] Validation Time: 10.93 seconds
--------------------------------------------------
Epoch [3/6], Batch [1/428], Loss: 0.0060
Epoch [3/6], Batch [2/428], Loss: 0.5305
Epoch [3/6], Batch [3/428], Loss: 0.0849
Epoch [3/6], Batch [4/428], Loss: 0.1754
Epoch [3/6], Batch [5/428], Loss: 5.3057
Epoch [3/6], Batch [6/428], Loss: 2.9587
Epoch [3/6], Batch [7/428], Loss: 1.3933
Epoch [3/6], Batch [8/428], Loss: 3.1667
Epoch [3/6], Batch [9/428], Loss: 0.1202
Epoch [3/6], Batch [10/428], Loss: 5.4416
Epoch [3/6], Batch [11/428], Loss: 2.0754
Epoch [3/6], Batch [12/428], Loss: 0.3437
Epoch [3/6], Batch [13/428], Loss: 2.8090
Epoch [3/6], Batch [14/428], Loss: 0.5617
Epoch [3/6], Batch [15/428], Loss: 0.6125
Epoch [3/6], Batch [16/428], Loss: 0.2388
Epoch [3/6], Batch [17/428], Loss: 1.3122
Epoch [3/6], Batch [18/428], Loss: 0.1679
Epoch [3/6], Batch [19/428], Loss: 0.0042
Epoch [3/6], Batch [20/428], Loss: 0.0341
Epoch [3/6], Batch [21/428], Loss: 0.0896
Epoch [3/6], Batch [22/428], Loss: 0.8262
Epoch [3/6], Batch [23/428], Loss: 0.1992
Epoch [3/6], Batch [24/428], Loss: 0.0043
Epoch [3/6], Batch [25/428], Loss: 0.1521
Epoch [3/6], Batch [26/428], Loss: 0.6061
Epoch [3/6], Batch [27/428], Loss: 1.6656
Epoch [3/6], Batch [28/428], Loss: 0.0192
Epoch [3/6], Batch [29/428], Loss: 0.0416
Epoch [3/6], Batch [30/428], Loss: 0.0116
Epoch [3/6], Batch [31/428], Loss: 0.0002
Epoch [3/6], Batch [32/428], Loss: 2.3404
Epoch [3/6], Batch [33/428], Loss: 4.3113
Epoch [3/6], Batch [34/428], Loss: 1.3331
Epoch [3/6], Batch [35/428], Loss: 0.0004
Epoch [3/6], Batch [36/428], Loss: 0.5698
Epoch [3/6], Batch [37/428], Loss: 2.5240
Epoch [3/6], Batch [38/428], Loss: 0.0106
Epoch [3/6], Batch [39/428], Loss: 0.0542
Epoch [3/6], Batch [40/428], Loss: 0.3731
Epoch [3/6], Batch [41/428], Loss: 0.0386
Epoch [3/6], Batch [42/428], Loss: 0.0002
Epoch [3/6], Batch [43/428], Loss: 0.6154
Epoch [3/6], Batch [44/428], Loss: 0.6285
Epoch [3/6], Batch [45/428], Loss: 0.0033
Epoch [3/6], Batch [46/428], Loss: 0.0684
Epoch [3/6], Batch [47/428], Loss: 0.0011
Epoch [3/6], Batch [48/428], Loss: 0.4956
Epoch [3/6], Batch [49/428], Loss: 0.6675
Epoch [3/6], Batch [50/428], Loss: 1.2583
Epoch [3/6], Batch [51/428], Loss: 3.3383
Epoch [3/6], Batch [52/428], Loss: 0.3022
Epoch [3/6], Batch [53/428], Loss: 0.0001
Epoch [3/6], Batch [54/428], Loss: 0.7222
Epoch [3/6], Batch [55/428], Loss: 1.8450
Epoch [3/6], Batch [56/428], Loss: 0.1364
Epoch [3/6], Batch [57/428], Loss: 1.7067
Epoch [3/6], Batch [58/428], Loss: 0.0002
Epoch [3/6], Batch [59/428], Loss: 0.0105
Epoch [3/6], Batch [60/428], Loss: 0.3376
Epoch [3/6], Batch [61/428], Loss: 1.6358
Epoch [3/6], Batch [62/428], Loss: 1.2119
Epoch [3/6], Batch [63/428], Loss: 0.2041
Epoch [3/6], Batch [64/428], Loss: 0.0001
Epoch [3/6], Batch [65/428], Loss: 2.6353
Epoch [3/6], Batch [66/428], Loss: 1.2600
Epoch [3/6], Batch [67/428], Loss: 0.6996
Epoch [3/6], Batch [68/428], Loss: 1.7432
Epoch [3/6], Batch [69/428], Loss: 1.6031
Epoch [3/6], Batch [70/428], Loss: 1.7459
Epoch [3/6], Batch [71/428], Loss: 0.3141
Epoch [3/6], Batch [72/428], Loss: 3.7452
Epoch [3/6], Batch [73/428], Loss: 2.0367
Epoch [3/6], Batch [74/428], Loss: 1.5394
Epoch [3/6], Batch [75/428], Loss: 4.3585
Epoch [3/6], Batch [76/428], Loss: 1.8187
Epoch [3/6], Batch [77/428], Loss: 4.0492
Epoch [3/6], Batch [78/428], Loss: 0.5838
Epoch [3/6], Batch [79/428], Loss: 0.3552
Epoch [3/6], Batch [80/428], Loss: 2.1412
Epoch [3/6], Batch [81/428], Loss: 0.0130
Epoch [3/6], Batch [82/428], Loss: 0.9207
Epoch [3/6], Batch [83/428], Loss: 1.8497
Epoch [3/6], Batch [84/428], Loss: 0.0076
Epoch [3/6], Batch [85/428], Loss: 5.4768
Epoch [3/6], Batch [86/428], Loss: 1.5785
Epoch [3/6], Batch [87/428], Loss: 0.0001
Epoch [3/6], Batch [88/428], Loss: 2.2897
Epoch [3/6], Batch [89/428], Loss: 1.4240
Epoch [3/6], Batch [90/428], Loss: 1.5471
Epoch [3/6], Batch [91/428], Loss: 0.0001
Epoch [3/6], Batch [92/428], Loss: 1.0207
Epoch [3/6], Batch [93/428], Loss: 0.0378
Epoch [3/6], Batch [94/428], Loss: 0.9889
Epoch [3/6], Batch [95/428], Loss: 0.2443
Epoch [3/6], Batch [96/428], Loss: 0.0124
Epoch [3/6], Batch [97/428], Loss: 1.0624
Epoch [3/6], Batch [98/428], Loss: 0.0001
Epoch [3/6], Batch [99/428], Loss: 0.0101
Epoch [3/6], Batch [100/428], Loss: 0.3018
Epoch [3/6], Batch [101/428], Loss: 3.4557
Epoch [3/6], Batch [102/428], Loss: 2.9214
Epoch [3/6], Batch [103/428], Loss: 0.0443
Epoch [3/6], Batch [104/428], Loss: 0.0353
Epoch [3/6], Batch [105/428], Loss: 0.0113
Epoch [3/6], Batch [106/428], Loss: 0.1190
Epoch [3/6], Batch [107/428], Loss: 0.0924
Epoch [3/6], Batch [108/428], Loss: 0.4900
Epoch [3/6], Batch [109/428], Loss: 0.5435
Epoch [3/6], Batch [110/428], Loss: 0.5157
Epoch [3/6], Batch [111/428], Loss: 2.8058
Epoch [3/6], Batch [112/428], Loss: 0.5061
Epoch [3/6], Batch [113/428], Loss: 3.4540
Epoch [3/6], Batch [114/428], Loss: 0.0994
Epoch [3/6], Batch [115/428], Loss: 0.0180
Epoch [3/6], Batch [116/428], Loss: 2.8133
Epoch [3/6], Batch [117/428], Loss: 1.5375
Epoch [3/6], Batch [118/428], Loss: 0.3633
Epoch [3/6], Batch [119/428], Loss: 0.3425
Epoch [3/6], Batch [120/428], Loss: 0.4659
Epoch [3/6], Batch [121/428], Loss: 0.1884
Epoch [3/6], Batch [122/428], Loss: 0.3207
Epoch [3/6], Batch [123/428], Loss: 2.9544
Epoch [3/6], Batch [124/428], Loss: 0.8651
Epoch [3/6], Batch [125/428], Loss: 2.2793
Epoch [3/6], Batch [126/428], Loss: 0.2759
Epoch [3/6], Batch [127/428], Loss: 0.0985
Epoch [3/6], Batch [128/428], Loss: 2.0090
Epoch [3/6], Batch [129/428], Loss: 0.0046
Epoch [3/6], Batch [130/428], Loss: 0.9223
Epoch [3/6], Batch [131/428], Loss: 0.7316
Epoch [3/6], Batch [132/428], Loss: 0.8642
Epoch [3/6], Batch [133/428], Loss: 0.0001
Epoch [3/6], Batch [134/428], Loss: 0.0001
Epoch [3/6], Batch [135/428], Loss: 0.0775
Epoch [3/6], Batch [136/428], Loss: 0.0001
Epoch [3/6], Batch [137/428], Loss: 0.0139
Epoch [3/6], Batch [138/428], Loss: 0.3503
Epoch [3/6], Batch [139/428], Loss: 0.0176
Epoch [3/6], Batch [140/428], Loss: 0.9218
Epoch [3/6], Batch [141/428], Loss: 0.1989
Epoch [3/6], Batch [142/428], Loss: 0.0001
Epoch [3/6], Batch [143/428], Loss: 0.0690
Epoch [3/6], Batch [144/428], Loss: 0.7972
Epoch [3/6], Batch [145/428], Loss: 0.1377
Epoch [3/6], Batch [146/428], Loss: 1.4923
Epoch [3/6], Batch [147/428], Loss: 0.1542
Epoch [3/6], Batch [148/428], Loss: 0.4485
Epoch [3/6], Batch [149/428], Loss: 3.7696
Epoch [3/6], Batch [150/428], Loss: 1.0487
Epoch [3/6], Batch [151/428], Loss: 0.0001
Epoch [3/6], Batch [152/428], Loss: 1.4049
Epoch [3/6], Batch [153/428], Loss: 0.0004
Epoch [3/6], Batch [154/428], Loss: 0.0001
Epoch [3/6], Batch [155/428], Loss: 0.8071
Epoch [3/6], Batch [156/428], Loss: 0.0107
Epoch [3/6], Batch [157/428], Loss: 1.1974
Epoch [3/6], Batch [158/428], Loss: 1.6321
Epoch [3/6], Batch [159/428], Loss: 0.6810
Epoch [3/6], Batch [160/428], Loss: 0.0000
Epoch [3/6], Batch [161/428], Loss: 1.2409
Epoch [3/6], Batch [162/428], Loss: 1.2147
Epoch [3/6], Batch [163/428], Loss: 2.0429
Epoch [3/6], Batch [164/428], Loss: 0.6074
Epoch [3/6], Batch [165/428], Loss: 0.9631
Epoch [3/6], Batch [166/428], Loss: 0.0093
Epoch [3/6], Batch [167/428], Loss: 3.6082
Epoch [3/6], Batch [168/428], Loss: 0.6364
Epoch [3/6], Batch [169/428], Loss: 0.0001
Epoch [3/6], Batch [170/428], Loss: 0.3403
Epoch [3/6], Batch [171/428], Loss: 0.0003
Epoch [3/6], Batch [172/428], Loss: 2.0552
Epoch [3/6], Batch [173/428], Loss: 0.9634
Epoch [3/6], Batch [174/428], Loss: 1.3674
Epoch [3/6], Batch [175/428], Loss: 1.8251
Epoch [3/6], Batch [176/428], Loss: 0.7221
Epoch [3/6], Batch [177/428], Loss: 0.7462
Epoch [3/6], Batch [178/428], Loss: 0.5357
Epoch [3/6], Batch [179/428], Loss: 2.5734
Epoch [3/6], Batch [180/428], Loss: 0.8076
Epoch [3/6], Batch [181/428], Loss: 0.0001
Epoch [3/6], Batch [182/428], Loss: 0.0006
Epoch [3/6], Batch [183/428], Loss: 3.4260
Epoch [3/6], Batch [184/428], Loss: 0.5899
Epoch [3/6], Batch [185/428], Loss: 2.0138
Epoch [3/6], Batch [186/428], Loss: 5.1198
Epoch [3/6], Batch [187/428], Loss: 0.2312
Epoch [3/6], Batch [188/428], Loss: 0.0306
Epoch [3/6], Batch [189/428], Loss: 0.0056
Epoch [3/6], Batch [190/428], Loss: 0.0000
Epoch [3/6], Batch [191/428], Loss: 1.0942
Epoch [3/6], Batch [192/428], Loss: 0.0219
Epoch [3/6], Batch [193/428], Loss: 0.0156
Epoch [3/6], Batch [194/428], Loss: 0.6921
Epoch [3/6], Batch [195/428], Loss: 0.1858
Epoch [3/6], Batch [196/428], Loss: 0.1019
Epoch [3/6], Batch [197/428], Loss: 0.2859
Epoch [3/6], Batch [198/428], Loss: 0.0022
Epoch [3/6], Batch [199/428], Loss: 0.2303
Epoch [3/6], Batch [200/428], Loss: 1.6001
Epoch [3/6], Batch [201/428], Loss: 1.6086
Epoch [3/6], Batch [202/428], Loss: 0.0013
Epoch [3/6], Batch [203/428], Loss: 0.4132
Epoch [3/6], Batch [204/428], Loss: 0.4698
Epoch [3/6], Batch [205/428], Loss: 0.6202
Epoch [3/6], Batch [206/428], Loss: 0.2067
Epoch [3/6], Batch [207/428], Loss: 0.8991
Epoch [3/6], Batch [208/428], Loss: 3.9126
Epoch [3/6], Batch [209/428], Loss: 1.0726
Epoch [3/6], Batch [210/428], Loss: 0.5827
Epoch [3/6], Batch [211/428], Loss: 0.4434
Epoch [3/6], Batch [212/428], Loss: 1.3409
Epoch [3/6], Batch [213/428], Loss: 0.1267
Epoch [3/6], Batch [214/428], Loss: 0.0026
Epoch [3/6], Batch [215/428], Loss: 4.1337
Epoch [3/6], Batch [216/428], Loss: 0.0000
Epoch [3/6], Batch [217/428], Loss: 0.5532
Epoch [3/6], Batch [218/428], Loss: 0.0596
Epoch [3/6], Batch [219/428], Loss: 3.7938
Epoch [3/6], Batch [220/428], Loss: 0.0006
Epoch [3/6], Batch [221/428], Loss: 0.0000
Epoch [3/6], Batch [222/428], Loss: 3.2442
Epoch [3/6], Batch [223/428], Loss: 0.6950
Epoch [3/6], Batch [224/428], Loss: 0.1260
Epoch [3/6], Batch [225/428], Loss: 0.0004
Epoch [3/6], Batch [226/428], Loss: 0.0745
Epoch [3/6], Batch [227/428], Loss: 1.9086
Epoch [3/6], Batch [228/428], Loss: 0.0950
Epoch [3/6], Batch [229/428], Loss: 0.9967
Epoch [3/6], Batch [230/428], Loss: 0.0065
Epoch [3/6], Batch [231/428], Loss: 0.0834
Epoch [3/6], Batch [232/428], Loss: 0.8353
Epoch [3/6], Batch [233/428], Loss: 1.4915
Epoch [3/6], Batch [234/428], Loss: 1.3339
Epoch [3/6], Batch [235/428], Loss: 0.9564
Epoch [3/6], Batch [236/428], Loss: 0.7912
Epoch [3/6], Batch [237/428], Loss: 0.3891
Epoch [3/6], Batch [238/428], Loss: 0.0001
Epoch [3/6], Batch [239/428], Loss: 2.1773
Epoch [3/6], Batch [240/428], Loss: 1.0425
Epoch [3/6], Batch [241/428], Loss: 0.0267
Epoch [3/6], Batch [242/428], Loss: 0.0829
Epoch [3/6], Batch [243/428], Loss: 0.0008
Epoch [3/6], Batch [244/428], Loss: 0.7073
Epoch [3/6], Batch [245/428], Loss: 3.5004
Epoch [3/6], Batch [246/428], Loss: 0.2127
Epoch [3/6], Batch [247/428], Loss: 0.9829
Epoch [3/6], Batch [248/428], Loss: 0.1453
Epoch [3/6], Batch [249/428], Loss: 1.9088
Epoch [3/6], Batch [250/428], Loss: 0.0000
Epoch [3/6], Batch [251/428], Loss: 0.0243
Epoch [3/6], Batch [252/428], Loss: 1.3050
Epoch [3/6], Batch [253/428], Loss: 0.0330
Epoch [3/6], Batch [254/428], Loss: 0.5138
Epoch [3/6], Batch [255/428], Loss: 6.2048
Epoch [3/6], Batch [256/428], Loss: 3.5970
Epoch [3/6], Batch [257/428], Loss: 4.1434
Epoch [3/6], Batch [258/428], Loss: 2.0798
Epoch [3/6], Batch [259/428], Loss: 0.0101
Epoch [3/6], Batch [260/428], Loss: 0.1384
Epoch [3/6], Batch [261/428], Loss: 0.0101
Epoch [3/6], Batch [262/428], Loss: 1.3559
Epoch [3/6], Batch [263/428], Loss: 0.1107
Epoch [3/6], Batch [264/428], Loss: 1.5943
Epoch [3/6], Batch [265/428], Loss: 1.2953
Epoch [3/6], Batch [266/428], Loss: 0.7998
Epoch [3/6], Batch [267/428], Loss: 0.8745
Epoch [3/6], Batch [268/428], Loss: 0.0131
Epoch [3/6], Batch [269/428], Loss: 0.8635
Epoch [3/6], Batch [270/428], Loss: 3.0362
Epoch [3/6], Batch [271/428], Loss: 3.2484
Epoch [3/6], Batch [272/428], Loss: 0.0737
Epoch [3/6], Batch [273/428], Loss: 0.7750
Epoch [3/6], Batch [274/428], Loss: 0.4464
Epoch [3/6], Batch [275/428], Loss: 0.2520
Epoch [3/6], Batch [276/428], Loss: 0.0000
Epoch [3/6], Batch [277/428], Loss: 0.5313
Epoch [3/6], Batch [278/428], Loss: 0.2214
Epoch [3/6], Batch [279/428], Loss: 0.9890
Epoch [3/6], Batch [280/428], Loss: 0.0033
Epoch [3/6], Batch [281/428], Loss: 0.3267
Epoch [3/6], Batch [282/428], Loss: 0.0020
Epoch [3/6], Batch [283/428], Loss: 0.0001
Epoch [3/6], Batch [284/428], Loss: 2.1884
Epoch [3/6], Batch [285/428], Loss: 2.1414
Epoch [3/6], Batch [286/428], Loss: 0.7136
Epoch [3/6], Batch [287/428], Loss: 2.3363
Epoch [3/6], Batch [288/428], Loss: 0.1224
Epoch [3/6], Batch [289/428], Loss: 0.8740
Epoch [3/6], Batch [290/428], Loss: 0.1431
Epoch [3/6], Batch [291/428], Loss: 0.8502
Epoch [3/6], Batch [292/428], Loss: 0.0115
Epoch [3/6], Batch [293/428], Loss: 0.1493
Epoch [3/6], Batch [294/428], Loss: 2.7760
Epoch [3/6], Batch [295/428], Loss: 1.4074
Epoch [3/6], Batch [296/428], Loss: 0.9464
Epoch [3/6], Batch [297/428], Loss: 0.0000
Epoch [3/6], Batch [298/428], Loss: 3.4011
Epoch [3/6], Batch [299/428], Loss: 0.1057
Epoch [3/6], Batch [300/428], Loss: 0.6591
Epoch [3/6], Batch [301/428], Loss: 0.8198
Epoch [3/6], Batch [302/428], Loss: 0.0145
Epoch [3/6], Batch [303/428], Loss: 0.2214
Epoch [3/6], Batch [304/428], Loss: 0.0000
Epoch [3/6], Batch [305/428], Loss: 0.0166
Epoch [3/6], Batch [306/428], Loss: 0.7261
Epoch [3/6], Batch [307/428], Loss: 1.3014
Epoch [3/6], Batch [308/428], Loss: 0.4469
Epoch [3/6], Batch [309/428], Loss: 1.9568
Epoch [3/6], Batch [310/428], Loss: 4.5454
Epoch [3/6], Batch [311/428], Loss: 0.1138
Epoch [3/6], Batch [312/428], Loss: 0.0169
Epoch [3/6], Batch [313/428], Loss: 2.2972
Epoch [3/6], Batch [314/428], Loss: 2.2476
Epoch [3/6], Batch [315/428], Loss: 1.2809
Epoch [3/6], Batch [316/428], Loss: 3.2366
Epoch [3/6], Batch [317/428], Loss: 0.0051
Epoch [3/6], Batch [318/428], Loss: 4.1466
Epoch [3/6], Batch [319/428], Loss: 0.0008
Epoch [3/6], Batch [320/428], Loss: 0.0062
Epoch [3/6], Batch [321/428], Loss: 0.0702
Epoch [3/6], Batch [322/428], Loss: 0.0262
Epoch [3/6], Batch [323/428], Loss: 0.2231
Epoch [3/6], Batch [324/428], Loss: 0.7024
Epoch [3/6], Batch [325/428], Loss: 1.6507
Epoch [3/6], Batch [326/428], Loss: 2.3221
Epoch [3/6], Batch [327/428], Loss: 0.3131
Epoch [3/6], Batch [328/428], Loss: 0.0411
Epoch [3/6], Batch [329/428], Loss: 1.2086
Epoch [3/6], Batch [330/428], Loss: 0.0742
Epoch [3/6], Batch [331/428], Loss: 0.8527
Epoch [3/6], Batch [332/428], Loss: 1.7745
Epoch [3/6], Batch [333/428], Loss: 3.2575
Epoch [3/6], Batch [334/428], Loss: 0.9346
Epoch [3/6], Batch [335/428], Loss: 1.5794
Epoch [3/6], Batch [336/428], Loss: 0.0001
Epoch [3/6], Batch [337/428], Loss: 0.1095
Epoch [3/6], Batch [338/428], Loss: 0.0039
Epoch [3/6], Batch [339/428], Loss: 0.1497
Epoch [3/6], Batch [340/428], Loss: 0.8051
Epoch [3/6], Batch [341/428], Loss: 2.2585
Epoch [3/6], Batch [342/428], Loss: 1.7391
Epoch [3/6], Batch [343/428], Loss: 0.0033
Epoch [3/6], Batch [344/428], Loss: 0.0758
Epoch [3/6], Batch [345/428], Loss: 0.0045
Epoch [3/6], Batch [346/428], Loss: 0.0036
Epoch [3/6], Batch [347/428], Loss: 0.0203
Epoch [3/6], Batch [348/428], Loss: 0.0004
Epoch [3/6], Batch [349/428], Loss: 10.0036
Epoch [3/6], Batch [350/428], Loss: 0.0014
Epoch [3/6], Batch [351/428], Loss: 0.2591
Epoch [3/6], Batch [352/428], Loss: 0.1389
Epoch [3/6], Batch [353/428], Loss: 3.2194
Epoch [3/6], Batch [354/428], Loss: 0.5153
Epoch [3/6], Batch [355/428], Loss: 0.0023
Epoch [3/6], Batch [356/428], Loss: 0.8029
Epoch [3/6], Batch [357/428], Loss: 0.0757
Epoch [3/6], Batch [358/428], Loss: 0.0166
Epoch [3/6], Batch [359/428], Loss: 0.0002
Epoch [3/6], Batch [360/428], Loss: 0.0747
Epoch [3/6], Batch [361/428], Loss: 0.1641
Epoch [3/6], Batch [362/428], Loss: 0.5718
Epoch [3/6], Batch [363/428], Loss: 0.2499
Epoch [3/6], Batch [364/428], Loss: 0.7598
Epoch [3/6], Batch [365/428], Loss: 0.4649
Epoch [3/6], Batch [366/428], Loss: 0.0000
Epoch [3/6], Batch [367/428], Loss: 0.0026
Epoch [3/6], Batch [368/428], Loss: 0.0391
Epoch [3/6], Batch [369/428], Loss: 0.0019
Epoch [3/6], Batch [370/428], Loss: 0.0026
Epoch [3/6], Batch [371/428], Loss: 1.4971
Epoch [3/6], Batch [372/428], Loss: 1.7604
Epoch [3/6], Batch [373/428], Loss: 1.9397
Epoch [3/6], Batch [374/428], Loss: 2.5055
Epoch [3/6], Batch [375/428], Loss: 0.1333
Epoch [3/6], Batch [376/428], Loss: 1.5604
Epoch [3/6], Batch [377/428], Loss: 0.0002
Epoch [3/6], Batch [378/428], Loss: 0.0095
Epoch [3/6], Batch [379/428], Loss: 0.8147
Epoch [3/6], Batch [380/428], Loss: 0.3569
Epoch [3/6], Batch [381/428], Loss: 6.1733
Epoch [3/6], Batch [382/428], Loss: 3.2034
Epoch [3/6], Batch [383/428], Loss: 4.4076
Epoch [3/6], Batch [384/428], Loss: 0.1676
Epoch [3/6], Batch [385/428], Loss: 2.4480
Epoch [3/6], Batch [386/428], Loss: 1.3881
Epoch [3/6], Batch [387/428], Loss: 0.0104
Epoch [3/6], Batch [388/428], Loss: 9.8658
Epoch [3/6], Batch [389/428], Loss: 5.6448
Epoch [3/6], Batch [390/428], Loss: 0.0767
Epoch [3/6], Batch [391/428], Loss: 0.0021
Epoch [3/6], Batch [392/428], Loss: 3.0033
Epoch [3/6], Batch [393/428], Loss: 0.4600
Epoch [3/6], Batch [394/428], Loss: 0.0001
Epoch [3/6], Batch [395/428], Loss: 0.6925
Epoch [3/6], Batch [396/428], Loss: 1.0607
Epoch [3/6], Batch [397/428], Loss: 3.6302
Epoch [3/6], Batch [398/428], Loss: 4.8097
Epoch [3/6], Batch [399/428], Loss: 0.0001
Epoch [3/6], Batch [400/428], Loss: 0.3307
Epoch [3/6], Batch [401/428], Loss: 0.2401
Epoch [3/6], Batch [402/428], Loss: 2.6186
Epoch [3/6], Batch [403/428], Loss: 1.2662
Epoch [3/6], Batch [404/428], Loss: 3.1024
Epoch [3/6], Batch [405/428], Loss: 1.6198
Epoch [3/6], Batch [406/428], Loss: 4.3041
Epoch [3/6], Batch [407/428], Loss: 0.0426
Epoch [3/6], Batch [408/428], Loss: 1.3617
Epoch [3/6], Batch [409/428], Loss: 3.3108
Epoch [3/6], Batch [410/428], Loss: 0.2875
Epoch [3/6], Batch [411/428], Loss: 0.0045
Epoch [3/6], Batch [412/428], Loss: 2.8426
Epoch [3/6], Batch [413/428], Loss: 0.0025
Epoch [3/6], Batch [414/428], Loss: 0.0828
Epoch [3/6], Batch [415/428], Loss: 1.9060
Epoch [3/6], Batch [416/428], Loss: 0.2213
Epoch [3/6], Batch [417/428], Loss: 0.0001
Epoch [3/6], Batch [418/428], Loss: 0.2768
Epoch [3/6], Batch [419/428], Loss: 0.0149
Epoch [3/6], Batch [420/428], Loss: 0.2271
Epoch [3/6], Batch [421/428], Loss: 0.0003
Epoch [3/6], Batch [422/428], Loss: 0.0686
Epoch [3/6], Batch [423/428], Loss: 1.4811
Epoch [3/6], Batch [424/428], Loss: 0.0058
Epoch [3/6], Batch [425/428], Loss: 0.3824
Epoch [3/6], Batch [426/428], Loss: 0.3729
Epoch [3/6], Batch [427/428], Loss: 0.2995
Epoch [3/6], Batch [428/428], Loss: 2.2014
Epoch [3] Training Time: 173.77 seconds
Epoch [3/6], Average Loss: 1.0225, Training Accuracy: 0.6542
Epoch [3], Validation Loss: 1.4376, Validation Accuracy: 0.5450
Epoch [3] Validation Time: 10.94 seconds
--------------------------------------------------
Epoch 4: Unfreezing feature extractor layers...
Epoch [4/6], Batch [1/428], Loss: 2.4840
Epoch [4/6], Batch [2/428], Loss: 24.0583
Epoch [4/6], Batch [3/428], Loss: 0.0005
Epoch [4/6], Batch [4/428], Loss: 20.7257
Epoch [4/6], Batch [5/428], Loss: 15.8402
Epoch [4/6], Batch [6/428], Loss: 7.4999
Epoch [4/6], Batch [7/428], Loss: 3.9708
Epoch [4/6], Batch [8/428], Loss: 3.1813
Epoch [4/6], Batch [9/428], Loss: 0.8626
Epoch [4/6], Batch [10/428], Loss: 9.1559
Epoch [4/6], Batch [11/428], Loss: 10.6789
Epoch [4/6], Batch [12/428], Loss: 5.8154
Epoch [4/6], Batch [13/428], Loss: 1.4430
Epoch [4/6], Batch [14/428], Loss: 10.9989
Epoch [4/6], Batch [15/428], Loss: 2.9347
Epoch [4/6], Batch [16/428], Loss: 7.9959
Epoch [4/6], Batch [17/428], Loss: 17.0639
Epoch [4/6], Batch [18/428], Loss: 3.0938
Epoch [4/6], Batch [19/428], Loss: 11.9434
Epoch [4/6], Batch [20/428], Loss: 0.9947
Epoch [4/6], Batch [21/428], Loss: 3.8770
Epoch [4/6], Batch [22/428], Loss: 1.9057
Epoch [4/6], Batch [23/428], Loss: 4.9746
Epoch [4/6], Batch [24/428], Loss: 3.3099
Epoch [4/6], Batch [25/428], Loss: 2.4027
Epoch [4/6], Batch [26/428], Loss: 1.6617
Epoch [4/6], Batch [27/428], Loss: 4.3440
Epoch [4/6], Batch [28/428], Loss: 13.0401
Epoch [4/6], Batch [29/428], Loss: 1.4252
Epoch [4/6], Batch [30/428], Loss: 3.6645
Epoch [4/6], Batch [31/428], Loss: 1.7972
Epoch [4/6], Batch [32/428], Loss: 1.4079
Epoch [4/6], Batch [33/428], Loss: 2.1158
Epoch [4/6], Batch [34/428], Loss: 2.0851
Epoch [4/6], Batch [35/428], Loss: 4.4292
Epoch [4/6], Batch [36/428], Loss: 3.9257
Epoch [4/6], Batch [37/428], Loss: 5.4488
Epoch [4/6], Batch [38/428], Loss: 4.5830
Epoch [4/6], Batch [39/428], Loss: 3.9414
Epoch [4/6], Batch [40/428], Loss: 2.2874
Epoch [4/6], Batch [41/428], Loss: 2.2404
Epoch [4/6], Batch [42/428], Loss: 0.8693
Epoch [4/6], Batch [43/428], Loss: 0.8029
Epoch [4/6], Batch [44/428], Loss: 4.2624
Epoch [4/6], Batch [45/428], Loss: 2.1968
Epoch [4/6], Batch [46/428], Loss: 4.0021
Epoch [4/6], Batch [47/428], Loss: 6.4560
Epoch [4/6], Batch [48/428], Loss: 7.5634
Epoch [4/6], Batch [49/428], Loss: 1.2007
Epoch [4/6], Batch [50/428], Loss: 1.6592
Epoch [4/6], Batch [51/428], Loss: 0.9947
Epoch [4/6], Batch [52/428], Loss: 6.5788
Epoch [4/6], Batch [53/428], Loss: 6.3510
Epoch [4/6], Batch [54/428], Loss: 3.1641
Epoch [4/6], Batch [55/428], Loss: 2.8175
Epoch [4/6], Batch [56/428], Loss: 2.0673
Epoch [4/6], Batch [57/428], Loss: 0.9243
Epoch [4/6], Batch [58/428], Loss: 1.2011
Epoch [4/6], Batch [59/428], Loss: 3.0107
Epoch [4/6], Batch [60/428], Loss: 3.5712
Epoch [4/6], Batch [61/428], Loss: 1.8787
Epoch [4/6], Batch [62/428], Loss: 3.8271
Epoch [4/6], Batch [63/428], Loss: 1.7637
Epoch [4/6], Batch [64/428], Loss: 4.2466
Epoch [4/6], Batch [65/428], Loss: 0.5057
Epoch [4/6], Batch [66/428], Loss: 3.8766
Epoch [4/6], Batch [67/428], Loss: 3.3849
Epoch [4/6], Batch [68/428], Loss: 0.3078
Epoch [4/6], Batch [69/428], Loss: 0.2884
Epoch [4/6], Batch [70/428], Loss: 5.8575
Epoch [4/6], Batch [71/428], Loss: 5.7634
Epoch [4/6], Batch [72/428], Loss: 5.9684
Epoch [4/6], Batch [73/428], Loss: 1.4242
Epoch [4/6], Batch [74/428], Loss: 4.4790
Epoch [4/6], Batch [75/428], Loss: 1.0820
Epoch [4/6], Batch [76/428], Loss: 4.4818
Epoch [4/6], Batch [77/428], Loss: 3.9726
Epoch [4/6], Batch [78/428], Loss: 2.8389
Epoch [4/6], Batch [79/428], Loss: 2.6987
Epoch [4/6], Batch [80/428], Loss: 2.2363
Epoch [4/6], Batch [81/428], Loss: 2.0248
Epoch [4/6], Batch [82/428], Loss: 1.4194
Epoch [4/6], Batch [83/428], Loss: 1.3682
Epoch [4/6], Batch [84/428], Loss: 1.1221
Epoch [4/6], Batch [85/428], Loss: 0.8630
Epoch [4/6], Batch [86/428], Loss: 1.7343
Epoch [4/6], Batch [87/428], Loss: 4.6697
Epoch [4/6], Batch [88/428], Loss: 4.6893
Epoch [4/6], Batch [89/428], Loss: 5.4524
Epoch [4/6], Batch [90/428], Loss: 4.9461
Epoch [4/6], Batch [91/428], Loss: 3.4819
Epoch [4/6], Batch [92/428], Loss: 0.6081
Epoch [4/6], Batch [93/428], Loss: 2.6638
Epoch [4/6], Batch [94/428], Loss: 0.7739
Epoch [4/6], Batch [95/428], Loss: 5.7699
Epoch [4/6], Batch [96/428], Loss: 0.7466
Epoch [4/6], Batch [97/428], Loss: 5.5297
Epoch [4/6], Batch [98/428], Loss: 2.8129
Epoch [4/6], Batch [99/428], Loss: 1.5474
Epoch [4/6], Batch [100/428], Loss: 0.8152
Epoch [4/6], Batch [101/428], Loss: 1.1943
Epoch [4/6], Batch [102/428], Loss: 0.9816
Epoch [4/6], Batch [103/428], Loss: 1.3367
Epoch [4/6], Batch [104/428], Loss: 0.5390
Epoch [4/6], Batch [105/428], Loss: 3.8420
Epoch [4/6], Batch [106/428], Loss: 2.2772
Epoch [4/6], Batch [107/428], Loss: 2.1644
Epoch [4/6], Batch [108/428], Loss: 4.1007
Epoch [4/6], Batch [109/428], Loss: 3.7656
Epoch [4/6], Batch [110/428], Loss: 0.6998
Epoch [4/6], Batch [111/428], Loss: 3.3059
Epoch [4/6], Batch [112/428], Loss: 1.1953
Epoch [4/6], Batch [113/428], Loss: 4.5883
Epoch [4/6], Batch [114/428], Loss: 0.9195
Epoch [4/6], Batch [115/428], Loss: 3.7631
Epoch [4/6], Batch [116/428], Loss: 0.6122
Epoch [4/6], Batch [117/428], Loss: 2.3980
Epoch [4/6], Batch [118/428], Loss: 0.3925
Epoch [4/6], Batch [119/428], Loss: 4.1599
Epoch [4/6], Batch [120/428], Loss: 2.7985
Epoch [4/6], Batch [121/428], Loss: 2.7494
Epoch [4/6], Batch [122/428], Loss: 3.1035
Epoch [4/6], Batch [123/428], Loss: 0.4966
Epoch [4/6], Batch [124/428], Loss: 5.3501
Epoch [4/6], Batch [125/428], Loss: 0.6801
Epoch [4/6], Batch [126/428], Loss: 5.3316
Epoch [4/6], Batch [127/428], Loss: 2.0821
Epoch [4/6], Batch [128/428], Loss: 2.2044
Epoch [4/6], Batch [129/428], Loss: 0.9346
Epoch [4/6], Batch [130/428], Loss: 1.9178
Epoch [4/6], Batch [131/428], Loss: 0.9913
Epoch [4/6], Batch [132/428], Loss: 1.4567
Epoch [4/6], Batch [133/428], Loss: 1.0052
Epoch [4/6], Batch [134/428], Loss: 0.8800
Epoch [4/6], Batch [135/428], Loss: 4.1939
Epoch [4/6], Batch [136/428], Loss: 4.0090
Epoch [4/6], Batch [137/428], Loss: 0.4305
Epoch [4/6], Batch [138/428], Loss: 0.2886
Epoch [4/6], Batch [139/428], Loss: 5.0084
Epoch [4/6], Batch [140/428], Loss: 5.8403
Epoch [4/6], Batch [141/428], Loss: 5.6945
Epoch [4/6], Batch [142/428], Loss: 0.1257
Epoch [4/6], Batch [143/428], Loss: 3.8204
Epoch [4/6], Batch [144/428], Loss: 5.2097
Epoch [4/6], Batch [145/428], Loss: 2.3663
Epoch [4/6], Batch [146/428], Loss: 1.9416
Epoch [4/6], Batch [147/428], Loss: 0.4531
Epoch [4/6], Batch [148/428], Loss: 4.1150
Epoch [4/6], Batch [149/428], Loss: 4.1913
Epoch [4/6], Batch [150/428], Loss: 3.7194
Epoch [4/6], Batch [151/428], Loss: 3.0963
Epoch [4/6], Batch [152/428], Loss: 4.7611
Epoch [4/6], Batch [153/428], Loss: 1.7600
Epoch [4/6], Batch [154/428], Loss: 1.2762
Epoch [4/6], Batch [155/428], Loss: 2.9399
Epoch [4/6], Batch [156/428], Loss: 2.6712
Epoch [4/6], Batch [157/428], Loss: 2.4898
Epoch [4/6], Batch [158/428], Loss: 0.6003
Epoch [4/6], Batch [159/428], Loss: 1.7427
Epoch [4/6], Batch [160/428], Loss: 3.9780
Epoch [4/6], Batch [161/428], Loss: 2.9204
Epoch [4/6], Batch [162/428], Loss: 1.1184
Epoch [4/6], Batch [163/428], Loss: 0.6788
Epoch [4/6], Batch [164/428], Loss: 3.8365
Epoch [4/6], Batch [165/428], Loss: 0.4166
Epoch [4/6], Batch [166/428], Loss: 4.0897
Epoch [4/6], Batch [167/428], Loss: 4.2056
Epoch [4/6], Batch [168/428], Loss: 4.0249
Epoch [4/6], Batch [169/428], Loss: 2.7725
Epoch [4/6], Batch [170/428], Loss: 0.3334
Epoch [4/6], Batch [171/428], Loss: 3.0022
Epoch [4/6], Batch [172/428], Loss: 2.6490
Epoch [4/6], Batch [173/428], Loss: 2.1510
Epoch [4/6], Batch [174/428], Loss: 2.0069
Epoch [4/6], Batch [175/428], Loss: 1.2958
Epoch [4/6], Batch [176/428], Loss: 1.4725
Epoch [4/6], Batch [177/428], Loss: 4.9835
Epoch [4/6], Batch [178/428], Loss: 0.7436
Epoch [4/6], Batch [179/428], Loss: 5.0433
Epoch [4/6], Batch [180/428], Loss: 4.4354
Epoch [4/6], Batch [181/428], Loss: 1.3787
Epoch [4/6], Batch [182/428], Loss: 4.0026
Epoch [4/6], Batch [183/428], Loss: 3.7965
Epoch [4/6], Batch [184/428], Loss: 0.9101
Epoch [4/6], Batch [185/428], Loss: 3.4110
Epoch [4/6], Batch [186/428], Loss: 5.6020
Epoch [4/6], Batch [187/428], Loss: 1.1068
Epoch [4/6], Batch [188/428], Loss: 4.3519
Epoch [4/6], Batch [189/428], Loss: 2.4818
Epoch [4/6], Batch [190/428], Loss: 3.8901
Epoch [4/6], Batch [191/428], Loss: 4.2672
Epoch [4/6], Batch [192/428], Loss: 2.2596
Epoch [4/6], Batch [193/428], Loss: 1.8159
Epoch [4/6], Batch [194/428], Loss: 1.9760
Epoch [4/6], Batch [195/428], Loss: 1.8096
Epoch [4/6], Batch [196/428], Loss: 2.5321
Epoch [4/6], Batch [197/428], Loss: 2.0970
Epoch [4/6], Batch [198/428], Loss: 2.4237
Epoch [4/6], Batch [199/428], Loss: 1.6256
Epoch [4/6], Batch [200/428], Loss: 2.2732
Epoch [4/6], Batch [201/428], Loss: 2.6138
Epoch [4/6], Batch [202/428], Loss: 1.9094
Epoch [4/6], Batch [203/428], Loss: 1.6376
Epoch [4/6], Batch [204/428], Loss: 1.4992
Epoch [4/6], Batch [205/428], Loss: 1.8187
Epoch [4/6], Batch [206/428], Loss: 3.0330
Epoch [4/6], Batch [207/428], Loss: 1.0004
Epoch [4/6], Batch [208/428], Loss: 2.0054
Epoch [4/6], Batch [209/428], Loss: 3.3281
Epoch [4/6], Batch [210/428], Loss: 1.8708
Epoch [4/6], Batch [211/428], Loss: 1.7772
Epoch [4/6], Batch [212/428], Loss: 1.8274
Epoch [4/6], Batch [213/428], Loss: 3.9339
Epoch [4/6], Batch [214/428], Loss: 3.8034
Epoch [4/6], Batch [215/428], Loss: 3.4115
Epoch [4/6], Batch [216/428], Loss: 2.9149
Epoch [4/6], Batch [217/428], Loss: 2.6862
Epoch [4/6], Batch [218/428], Loss: 2.4018
Epoch [4/6], Batch [219/428], Loss: 2.1092
Epoch [4/6], Batch [220/428], Loss: 2.6549
Epoch [4/6], Batch [221/428], Loss: 3.4289
Epoch [4/6], Batch [222/428], Loss: 2.5908
Epoch [4/6], Batch [223/428], Loss: 2.6023
Epoch [4/6], Batch [224/428], Loss: 1.0170
Epoch [4/6], Batch [225/428], Loss: 0.9250
Epoch [4/6], Batch [226/428], Loss: 1.0406
Epoch [4/6], Batch [227/428], Loss: 3.1923
Epoch [4/6], Batch [228/428], Loss: 5.0640
Epoch [4/6], Batch [229/428], Loss: 3.1889
Epoch [4/6], Batch [230/428], Loss: 1.0622
Epoch [4/6], Batch [231/428], Loss: 3.7205
Epoch [4/6], Batch [232/428], Loss: 2.7363
Epoch [4/6], Batch [233/428], Loss: 1.8653
Epoch [4/6], Batch [234/428], Loss: 1.4935
Epoch [4/6], Batch [235/428], Loss: 3.0679
Epoch [4/6], Batch [236/428], Loss: 1.1641
Epoch [4/6], Batch [237/428], Loss: 0.9037
Epoch [4/6], Batch [238/428], Loss: 2.1934
Epoch [4/6], Batch [239/428], Loss: 0.4344
Epoch [4/6], Batch [240/428], Loss: 4.4566
Epoch [4/6], Batch [241/428], Loss: 0.2131
Epoch [4/6], Batch [242/428], Loss: 3.5687
Epoch [4/6], Batch [243/428], Loss: 4.9422
Epoch [4/6], Batch [244/428], Loss: 3.7929
Epoch [4/6], Batch [245/428], Loss: 4.4195
Epoch [4/6], Batch [246/428], Loss: 3.2057
Epoch [4/6], Batch [247/428], Loss: 3.1175
Epoch [4/6], Batch [248/428], Loss: 5.0837
Epoch [4/6], Batch [249/428], Loss: 1.7944
Epoch [4/6], Batch [250/428], Loss: 1.3233
Epoch [4/6], Batch [251/428], Loss: 3.4132
Epoch [4/6], Batch [252/428], Loss: 0.7087
Epoch [4/6], Batch [253/428], Loss: 0.4796
Epoch [4/6], Batch [254/428], Loss: 3.8584
Epoch [4/6], Batch [255/428], Loss: 5.3194
Epoch [4/6], Batch [256/428], Loss: 0.1319
Epoch [4/6], Batch [257/428], Loss: 0.0803
Epoch [4/6], Batch [258/428], Loss: 4.9969
Epoch [4/6], Batch [259/428], Loss: 4.5732
Epoch [4/6], Batch [260/428], Loss: 0.0257
Epoch [4/6], Batch [261/428], Loss: 6.1862
Epoch [4/6], Batch [262/428], Loss: 5.9703
Epoch [4/6], Batch [263/428], Loss: 0.0196
Epoch [4/6], Batch [264/428], Loss: 5.3194
Epoch [4/6], Batch [265/428], Loss: 7.6961
Epoch [4/6], Batch [266/428], Loss: 4.7108
Epoch [4/6], Batch [267/428], Loss: 7.0230
Epoch [4/6], Batch [268/428], Loss: 0.0675
Epoch [4/6], Batch [269/428], Loss: 4.0552
Epoch [4/6], Batch [270/428], Loss: 3.6488
Epoch [4/6], Batch [271/428], Loss: 3.0040
Epoch [4/6], Batch [272/428], Loss: 2.2143
Epoch [4/6], Batch [273/428], Loss: 0.7142
Epoch [4/6], Batch [274/428], Loss: 4.1799
Epoch [4/6], Batch [275/428], Loss: 0.6949
Epoch [4/6], Batch [276/428], Loss: 3.5730
Epoch [4/6], Batch [277/428], Loss: 2.6315
Epoch [4/6], Batch [278/428], Loss: 4.5026
Epoch [4/6], Batch [279/428], Loss: 4.2530
Epoch [4/6], Batch [280/428], Loss: 2.9712
Epoch [4/6], Batch [281/428], Loss: 2.5240
Epoch [4/6], Batch [282/428], Loss: 2.4118
Epoch [4/6], Batch [283/428], Loss: 2.0151
Epoch [4/6], Batch [284/428], Loss: 1.5632
Epoch [4/6], Batch [285/428], Loss: 1.1171
Epoch [4/6], Batch [286/428], Loss: 2.7154
Epoch [4/6], Batch [287/428], Loss: 2.2848
Epoch [4/6], Batch [288/428], Loss: 3.0075
Epoch [4/6], Batch [289/428], Loss: 0.3390
Epoch [4/6], Batch [290/428], Loss: 0.2842
Epoch [4/6], Batch [291/428], Loss: 3.2949
Epoch [4/6], Batch [292/428], Loss: 0.1561
Epoch [4/6], Batch [293/428], Loss: 3.4587
Epoch [4/6], Batch [294/428], Loss: 4.8085
Epoch [4/6], Batch [295/428], Loss: 4.2178
Epoch [4/6], Batch [296/428], Loss: 3.4645
Epoch [4/6], Batch [297/428], Loss: 4.5549
Epoch [4/6], Batch [298/428], Loss: 4.0867
Epoch [4/6], Batch [299/428], Loss: 2.8707
Epoch [4/6], Batch [300/428], Loss: 5.5236
Epoch [4/6], Batch [301/428], Loss: 5.7472
Epoch [4/6], Batch [302/428], Loss: 5.3868
Epoch [4/6], Batch [303/428], Loss: 4.3993
Epoch [4/6], Batch [304/428], Loss: 1.4820
Epoch [4/6], Batch [305/428], Loss: 1.2483
Epoch [4/6], Batch [306/428], Loss: 4.2074
Epoch [4/6], Batch [307/428], Loss: 2.0586
Epoch [4/6], Batch [308/428], Loss: 3.7241
Epoch [4/6], Batch [309/428], Loss: 2.7414
Epoch [4/6], Batch [310/428], Loss: 2.5466
Epoch [4/6], Batch [311/428], Loss: 2.2657
Epoch [4/6], Batch [312/428], Loss: 2.0290
Epoch [4/6], Batch [313/428], Loss: 1.8082
Epoch [4/6], Batch [314/428], Loss: 2.2104
Epoch [4/6], Batch [315/428], Loss: 1.8190
Epoch [4/6], Batch [316/428], Loss: 1.6337
Epoch [4/6], Batch [317/428], Loss: 3.0052
Epoch [4/6], Batch [318/428], Loss: 3.1547
Epoch [4/6], Batch [319/428], Loss: 2.9550
Epoch [4/6], Batch [320/428], Loss: 5.2837
Epoch [4/6], Batch [321/428], Loss: 1.7330
Epoch [4/6], Batch [322/428], Loss: 1.6707
Epoch [4/6], Batch [323/428], Loss: 2.8663
Epoch [4/6], Batch [324/428], Loss: 2.4043
Epoch [4/6], Batch [325/428], Loss: 1.1545
Epoch [4/6], Batch [326/428], Loss: 1.4789
Epoch [4/6], Batch [327/428], Loss: 2.4545
Epoch [4/6], Batch [328/428], Loss: 5.0781
Epoch [4/6], Batch [329/428], Loss: 4.9149
Epoch [4/6], Batch [330/428], Loss: 0.8811
Epoch [4/6], Batch [331/428], Loss: 4.3606
Epoch [4/6], Batch [332/428], Loss: 3.9230
Epoch [4/6], Batch [333/428], Loss: 0.7615
Epoch [4/6], Batch [334/428], Loss: 3.0494
Epoch [4/6], Batch [335/428], Loss: 2.5844
Epoch [4/6], Batch [336/428], Loss: 2.4842
Epoch [4/6], Batch [337/428], Loss: 0.8712
Epoch [4/6], Batch [338/428], Loss: 0.9172
Epoch [4/6], Batch [339/428], Loss: 1.0657
Epoch [4/6], Batch [340/428], Loss: 0.8328
Epoch [4/6], Batch [341/428], Loss: 1.2423
Epoch [4/6], Batch [342/428], Loss: 2.9989
Epoch [4/6], Batch [343/428], Loss: 4.2781
Epoch [4/6], Batch [344/428], Loss: 0.3668
Epoch [4/6], Batch [345/428], Loss: 4.4484
Epoch [4/6], Batch [346/428], Loss: 3.0691
Epoch [4/6], Batch [347/428], Loss: 4.8523
Epoch [4/6], Batch [348/428], Loss: 5.2413
Epoch [4/6], Batch [349/428], Loss: 5.1122
Epoch [4/6], Batch [350/428], Loss: 4.6451
Epoch [4/6], Batch [351/428], Loss: 4.1202
Epoch [4/6], Batch [352/428], Loss: 1.6232
Epoch [4/6], Batch [353/428], Loss: 4.0456
Epoch [4/6], Batch [354/428], Loss: 2.7786
Epoch [4/6], Batch [355/428], Loss: 2.1135
Epoch [4/6], Batch [356/428], Loss: 2.0222
Epoch [4/6], Batch [357/428], Loss: 2.2780
Epoch [4/6], Batch [358/428], Loss: 2.4355
Epoch [4/6], Batch [359/428], Loss: 2.5635
Epoch [4/6], Batch [360/428], Loss: 1.6364
Epoch [4/6], Batch [361/428], Loss: 2.2749
Epoch [4/6], Batch [362/428], Loss: 2.1224
Epoch [4/6], Batch [363/428], Loss: 2.2306
Epoch [4/6], Batch [364/428], Loss: 2.4941
Epoch [4/6], Batch [365/428], Loss: 1.7214
Epoch [4/6], Batch [366/428], Loss: 1.8177
Epoch [4/6], Batch [367/428], Loss: 1.6736
Epoch [4/6], Batch [368/428], Loss: 2.0300
Epoch [4/6], Batch [369/428], Loss: 1.5122
Epoch [4/6], Batch [370/428], Loss: 1.9378
Epoch [4/6], Batch [371/428], Loss: 1.9455
Epoch [4/6], Batch [372/428], Loss: 1.8811
Epoch [4/6], Batch [373/428], Loss: 2.2343
Epoch [4/6], Batch [374/428], Loss: 1.6065
Epoch [4/6], Batch [375/428], Loss: 3.8350
Epoch [4/6], Batch [376/428], Loss: 1.5432
Epoch [4/6], Batch [377/428], Loss: 1.1931
Epoch [4/6], Batch [378/428], Loss: 1.4447
Epoch [4/6], Batch [379/428], Loss: 0.9155
Epoch [4/6], Batch [380/428], Loss: 2.6947
Epoch [4/6], Batch [381/428], Loss: 2.9629
Epoch [4/6], Batch [382/428], Loss: 3.9278
Epoch [4/6], Batch [383/428], Loss: 3.0008
Epoch [4/6], Batch [384/428], Loss: 0.6286
Epoch [4/6], Batch [385/428], Loss: 0.5652
Epoch [4/6], Batch [386/428], Loss: 1.8831
Epoch [4/6], Batch [387/428], Loss: 3.7948
Epoch [4/6], Batch [388/428], Loss: 3.3961
Epoch [4/6], Batch [389/428], Loss: 3.8343
Epoch [4/6], Batch [390/428], Loss: 3.2695
Epoch [4/6], Batch [391/428], Loss: 3.0422
Epoch [4/6], Batch [392/428], Loss: 2.0119
Epoch [4/6], Batch [393/428], Loss: 0.7495
Epoch [4/6], Batch [394/428], Loss: 2.2892
Epoch [4/6], Batch [395/428], Loss: 2.0950
Epoch [4/6], Batch [396/428], Loss: 1.0944
Epoch [4/6], Batch [397/428], Loss: 1.1564
Epoch [4/6], Batch [398/428], Loss: 2.1001
Epoch [4/6], Batch [399/428], Loss: 2.8104
Epoch [4/6], Batch [400/428], Loss: 3.3043
Epoch [4/6], Batch [401/428], Loss: 2.1826
Epoch [4/6], Batch [402/428], Loss: 2.3400
Epoch [4/6], Batch [403/428], Loss: 2.2062
Epoch [4/6], Batch [404/428], Loss: 1.4708
Epoch [4/6], Batch [405/428], Loss: 1.7691
Epoch [4/6], Batch [406/428], Loss: 1.6166
Epoch [4/6], Batch [407/428], Loss: 2.3398
Epoch [4/6], Batch [408/428], Loss: 1.8691
Epoch [4/6], Batch [409/428], Loss: 2.9655
Epoch [4/6], Batch [410/428], Loss: 2.8505
Epoch [4/6], Batch [411/428], Loss: 2.1507
Epoch [4/6], Batch [412/428], Loss: 2.6726
Epoch [4/6], Batch [413/428], Loss: 2.1088
Epoch [4/6], Batch [414/428], Loss: 1.9779
Epoch [4/6], Batch [415/428], Loss: 1.7355
Epoch [4/6], Batch [416/428], Loss: 1.6054
Epoch [4/6], Batch [417/428], Loss: 1.2967
Epoch [4/6], Batch [418/428], Loss: 1.0102
Epoch [4/6], Batch [419/428], Loss: 3.2016
Epoch [4/6], Batch [420/428], Loss: 3.1800
Epoch [4/6], Batch [421/428], Loss: 3.0373
Epoch [4/6], Batch [422/428], Loss: 3.2828
Epoch [4/6], Batch [423/428], Loss: 2.7910
Epoch [4/6], Batch [424/428], Loss: 3.0660
Epoch [4/6], Batch [425/428], Loss: 3.1697
Epoch [4/6], Batch [426/428], Loss: 2.4888
Epoch [4/6], Batch [427/428], Loss: 0.6257
Epoch [4/6], Batch [428/428], Loss: 2.5417
Epoch [4] Training Time: 276.46 seconds
Epoch [4/6], Average Loss: 2.9476, Training Accuracy: 0.1706
Epoch [4], Validation Loss: 2.2568, Validation Accuracy: 0.1429
Epoch [4] Validation Time: 10.97 seconds
--------------------------------------------------
Epoch [5/6], Batch [1/428], Loss: 2.9760
Epoch [5/6], Batch [2/428], Loss: 2.4106
Epoch [5/6], Batch [3/428], Loss: 2.2938
Epoch [5/6], Batch [4/428], Loss: 1.3771
Epoch [5/6], Batch [5/428], Loss: 2.8570
Epoch [5/6], Batch [6/428], Loss: 1.1383
Epoch [5/6], Batch [7/428], Loss: 1.6267
Epoch [5/6], Batch [8/428], Loss: 3.0253
Epoch [5/6], Batch [9/428], Loss: 0.8899
Epoch [5/6], Batch [10/428], Loss: 2.7857
Epoch [5/6], Batch [11/428], Loss: 3.1092
Epoch [5/6], Batch [12/428], Loss: 2.3019
Epoch [5/6], Batch [13/428], Loss: 2.2838
Epoch [5/6], Batch [14/428], Loss: 0.7319
Epoch [5/6], Batch [15/428], Loss: 0.7378
Epoch [5/6], Batch [16/428], Loss: 2.1907
Epoch [5/6], Batch [17/428], Loss: 2.1043
Epoch [5/6], Batch [18/428], Loss: 3.1367
Epoch [5/6], Batch [19/428], Loss: 3.0032
Epoch [5/6], Batch [20/428], Loss: 3.0392
Epoch [5/6], Batch [21/428], Loss: 2.9478
Epoch [5/6], Batch [22/428], Loss: 1.5003
Epoch [5/6], Batch [23/428], Loss: 1.3635
Epoch [5/6], Batch [24/428], Loss: 2.5343
Epoch [5/6], Batch [25/428], Loss: 2.4441
Epoch [5/6], Batch [26/428], Loss: 2.8707
Epoch [5/6], Batch [27/428], Loss: 2.5724
Epoch [5/6], Batch [28/428], Loss: 2.4598
Epoch [5/6], Batch [29/428], Loss: 2.8107
Epoch [5/6], Batch [30/428], Loss: 2.5174
Epoch [5/6], Batch [31/428], Loss: 1.9371
Epoch [5/6], Batch [32/428], Loss: 2.3281
Epoch [5/6], Batch [33/428], Loss: 1.2706
Epoch [5/6], Batch [34/428], Loss: 1.9766
Epoch [5/6], Batch [35/428], Loss: 1.9636
Epoch [5/6], Batch [36/428], Loss: 1.8372
Epoch [5/6], Batch [37/428], Loss: 1.9042
Epoch [5/6], Batch [38/428], Loss: 1.7626
Epoch [5/6], Batch [39/428], Loss: 2.6346
Epoch [5/6], Batch [40/428], Loss: 2.0087
Epoch [5/6], Batch [41/428], Loss: 1.2639
Epoch [5/6], Batch [42/428], Loss: 2.6418
Epoch [5/6], Batch [43/428], Loss: 2.5703
Epoch [5/6], Batch [44/428], Loss: 3.3206
Epoch [5/6], Batch [45/428], Loss: 0.8590
Epoch [5/6], Batch [46/428], Loss: 2.4733
Epoch [5/6], Batch [47/428], Loss: 2.5395
Epoch [5/6], Batch [48/428], Loss: 2.4392
Epoch [5/6], Batch [49/428], Loss: 2.2427
Epoch [5/6], Batch [50/428], Loss: 1.8090
Epoch [5/6], Batch [51/428], Loss: 3.1565
Epoch [5/6], Batch [52/428], Loss: 3.0239
Epoch [5/6], Batch [53/428], Loss: 2.7795
Epoch [5/6], Batch [54/428], Loss: 1.2975
Epoch [5/6], Batch [55/428], Loss: 1.1712
Epoch [5/6], Batch [56/428], Loss: 1.4207
Epoch [5/6], Batch [57/428], Loss: 2.0010
Epoch [5/6], Batch [58/428], Loss: 5.0718
Epoch [5/6], Batch [59/428], Loss: 1.3425
Epoch [5/6], Batch [60/428], Loss: 3.1198
Epoch [5/6], Batch [61/428], Loss: 3.9308
Epoch [5/6], Batch [62/428], Loss: 3.1040
Epoch [5/6], Batch [63/428], Loss: 1.1664
Epoch [5/6], Batch [64/428], Loss: 3.7489
Epoch [5/6], Batch [65/428], Loss: 3.7224
Epoch [5/6], Batch [66/428], Loss: 1.5320
Epoch [5/6], Batch [67/428], Loss: 3.4945
Epoch [5/6], Batch [68/428], Loss: 2.5297
Epoch [5/6], Batch [69/428], Loss: 1.5734
Epoch [5/6], Batch [70/428], Loss: 4.4409
Epoch [5/6], Batch [71/428], Loss: 2.1620
Epoch [5/6], Batch [72/428], Loss: 1.1113
Epoch [5/6], Batch [73/428], Loss: 4.0177
Epoch [5/6], Batch [74/428], Loss: 1.7090
Epoch [5/6], Batch [75/428], Loss: 2.0635
Epoch [5/6], Batch [76/428], Loss: 2.0886
Epoch [5/6], Batch [77/428], Loss: 2.2793
Epoch [5/6], Batch [78/428], Loss: 2.1681
Epoch [5/6], Batch [79/428], Loss: 1.5589
Epoch [5/6], Batch [80/428], Loss: 3.1125
Epoch [5/6], Batch [81/428], Loss: 2.9553
Epoch [5/6], Batch [82/428], Loss: 2.3729
Epoch [5/6], Batch [83/428], Loss: 1.9697
Epoch [5/6], Batch [84/428], Loss: 1.7973
Epoch [5/6], Batch [85/428], Loss: 1.4208
Epoch [5/6], Batch [86/428], Loss: 1.8771
Epoch [5/6], Batch [87/428], Loss: 1.2458
Epoch [5/6], Batch [88/428], Loss: 3.6363
Epoch [5/6], Batch [89/428], Loss: 2.1663
Epoch [5/6], Batch [90/428], Loss: 1.9538
Epoch [5/6], Batch [91/428], Loss: 2.1187
Epoch [5/6], Batch [92/428], Loss: 1.8596
Epoch [5/6], Batch [93/428], Loss: 1.7566
Epoch [5/6], Batch [94/428], Loss: 1.2800
Epoch [5/6], Batch [95/428], Loss: 1.5961
Epoch [5/6], Batch [96/428], Loss: 1.4417
Epoch [5/6], Batch [97/428], Loss: 1.2184
Epoch [5/6], Batch [98/428], Loss: 3.1618
Epoch [5/6], Batch [99/428], Loss: 2.3325
Epoch [5/6], Batch [100/428], Loss: 3.4419
Epoch [5/6], Batch [101/428], Loss: 0.6792
Epoch [5/6], Batch [102/428], Loss: 3.1885
Epoch [5/6], Batch [103/428], Loss: 2.3593
Epoch [5/6], Batch [104/428], Loss: 3.3265
Epoch [5/6], Batch [105/428], Loss: 3.3004
Epoch [5/6], Batch [106/428], Loss: 3.2325
Epoch [5/6], Batch [107/428], Loss: 3.0813
Epoch [5/6], Batch [108/428], Loss: 2.6658
Epoch [5/6], Batch [109/428], Loss: 2.5907
Epoch [5/6], Batch [110/428], Loss: 0.7470
Epoch [5/6], Batch [111/428], Loss: 2.0314
Epoch [5/6], Batch [112/428], Loss: 2.3261
Epoch [5/6], Batch [113/428], Loss: 0.9799
Epoch [5/6], Batch [114/428], Loss: 1.5775
Epoch [5/6], Batch [115/428], Loss: 2.1379
Epoch [5/6], Batch [116/428], Loss: 2.7990
Epoch [5/6], Batch [117/428], Loss: 1.3668
Epoch [5/6], Batch [118/428], Loss: 1.9030
Epoch [5/6], Batch [119/428], Loss: 1.9774
Epoch [5/6], Batch [120/428], Loss: 3.5880
Epoch [5/6], Batch [121/428], Loss: 1.5068
Epoch [5/6], Batch [122/428], Loss: 1.6809
Epoch [5/6], Batch [123/428], Loss: 1.5404
Epoch [5/6], Batch [124/428], Loss: 1.5963
Epoch [5/6], Batch [125/428], Loss: 2.8397
Epoch [5/6], Batch [126/428], Loss: 3.4921
Epoch [5/6], Batch [127/428], Loss: 1.7618
Epoch [5/6], Batch [128/428], Loss: 1.7533
Epoch [5/6], Batch [129/428], Loss: 1.5256
Epoch [5/6], Batch [130/428], Loss: 4.0032
Epoch [5/6], Batch [131/428], Loss: 3.9282
Epoch [5/6], Batch [132/428], Loss: 3.7308
Epoch [5/6], Batch [133/428], Loss: 1.3963
Epoch [5/6], Batch [134/428], Loss: 1.3350
Epoch [5/6], Batch [135/428], Loss: 2.5589
Epoch [5/6], Batch [136/428], Loss: 1.6867
Epoch [5/6], Batch [137/428], Loss: 2.8669
Epoch [5/6], Batch [138/428], Loss: 1.2650
Epoch [5/6], Batch [139/428], Loss: 1.2469
Epoch [5/6], Batch [140/428], Loss: 1.9948
Epoch [5/6], Batch [141/428], Loss: 1.0460
Epoch [5/6], Batch [142/428], Loss: 0.9790
Epoch [5/6], Batch [143/428], Loss: 2.6075
Epoch [5/6], Batch [144/428], Loss: 2.1980
Epoch [5/6], Batch [145/428], Loss: 2.1388
Epoch [5/6], Batch [146/428], Loss: 2.3201
Epoch [5/6], Batch [147/428], Loss: 1.9196
Epoch [5/6], Batch [148/428], Loss: 1.7746
Epoch [5/6], Batch [149/428], Loss: 2.2983
Epoch [5/6], Batch [150/428], Loss: 2.8349
Epoch [5/6], Batch [151/428], Loss: 0.9782
Epoch [5/6], Batch [152/428], Loss: 2.6716
Epoch [5/6], Batch [153/428], Loss: 1.1023
Epoch [5/6], Batch [154/428], Loss: 2.7285
Epoch [5/6], Batch [155/428], Loss: 1.0878
Epoch [5/6], Batch [156/428], Loss: 1.0462
Epoch [5/6], Batch [157/428], Loss: 2.5541
Epoch [5/6], Batch [158/428], Loss: 2.7509
Epoch [5/6], Batch [159/428], Loss: 2.3127
Epoch [5/6], Batch [160/428], Loss: 2.6148
Epoch [5/6], Batch [161/428], Loss: 4.6632
Epoch [5/6], Batch [162/428], Loss: 2.3050
Epoch [5/6], Batch [163/428], Loss: 3.4029
Epoch [5/6], Batch [164/428], Loss: 4.3490
Epoch [5/6], Batch [165/428], Loss: 1.9819
Epoch [5/6], Batch [166/428], Loss: 3.1843
Epoch [5/6], Batch [167/428], Loss: 2.9391
Epoch [5/6], Batch [168/428], Loss: 1.9650
Epoch [5/6], Batch [169/428], Loss: 1.9014
Epoch [5/6], Batch [170/428], Loss: 2.1138
Epoch [5/6], Batch [171/428], Loss: 1.5147
Epoch [5/6], Batch [172/428], Loss: 1.9102
Epoch [5/6], Batch [173/428], Loss: 2.3140
Epoch [5/6], Batch [174/428], Loss: 1.6097
Epoch [5/6], Batch [175/428], Loss: 3.2114
Epoch [5/6], Batch [176/428], Loss: 3.1231
Epoch [5/6], Batch [177/428], Loss: 2.0769
Epoch [5/6], Batch [178/428], Loss: 1.4193
Epoch [5/6], Batch [179/428], Loss: 2.5634
Epoch [5/6], Batch [180/428], Loss: 1.5488
Epoch [5/6], Batch [181/428], Loss: 2.0521
Epoch [5/6], Batch [182/428], Loss: 2.9403
Epoch [5/6], Batch [183/428], Loss: 1.8902
Epoch [5/6], Batch [184/428], Loss: 1.3980
Epoch [5/6], Batch [185/428], Loss: 3.0880
Epoch [5/6], Batch [186/428], Loss: 2.8283
Epoch [5/6], Batch [187/428], Loss: 1.6966
Epoch [5/6], Batch [188/428], Loss: 1.6940
Epoch [5/6], Batch [189/428], Loss: 3.0598
Epoch [5/6], Batch [190/428], Loss: 1.6267
Epoch [5/6], Batch [191/428], Loss: 2.9438
Epoch [5/6], Batch [192/428], Loss: 2.8415
Epoch [5/6], Batch [193/428], Loss: 2.7848
Epoch [5/6], Batch [194/428], Loss: 2.6445
Epoch [5/6], Batch [195/428], Loss: 1.3813
Epoch [5/6], Batch [196/428], Loss: 2.6010
Epoch [5/6], Batch [197/428], Loss: 2.1961
Epoch [5/6], Batch [198/428], Loss: 1.9678
Epoch [5/6], Batch [199/428], Loss: 1.8664
Epoch [5/6], Batch [200/428], Loss: 1.3891
Epoch [5/6], Batch [201/428], Loss: 1.3773
Epoch [5/6], Batch [202/428], Loss: 1.3320
Epoch [5/6], Batch [203/428], Loss: 1.2153
Epoch [5/6], Batch [204/428], Loss: 2.2035
Epoch [5/6], Batch [205/428], Loss: 0.9460
Epoch [5/6], Batch [206/428], Loss: 0.7884
Epoch [5/6], Batch [207/428], Loss: 2.6925
Epoch [5/6], Batch [208/428], Loss: 1.9069
Epoch [5/6], Batch [209/428], Loss: 0.5070
Epoch [5/6], Batch [210/428], Loss: 3.8985
Epoch [5/6], Batch [211/428], Loss: 3.2040
Epoch [5/6], Batch [212/428], Loss: 0.3513
Epoch [5/6], Batch [213/428], Loss: 4.5614
Epoch [5/6], Batch [214/428], Loss: 4.1926
Epoch [5/6], Batch [215/428], Loss: 2.5681
Epoch [5/6], Batch [216/428], Loss: 0.2794
Epoch [5/6], Batch [217/428], Loss: 4.4811
Epoch [5/6], Batch [218/428], Loss: 0.2538
Epoch [5/6], Batch [219/428], Loss: 0.2405
Epoch [5/6], Batch [220/428], Loss: 0.2090
Epoch [5/6], Batch [221/428], Loss: 0.1672
Epoch [5/6], Batch [222/428], Loss: 4.2775
Epoch [5/6], Batch [223/428], Loss: 0.1115
Epoch [5/6], Batch [224/428], Loss: 4.8253
Epoch [5/6], Batch [225/428], Loss: 0.0736
Epoch [5/6], Batch [226/428], Loss: 4.3829
Epoch [5/6], Batch [227/428], Loss: 4.8808
Epoch [5/6], Batch [228/428], Loss: 5.0308
Epoch [5/6], Batch [229/428], Loss: 5.1237
Epoch [5/6], Batch [230/428], Loss: 4.5885
Epoch [5/6], Batch [231/428], Loss: 4.4649
Epoch [5/6], Batch [232/428], Loss: 0.0707
Epoch [5/6], Batch [233/428], Loss: 4.7047
Epoch [5/6], Batch [234/428], Loss: 4.3553
Epoch [5/6], Batch [235/428], Loss: 3.5354
Epoch [5/6], Batch [236/428], Loss: 0.1346
Epoch [5/6], Batch [237/428], Loss: 3.8372
Epoch [5/6], Batch [238/428], Loss: 4.4380
Epoch [5/6], Batch [239/428], Loss: 3.3104
Epoch [5/6], Batch [240/428], Loss: 3.0873
Epoch [5/6], Batch [241/428], Loss: 2.2094
Epoch [5/6], Batch [242/428], Loss: 0.4295
Epoch [5/6], Batch [243/428], Loss: 3.5621
Epoch [5/6], Batch [244/428], Loss: 0.6354[INFO 06-13 18:04:29] ax.service.ax_client: Completed trial 2 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 18:04:29] ax.service.ax_client: Generated new trial 3 with parameters {'lr': 4e-06, 'num_epochs': 4, 'unfreeze_epoch': 2, 'max_length': 48000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [5/6], Batch [245/428], Loss: 3.3202
Epoch [5/6], Batch [246/428], Loss: 3.4658
Epoch [5/6], Batch [247/428], Loss: 3.1325
Epoch [5/6], Batch [248/428], Loss: 0.9116
Epoch [5/6], Batch [249/428], Loss: 3.1752
Epoch [5/6], Batch [250/428], Loss: 0.9794
Epoch [5/6], Batch [251/428], Loss: 1.5073
Epoch [5/6], Batch [252/428], Loss: 1.8837
Epoch [5/6], Batch [253/428], Loss: 1.4382
Epoch [5/6], Batch [254/428], Loss: 1.8966
Epoch [5/6], Batch [255/428], Loss: 2.3644
Epoch [5/6], Batch [256/428], Loss: 1.2325
Epoch [5/6], Batch [257/428], Loss: 2.4683
Epoch [5/6], Batch [258/428], Loss: 1.5142
Epoch [5/6], Batch [259/428], Loss: 1.6213
Epoch [5/6], Batch [260/428], Loss: 3.4630
Epoch [5/6], Batch [261/428], Loss: 3.3762
Epoch [5/6], Batch [262/428], Loss: 1.1522
Epoch [5/6], Batch [263/428], Loss: 2.0478
Epoch [5/6], Batch [264/428], Loss: 2.9814
Epoch [5/6], Batch [265/428], Loss: 1.9631
Epoch [5/6], Batch [266/428], Loss: 2.2347
Epoch [5/6], Batch [267/428], Loss: 1.9993
Epoch [5/6], Batch [268/428], Loss: 3.2632
Epoch [5/6], Batch [269/428], Loss: 1.6042
Epoch [5/6], Batch [270/428], Loss: 1.9785
Epoch [5/6], Batch [271/428], Loss: 2.1868
Epoch [5/6], Batch [272/428], Loss: 1.8291
Epoch [5/6], Batch [273/428], Loss: 1.9356
Epoch [5/6], Batch [274/428], Loss: 1.8580
Epoch [5/6], Batch [275/428], Loss: 2.1574
Epoch [5/6], Batch [276/428], Loss: 3.0293
Epoch [5/6], Batch [277/428], Loss: 2.0786
Epoch [5/6], Batch [278/428], Loss: 1.5293
Epoch [5/6], Batch [279/428], Loss: 2.7902
Epoch [5/6], Batch [280/428], Loss: 1.5125
Epoch [5/6], Batch [281/428], Loss: 2.1578
Epoch [5/6], Batch [282/428], Loss: 2.4245
Epoch [5/6], Batch [283/428], Loss: 1.6037
Epoch [5/6], Batch [284/428], Loss: 2.0496
Epoch [5/6], Batch [285/428], Loss: 1.5418
Epoch [5/6], Batch [286/428], Loss: 1.4849
Epoch [5/6], Batch [287/428], Loss: 1.9456
Epoch [5/6], Batch [288/428], Loss: 2.2480
Epoch [5/6], Batch [289/428], Loss: 1.8618
Epoch [5/6], Batch [290/428], Loss: 1.7776
Epoch [5/6], Batch [291/428], Loss: 2.0000
Epoch [5/6], Batch [292/428], Loss: 3.2968
Epoch [5/6], Batch [293/428], Loss: 3.2726
Epoch [5/6], Batch [294/428], Loss: 1.4559
Epoch [5/6], Batch [295/428], Loss: 1.6102
Epoch [5/6], Batch [296/428], Loss: 2.1226
Epoch [5/6], Batch [297/428], Loss: 1.5005
Epoch [5/6], Batch [298/428], Loss: 2.0327
Epoch [5/6], Batch [299/428], Loss: 1.8882
Epoch [5/6], Batch [300/428], Loss: 2.7313
Epoch [5/6], Batch [301/428], Loss: 1.2886
Epoch [5/6], Batch [302/428], Loss: 3.8741
Epoch [5/6], Batch [303/428], Loss: 1.1024
Epoch [5/6], Batch [304/428], Loss: 2.7987
Epoch [5/6], Batch [305/428], Loss: 2.7255
Epoch [5/6], Batch [306/428], Loss: 2.6123
Epoch [5/6], Batch [307/428], Loss: 0.8497
Epoch [5/6], Batch [308/428], Loss: 2.0791
Epoch [5/6], Batch [309/428], Loss: 2.0614
Epoch [5/6], Batch [310/428], Loss: 2.0104
Epoch [5/6], Batch [311/428], Loss: 2.0458
Epoch [5/6], Batch [312/428], Loss: 2.1784
Epoch [5/6], Batch [313/428], Loss: 0.9857
Epoch [5/6], Batch [314/428], Loss: 1.4383
Epoch [5/6], Batch [315/428], Loss: 1.2754
Epoch [5/6], Batch [316/428], Loss: 1.1298
Epoch [5/6], Batch [317/428], Loss: 0.9030
Epoch [5/6], Batch [318/428], Loss: 2.2723
Epoch [5/6], Batch [319/428], Loss: 2.3217
Epoch [5/6], Batch [320/428], Loss: 3.7670
Epoch [5/6], Batch [321/428], Loss: 2.4620
Epoch [5/6], Batch [322/428], Loss: 3.9687
Epoch [5/6], Batch [323/428], Loss: 2.4798
Epoch [5/6], Batch [324/428], Loss: 2.6895
Epoch [5/6], Batch [325/428], Loss: 0.4725
Epoch [5/6], Batch [326/428], Loss: 2.1789
Epoch [5/6], Batch [327/428], Loss: 0.5054
Epoch [5/6], Batch [328/428], Loss: 2.0895
Epoch [5/6], Batch [329/428], Loss: 3.6500
Epoch [5/6], Batch [330/428], Loss: 1.9855
Epoch [5/6], Batch [331/428], Loss: 1.8864
Epoch [5/6], Batch [332/428], Loss: 4.2843
Epoch [5/6], Batch [333/428], Loss: 1.5391
Epoch [5/6], Batch [334/428], Loss: 3.4818
Epoch [5/6], Batch [335/428], Loss: 2.8934
Epoch [5/6], Batch [336/428], Loss: 2.8140
Epoch [5/6], Batch [337/428], Loss: 2.6798
Epoch [5/6], Batch [338/428], Loss: 1.6535
Epoch [5/6], Batch [339/428], Loss: 3.5557
Epoch [5/6], Batch [340/428], Loss: 0.9689
Epoch [5/6], Batch [341/428], Loss: 2.0127
Epoch [5/6], Batch [342/428], Loss: 2.2430
Epoch [5/6], Batch [343/428], Loss: 1.7838
Epoch [5/6], Batch [344/428], Loss: 3.0747
Epoch [5/6], Batch [345/428], Loss: 2.6707
Epoch [5/6], Batch [346/428], Loss: 1.1494
Epoch [5/6], Batch [347/428], Loss: 1.1773
Epoch [5/6], Batch [348/428], Loss: 2.8731
Epoch [5/6], Batch [349/428], Loss: 2.8245
Epoch [5/6], Batch [350/428], Loss: 2.6557
Epoch [5/6], Batch [351/428], Loss: 1.9715
Epoch [5/6], Batch [352/428], Loss: 2.2543
Epoch [5/6], Batch [353/428], Loss: 1.9419
Epoch [5/6], Batch [354/428], Loss: 1.8672
Epoch [5/6], Batch [355/428], Loss: 1.3842
Epoch [5/6], Batch [356/428], Loss: 1.3535
Epoch [5/6], Batch [357/428], Loss: 2.1237
Epoch [5/6], Batch [358/428], Loss: 2.7089
Epoch [5/6], Batch [359/428], Loss: 3.5333
Epoch [5/6], Batch [360/428], Loss: 2.4938
Epoch [5/6], Batch [361/428], Loss: 1.4747
Epoch [5/6], Batch [362/428], Loss: 2.3250
Epoch [5/6], Batch [363/428], Loss: 1.3706
Epoch [5/6], Batch [364/428], Loss: 1.2763
Epoch [5/6], Batch [365/428], Loss: 1.6021
Epoch [5/6], Batch [366/428], Loss: 1.6993
Epoch [5/6], Batch [367/428], Loss: 2.5474
Epoch [5/6], Batch [368/428], Loss: 2.0488
Epoch [5/6], Batch [369/428], Loss: 1.5757
Epoch [5/6], Batch [370/428], Loss: 1.4770
Epoch [5/6], Batch [371/428], Loss: 1.4142
Epoch [5/6], Batch [372/428], Loss: 1.2442
Epoch [5/6], Batch [373/428], Loss: 2.6141
Epoch [5/6], Batch [374/428], Loss: 2.2934
Epoch [5/6], Batch [375/428], Loss: 3.1396
Epoch [5/6], Batch [376/428], Loss: 0.7564
Epoch [5/6], Batch [377/428], Loss: 1.8376
Epoch [5/6], Batch [378/428], Loss: 2.6678
Epoch [5/6], Batch [379/428], Loss: 1.9861
Epoch [5/6], Batch [380/428], Loss: 0.5729
Epoch [5/6], Batch [381/428], Loss: 2.8249
Epoch [5/6], Batch [382/428], Loss: 2.5332
Epoch [5/6], Batch [383/428], Loss: 2.7798
Epoch [5/6], Batch [384/428], Loss: 0.5612
Epoch [5/6], Batch [385/428], Loss: 2.5719
Epoch [5/6], Batch [386/428], Loss: 3.1400
Epoch [5/6], Batch [387/428], Loss: 0.6159
Epoch [5/6], Batch [388/428], Loss: 0.6093
Epoch [5/6], Batch [389/428], Loss: 2.5830
Epoch [5/6], Batch [390/428], Loss: 2.5216
Epoch [5/6], Batch [391/428], Loss: 0.5610
Epoch [5/6], Batch [392/428], Loss: 0.5564
Epoch [5/6], Batch [393/428], Loss: 3.0105
Epoch [5/6], Batch [394/428], Loss: 0.4712
Epoch [5/6], Batch [395/428], Loss: 0.4175
Epoch [5/6], Batch [396/428], Loss: 2.8572
Epoch [5/6], Batch [397/428], Loss: 4.4493
Epoch [5/6], Batch [398/428], Loss: 2.9896
Epoch [5/6], Batch [399/428], Loss: 3.6230
Epoch [5/6], Batch [400/428], Loss: 4.3402
Epoch [5/6], Batch [401/428], Loss: 2.5180
Epoch [5/6], Batch [402/428], Loss: 2.4597
Epoch [5/6], Batch [403/428], Loss: 2.9127
Epoch [5/6], Batch [404/428], Loss: 3.8164
Epoch [5/6], Batch [405/428], Loss: 2.6017
Epoch [5/6], Batch [406/428], Loss: 2.3740
Epoch [5/6], Batch [407/428], Loss: 3.0914
Epoch [5/6], Batch [408/428], Loss: 0.9311
Epoch [5/6], Batch [409/428], Loss: 1.0348
Epoch [5/6], Batch [410/428], Loss: 3.2547
Epoch [5/6], Batch [411/428], Loss: 1.6633
Epoch [5/6], Batch [412/428], Loss: 1.4208
Epoch [5/6], Batch [413/428], Loss: 1.6006
Epoch [5/6], Batch [414/428], Loss: 2.8911
Epoch [5/6], Batch [415/428], Loss: 2.8006
Epoch [5/6], Batch [416/428], Loss: 1.4314
Epoch [5/6], Batch [417/428], Loss: 2.8597
Epoch [5/6], Batch [418/428], Loss: 2.9888
Epoch [5/6], Batch [419/428], Loss: 1.2355
Epoch [5/6], Batch [420/428], Loss: 2.0822
Epoch [5/6], Batch [421/428], Loss: 2.1721
Epoch [5/6], Batch [422/428], Loss: 1.7098
Epoch [5/6], Batch [423/428], Loss: 0.9820
Epoch [5/6], Batch [424/428], Loss: 0.9392
Epoch [5/6], Batch [425/428], Loss: 3.1742
Epoch [5/6], Batch [426/428], Loss: 2.6200
Epoch [5/6], Batch [427/428], Loss: 2.8019
Epoch [5/6], Batch [428/428], Loss: 2.6107
Epoch [5] Training Time: 279.64 seconds
Epoch [5/6], Average Loss: 2.2317, Training Accuracy: 0.1916
Epoch [5], Validation Loss: 2.2887, Validation Accuracy: 0.1429
Epoch [5] Validation Time: 11.20 seconds
--------------------------------------------------
Epoch [6/6], Batch [1/428], Loss: 0.7205
Epoch [6/6], Batch [2/428], Loss: 2.6556
Epoch [6/6], Batch [3/428], Loss: 0.7367
Epoch [6/6], Batch [4/428], Loss: 0.6976
Epoch [6/6], Batch [5/428], Loss: 2.4548
Epoch [6/6], Batch [6/428], Loss: 2.6369
Epoch [6/6], Batch [7/428], Loss: 2.6137
Epoch [6/6], Batch [8/428], Loss: 2.1026
Epoch [6/6], Batch [9/428], Loss: 3.2278
Epoch [6/6], Batch [10/428], Loss: 2.5118
Epoch [6/6], Batch [11/428], Loss: 2.5250
Epoch [6/6], Batch [12/428], Loss: 2.4760
Epoch [6/6], Batch [13/428], Loss: 2.4247
Epoch [6/6], Batch [14/428], Loss: 0.7864
Epoch [6/6], Batch [15/428], Loss: 2.3123
Epoch [6/6], Batch [16/428], Loss: 2.0845
Epoch [6/6], Batch [17/428], Loss: 2.1356
Epoch [6/6], Batch [18/428], Loss: 2.2543
Epoch [6/6], Batch [19/428], Loss: 2.1908
Epoch [6/6], Batch [20/428], Loss: 2.0243
Epoch [6/6], Batch [21/428], Loss: 1.9900
Epoch [6/6], Batch [22/428], Loss: 1.9287
Epoch [6/6], Batch [23/428], Loss: 2.3751
Epoch [6/6], Batch [24/428], Loss: 1.2348
Epoch [6/6], Batch [25/428], Loss: 1.9836
Epoch [6/6], Batch [26/428], Loss: 2.2898
Epoch [6/6], Batch [27/428], Loss: 1.3751
Epoch [6/6], Batch [28/428], Loss: 1.3472
Epoch [6/6], Batch [29/428], Loss: 1.6429
Epoch [6/6], Batch [30/428], Loss: 1.8840
Epoch [6/6], Batch [31/428], Loss: 3.0853
Epoch [6/6], Batch [32/428], Loss: 1.3662
Epoch [6/6], Batch [33/428], Loss: 1.9130
Epoch [6/6], Batch [34/428], Loss: 1.8327
Epoch [6/6], Batch [35/428], Loss: 1.9489
Epoch [6/6], Batch [36/428], Loss: 1.3538
Epoch [6/6], Batch [37/428], Loss: 2.6456
Epoch [6/6], Batch [38/428], Loss: 2.2498
Epoch [6/6], Batch [39/428], Loss: 1.7403
Epoch [6/6], Batch [40/428], Loss: 1.8716
Epoch [6/6], Batch [41/428], Loss: 1.7221
Epoch [6/6], Batch [42/428], Loss: 1.6512
Epoch [6/6], Batch [43/428], Loss: 2.6410
Epoch [6/6], Batch [44/428], Loss: 1.5157
Epoch [6/6], Batch [45/428], Loss: 1.7981
Epoch [6/6], Batch [46/428], Loss: 1.5348
Epoch [6/6], Batch [47/428], Loss: 1.5702
Epoch [6/6], Batch [48/428], Loss: 2.5491
Epoch [6/6], Batch [49/428], Loss: 2.2919
Epoch [6/6], Batch [50/428], Loss: 2.1017
Epoch [6/6], Batch [51/428], Loss: 2.0890
Epoch [6/6], Batch [52/428], Loss: 1.7716
Epoch [6/6], Batch [53/428], Loss: 1.3687
Epoch [6/6], Batch [54/428], Loss: 2.0597
Epoch [6/6], Batch [55/428], Loss: 1.3540
Epoch [6/6], Batch [56/428], Loss: 1.3098
Epoch [6/6], Batch [57/428], Loss: 2.4193
Epoch [6/6], Batch [58/428], Loss: 2.4092
Epoch [6/6], Batch [59/428], Loss: 2.3163
Epoch [6/6], Batch [60/428], Loss: 3.2578
Epoch [6/6], Batch [61/428], Loss: 1.8671
Epoch [6/6], Batch [62/428], Loss: 1.1816
Epoch [6/6], Batch [63/428], Loss: 2.2095
Epoch [6/6], Batch [64/428], Loss: 2.1301
Epoch [6/6], Batch [65/428], Loss: 2.3043
Epoch [6/6], Batch [66/428], Loss: 1.8904
Epoch [6/6], Batch [67/428], Loss: 1.1471
Epoch [6/6], Batch [68/428], Loss: 2.0025
Epoch [6/6], Batch [69/428], Loss: 3.2316
Epoch [6/6], Batch [70/428], Loss: 1.8879
Epoch [6/6], Batch [71/428], Loss: 1.8634
Epoch [6/6], Batch [72/428], Loss: 2.2709
Epoch [6/6], Batch [73/428], Loss: 1.7259
Epoch [6/6], Batch [74/428], Loss: 2.2915
Epoch [6/6], Batch [75/428], Loss: 1.2309
Epoch [6/6], Batch [76/428], Loss: 1.2421
Epoch [6/6], Batch [77/428], Loss: 2.3507
Epoch [6/6], Batch [78/428], Loss: 2.3475
Epoch [6/6], Batch [79/428], Loss: 1.5060
Epoch [6/6], Batch [80/428], Loss: 1.2333
Epoch [6/6], Batch [81/428], Loss: 2.2490
Epoch [6/6], Batch [82/428], Loss: 2.3759
Epoch [6/6], Batch [83/428], Loss: 2.4369
Epoch [6/6], Batch [84/428], Loss: 1.4390
Epoch [6/6], Batch [85/428], Loss: 3.1436
Epoch [6/6], Batch [86/428], Loss: 2.3279
Epoch [6/6], Batch [87/428], Loss: 3.1072
Epoch [6/6], Batch [88/428], Loss: 1.3271
Epoch [6/6], Batch [89/428], Loss: 1.3264
Epoch [6/6], Batch [90/428], Loss: 2.4137
Epoch [6/6], Batch [91/428], Loss: 1.2639
Epoch [6/6], Batch [92/428], Loss: 2.2494
Epoch [6/6], Batch [93/428], Loss: 2.3561
Epoch [6/6], Batch [94/428], Loss: 1.2305
Epoch [6/6], Batch [95/428], Loss: 2.3386
Epoch [6/6], Batch [96/428], Loss: 2.3397
Epoch [6/6], Batch [97/428], Loss: 2.1266
Epoch [6/6], Batch [98/428], Loss: 1.1710
Epoch [6/6], Batch [99/428], Loss: 1.1394
Epoch [6/6], Batch [100/428], Loss: 2.1446
Epoch [6/6], Batch [101/428], Loss: 2.7861
Epoch [6/6], Batch [102/428], Loss: 2.1072
Epoch [6/6], Batch [103/428], Loss: 1.8692
Epoch [6/6], Batch [104/428], Loss: 2.7661
Epoch [6/6], Batch [105/428], Loss: 2.5928
Epoch [6/6], Batch [106/428], Loss: 1.0668
Epoch [6/6], Batch [107/428], Loss: 2.5453
Epoch [6/6], Batch [108/428], Loss: 2.0144
Epoch [6/6], Batch [109/428], Loss: 2.0177
Epoch [6/6], Batch [110/428], Loss: 2.2957
Epoch [6/6], Batch [111/428], Loss: 1.1006
Epoch [6/6], Batch [112/428], Loss: 2.1202
Epoch [6/6], Batch [113/428], Loss: 2.5503
Epoch [6/6], Batch [114/428], Loss: 2.0558
Epoch [6/6], Batch [115/428], Loss: 2.4591
Epoch [6/6], Batch [116/428], Loss: 2.4105
Epoch [6/6], Batch [117/428], Loss: 2.3787
Epoch [6/6], Batch [118/428], Loss: 2.0996
Epoch [6/6], Batch [119/428], Loss: 1.2251
Epoch [6/6], Batch [120/428], Loss: 2.0356
Epoch [6/6], Batch [121/428], Loss: 1.2432
Epoch [6/6], Batch [122/428], Loss: 1.2747
Epoch [6/6], Batch [123/428], Loss: 2.4409
Epoch [6/6], Batch [124/428], Loss: 1.9758
Epoch [6/6], Batch [125/428], Loss: 1.2370
Epoch [6/6], Batch [126/428], Loss: 2.1502
Epoch [6/6], Batch [127/428], Loss: 1.8805
Epoch [6/6], Batch [128/428], Loss: 2.4411
Epoch [6/6], Batch [129/428], Loss: 2.1802
Epoch [6/6], Batch [130/428], Loss: 1.2252
Epoch [6/6], Batch [131/428], Loss: 1.1947
Epoch [6/6], Batch [132/428], Loss: 2.5350
Epoch [6/6], Batch [133/428], Loss: 2.3806
Epoch [6/6], Batch [134/428], Loss: 1.1258
Epoch [6/6], Batch [135/428], Loss: 2.3190
Epoch [6/6], Batch [136/428], Loss: 1.8067
Epoch [6/6], Batch [137/428], Loss: 2.4733
Epoch [6/6], Batch [138/428], Loss: 2.2782
Epoch [6/6], Batch [139/428], Loss: 2.1239
Epoch [6/6], Batch [140/428], Loss: 1.7634
Epoch [6/6], Batch [141/428], Loss: 1.1249
Epoch [6/6], Batch [142/428], Loss: 2.2614
Epoch [6/6], Batch [143/428], Loss: 2.1655
Epoch [6/6], Batch [144/428], Loss: 1.1150
Epoch [6/6], Batch [145/428], Loss: 1.1304
Epoch [6/6], Batch [146/428], Loss: 2.6419
Epoch [6/6], Batch [147/428], Loss: 2.1699
Epoch [6/6], Batch [148/428], Loss: 2.6275
Epoch [6/6], Batch [149/428], Loss: 2.5847
Epoch [6/6], Batch [150/428], Loss: 1.0722
Epoch [6/6], Batch [151/428], Loss: 2.5419
Epoch [6/6], Batch [152/428], Loss: 1.0636
Epoch [6/6], Batch [153/428], Loss: 1.0373
Epoch [6/6], Batch [154/428], Loss: 1.9346
Epoch [6/6], Batch [155/428], Loss: 2.6076
Epoch [6/6], Batch [156/428], Loss: 2.2174
Epoch [6/6], Batch [157/428], Loss: 2.5998
Epoch [6/6], Batch [158/428], Loss: 2.5359
Epoch [6/6], Batch [159/428], Loss: 2.0264
Epoch [6/6], Batch [160/428], Loss: 0.9711
Epoch [6/6], Batch [161/428], Loss: 2.3705
Epoch [6/6], Batch [162/428], Loss: 2.3172
Epoch [6/6], Batch [163/428], Loss: 2.3889
Epoch [6/6], Batch [164/428], Loss: 2.3465
Epoch [6/6], Batch [165/428], Loss: 2.3026
Epoch [6/6], Batch [166/428], Loss: 2.1571
Epoch [6/6], Batch [167/428], Loss: 2.2318
Epoch [6/6], Batch [168/428], Loss: 1.0739
Epoch [6/6], Batch [169/428], Loss: 1.9972
Epoch [6/6], Batch [170/428], Loss: 1.9374
Epoch [6/6], Batch [171/428], Loss: 2.1009
Epoch [6/6], Batch [172/428], Loss: 1.1293
Epoch [6/6], Batch [173/428], Loss: 1.1684
Epoch [6/6], Batch [174/428], Loss: 2.4424
Epoch [6/6], Batch [175/428], Loss: 2.4216
Epoch [6/6], Batch [176/428], Loss: 2.3867
Epoch [6/6], Batch [177/428], Loss: 1.5923
Epoch [6/6], Batch [178/428], Loss: 3.0291
Epoch [6/6], Batch [179/428], Loss: 2.9721
Epoch [6/6], Batch [180/428], Loss: 1.5643
Epoch [6/6], Batch [181/428], Loss: 2.0025
Epoch [6/6], Batch [182/428], Loss: 2.2626
Epoch [6/6], Batch [183/428], Loss: 1.4783
Epoch [6/6], Batch [184/428], Loss: 1.3364
Epoch [6/6], Batch [185/428], Loss: 2.8567
Epoch [6/6], Batch [186/428], Loss: 1.3834
Epoch [6/6], Batch [187/428], Loss: 2.0104
Epoch [6/6], Batch [188/428], Loss: 1.3631
Epoch [6/6], Batch [189/428], Loss: 2.2185
Epoch [6/6], Batch [190/428], Loss: 1.3916
Epoch [6/6], Batch [191/428], Loss: 1.9493
Epoch [6/6], Batch [192/428], Loss: 2.6688
Epoch [6/6], Batch [193/428], Loss: 2.1672
Epoch [6/6], Batch [194/428], Loss: 2.7642
Epoch [6/6], Batch [195/428], Loss: 2.6184
Epoch [6/6], Batch [196/428], Loss: 1.3667
Epoch [6/6], Batch [197/428], Loss: 2.7163
Epoch [6/6], Batch [198/428], Loss: 1.8643
Epoch [6/6], Batch [199/428], Loss: 2.6873
Epoch [6/6], Batch [200/428], Loss: 1.5422
Epoch [6/6], Batch [201/428], Loss: 2.3214
Epoch [6/6], Batch [202/428], Loss: 2.4950
Epoch [6/6], Batch [203/428], Loss: 1.5526
Epoch [6/6], Batch [204/428], Loss: 1.5394
Epoch [6/6], Batch [205/428], Loss: 1.8447
Epoch [6/6], Batch [206/428], Loss: 1.5785
Epoch [6/6], Batch [207/428], Loss: 2.1193
Epoch [6/6], Batch [208/428], Loss: 2.2967
Epoch [6/6], Batch [209/428], Loss: 2.7549
Epoch [6/6], Batch [210/428], Loss: 1.8163
Epoch [6/6], Batch [211/428], Loss: 2.1540
Epoch [6/6], Batch [212/428], Loss: 2.7210
Epoch [6/6], Batch [213/428], Loss: 2.0869
Epoch [6/6], Batch [214/428], Loss: 1.7517
Epoch [6/6], Batch [215/428], Loss: 1.6182
Epoch [6/6], Batch [216/428], Loss: 2.3525
Epoch [6/6], Batch [217/428], Loss: 2.3245
Epoch [6/6], Batch [218/428], Loss: 1.6762
Epoch [6/6], Batch [219/428], Loss: 1.9634
Epoch [6/6], Batch [220/428], Loss: 1.9928
Epoch [6/6], Batch [221/428], Loss: 1.6773
Epoch [6/6], Batch [222/428], Loss: 1.6977
Epoch [6/6], Batch [223/428], Loss: 1.6072
Epoch [6/6], Batch [224/428], Loss: 1.8199
Epoch [6/6], Batch [225/428], Loss: 1.5983
Epoch [6/6], Batch [226/428], Loss: 2.6471
Epoch [6/6], Batch [227/428], Loss: 1.5121
Epoch [6/6], Batch [228/428], Loss: 2.1347
Epoch [6/6], Batch [229/428], Loss: 2.5839
Epoch [6/6], Batch [230/428], Loss: 1.8145
Epoch [6/6], Batch [231/428], Loss: 2.1322
Epoch [6/6], Batch [232/428], Loss: 1.3254
Epoch [6/6], Batch [233/428], Loss: 1.7925
Epoch [6/6], Batch [234/428], Loss: 1.9467
Epoch [6/6], Batch [235/428], Loss: 1.9685
Epoch [6/6], Batch [236/428], Loss: 2.4486
Epoch [6/6], Batch [237/428], Loss: 2.4501
Epoch [6/6], Batch [238/428], Loss: 1.9051
Epoch [6/6], Batch [239/428], Loss: 2.2792
Epoch [6/6], Batch [240/428], Loss: 2.2781
Epoch [6/6], Batch [241/428], Loss: 1.7576
Epoch [6/6], Batch [242/428], Loss: 2.4692
Epoch [6/6], Batch [243/428], Loss: 1.3878
Epoch [6/6], Batch [244/428], Loss: 1.7627
Epoch [6/6], Batch [245/428], Loss: 2.3599
Epoch [6/6], Batch [246/428], Loss: 2.3935
Epoch [6/6], Batch [247/428], Loss: 1.4015
Epoch [6/6], Batch [248/428], Loss: 1.4235
Epoch [6/6], Batch [249/428], Loss: 2.1760
Epoch [6/6], Batch [250/428], Loss: 2.3495
Epoch [6/6], Batch [251/428], Loss: 2.2722
Epoch [6/6], Batch [252/428], Loss: 2.0846
Epoch [6/6], Batch [253/428], Loss: 2.0746
Epoch [6/6], Batch [254/428], Loss: 2.0492
Epoch [6/6], Batch [255/428], Loss: 2.0043
Epoch [6/6], Batch [256/428], Loss: 2.0419
Epoch [6/6], Batch [257/428], Loss: 1.3842
Epoch [6/6], Batch [258/428], Loss: 1.7885
Epoch [6/6], Batch [259/428], Loss: 1.3991
Epoch [6/6], Batch [260/428], Loss: 2.1411
Epoch [6/6], Batch [261/428], Loss: 1.9977
Epoch [6/6], Batch [262/428], Loss: 1.3734
Epoch [6/6], Batch [263/428], Loss: 1.3358
Epoch [6/6], Batch [264/428], Loss: 2.4591
Epoch [6/6], Batch [265/428], Loss: 1.9550
Epoch [6/6], Batch [266/428], Loss: 1.2987
Epoch [6/6], Batch [267/428], Loss: 2.5083
Epoch [6/6], Batch [268/428], Loss: 2.8950
Epoch [6/6], Batch [269/428], Loss: 2.1571
Epoch [6/6], Batch [270/428], Loss: 1.8779
Epoch [6/6], Batch [271/428], Loss: 1.2320
Epoch [6/6], Batch [272/428], Loss: 1.2012
Epoch [6/6], Batch [273/428], Loss: 1.7261
Epoch [6/6], Batch [274/428], Loss: 1.1449
Epoch [6/6], Batch [275/428], Loss: 1.8352
Epoch [6/6], Batch [276/428], Loss: 1.7826
Epoch [6/6], Batch [277/428], Loss: 1.0364
Epoch [6/6], Batch [278/428], Loss: 2.2087
Epoch [6/6], Batch [279/428], Loss: 2.9896
Epoch [6/6], Batch [280/428], Loss: 2.7573
Epoch [6/6], Batch [281/428], Loss: 2.9641
Epoch [6/6], Batch [282/428], Loss: 2.7539
Epoch [6/6], Batch [283/428], Loss: 0.9931
Epoch [6/6], Batch [284/428], Loss: 2.7364
Epoch [6/6], Batch [285/428], Loss: 1.8959
Epoch [6/6], Batch [286/428], Loss: 0.9918
Epoch [6/6], Batch [287/428], Loss: 0.9903
Epoch [6/6], Batch [288/428], Loss: 1.9477
Epoch [6/6], Batch [289/428], Loss: 2.6652
Epoch [6/6], Batch [290/428], Loss: 1.9838
Epoch [6/6], Batch [291/428], Loss: 0.9104
Epoch [6/6], Batch [292/428], Loss: 2.5313
Epoch [6/6], Batch [293/428], Loss: 1.9518
Epoch [6/6], Batch [294/428], Loss: 2.7759
Epoch [6/6], Batch [295/428], Loss: 0.9236
Epoch [6/6], Batch [296/428], Loss: 2.6917
Epoch [6/6], Batch [297/428], Loss: 2.4500
Epoch [6/6], Batch [298/428], Loss: 0.8661
Epoch [6/6], Batch [299/428], Loss: 2.5926
Epoch [6/6], Batch [300/428], Loss: 0.8694
Epoch [6/6], Batch [301/428], Loss: 2.4526
Epoch [6/6], Batch [302/428], Loss: 0.8634
Epoch [6/6], Batch [303/428], Loss: 2.7491
Epoch [6/6], Batch [304/428], Loss: 2.3926
Epoch [6/6], Batch [305/428], Loss: 2.5435
Epoch [6/6], Batch [306/428], Loss: 0.8151
Epoch [6/6], Batch [307/428], Loss: 0.7966
Epoch [6/6], Batch [308/428], Loss: 0.7748
Epoch [6/6], Batch [309/428], Loss: 0.7363
Epoch [6/6], Batch [310/428], Loss: 2.5854
Epoch [6/6], Batch [311/428], Loss: 2.5976
Epoch [6/6], Batch [312/428], Loss: 2.4637
Epoch [6/6], Batch [313/428], Loss: 2.4872
Epoch [6/6], Batch [314/428], Loss: 2.6143
Epoch [6/6], Batch [315/428], Loss: 2.8873
Epoch [6/6], Batch [316/428], Loss: 2.4653
Epoch [6/6], Batch [317/428], Loss: 2.6634
Epoch [6/6], Batch [318/428], Loss: 0.6815
Epoch [6/6], Batch [319/428], Loss: 2.2630
Epoch [6/6], Batch [320/428], Loss: 2.4180
Epoch [6/6], Batch [321/428], Loss: 2.4483
Epoch [6/6], Batch [322/428], Loss: 2.6621
Epoch [6/6], Batch [323/428], Loss: 2.7845
Epoch [6/6], Batch [324/428], Loss: 2.5562
Epoch [6/6], Batch [325/428], Loss: 0.8195
Epoch [6/6], Batch [326/428], Loss: 2.0215
Epoch [6/6], Batch [327/428], Loss: 2.1911
Epoch [6/6], Batch [328/428], Loss: 2.1806
Epoch [6/6], Batch [329/428], Loss: 1.9515
Epoch [6/6], Batch [330/428], Loss: 2.1189
Epoch [6/6], Batch [331/428], Loss: 1.0112
Epoch [6/6], Batch [332/428], Loss: 2.3362
Epoch [6/6], Batch [333/428], Loss: 2.5365
Epoch [6/6], Batch [334/428], Loss: 2.2820
Epoch [6/6], Batch [335/428], Loss: 2.2650
Epoch [6/6], Batch [336/428], Loss: 2.8126
Epoch [6/6], Batch [337/428], Loss: 2.7501
Epoch [6/6], Batch [338/428], Loss: 1.2400
Epoch [6/6], Batch [339/428], Loss: 2.0493
Epoch [6/6], Batch [340/428], Loss: 1.2765
Epoch [6/6], Batch [341/428], Loss: 1.2950
Epoch [6/6], Batch [342/428], Loss: 2.3708
Epoch [6/6], Batch [343/428], Loss: 1.9250
Epoch [6/6], Batch [344/428], Loss: 2.6056
Epoch [6/6], Batch [345/428], Loss: 2.5505
Epoch [6/6], Batch [346/428], Loss: 2.5288
Epoch [6/6], Batch [347/428], Loss: 2.4081
Epoch [6/6], Batch [348/428], Loss: 1.2609
Epoch [6/6], Batch [349/428], Loss: 2.3066
Epoch [6/6], Batch [350/428], Loss: 1.2940
Epoch [6/6], Batch [351/428], Loss: 1.2374
Epoch [6/6], Batch [352/428], Loss: 1.8754
Epoch [6/6], Batch [353/428], Loss: 1.2065
Epoch [6/6], Batch [354/428], Loss: 2.0777
Epoch [6/6], Batch [355/428], Loss: 2.0399
Epoch [6/6], Batch [356/428], Loss: 1.9317
Epoch [6/6], Batch [357/428], Loss: 1.8927
Epoch [6/6], Batch [358/428], Loss: 1.8537
Epoch [6/6], Batch [359/428], Loss: 1.7501
Epoch [6/6], Batch [360/428], Loss: 2.4486
Epoch [6/6], Batch [361/428], Loss: 1.1439
Epoch [6/6], Batch [362/428], Loss: 1.5567
Epoch [6/6], Batch [363/428], Loss: 2.5180
Epoch [6/6], Batch [364/428], Loss: 2.0630
Epoch [6/6], Batch [365/428], Loss: 1.3646
Epoch [6/6], Batch [366/428], Loss: 2.6032
Epoch [6/6], Batch [367/428], Loss: 2.5872
Epoch [6/6], Batch [368/428], Loss: 1.3488
Epoch [6/6], Batch [369/428], Loss: 2.5268
Epoch [6/6], Batch [370/428], Loss: 2.3199
Epoch [6/6], Batch [371/428], Loss: 1.4011
Epoch [6/6], Batch [372/428], Loss: 2.0801
Epoch [6/6], Batch [373/428], Loss: 2.3206
Epoch [6/6], Batch [374/428], Loss: 1.3859
Epoch [6/6], Batch [375/428], Loss: 2.0776
Epoch [6/6], Batch [376/428], Loss: 1.2551
Epoch [6/6], Batch [377/428], Loss: 2.1519
Epoch [6/6], Batch [378/428], Loss: 1.3894
Epoch [6/6], Batch [379/428], Loss: 1.3243
Epoch [6/6], Batch [380/428], Loss: 1.9678
Epoch [6/6], Batch [381/428], Loss: 2.3749
Epoch [6/6], Batch [382/428], Loss: 1.2547
Epoch [6/6], Batch [383/428], Loss: 2.7169
Epoch [6/6], Batch [384/428], Loss: 3.4003
Epoch [6/6], Batch [385/428], Loss: 1.6084
Epoch [6/6], Batch [386/428], Loss: 1.8633
Epoch [6/6], Batch [387/428], Loss: 1.6763
Epoch [6/6], Batch [388/428], Loss: 2.3540
Epoch [6/6], Batch [389/428], Loss: 2.3092
Epoch [6/6], Batch [390/428], Loss: 1.1875
Epoch [6/6], Batch [391/428], Loss: 2.2187
Epoch [6/6], Batch [392/428], Loss: 2.1745
Epoch [6/6], Batch [393/428], Loss: 2.7396
Epoch [6/6], Batch [394/428], Loss: 1.8349
Epoch [6/6], Batch [395/428], Loss: 1.2043
Epoch [6/6], Batch [396/428], Loss: 1.2147
Epoch [6/6], Batch [397/428], Loss: 1.8125
Epoch [6/6], Batch [398/428], Loss: 1.8385
Epoch [6/6], Batch [399/428], Loss: 2.6979
Epoch [6/6], Batch [400/428], Loss: 3.3007
Epoch [6/6], Batch [401/428], Loss: 2.1916
Epoch [6/6], Batch [402/428], Loss: 1.2217
Epoch [6/6], Batch [403/428], Loss: 1.9166
Epoch [6/6], Batch [404/428], Loss: 3.2301
Epoch [6/6], Batch [405/428], Loss: 1.1907
Epoch [6/6], Batch [406/428], Loss: 2.5458
Epoch [6/6], Batch [407/428], Loss: 2.2660
Epoch [6/6], Batch [408/428], Loss: 2.4966
Epoch [6/6], Batch [409/428], Loss: 2.2385
Epoch [6/6], Batch [410/428], Loss: 1.7343
Epoch [6/6], Batch [411/428], Loss: 2.3268
Epoch [6/6], Batch [412/428], Loss: 2.2119
Epoch [6/6], Batch [413/428], Loss: 2.0955
Epoch [6/6], Batch [414/428], Loss: 2.0583
Epoch [6/6], Batch [415/428], Loss: 1.6753
Epoch [6/6], Batch [416/428], Loss: 1.9246
Epoch [6/6], Batch [417/428], Loss: 2.0267
Epoch [6/6], Batch [418/428], Loss: 1.4505
Epoch [6/6], Batch [419/428], Loss: 1.4757
Epoch [6/6], Batch [420/428], Loss: 2.2088
Epoch [6/6], Batch [421/428], Loss: 1.4919
Epoch [6/6], Batch [422/428], Loss: 1.4730
Epoch [6/6], Batch [423/428], Loss: 1.4223
Epoch [6/6], Batch [424/428], Loss: 1.6675
Epoch [6/6], Batch [425/428], Loss: 1.7959
Epoch [6/6], Batch [426/428], Loss: 1.6217
Epoch [6/6], Batch [427/428], Loss: 2.3017
Epoch [6/6], Batch [428/428], Loss: 2.3169
Epoch [6] Training Time: 278.09 seconds
Epoch [6/6], Average Loss: 1.9861, Training Accuracy: 0.2266
Epoch [6], Validation Loss: 2.0246, Validation Accuracy: 0.1429
Epoch [6] Validation Time: 10.99 seconds
--------------------------------------------------

Running trial 3 with config: {'batch_size': 1, 'lr': 4.450209767149518e-06, 'num_epochs': 4, 'unfreeze_epoch': 2, 'max_length': 48000, 'device': device(type='cpu')}
Epoch [1/4], Batch [1/428], Loss: 2.6775
Epoch [1/4], Batch [2/428], Loss: 3.9060
Epoch [1/4], Batch [3/428], Loss: 0.9658
Epoch [1/4], Batch [4/428], Loss: 3.1608
Epoch [1/4], Batch [5/428], Loss: 2.6786
Epoch [1/4], Batch [6/428], Loss: 4.0520
Epoch [1/4], Batch [7/428], Loss: 3.9547
Epoch [1/4], Batch [8/428], Loss: 2.6738
Epoch [1/4], Batch [9/428], Loss: 3.3435
Epoch [1/4], Batch [10/428], Loss: 2.3738
Epoch [1/4], Batch [11/428], Loss: 4.2479
Epoch [1/4], Batch [12/428], Loss: 0.9914
Epoch [1/4], Batch [13/428], Loss: 2.0377
Epoch [1/4], Batch [14/428], Loss: 1.3232
Epoch [1/4], Batch [15/428], Loss: 1.2435
Epoch [1/4], Batch [16/428], Loss: 2.5746
Epoch [1/4], Batch [17/428], Loss: 2.8199
Epoch [1/4], Batch [18/428], Loss: 1.5616
Epoch [1/4], Batch [19/428], Loss: 1.5626
Epoch [1/4], Batch [20/428], Loss: 1.5304
Epoch [1/4], Batch [21/428], Loss: 1.3201
Epoch [1/4], Batch [22/428], Loss: 3.9046
Epoch [1/4], Batch [23/428], Loss: 4.2810
Epoch [1/4], Batch [24/428], Loss: 2.5213
Epoch [1/4], Batch [25/428], Loss: 1.2056
Epoch [1/4], Batch [26/428], Loss: 2.8913
Epoch [1/4], Batch [27/428], Loss: 2.1335
Epoch [1/4], Batch [28/428], Loss: 3.5984
Epoch [1/4], Batch [29/428], Loss: 1.7697
Epoch [1/4], Batch [30/428], Loss: 3.6808
Epoch [1/4], Batch [31/428], Loss: 4.0957
Epoch [1/4], Batch [32/428], Loss: 1.3716
Epoch [1/4], Batch [33/428], Loss: 1.6378
Epoch [1/4], Batch [34/428], Loss: 1.7253
Epoch [1/4], Batch [35/428], Loss: 2.1349
Epoch [1/4], Batch [36/428], Loss: 2.3698
Epoch [1/4], Batch [37/428], Loss: 1.8891
Epoch [1/4], Batch [38/428], Loss: 3.9880
Epoch [1/4], Batch [39/428], Loss: 4.4437
Epoch [1/4], Batch [40/428], Loss: 1.8789
Epoch [1/4], Batch [41/428], Loss: 3.8730
Epoch [1/4], Batch [42/428], Loss: 4.2468
Epoch [1/4], Batch [43/428], Loss: 2.1802
Epoch [1/4], Batch [44/428], Loss: 1.3004
Epoch [1/4], Batch [45/428], Loss: 3.9938
Epoch [1/4], Batch [46/428], Loss: 2.0117
Epoch [1/4], Batch [47/428], Loss: 1.4694
Epoch [1/4], Batch [48/428], Loss: 3.8728
Epoch [1/4], Batch [49/428], Loss: 1.1835
Epoch [1/4], Batch [50/428], Loss: 2.2013
Epoch [1/4], Batch [51/428], Loss: 1.5264
Epoch [1/4], Batch [52/428], Loss: 1.8802
Epoch [1/4], Batch [53/428], Loss: 1.8739
Epoch [1/4], Batch [54/428], Loss: 4.6557
Epoch [1/4], Batch [55/428], Loss: 1.1725
Epoch [1/4], Batch [56/428], Loss: 3.5426
Epoch [1/4], Batch [57/428], Loss: 3.7672
Epoch [1/4], Batch [58/428], Loss: 4.0848
Epoch [1/4], Batch [59/428], Loss: 3.4405
Epoch [1/4], Batch [60/428], Loss: 2.4478
Epoch [1/4], Batch [61/428], Loss: 1.8024
Epoch [1/4], Batch [62/428], Loss: 2.8966
Epoch [1/4], Batch [63/428], Loss: 3.9287
Epoch [1/4], Batch [64/428], Loss: 1.6894
Epoch [1/4], Batch [65/428], Loss: 2.7408
Epoch [1/4], Batch [66/428], Loss: 2.7289
Epoch [1/4], Batch [67/428], Loss: 2.6424
Epoch [1/4], Batch [68/428], Loss: 2.5164
Epoch [1/4], Batch [69/428], Loss: 4.2192
Epoch [1/4], Batch [70/428], Loss: 3.1532
Epoch [1/4], Batch [71/428], Loss: 2.4162
Epoch [1/4], Batch [72/428], Loss: 4.4791
Epoch [1/4], Batch [73/428], Loss: 3.8005
Epoch [1/4], Batch [74/428], Loss: 3.4843
Epoch [1/4], Batch [75/428], Loss: 1.5416
Epoch [1/4], Batch [76/428], Loss: 1.7075
Epoch [1/4], Batch [77/428], Loss: 4.4346
Epoch [1/4], Batch [78/428], Loss: 2.2042
Epoch [1/4], Batch [79/428], Loss: 2.4858
Epoch [1/4], Batch [80/428], Loss: 2.7207
Epoch [1/4], Batch [81/428], Loss: 4.0404
Epoch [1/4], Batch [82/428], Loss: 0.9538
Epoch [1/4], Batch [83/428], Loss: 1.3385
Epoch [1/4], Batch [84/428], Loss: 2.5141
Epoch [1/4], Batch [85/428], Loss: 1.3340
Epoch [1/4], Batch [86/428], Loss: 4.1501
Epoch [1/4], Batch [87/428], Loss: 3.6781
Epoch [1/4], Batch [88/428], Loss: 2.1982
Epoch [1/4], Batch [89/428], Loss: 1.9840
Epoch [1/4], Batch [90/428], Loss: 1.1585
Epoch [1/4], Batch [91/428], Loss: 3.1695
Epoch [1/4], Batch [92/428], Loss: 1.1916
Epoch [1/4], Batch [93/428], Loss: 2.1118
Epoch [1/4], Batch [94/428], Loss: 4.0429
Epoch [1/4], Batch [95/428], Loss: 3.0923
Epoch [1/4], Batch [96/428], Loss: 1.8899
Epoch [1/4], Batch [97/428], Loss: 3.0543
Epoch [1/4], Batch [98/428], Loss: 2.6704
Epoch [1/4], Batch [99/428], Loss: 1.5225
Epoch [1/4], Batch [100/428], Loss: 3.1210
Epoch [1/4], Batch [101/428], Loss: 3.6446
Epoch [1/4], Batch [102/428], Loss: 4.4124
Epoch [1/4], Batch [103/428], Loss: 4.0091
Epoch [1/4], Batch [104/428], Loss: 3.8071
Epoch [1/4], Batch [105/428], Loss: 2.2925
Epoch [1/4], Batch [106/428], Loss: 1.5336
Epoch [1/4], Batch [107/428], Loss: 2.5894
Epoch [1/4], Batch [108/428], Loss: 1.2244
Epoch [1/4], Batch [109/428], Loss: 2.0653
Epoch [1/4], Batch [110/428], Loss: 3.3306
Epoch [1/4], Batch [111/428], Loss: 2.4949
Epoch [1/4], Batch [112/428], Loss: 2.7212
Epoch [1/4], Batch [113/428], Loss: 2.4826
Epoch [1/4], Batch [114/428], Loss: 3.9703
Epoch [1/4], Batch [115/428], Loss: 0.8376
Epoch [1/4], Batch [116/428], Loss: 4.2203
Epoch [1/4], Batch [117/428], Loss: 3.1647
Epoch [1/4], Batch [118/428], Loss: 1.8439
Epoch [1/4], Batch [119/428], Loss: 1.6350
Epoch [1/4], Batch [120/428], Loss: 3.6252
Epoch [1/4], Batch [121/428], Loss: 1.1913
Epoch [1/4], Batch [122/428], Loss: 0.8363
Epoch [1/4], Batch [123/428], Loss: 1.3843
Epoch [1/4], Batch [124/428], Loss: 1.3710
Epoch [1/4], Batch [125/428], Loss: 3.4324
Epoch [1/4], Batch [126/428], Loss: 4.3960
Epoch [1/4], Batch [127/428], Loss: 4.1192
Epoch [1/4], Batch [128/428], Loss: 3.4339
Epoch [1/4], Batch [129/428], Loss: 2.9367
Epoch [1/4], Batch [130/428], Loss: 2.9544
Epoch [1/4], Batch [131/428], Loss: 1.5335
Epoch [1/4], Batch [132/428], Loss: 1.3706
Epoch [1/4], Batch [133/428], Loss: 3.7691
Epoch [1/4], Batch [134/428], Loss: 3.7045
Epoch [1/4], Batch [135/428], Loss: 3.0203
Epoch [1/4], Batch [136/428], Loss: 4.7604
Epoch [1/4], Batch [137/428], Loss: 1.3670
Epoch [1/4], Batch [138/428], Loss: 2.9277
Epoch [1/4], Batch [139/428], Loss: 3.9143
Epoch [1/4], Batch [140/428], Loss: 1.3215
Epoch [1/4], Batch [141/428], Loss: 1.3685
Epoch [1/4], Batch [142/428], Loss: 2.0659
Epoch [1/4], Batch [143/428], Loss: 2.7115
Epoch [1/4], Batch [144/428], Loss: 1.8506
Epoch [1/4], Batch [145/428], Loss: 1.3424
Epoch [1/4], Batch [146/428], Loss: 2.5153
Epoch [1/4], Batch [147/428], Loss: 1.4099
Epoch [1/4], Batch [148/428], Loss: 4.1085
Epoch [1/4], Batch [149/428], Loss: 3.9701
Epoch [1/4], Batch [150/428], Loss: 2.5811
Epoch [1/4], Batch [151/428], Loss: 4.1761
Epoch [1/4], Batch [152/428], Loss: 1.8076
Epoch [1/4], Batch [153/428], Loss: 1.7274
Epoch [1/4], Batch [154/428], Loss: 2.8351
Epoch [1/4], Batch [155/428], Loss: 4.2645
Epoch [1/4], Batch [156/428], Loss: 3.5689
Epoch [1/4], Batch [157/428], Loss: 2.4121
Epoch [1/4], Batch [158/428], Loss: 1.8898
Epoch [1/4], Batch [159/428], Loss: 2.7569
Epoch [1/4], Batch [160/428], Loss: 1.5960
Epoch [1/4], Batch [161/428], Loss: 1.2447
Epoch [1/4], Batch [162/428], Loss: 1.6787
Epoch [1/4], Batch [163/428], Loss: 4.8447
Epoch [1/4], Batch [164/428], Loss: 2.9207
Epoch [1/4], Batch [165/428], Loss: 2.7519
Epoch [1/4], Batch [166/428], Loss: 1.9203
Epoch [1/4], Batch [167/428], Loss: 3.7253
Epoch [1/4], Batch [168/428], Loss: 2.4339
Epoch [1/4], Batch [169/428], Loss: 1.1345
Epoch [1/4], Batch [170/428], Loss: 1.4707
Epoch [1/4], Batch [171/428], Loss: 2.5254
Epoch [1/4], Batch [172/428], Loss: 1.9138
Epoch [1/4], Batch [173/428], Loss: 3.1134
Epoch [1/4], Batch [174/428], Loss: 1.3284
Epoch [1/4], Batch [175/428], Loss: 1.6328
Epoch [1/4], Batch [176/428], Loss: 1.8688
Epoch [1/4], Batch [177/428], Loss: 3.8275
Epoch [1/4], Batch [178/428], Loss: 1.5402
Epoch [1/4], Batch [179/428], Loss: 1.7718
Epoch [1/4], Batch [180/428], Loss: 3.4070
Epoch [1/4], Batch [181/428], Loss: 4.3826
Epoch [1/4], Batch [182/428], Loss: 3.5899
Epoch [1/4], Batch [183/428], Loss: 2.3824
Epoch [1/4], Batch [184/428], Loss: 1.3061
Epoch [1/4], Batch [185/428], Loss: 3.2228
Epoch [1/4], Batch [186/428], Loss: 2.0342
Epoch [1/4], Batch [187/428], Loss: 1.5810
Epoch [1/4], Batch [188/428], Loss: 4.2808
Epoch [1/4], Batch [189/428], Loss: 1.8259
Epoch [1/4], Batch [190/428], Loss: 1.0468
Epoch [1/4], Batch [191/428], Loss: 1.6148
Epoch [1/4], Batch [192/428], Loss: 2.0200
Epoch [1/4], Batch [193/428], Loss: 1.5152
Epoch [1/4], Batch [194/428], Loss: 4.4432
Epoch [1/4], Batch [195/428], Loss: 1.6180
Epoch [1/4], Batch [196/428], Loss: 1.9159
Epoch [1/4], Batch [197/428], Loss: 2.4762
Epoch [1/4], Batch [198/428], Loss: 2.5333
Epoch [1/4], Batch [199/428], Loss: 1.6056
Epoch [1/4], Batch [200/428], Loss: 2.2872
Epoch [1/4], Batch [201/428], Loss: 1.7748
Epoch [1/4], Batch [202/428], Loss: 3.6232
Epoch [1/4], Batch [203/428], Loss: 2.4976
Epoch [1/4], Batch [204/428], Loss: 4.8020
Epoch [1/4], Batch [205/428], Loss: 3.6627
Epoch [1/4], Batch [206/428], Loss: 3.9634
Epoch [1/4], Batch [207/428], Loss: 1.7385
Epoch [1/4], Batch [208/428], Loss: 1.7775
Epoch [1/4], Batch [209/428], Loss: 1.2224
Epoch [1/4], Batch [210/428], Loss: 3.0825
Epoch [1/4], Batch [211/428], Loss: 2.7876
Epoch [1/4], Batch [212/428], Loss: 2.4228
Epoch [1/4], Batch [213/428], Loss: 3.6421
Epoch [1/4], Batch [214/428], Loss: 2.0882
Epoch [1/4], Batch [215/428], Loss: 3.2250
Epoch [1/4], Batch [216/428], Loss: 2.2783
Epoch [1/4], Batch [217/428], Loss: 2.0844
Epoch [1/4], Batch [218/428], Loss: 2.6208
Epoch [1/4], Batch [219/428], Loss: 1.7338
Epoch [1/4], Batch [220/428], Loss: 1.2323
Epoch [1/4], Batch [221/428], Loss: 1.7790
Epoch [1/4], Batch [222/428], Loss: 1.0773
Epoch [1/4], Batch [223/428], Loss: 1.4903
Epoch [1/4], Batch [224/428], Loss: 1.2711
Epoch [1/4], Batch [225/428], Loss: 2.8241
Epoch [1/4], Batch [226/428], Loss: 1.9601
Epoch [1/4], Batch [227/428], Loss: 3.2129
Epoch [1/4], Batch [228/428], Loss: 3.8265
Epoch [1/4], Batch [229/428], Loss: 2.6256
Epoch [1/4], Batch [230/428], Loss: 3.1670
Epoch [1/4], Batch [231/428], Loss: 1.2598
Epoch [1/4], Batch [232/428], Loss: 3.2613
Epoch [1/4], Batch [233/428], Loss: 3.0178
Epoch [1/4], Batch [234/428], Loss: 4.0298
Epoch [1/4], Batch [235/428], Loss: 3.9998
Epoch [1/4], Batch [236/428], Loss: 2.3921
Epoch [1/4], Batch [237/428], Loss: 4.2887
Epoch [1/4], Batch [238/428], Loss: 3.0617
Epoch [1/4], Batch [239/428], Loss: 2.1807
Epoch [1/4], Batch [240/428], Loss: 1.9851
Epoch [1/4], Batch [241/428], Loss: 1.0080
Epoch [1/4], Batch [242/428], Loss: 4.7064
Epoch [1/4], Batch [243/428], Loss: 1.2046
Epoch [1/4], Batch [244/428], Loss: 4.1829
Epoch [1/4], Batch [245/428], Loss: 1.7956
Epoch [1/4], Batch [246/428], Loss: 2.7425
Epoch [1/4], Batch [247/428], Loss: 2.2427
Epoch [1/4], Batch [248/428], Loss: 3.9804
Epoch [1/4], Batch [249/428], Loss: 4.5812
Epoch [1/4], Batch [250/428], Loss: 2.3148
Epoch [1/4], Batch [251/428], Loss: 4.1690
Epoch [1/4], Batch [252/428], Loss: 3.6146
Epoch [1/4], Batch [253/428], Loss: 1.9184
Epoch [1/4], Batch [254/428], Loss: 3.8926
Epoch [1/4], Batch [255/428], Loss: 3.6381
Epoch [1/4], Batch [256/428], Loss: 1.7590
Epoch [1/4], Batch [257/428], Loss: 4.8017
Epoch [1/4], Batch [258/428], Loss: 2.3177
Epoch [1/4], Batch [259/428], Loss: 2.9254
Epoch [1/4], Batch [260/428], Loss: 3.6774
Epoch [1/4], Batch [261/428], Loss: 4.6822
Epoch [1/4], Batch [262/428], Loss: 3.1516
Epoch [1/4], Batch [263/428], Loss: 1.8304
Epoch [1/4], Batch [264/428], Loss: 1.7043
Epoch [1/4], Batch [265/428], Loss: 1.0273
Epoch [1/4], Batch [266/428], Loss: 1.1309
Epoch [1/4], Batch [267/428], Loss: 1.4898
Epoch [1/4], Batch [268/428], Loss: 1.8757
Epoch [1/4], Batch [269/428], Loss: 1.2119
Epoch [1/4], Batch [270/428], Loss: 3.1645
Epoch [1/4], Batch [271/428], Loss: 2.0438
Epoch [1/4], Batch [272/428], Loss: 1.4153
Epoch [1/4], Batch [273/428], Loss: 3.3857
Epoch [1/4], Batch [274/428], Loss: 2.2336
Epoch [1/4], Batch [275/428], Loss: 3.4778
Epoch [1/4], Batch [276/428], Loss: 4.2582
Epoch [1/4], Batch [277/428], Loss: 1.4379
Epoch [1/4], Batch [278/428], Loss: 2.5213
Epoch [1/4], Batch [279/428], Loss: 3.5085
Epoch [1/4], Batch [280/428], Loss: 1.4396
Epoch [1/4], Batch [281/428], Loss: 2.4563
Epoch [1/4], Batch [282/428], Loss: 2.0969
Epoch [1/4], Batch [283/428], Loss: 1.0392
Epoch [1/4], Batch [284/428], Loss: 1.0836
Epoch [1/4], Batch [285/428], Loss: 1.6681
Epoch [1/4], Batch [286/428], Loss: 2.6024
Epoch [1/4], Batch [287/428], Loss: 4.1707
Epoch [1/4], Batch [288/428], Loss: 2.5561
Epoch [1/4], Batch [289/428], Loss: 0.9917
Epoch [1/4], Batch [290/428], Loss: 2.1843
Epoch [1/4], Batch [291/428], Loss: 5.2069
Epoch [1/4], Batch [292/428], Loss: 3.5100
Epoch [1/4], Batch [293/428], Loss: 2.1838
Epoch [1/4], Batch [294/428], Loss: 1.1928
Epoch [1/4], Batch [295/428], Loss: 3.1240
Epoch [1/4], Batch [296/428], Loss: 2.0703
Epoch [1/4], Batch [297/428], Loss: 2.1024
Epoch [1/4], Batch [298/428], Loss: 3.6736
Epoch [1/4], Batch [299/428], Loss: 1.3977
Epoch [1/4], Batch [300/428], Loss: 3.7116
Epoch [1/4], Batch [301/428], Loss: 2.3021
Epoch [1/4], Batch [302/428], Loss: 3.3890
Epoch [1/4], Batch [303/428], Loss: 4.1289
Epoch [1/4], Batch [304/428], Loss: 3.4720
Epoch [1/4], Batch [305/428], Loss: 2.7667
Epoch [1/4], Batch [306/428], Loss: 2.6210
Epoch [1/4], Batch [307/428], Loss: 3.1858
Epoch [1/4], Batch [308/428], Loss: 1.4162
Epoch [1/4], Batch [309/428], Loss: 4.0939
Epoch [1/4], Batch [310/428], Loss: 1.2390
Epoch [1/4], Batch [311/428], Loss: 1.4650
Epoch [1/4], Batch [312/428], Loss: 1.7253
Epoch [1/4], Batch [313/428], Loss: 3.6431
Epoch [1/4], Batch [314/428], Loss: 2.6491
Epoch [1/4], Batch [315/428], Loss: 3.5509
Epoch [1/4], Batch [316/428], Loss: 1.9768
Epoch [1/4], Batch [317/428], Loss: 2.6968
Epoch [1/4], Batch [318/428], Loss: 3.5652
Epoch [1/4], Batch [319/428], Loss: 1.4101
Epoch [1/4], Batch [320/428], Loss: 1.5942
Epoch [1/4], Batch [321/428], Loss: 1.0719
Epoch [1/4], Batch [322/428], Loss: 2.5632
Epoch [1/4], Batch [323/428], Loss: 1.9929
Epoch [1/4], Batch [324/428], Loss: 2.1051
Epoch [1/4], Batch [325/428], Loss: 3.2529
Epoch [1/4], Batch [326/428], Loss: 1.1933
Epoch [1/4], Batch [327/428], Loss: 1.8848
Epoch [1/4], Batch [328/428], Loss: 1.9817
Epoch [1/4], Batch [329/428], Loss: 1.5259
Epoch [1/4], Batch [330/428], Loss: 1.1614
Epoch [1/4], Batch [331/428], Loss: 3.4403
Epoch [1/4], Batch [332/428], Loss: 3.4940
Epoch [1/4], Batch [333/428], Loss: 2.6604
Epoch [1/4], Batch [334/428], Loss: 2.2959
Epoch [1/4], Batch [335/428], Loss: 1.7579
Epoch [1/4], Batch [336/428], Loss: 2.2334
Epoch [1/4], Batch [337/428], Loss: 1.0330
Epoch [1/4], Batch [338/428], Loss: 3.1440
Epoch [1/4], Batch [339/428], Loss: 0.9460
Epoch [1/4], Batch [340/428], Loss: 2.2933
Epoch [1/4], Batch [341/428], Loss: 2.3092
Epoch [1/4], Batch [342/428], Loss: 1.4380
Epoch [1/4], Batch [343/428], Loss: 3.5155
Epoch [1/4], Batch [344/428], Loss: 4.6053
Epoch [1/4], Batch [345/428], Loss: 2.8091
Epoch [1/4], Batch [346/428], Loss: 1.5403
Epoch [1/4], Batch [347/428], Loss: 3.9718
Epoch [1/4], Batch [348/428], Loss: 1.7598
Epoch [1/4], Batch [349/428], Loss: 1.2973
Epoch [1/4], Batch [350/428], Loss: 2.0152
Epoch [1/4], Batch [351/428], Loss: 2.2073
Epoch [1/4], Batch [352/428], Loss: 2.8840
Epoch [1/4], Batch [353/428], Loss: 1.6597
Epoch [1/4], Batch [354/428], Loss: 2.5117
Epoch [1/4], Batch [355/428], Loss: 3.4371
Epoch [1/4], Batch [356/428], Loss: 1.6577
Epoch [1/4], Batch [357/428], Loss: 1.6077
Epoch [1/4], Batch [358/428], Loss: 2.5793
Epoch [1/4], Batch [359/428], Loss: 1.5311
Epoch [1/4], Batch [360/428], Loss: 1.4220
Epoch [1/4], Batch [361/428], Loss: 4.6743
Epoch [1/4], Batch [362/428], Loss: 3.2498
Epoch [1/4], Batch [363/428], Loss: 2.8978
Epoch [1/4], Batch [364/428], Loss: 2.1943
Epoch [1/4], Batch [365/428], Loss: 1.9704
Epoch [1/4], Batch [366/428], Loss: 2.5199
Epoch [1/4], Batch [367/428], Loss: 3.5854
Epoch [1/4], Batch [368/428], Loss: 2.8011
Epoch [1/4], Batch [369/428], Loss: 1.8494
Epoch [1/4], Batch [370/428], Loss: 3.8019
Epoch [1/4], Batch [371/428], Loss: 3.5071
Epoch [1/4], Batch [372/428], Loss: 2.6402
Epoch [1/4], Batch [373/428], Loss: 2.7687
Epoch [1/4], Batch [374/428], Loss: 2.2893
Epoch [1/4], Batch [375/428], Loss: 2.1464
Epoch [1/4], Batch [376/428], Loss: 4.8342
Epoch [1/4], Batch [377/428], Loss: 2.4047
Epoch [1/4], Batch [378/428], Loss: 1.8098
Epoch [1/4], Batch [379/428], Loss: 2.0123
Epoch [1/4], Batch [380/428], Loss: 2.4200
Epoch [1/4], Batch [381/428], Loss: 4.4037
Epoch [1/4], Batch [382/428], Loss: 1.3514
Epoch [1/4], Batch [383/428], Loss: 2.5447
Epoch [1/4], Batch [384/428], Loss: 4.0402
Epoch [1/4], Batch [385/428], Loss: 1.9877
Epoch [1/4], Batch [386/428], Loss: 4.2112
Epoch [1/4], Batch [387/428], Loss: 2.0238
Epoch [1/4], Batch [388/428], Loss: 3.3799
Epoch [1/4], Batch [389/428], Loss: 3.8801
Epoch [1/4], Batch [390/428], Loss: 1.8158
Epoch [1/4], Batch [391/428], Loss: 3.2261
Epoch [1/4], Batch [392/428], Loss: 2.8761
Epoch [1/4], Batch [393/428], Loss: 3.6036
Epoch [1/4], Batch [394/428], Loss: 1.6363
Epoch [1/4], Batch [395/428], Loss: 3.8831
Epoch [1/4], Batch [396/428], Loss: 1.9413
Epoch [1/4], Batch [397/428], Loss: 2.3119
Epoch [1/4], Batch [398/428], Loss: 1.8128
Epoch [1/4], Batch [399/428], Loss: 1.2129
Epoch [1/4], Batch [400/428], Loss: 2.3098
Epoch [1/4], Batch [401/428], Loss: 3.8114
Epoch [1/4], Batch [402/428], Loss: 2.4578
Epoch [1/4], Batch [403/428], Loss: 1.7809
Epoch [1/4], Batch [404/428], Loss: 1.1023
Epoch [1/4], Batch [405/428], Loss: 2.8761
Epoch [1/4], Batch [406/428], Loss: 1.3194
Epoch [1/4], Batch [407/428], Loss: 1.0652
Epoch [1/4], Batch [408/428], Loss: 2.2662
Epoch [1/4], Batch [409/428], Loss: 4.0855
Epoch [1/4], Batch [410/428], Loss: 4.3823
Epoch [1/4], Batch [411/428], Loss: 3.4145
Epoch [1/4], Batch [412/428], Loss: 1.4198
Epoch [1/4], Batch [413/428], Loss: 4.1541
Epoch [1/4], Batch [414/428], Loss: 3.8757
Epoch [1/4], Batch [415/428], Loss: 1.8873
Epoch [1/4], Batch [416/428], Loss: 1.4468
Epoch [1/4], Batch [417/428], Loss: 2.7566
Epoch [1/4], Batch [418/428], Loss: 3.4513
Epoch [1/4], Batch [419/428], Loss: 0.9454
Epoch [1/4], Batch [420/428], Loss: 4.9516
Epoch [1/4], Batch [421/428], Loss: 1.3095
Epoch [1/4], Batch [422/428], Loss: 2.2347
Epoch [1/4], Batch [423/428], Loss: 3.3414
Epoch [1/4], Batch [424/428], Loss: 1.8091
Epoch [1/4], Batch [425/428], Loss: 3.2559
Epoch [1/4], Batch [426/428], Loss: 1.9807
Epoch [1/4], Batch [427/428], Loss: 1.9556
Epoch [1/4], Batch [428/428], Loss: 4.4289
Epoch [1] Training Time: 133.76 seconds
Epoch [1/4], Average Loss: 2.5891, Training Accuracy: 0.1145
Epoch [1], Validation Loss: 2.4484, Validation Accuracy: 0.1468
Epoch [1] Validation Time: 7.39 seconds
--------------------------------------------------
Epoch [2/4], Batch [1/428], Loss: 4.2477
Epoch [2/4], Batch [2/428], Loss: 0.8468
Epoch [2/4], Batch [3/428], Loss: 2.4491
Epoch [2/4], Batch [4/428], Loss: 2.1749
Epoch [2/4], Batch [5/428], Loss: 2.1875
Epoch [2/4], Batch [6/428], Loss: 3.6901
Epoch [2/4], Batch [7/428], Loss: 3.9196
Epoch [2/4], Batch [8/428], Loss: 3.5318
Epoch [2/4], Batch [9/428], Loss: 3.4833
Epoch [2/4], Batch [10/428], Loss: 1.7549
Epoch [2/4], Batch [11/428], Loss: 1.2948
Epoch [2/4], Batch [12/428], Loss: 3.9360
Epoch [2/4], Batch [13/428], Loss: 1.3244
Epoch [2/4], Batch [14/428], Loss: 2.6131
Epoch [2/4], Batch [15/428], Loss: 1.8617
Epoch [2/4], Batch [16/428], Loss: 1.4809
Epoch [2/4], Batch [17/428], Loss: 3.2465
Epoch [2/4], Batch [18/428], Loss: 1.9463
Epoch [2/4], Batch [19/428], Loss: 3.4081
Epoch [2/4], Batch [20/428], Loss: 1.1603
Epoch [2/4], Batch [21/428], Loss: 2.0622
Epoch [2/4], Batch [22/428], Loss: 3.4114
Epoch [2/4], Batch [23/428], Loss: 4.4851
Epoch [2/4], Batch [24/428], Loss: 4.2826
Epoch [2/4], Batch [25/428], Loss: 1.5637
Epoch [2/4], Batch [26/428], Loss: 3.9213
Epoch [2/4], Batch [27/428], Loss: 1.8412
Epoch [2/4], Batch [28/428], Loss: 1.9599
Epoch [2/4], Batch [29/428], Loss: 1.3569
Epoch [2/4], Batch [30/428], Loss: 3.0546
Epoch [2/4], Batch [31/428], Loss: 2.7963
Epoch [2/4], Batch [32/428], Loss: 1.4298
Epoch [2/4], Batch [33/428], Loss: 2.0490
Epoch [2/4], Batch [34/428], Loss: 3.2365
Epoch [2/4], Batch [35/428], Loss: 1.0637
Epoch [2/4], Batch [36/428], Loss: 1.6306
Epoch [2/4], Batch [37/428], Loss: 2.9072
Epoch [2/4], Batch [38/428], Loss: 3.8479
Epoch [2/4], Batch [39/428], Loss: 1.4924
Epoch [2/4], Batch [40/428], Loss: 2.4301
Epoch [2/4], Batch [41/428], Loss: 3.0194
Epoch [2/4], Batch [42/428], Loss: 1.8409
Epoch [2/4], Batch [43/428], Loss: 3.4725
Epoch [2/4], Batch [44/428], Loss: 1.6638
Epoch [2/4], Batch [45/428], Loss: 2.2857
Epoch [2/4], Batch [46/428], Loss: 1.6836
Epoch [2/4], Batch [47/428], Loss: 1.9210
Epoch [2/4], Batch [48/428], Loss: 1.7435
Epoch [2/4], Batch [49/428], Loss: 4.5435
Epoch [2/4], Batch [50/428], Loss: 3.3035
Epoch [2/4], Batch [51/428], Loss: 3.4989
Epoch [2/4], Batch [52/428], Loss: 1.1991
Epoch [2/4], Batch [53/428], Loss: 1.2713
Epoch [2/4], Batch [54/428], Loss: 2.5154
Epoch [2/4], Batch [55/428], Loss: 0.9446
Epoch [2/4], Batch [56/428], Loss: 4.1741
Epoch [2/4], Batch [57/428], Loss: 3.0296
Epoch [2/4], Batch [58/428], Loss: 1.2025
Epoch [2/4], Batch [59/428], Loss: 1.8244
Epoch [2/4], Batch [60/428], Loss: 3.2221
Epoch [2/4], Batch [61/428], Loss: 2.2378
Epoch [2/4], Batch [62/428], Loss: 3.3103
Epoch [2/4], Batch [63/428], Loss: 2.9013
Epoch [2/4], Batch [64/428], Loss: 3.1420
Epoch [2/4], Batch [65/428], Loss: 1.3556
Epoch [2/4], Batch [66/428], Loss: 1.3063
Epoch [2/4], Batch [67/428], Loss: 3.0873
Epoch [2/4], Batch [68/428], Loss: 1.6822
Epoch [2/4], Batch [69/428], Loss: 3.8499
Epoch [2/4], Batch [70/428], Loss: 3.2451
Epoch [2/4], Batch [71/428], Loss: 1.4517
Epoch [2/4], Batch [72/428], Loss: 1.1972
Epoch [2/4], Batch [73/428], Loss: 3.4114
Epoch [2/4], Batch [74/428], Loss: 1.9520
Epoch [2/4], Batch [75/428], Loss: 1.2712
Epoch [2/4], Batch [76/428], Loss: 2.0478
Epoch [2/4], Batch [77/428], Loss: 3.5298
Epoch [2/4], Batch [78/428], Loss: 3.3852
Epoch [2/4], Batch [79/428], Loss: 1.5132
Epoch [2/4], Batch [80/428], Loss: 4.6254
Epoch [2/4], Batch [81/428], Loss: 1.9817
Epoch [2/4], Batch [82/428], Loss: 3.2493
Epoch [2/4], Batch [83/428], Loss: 3.2482
Epoch [2/4], Batch [84/428], Loss: 2.6163
Epoch [2/4], Batch [85/428], Loss: 2.5517
Epoch [2/4], Batch [86/428], Loss: 1.2727
Epoch [2/4], Batch [87/428], Loss: 3.7427
Epoch [2/4], Batch [88/428], Loss: 1.5308
Epoch [2/4], Batch [89/428], Loss: 3.0806
Epoch [2/4], Batch [90/428], Loss: 2.8768
Epoch [2/4], Batch [91/428], Loss: 2.0536
Epoch [2/4], Batch [92/428], Loss: 1.6130
Epoch [2/4], Batch [93/428], Loss: 1.3247
Epoch [2/4], Batch [94/428], Loss: 2.4468
Epoch [2/4], Batch [95/428], Loss: 1.3945
Epoch [2/4], Batch [96/428], Loss: 1.1574
Epoch [2/4], Batch [97/428], Loss: 2.0834
Epoch [2/4], Batch [98/428], Loss: 3.8147
Epoch [2/4], Batch [99/428], Loss: 1.5247
Epoch [2/4], Batch [100/428], Loss: 2.0034
Epoch [2/4], Batch [101/428], Loss: 4.3361
Epoch [2/4], Batch [102/428], Loss: 1.7961
Epoch [2/4], Batch [103/428], Loss: 2.7535
Epoch [2/4], Batch [104/428], Loss: 1.7865
Epoch [2/4], Batch [105/428], Loss: 2.7410
Epoch [2/4], Batch [106/428], Loss: 1.5997
Epoch [2/4], Batch [107/428], Loss: 3.9174
Epoch [2/4], Batch [108/428], Loss: 2.4304
Epoch [2/4], Batch [109/428], Loss: 1.8828
Epoch [2/4], Batch [110/428], Loss: 1.1983
Epoch [2/4], Batch [111/428], Loss: 2.5808
Epoch [2/4], Batch [112/428], Loss: 1.6489
Epoch [2/4], Batch [113/428], Loss: 3.3190
Epoch [2/4], Batch [114/428], Loss: 3.4280
Epoch [2/4], Batch [115/428], Loss: 4.9443
Epoch [2/4], Batch [116/428], Loss: 1.6755
Epoch [2/4], Batch [117/428], Loss: 3.5641
Epoch [2/4], Batch [118/428], Loss: 1.3428
Epoch [2/4], Batch [119/428], Loss: 2.3248
Epoch [2/4], Batch [120/428], Loss: 1.8594
Epoch [2/4], Batch [121/428], Loss: 1.0574
Epoch [2/4], Batch [122/428], Loss: 2.2375
Epoch [2/4], Batch [123/428], Loss: 2.2936
Epoch [2/4], Batch [124/428], Loss: 1.7403
Epoch [2/4], Batch [125/428], Loss: 1.5733
Epoch [2/4], Batch [126/428], Loss: 3.2446
Epoch [2/4], Batch [127/428], Loss: 1.7417
Epoch [2/4], Batch [128/428], Loss: 2.0295
Epoch [2/4], Batch [129/428], Loss: 1.5477
Epoch [2/4], Batch [130/428], Loss: 2.0325
Epoch [2/4], Batch [131/428], Loss: 3.4248
Epoch [2/4], Batch [132/428], Loss: 1.8816
Epoch [2/4], Batch [133/428], Loss: 3.4759
Epoch [2/4], Batch [134/428], Loss: 1.7128
Epoch [2/4], Batch [135/428], Loss: 1.1704
Epoch [2/4], Batch [136/428], Loss: 3.8259
Epoch [2/4], Batch [137/428], Loss: 2.5821
Epoch [2/4], Batch [138/428], Loss: 1.0365
Epoch [2/4], Batch [139/428], Loss: 1.2559
Epoch [2/4], Batch [140/428], Loss: 2.4224
Epoch [2/4], Batch [141/428], Loss: 3.3987
Epoch [2/4], Batch [142/428], Loss: 3.1186
Epoch [2/4], Batch [143/428], Loss: 1.5258
Epoch [2/4], Batch [144/428], Loss: 2.2536
Epoch [2/4], Batch [145/428], Loss: 1.9264
Epoch [2/4], Batch [146/428], Loss: 3.5602
Epoch [2/4], Batch [147/428], Loss: 2.0768
Epoch [2/4], Batch [148/428], Loss: 2.3375
Epoch [2/4], Batch [149/428], Loss: 2.1989
Epoch [2/4], Batch [150/428], Loss: 1.8368
Epoch [2/4], Batch [151/428], Loss: 1.9889
Epoch [2/4], Batch [152/428], Loss: 4.0452
Epoch [2/4], Batch [153/428], Loss: 1.4399
Epoch [2/4], Batch [154/428], Loss: 4.2653
Epoch [2/4], Batch [155/428], Loss: 4.1158
Epoch [2/4], Batch [156/428], Loss: 4.5093
Epoch [2/4], Batch [157/428], Loss: 1.3724
Epoch [2/4], Batch [158/428], Loss: 3.0254
Epoch [2/4], Batch [159/428], Loss: 4.4369
Epoch [2/4], Batch [160/428], Loss: 1.2457
Epoch [2/4], Batch [161/428], Loss: 2.8937
Epoch [2/4], Batch [162/428], Loss: 4.1889
Epoch [2/4], Batch [163/428], Loss: 3.6407
Epoch [2/4], Batch [164/428], Loss: 3.2158
Epoch [2/4], Batch [165/428], Loss: 4.5581
Epoch [2/4], Batch [166/428], Loss: 2.3487
Epoch [2/4], Batch [167/428], Loss: 2.6543
Epoch [2/4], Batch [168/428], Loss: 2.1339
Epoch [2/4], Batch [169/428], Loss: 1.5982
Epoch [2/4], Batch [170/428], Loss: 2.7006
Epoch [2/4], Batch [171/428], Loss: 2.5544
Epoch [2/4], Batch [172/428], Loss: 2.7128
Epoch [2/4], Batch [173/428], Loss: 2.8819
Epoch [2/4], Batch [174/428], Loss: 1.8976
Epoch [2/4], Batch [175/428], Loss: 3.7187
Epoch [2/4], Batch [176/428], Loss: 1.8443
Epoch [2/4], Batch [177/428], Loss: 3.2564
Epoch [2/4], Batch [178/428], Loss: 4.0632
Epoch [2/4], Batch [179/428], Loss: 2.7229
Epoch [2/4], Batch [180/428], Loss: 1.5291
Epoch [2/4], Batch [181/428], Loss: 3.6742
Epoch [2/4], Batch [182/428], Loss: 1.2535
Epoch [2/4], Batch [183/428], Loss: 2.4112
Epoch [2/4], Batch [184/428], Loss: 2.7145
Epoch [2/4], Batch [185/428], Loss: 3.0402
Epoch [2/4], Batch [186/428], Loss: 1.2055
Epoch [2/4], Batch [187/428], Loss: 2.3660
Epoch [2/4], Batch [188/428], Loss: 1.3528
Epoch [2/4], Batch [189/428], Loss: 1.0818
Epoch [2/4], Batch [190/428], Loss: 2.2919
Epoch [2/4], Batch [191/428], Loss: 2.2147
Epoch [2/4], Batch [192/428], Loss: 2.2137
Epoch [2/4], Batch [193/428], Loss: 3.4903
Epoch [2/4], Batch [194/428], Loss: 2.9312
Epoch [2/4], Batch [195/428], Loss: 4.7495
Epoch [2/4], Batch [196/428], Loss: 1.8869
Epoch [2/4], Batch [197/428], Loss: 1.1903
Epoch [2/4], Batch [198/428], Loss: 3.1806
Epoch [2/4], Batch [199/428], Loss: 2.1080
Epoch [2/4], Batch [200/428], Loss: 2.2337
Epoch [2/4], Batch [201/428], Loss: 3.3220
Epoch [2/4], Batch [202/428], Loss: 1.8647
Epoch [2/4], Batch [203/428], Loss: 2.1503
Epoch [2/4], Batch [204/428], Loss: 2.2656
Epoch [2/4], Batch [205/428], Loss: 1.0886
Epoch [2/4], Batch [206/428], Loss: 1.1045
Epoch [2/4], Batch [207/428], Loss: 3.3454
Epoch [2/4], Batch [208/428], Loss: 1.9935
Epoch [2/4], Batch [209/428], Loss: 1.8697
Epoch [2/4], Batch [210/428], Loss: 3.1331
Epoch [2/4], Batch [211/428], Loss: 4.3078
Epoch [2/4], Batch [212/428], Loss: 3.4799
Epoch [2/4], Batch [213/428], Loss: 2.3587
Epoch [2/4], Batch [214/428], Loss: 4.4407
Epoch [2/4], Batch [215/428], Loss: 2.1819
Epoch [2/4], Batch [216/428], Loss: 1.8312
Epoch [2/4], Batch [217/428], Loss: 1.7631
Epoch [2/4], Batch [218/428], Loss: 1.7761
Epoch [2/4], Batch [219/428], Loss: 2.1630
Epoch [2/4], Batch [220/428], Loss: 1.8378
Epoch [2/4], Batch [221/428], Loss: 3.1359
Epoch [2/4], Batch [222/428], Loss: 1.5742
Epoch [2/4], Batch [223/428], Loss: 1.4476
Epoch [2/4], Batch [224/428], Loss: 4.1569
Epoch [2/4], Batch [225/428], Loss: 1.1356
Epoch [2/4], Batch [226/428], Loss: 2.8373
Epoch [2/4], Batch [227/428], Loss: 1.7753
Epoch [2/4], Batch [228/428], Loss: 3.2422
Epoch [2/4], Batch [229/428], Loss: 3.8708
Epoch [2/4], Batch [230/428], Loss: 2.0997
Epoch [2/4], Batch [231/428], Loss: 1.8522
Epoch [2/4], Batch [232/428], Loss: 1.9911
Epoch [2/4], Batch [233/428], Loss: 3.0885
Epoch [2/4], Batch [234/428], Loss: 3.2959
Epoch [2/4], Batch [235/428], Loss: 1.3599
Epoch [2/4], Batch [236/428], Loss: 2.9192
Epoch [2/4], Batch [237/428], Loss: 2.2240
Epoch [2/4], Batch [238/428], Loss: 3.5887
Epoch [2/4], Batch [239/428], Loss: 3.2479
Epoch [2/4], Batch [240/428], Loss: 2.3448
Epoch [2/4], Batch [241/428], Loss: 4.4116
Epoch [2/4], Batch [242/428], Loss: 2.8011
Epoch [2/4], Batch [243/428], Loss: 2.8364
Epoch [2/4], Batch [244/428], Loss: 4.6400
Epoch [2/4], Batch [245/428], Loss: 2.1279
Epoch [2/4], Batch [246/428], Loss: 2.3338
Epoch [2/4], Batch [247/428], Loss: 2.3161
Epoch [2/4], Batch [248/428], Loss: 1.8970
Epoch [2/4], Batch [249/428], Loss: 3.9985
Epoch [2/4], Batch [250/428], Loss: 2.3495
Epoch [2/4], Batch [251/428], Loss: 2.5576
Epoch [2/4], Batch [252/428], Loss: 1.7795
Epoch [2/4], Batch [253/428], Loss: 1.4635
Epoch [2/4], Batch [254/428], Loss: 2.9978
Epoch [2/4], Batch [255/428], Loss: 1.4246
Epoch [2/4], Batch [256/428], Loss: 1.3090
Epoch [2/4], Batch [257/428], Loss: 1.5352
Epoch [2/4], Batch [258/428], Loss: 3.1425
Epoch [2/4], Batch [259/428], Loss: 1.2837
Epoch [2/4], Batch [260/428], Loss: 2.2806
Epoch [2/4], Batch [261/428], Loss: 1.1384
Epoch [2/4], Batch [262/428], Loss: 2.5041
Epoch [2/4], Batch [263/428], Loss: 1.8907
Epoch [2/4], Batch [264/428], Loss: 1.7426
Epoch [2/4], Batch [265/428], Loss: 1.6782
Epoch [2/4], Batch [266/428], Loss: 3.1725
Epoch [2/4], Batch [267/428], Loss: 1.4444
Epoch [2/4], Batch [268/428], Loss: 0.9835
Epoch [2/4], Batch [269/428], Loss: 0.7473
Epoch [2/4], Batch [270/428], Loss: 2.0901
Epoch [2/4], Batch [271/428], Loss: 3.0388
Epoch [2/4], Batch [272/428], Loss: 1.8537
Epoch [2/4], Batch [273/428], Loss: 1.9130
Epoch [2/4], Batch [274/428], Loss: 1.5500
Epoch [2/4], Batch [275/428], Loss: 3.3204
Epoch [2/4], Batch [276/428], Loss: 4.0299
Epoch [2/4], Batch [277/428], Loss: 1.3991
Epoch [2/4], Batch [278/428], Loss: 3.7137
Epoch [2/4], Batch [279/428], Loss: 4.3376
Epoch [2/4], Batch [280/428], Loss: 1.2685
Epoch [2/4], Batch [281/428], Loss: 1.2619
Epoch [2/4], Batch [282/428], Loss: 1.1359
Epoch [2/4], Batch [283/428], Loss: 2.3002
Epoch [2/4], Batch [284/428], Loss: 2.7775
Epoch [2/4], Batch [285/428], Loss: 4.0064
Epoch [2/4], Batch [286/428], Loss: 2.3663
Epoch [2/4], Batch [287/428], Loss: 3.1145
Epoch [2/4], Batch [288/428], Loss: 1.2166
Epoch [2/4], Batch [289/428], Loss: 1.4861
Epoch [2/4], Batch [290/428], Loss: 1.0804
Epoch [2/4], Batch [291/428], Loss: 2.9086
Epoch [2/4], Batch [292/428], Loss: 3.4305
Epoch [2/4], Batch [293/428], Loss: 2.0353
Epoch [2/4], Batch [294/428], Loss: 3.0719
Epoch [2/4], Batch [295/428], Loss: 2.5485
Epoch [2/4], Batch [296/428], Loss: 1.6249
Epoch [2/4], Batch [297/428], Loss: 1.4141
Epoch [2/4], Batch [298/428], Loss: 2.0725
Epoch [2/4], Batch [299/428], Loss: 2.6329
Epoch [2/4], Batch [300/428], Loss: 2.5251
Epoch [2/4], Batch [301/428], Loss: 1.2416
Epoch [2/4], Batch [302/428], Loss: 1.7092
Epoch [2/4], Batch [303/428], Loss: 2.4021
Epoch [2/4], Batch [304/428], Loss: 0.7200
Epoch [2/4], Batch [305/428], Loss: 1.3228
Epoch [2/4], Batch [306/428], Loss: 2.0490
Epoch [2/4], Batch [307/428], Loss: 3.6778
Epoch [2/4], Batch [308/428], Loss: 1.9749
Epoch [2/4], Batch [309/428], Loss: 2.2685
Epoch [2/4], Batch [310/428], Loss: 2.6151
Epoch [2/4], Batch [311/428], Loss: 4.1775
Epoch [2/4], Batch [312/428], Loss: 3.3552
Epoch [2/4], Batch [313/428], Loss: 3.0511
Epoch [2/4], Batch [314/428], Loss: 1.6734
Epoch [2/4], Batch [315/428], Loss: 1.8440
Epoch [2/4], Batch [316/428], Loss: 3.0080
Epoch [2/4], Batch [317/428], Loss: 1.1859
Epoch [2/4], Batch [318/428], Loss: 1.6841
Epoch [2/4], Batch [319/428], Loss: 0.9687
Epoch [2/4], Batch [320/428], Loss: 1.5082
Epoch [2/4], Batch [321/428], Loss: 1.6643
Epoch [2/4], Batch [322/428], Loss: 0.8711
Epoch [2/4], Batch [323/428], Loss: 3.0661
Epoch [2/4], Batch [324/428], Loss: 2.8858
Epoch [2/4], Batch [325/428], Loss: 2.6387
Epoch [2/4], Batch [326/428], Loss: 1.6711
Epoch [2/4], Batch [327/428], Loss: 2.2138
Epoch [2/4], Batch [328/428], Loss: 3.7118
Epoch [2/4], Batch [329/428], Loss: 1.6736
Epoch [2/4], Batch [330/428], Loss: 1.6952
Epoch [2/4], Batch [331/428], Loss: 2.3852
Epoch [2/4], Batch [332/428], Loss: 3.4667
Epoch [2/4], Batch [333/428], Loss: 1.2196
Epoch [2/4], Batch [334/428], Loss: 1.9360
Epoch [2/4], Batch [335/428], Loss: 1.2710
Epoch [2/4], Batch [336/428], Loss: 1.3945
Epoch [2/4], Batch [337/428], Loss: 3.7338
Epoch [2/4], Batch [338/428], Loss: 1.6181
Epoch [2/4], Batch [339/428], Loss: 3.7299
Epoch [2/4], Batch [340/428], Loss: 2.9560
Epoch [2/4], Batch [341/428], Loss: 2.7271
Epoch [2/4], Batch [342/428], Loss: 3.6739
Epoch [2/4], Batch [343/428], Loss: 3.6348
Epoch [2/4], Batch [344/428], Loss: 1.9010
Epoch [2/4], Batch [345/428], Loss: 1.7516
Epoch [2/4], Batch [346/428], Loss: 1.4998
Epoch [2/4], Batch [347/428], Loss: 1.8139
Epoch [2/4], Batch [348/428], Loss: 2.1754
Epoch [2/4], Batch [349/428], Loss: 2.5677
Epoch [2/4], Batch [350/428], Loss: 4.4978
Epoch [2/4], Batch [351/428], Loss: 1.8771
Epoch [2/4], Batch [352/428], Loss: 2.0893
Epoch [2/4], Batch [353/428], Loss: 2.4861
Epoch [2/4], Batch [354/428], Loss: 2.1010
Epoch [2/4], Batch [355/428], Loss: 3.9417
Epoch [2/4], Batch [356/428], Loss: 1.7845
Epoch [2/4], Batch [357/428], Loss: 1.4313
Epoch [2/4], Batch [358/428], Loss: 1.2713
Epoch [2/4], Batch [359/428], Loss: 3.4545
Epoch [2/4], Batch [360/428], Loss: 2.1250
Epoch [2/4], Batch [361/428], Loss: 2.5027
Epoch [2/4], Batch [362/428], Loss: 2.1515
Epoch [2/4], Batch [363/428], Loss: 1.8984
Epoch [2/4], Batch [364/428], Loss: 2.9700
Epoch [2/4], Batch [365/428], Loss: 3.6709
Epoch [2/4], Batch [366/428], Loss: 1.5234
Epoch [2/4], Batch [367/428], Loss: 1.1662
Epoch [2/4], Batch [368/428], Loss: 2.3845
Epoch [2/4], Batch [369/428], Loss: 1.4638
Epoch [2/4], Batch [370/428], Loss: 2.7903
Epoch [2/4], Batch [371/428], Loss: 5.1994
Epoch [2/4], Batch [372/428], Loss: 2.6565
Epoch [2/4], Batch [373/428], Loss: 1.8510
Epoch [2/4], Batch [374/428], Loss: 1.3476
Epoch [2/4], Batch [375/428], Loss: 3.3298
Epoch [2/4], Batch [376/428], Loss: 1.6431
Epoch [2/4], Batch [377/428], Loss: 2.6936
Epoch [2/4], Batch [378/428], Loss: 2.1118
Epoch [2/4], Batch [379/428], Loss: 1.3383
Epoch [2/4], Batch [380/428], Loss: 2.0397
Epoch [2/4], Batch [381/428], Loss: 1.5220
Epoch [2/4], Batch [382/428], Loss: 2.0175
Epoch [2/4], Batch [383/428], Loss: 2.1041
Epoch [2/4], Batch [384/428], Loss: 3.2073
Epoch [2/4], Batch [385/428], Loss: 1.6074
Epoch [2/4], Batch [386/428], Loss: 1.9679
Epoch [2/4], Batch [387/428], Loss: 1.3248
Epoch [2/4], Batch [388/428], Loss: 2.1030
Epoch [2/4], Batch [389/428], Loss: 1.7450
Epoch [2/4], Batch [390/428], Loss: 1.0386
Epoch [2/4], Batch [391/428], Loss: 2.4268
Epoch [2/4], Batch [392/428], Loss: 2.7851
Epoch [2/4], Batch [393/428], Loss: 2.2296
Epoch [2/4], Batch [394/428], Loss: 1.5833
Epoch [2/4], Batch [395/428], Loss: 1.2843
Epoch [2/4], Batch [396/428], Loss: 2.6454
Epoch [2/4], Batch [397/428], Loss: 2.0795
Epoch [2/4], Batch [398/428], Loss: 3.2933
Epoch [2/4], Batch [399/428], Loss: 1.2736
Epoch [2/4], Batch [400/428], Loss: 0.8901
Epoch [2/4], Batch [401/428], Loss: 2.7897
Epoch [2/4], Batch [402/428], Loss: 2.7015
Epoch [2/4], Batch [403/428], Loss: 1.8398
Epoch [2/4], Batch [404/428], Loss: 1.8400
Epoch [2/4], Batch [405/428], Loss: 2.2910
Epoch [2/4], Batch [406/428], Loss: 1.6810
Epoch [2/4], Batch [407/428], Loss: 1.8906
Epoch [2/4], Batch [408/428], Loss: 1.6046
Epoch [2/4], Batch [409/428], Loss: 2.4247
Epoch [2/4], Batch [410/428], Loss: 3.1132
Epoch [2/4], Batch [411/428], Loss: 3.2973
Epoch [2/4], Batch [412/428], Loss: 4.0015
Epoch [2/4], Batch [413/428], Loss: 3.4047
Epoch [2/4], Batch [414/428], Loss: 1.9478
Epoch [2/4], Batch [415/428], Loss: 2.9345
Epoch [2/4], Batch [416/428], Loss: 3.0040
Epoch [2/4], Batch [417/428], Loss: 3.2440
Epoch [2/4], Batch [418/428], Loss: 3.1507
Epoch [2/4], Batch [419/428], Loss: 2.4472
Epoch [2/4], Batch [420/428], Loss: 1.1274
Epoch [2/4], Batch [421/428], Loss: 2.1519
Epoch [2/4], Batch [422/428], Loss: 1.9886
Epoch [2/4], Batch [423/428], Loss: 1.1012
Epoch [2/4], Batch [424/428], Loss: 2.9881
Epoch [2/4], Batch [425/428], Loss: 1.6276
Epoch [2/4], Batch [426/428], Loss: 3.0179
Epoch [2/4], Batch [427/428], Loss: 3.6379
Epoch [2/4], Batch [428/428], Loss: 1.6524
Epoch [2] Training Time: 130.18 seconds
Epoch [2/4], Average Loss: 2.4023, Training Accuracy: 0.1472
Epoch [2], Validation Loss: 2.2971, Validation Accuracy: 0.1468
Epoch [2] Validation Time: 7.40 seconds
--------------------------------------------------
Epoch 3: Unfreezing feature extractor layers...
Epoch [3/4], Batch [1/428], Loss: 1.6361
Epoch [3/4], Batch [2/428], Loss: 1.5260
Epoch [3/4], Batch [3/428], Loss: 2.3043
Epoch [3/4], Batch [4/428], Loss: 0.9919
Epoch [3/4], Batch [5/428], Loss: 2.1422
Epoch [3/4], Batch [6/428], Loss: 3.7671
Epoch [3/4], Batch [7/428], Loss: 3.9934
Epoch [3/4], Batch [8/428], Loss: 3.4141
Epoch [3/4], Batch [9/428], Loss: 2.3801
Epoch [3/4], Batch [10/428], Loss: 0.6544
Epoch [3/4], Batch [11/428], Loss: 2.7192
Epoch [3/4], Batch [12/428], Loss: 1.6127
Epoch [3/4], Batch [13/428], Loss: 1.4472
Epoch [3/4], Batch [14/428], Loss: 2.2151
Epoch [3/4], Batch [15/428], Loss: 1.7993
Epoch [3/4], Batch [16/428], Loss: 1.7964
Epoch [3/4], Batch [17/428], Loss: 0.7791
Epoch [3/4], Batch [18/428], Loss: 2.2456
Epoch [3/4], Batch [19/428], Loss: 2.7511
Epoch [3/4], Batch [20/428], Loss: 1.2582
Epoch [3/4], Batch [21/428], Loss: 0.9499
Epoch [3/4], Batch [22/428], Loss: 2.2718
Epoch [3/4], Batch [23/428], Loss: 1.5169
Epoch [3/4], Batch [24/428], Loss: 1.8998
Epoch [3/4], Batch [25/428], Loss: 4.2048
Epoch [3/4], Batch [26/428], Loss: 1.9701
Epoch [3/4], Batch [27/428], Loss: 0.3786
Epoch [3/4], Batch [28/428], Loss: 1.8839
Epoch [3/4], Batch [29/428], Loss: 0.6822
Epoch [3/4], Batch [30/428], Loss: 0.5498
Epoch [3/4], Batch [31/428], Loss: 2.8826
Epoch [3/4], Batch [32/428], Loss: 1.4107
Epoch [3/4], Batch [33/428], Loss: 1.6659
Epoch [3/4], Batch [34/428], Loss: 3.8433
Epoch [3/4], Batch [35/428], Loss: 1.3558
Epoch [3/4], Batch [36/428], Loss: 1.5295
Epoch [3/4], Batch [37/428], Loss: 3.3401
Epoch [3/4], Batch [38/428], Loss: 0.7789
Epoch [3/4], Batch [39/428], Loss: 1.4735
Epoch [3/4], Batch [40/428], Loss: 0.8880
Epoch [3/4], Batch [41/428], Loss: 1.0898
Epoch [3/4], Batch [42/428], Loss: 1.0337
Epoch [3/4], Batch [43/428], Loss: 2.5083
Epoch [3/4], Batch [44/428], Loss: 0.4230
Epoch [3/4], Batch [45/428], Loss: 0.7140
Epoch [3/4], Batch [46/428], Loss: 1.1018
Epoch [3/4], Batch [47/428], Loss: 1.6238
Epoch [3/4], Batch [48/428], Loss: 1.7105
Epoch [3/4], Batch [49/428], Loss: 0.7435
Epoch [3/4], Batch [50/428], Loss: 4.3464
Epoch [3/4], Batch [51/428], Loss: 2.3458
Epoch [3/4], Batch [52/428], Loss: 0.5714
Epoch [3/4], Batch [53/428], Loss: 0.3795
Epoch [3/4], Batch [54/428], Loss: 0.4024
Epoch [3/4], Batch [55/428], Loss: 0.2039
Epoch [3/4], Batch [56/428], Loss: 0.4830
Epoch [3/4], Batch [57/428], Loss: 0.1229
Epoch [3/4], Batch [58/428], Loss: 0.2530
Epoch [3/4], Batch [59/428], Loss: 2.1745
Epoch [3/4], Batch [60/428], Loss: 0.3582
Epoch [3/4], Batch [61/428], Loss: 1.9787
Epoch [3/4], Batch [62/428], Loss: 2.2883
Epoch [3/4], Batch [63/428], Loss: 0.1673
Epoch [3/4], Batch [64/428], Loss: 1.6448
Epoch [3/4], Batch [65/428], Loss: 0.1539
Epoch [3/4], Batch [66/428], Loss: 3.2972
Epoch [3/4], Batch [67/428], Loss: 2.8037
Epoch [3/4], Batch [68/428], Loss: 3.1544
Epoch [3/4], Batch [69/428], Loss: 2.0952
Epoch [3/4], Batch [70/428], Loss: 0.0806
Epoch [3/4], Batch [71/428], Loss: 0.1777
Epoch [3/4], Batch [72/428], Loss: 2.0154
Epoch [3/4], Batch [73/428], Loss: 3.3784
Epoch [3/4], Batch [74/428], Loss: 0.0540
Epoch [3/4], Batch [75/428], Loss: 0.2681
Epoch [3/4], Batch [76/428], Loss: 2.5007
Epoch [3/4], Batch [77/428], Loss: 3.4598
Epoch [3/4], Batch [78/428], Loss: 0.1353
Epoch [3/4], Batch [79/428], Loss: 0.0339
Epoch [3/4], Batch [80/428], Loss: 4.0458
Epoch [3/4], Batch [81/428], Loss: 1.6710
Epoch [3/4], Batch [82/428], Loss: 0.6212
Epoch [3/4], Batch [83/428], Loss: 0.0442
Epoch [3/4], Batch [84/428], Loss: 2.6963
Epoch [3/4], Batch [85/428], Loss: 2.6981
Epoch [3/4], Batch [86/428], Loss: 0.1329
Epoch [3/4], Batch [87/428], Loss: 3.5587
Epoch [3/4], Batch [88/428], Loss: 3.9910
Epoch [3/4], Batch [89/428], Loss: 1.0772
Epoch [3/4], Batch [90/428], Loss: 2.9819
Epoch [3/4], Batch [91/428], Loss: 0.1229
Epoch [3/4], Batch [92/428], Loss: 1.9975
Epoch [3/4], Batch [93/428], Loss: 1.9901
Epoch [3/4], Batch [94/428], Loss: 0.0626
Epoch [3/4], Batch [95/428], Loss: 0.0298
Epoch [3/4], Batch [96/428], Loss: 2.0391
Epoch [3/4], Batch [97/428], Loss: 2.5559
Epoch [3/4], Batch [98/428], Loss: 0.0179
Epoch [3/4], Batch [99/428], Loss: 0.0118
Epoch [3/4], Batch [100/428], Loss: 1.2554
Epoch [3/4], Batch [101/428], Loss: 2.4178
Epoch [3/4], Batch [102/428], Loss: 2.6391
Epoch [3/4], Batch [103/428], Loss: 1.5058
Epoch [3/4], Batch [104/428], Loss: 0.0112
Epoch [3/4], Batch [105/428], Loss: 0.1922
Epoch [3/4], Batch [106/428], Loss: 0.4048
Epoch [3/4], Batch [107/428], Loss: 0.6446
Epoch [3/4], Batch [108/428], Loss: 0.6394
Epoch [3/4], Batch [109/428], Loss: 0.0961
Epoch [3/4], Batch [110/428], Loss: 2.6748
Epoch [3/4], Batch [111/428], Loss: 6.0357
Epoch [3/4], Batch [112/428], Loss: 0.0583
Epoch [3/4], Batch [113/428], Loss: 0.1505
Epoch [3/4], Batch [114/428], Loss: 0.7373
Epoch [3/4], Batch [115/428], Loss: 1.3905
Epoch [3/4], Batch [116/428], Loss: 0.7219
Epoch [3/4], Batch [117/428], Loss: 0.7398
Epoch [3/4], Batch [118/428], Loss: 0.8391
Epoch [3/4], Batch [119/428], Loss: 0.0057
Epoch [3/4], Batch [120/428], Loss: 1.0764
Epoch [3/4], Batch [121/428], Loss: 1.1667
Epoch [3/4], Batch [122/428], Loss: 2.4630
Epoch [3/4], Batch [123/428], Loss: 1.4600
Epoch [3/4], Batch [124/428], Loss: 2.0502
Epoch [3/4], Batch [125/428], Loss: 0.0089
Epoch [3/4], Batch [126/428], Loss: 0.0975
Epoch [3/4], Batch [127/428], Loss: 0.0937
Epoch [3/4], Batch [128/428], Loss: 3.6722
Epoch [3/4], Batch [129/428], Loss: 3.6141
Epoch [3/4], Batch [130/428], Loss: 1.0359
Epoch [3/4], Batch [131/428], Loss: 4.2392
Epoch [3/4], Batch [132/428], Loss: 1.9604
Epoch [3/4], Batch [133/428], Loss: 3.1146
Epoch [3/4], Batch [134/428], Loss: 0.0050
Epoch [3/4], Batch [135/428], Loss: 0.0039
Epoch [3/4], Batch [136/428], Loss: 1.0071
Epoch [3/4], Batch [137/428], Loss: 3.5851
Epoch [3/4], Batch [138/428], Loss: 0.1591
Epoch [3/4], Batch [139/428], Loss: 0.0465
Epoch [3/4], Batch [140/428], Loss: 0.6459
Epoch [3/4], Batch [141/428], Loss: 2.4895
Epoch [3/4], Batch [142/428], Loss: 1.5533
Epoch [3/4], Batch [143/428], Loss: 0.0025
Epoch [3/4], Batch [144/428], Loss: 4.4031
Epoch [3/4], Batch [145/428], Loss: 2.8844
Epoch [3/4], Batch [146/428], Loss: 1.9185
Epoch [3/4], Batch [147/428], Loss: 1.0243
Epoch [3/4], Batch [148/428], Loss: 2.0302
Epoch [3/4], Batch [149/428], Loss: 0.0168
Epoch [3/4], Batch [150/428], Loss: 4.9811
Epoch [3/4], Batch [151/428], Loss: 3.5280
Epoch [3/4], Batch [152/428], Loss: 1.9861
Epoch [3/4], Batch [153/428], Loss: 0.0368
Epoch [3/4], Batch [154/428], Loss: 1.4711
Epoch [3/4], Batch [155/428], Loss: 0.0701
Epoch [3/4], Batch [156/428], Loss: 1.4834
Epoch [3/4], Batch [157/428], Loss: 0.0031
Epoch [3/4], Batch [158/428], Loss: 2.1680
Epoch [3/4], Batch [159/428], Loss: 0.0025
Epoch [3/4], Batch [160/428], Loss: 1.7979
Epoch [3/4], Batch [161/428], Loss: 0.0251
Epoch [3/4], Batch [162/428], Loss: 0.5380
Epoch [3/4], Batch [163/428], Loss: 0.0021
Epoch [3/4], Batch [164/428], Loss: 0.0024
Epoch [3/4], Batch [165/428], Loss: 3.8667
Epoch [3/4], Batch [166/428], Loss: 0.9784
Epoch [3/4], Batch [167/428], Loss: 2.3463
Epoch [3/4], Batch [168/428], Loss: 1.4841
Epoch [3/4], Batch [169/428], Loss: 1.6216
Epoch [3/4], Batch [170/428], Loss: 1.8651
Epoch [3/4], Batch [171/428], Loss: 1.8037
Epoch [3/4], Batch [172/428], Loss: 1.7394
Epoch [3/4], Batch [173/428], Loss: 0.0743
Epoch [3/4], Batch [174/428], Loss: 0.7835
Epoch [3/4], Batch [175/428], Loss: 1.1911
Epoch [3/4], Batch [176/428], Loss: 0.7282
Epoch [3/4], Batch [177/428], Loss: 0.0381
Epoch [3/4], Batch [178/428], Loss: 2.4591
Epoch [3/4], Batch [179/428], Loss: 0.2847
Epoch [3/4], Batch [180/428], Loss: 0.0030
Epoch [3/4], Batch [181/428], Loss: 0.0034
Epoch [3/4], Batch [182/428], Loss: 0.0011
Epoch [3/4], Batch [183/428], Loss: 0.6748
Epoch [3/4], Batch [184/428], Loss: 0.0743
Epoch [3/4], Batch [185/428], Loss: 2.2513
Epoch [3/4], Batch [186/428], Loss: 0.0330
Epoch [3/4], Batch [187/428], Loss: 1.0961
Epoch [3/4], Batch [188/428], Loss: 0.0021
Epoch [3/4], Batch [189/428], Loss: 1.6125
Epoch [3/4], Batch [190/428], Loss: 0.5613
Epoch [3/4], Batch [191/428], Loss: 1.1008
Epoch [3/4], Batch [192/428], Loss: 0.5087
Epoch [3/4], Batch [193/428], Loss: 0.0014
Epoch [3/4], Batch [194/428], Loss: 0.4466
Epoch [3/4], Batch [195/428], Loss: 0.0013
Epoch [3/4], Batch [196/428], Loss: 2.0292
Epoch [3/4], Batch [197/428], Loss: 0.9033
Epoch [3/4], Batch [198/428], Loss: 0.4989
Epoch [3/4], Batch [199/428], Loss: 0.0031
Epoch [3/4], Batch [200/428], Loss: 0.2424
Epoch [3/4], Batch [201/428], Loss: 0.7261
Epoch [3/4], Batch [202/428], Loss: 0.0010
Epoch [3/4], Batch [203/428], Loss: 3.4040
Epoch [3/4], Batch [204/428], Loss: 0.2545
Epoch [3/4], Batch [205/428], Loss: 7.0717
Epoch [3/4], Batch [206/428], Loss: 0.0010
Epoch [3/4], Batch [207/428], Loss: 1.3500
Epoch [3/4], Batch [208/428], Loss: 0.0009
Epoch [3/4], Batch [209/428], Loss: 6.5357
Epoch [3/4], Batch [210/428], Loss: 2.4230
Epoch [3/4], Batch [211/428], Loss: 0.0009
Epoch [3/4], Batch [212/428], Loss: 4.3581
Epoch [3/4], Batch [213/428], Loss: 0.3543
Epoch [3/4], Batch [214/428], Loss: 2.6012
Epoch [3/4], Batch [215/428], Loss: 0.0018
Epoch [3/4], Batch [216/428], Loss: 4.6594
Epoch [3/4], Batch [217/428], Loss: 3.5872
Epoch [3/4], Batch [218/428], Loss: 1.0234
Epoch [3/4], Batch [219/428], Loss: 0.0009
Epoch [3/4], Batch [220/428], Loss: 1.1012
Epoch [3/4], Batch [221/428], Loss: 1.7793
Epoch [3/4], Batch [222/428], Loss: 0.3714
Epoch [3/4], Batch [223/428], Loss: 1.9017
Epoch [3/4], Batch [224/428], Loss: 2.4873
Epoch [3/4], Batch [225/428], Loss: 0.3660
Epoch [3/4], Batch [226/428], Loss: 2.5462
Epoch [3/4], Batch [227/428], Loss: 0.0388
Epoch [3/4], Batch [228/428], Loss: 1.1978
Epoch [3/4], Batch [229/428], Loss: 0.8206
Epoch [3/4], Batch [230/428], Loss: 0.5456
Epoch [3/4], Batch [231/428], Loss: 0.6792[INFO 06-13 18:16:31] ax.service.ax_client: Completed trial 3 with data: {'objective': (np.float64(-0.723158), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 18:16:31] ax.service.ax_client: Generated new trial 4 with parameters {'lr': 1e-06, 'num_epochs': 7, 'unfreeze_epoch': 0, 'max_length': 64000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [3/4], Batch [232/428], Loss: 0.9855
Epoch [3/4], Batch [233/428], Loss: 0.2948
Epoch [3/4], Batch [234/428], Loss: 0.2023
Epoch [3/4], Batch [235/428], Loss: 0.0025
Epoch [3/4], Batch [236/428], Loss: 2.0144
Epoch [3/4], Batch [237/428], Loss: 2.0402
Epoch [3/4], Batch [238/428], Loss: 0.1790
Epoch [3/4], Batch [239/428], Loss: 0.1099
Epoch [3/4], Batch [240/428], Loss: 0.9296
Epoch [3/4], Batch [241/428], Loss: 0.6001
Epoch [3/4], Batch [242/428], Loss: 0.5656
Epoch [3/4], Batch [243/428], Loss: 1.0526
Epoch [3/4], Batch [244/428], Loss: 1.7518
Epoch [3/4], Batch [245/428], Loss: 1.1771
Epoch [3/4], Batch [246/428], Loss: 1.4420
Epoch [3/4], Batch [247/428], Loss: 0.8820
Epoch [3/4], Batch [248/428], Loss: 0.1351
Epoch [3/4], Batch [249/428], Loss: 0.9385
Epoch [3/4], Batch [250/428], Loss: 0.5482
Epoch [3/4], Batch [251/428], Loss: 2.4116
Epoch [3/4], Batch [252/428], Loss: 1.1170
Epoch [3/4], Batch [253/428], Loss: 0.1670
Epoch [3/4], Batch [254/428], Loss: 4.3524
Epoch [3/4], Batch [255/428], Loss: 0.6739
Epoch [3/4], Batch [256/428], Loss: 0.4848
Epoch [3/4], Batch [257/428], Loss: 0.1189
Epoch [3/4], Batch [258/428], Loss: 1.7102
Epoch [3/4], Batch [259/428], Loss: 2.4536
Epoch [3/4], Batch [260/428], Loss: 0.7646
Epoch [3/4], Batch [261/428], Loss: 0.9202
Epoch [3/4], Batch [262/428], Loss: 0.8413
Epoch [3/4], Batch [263/428], Loss: 0.6050
Epoch [3/4], Batch [264/428], Loss: 0.5144
Epoch [3/4], Batch [265/428], Loss: 0.1037
Epoch [3/4], Batch [266/428], Loss: 0.0855
Epoch [3/4], Batch [267/428], Loss: 0.8726
Epoch [3/4], Batch [268/428], Loss: 1.5515
Epoch [3/4], Batch [269/428], Loss: 0.1402
Epoch [3/4], Batch [270/428], Loss: 2.2216
Epoch [3/4], Batch [271/428], Loss: 1.5640
Epoch [3/4], Batch [272/428], Loss: 0.0049
Epoch [3/4], Batch [273/428], Loss: 1.3860
Epoch [3/4], Batch [274/428], Loss: 0.2052
Epoch [3/4], Batch [275/428], Loss: 0.4188
Epoch [3/4], Batch [276/428], Loss: 0.0027
Epoch [3/4], Batch [277/428], Loss: 1.6156
Epoch [3/4], Batch [278/428], Loss: 2.1611
Epoch [3/4], Batch [279/428], Loss: 0.0018
Epoch [3/4], Batch [280/428], Loss: 0.4558
Epoch [3/4], Batch [281/428], Loss: 2.6886
Epoch [3/4], Batch [282/428], Loss: 0.0016
Epoch [3/4], Batch [283/428], Loss: 0.2096
Epoch [3/4], Batch [284/428], Loss: 0.3881
Epoch [3/4], Batch [285/428], Loss: 0.7809
Epoch [3/4], Batch [286/428], Loss: 2.6863
Epoch [3/4], Batch [287/428], Loss: 0.3492
Epoch [3/4], Batch [288/428], Loss: 1.4696
Epoch [3/4], Batch [289/428], Loss: 0.0231
Epoch [3/4], Batch [290/428], Loss: 1.4785
Epoch [3/4], Batch [291/428], Loss: 0.0012
Epoch [3/4], Batch [292/428], Loss: 7.6117
Epoch [3/4], Batch [293/428], Loss: 3.4299
Epoch [3/4], Batch [294/428], Loss: 2.5331
Epoch [3/4], Batch [295/428], Loss: 0.0019
Epoch [3/4], Batch [296/428], Loss: 0.4898
Epoch [3/4], Batch [297/428], Loss: 3.4248
Epoch [3/4], Batch [298/428], Loss: 0.0772
Epoch [3/4], Batch [299/428], Loss: 0.8243
Epoch [3/4], Batch [300/428], Loss: 1.2372
Epoch [3/4], Batch [301/428], Loss: 0.0488
Epoch [3/4], Batch [302/428], Loss: 0.0022
Epoch [3/4], Batch [303/428], Loss: 0.0013
Epoch [3/4], Batch [304/428], Loss: 3.5518
Epoch [3/4], Batch [305/428], Loss: 4.1447
Epoch [3/4], Batch [306/428], Loss: 0.1757
Epoch [3/4], Batch [307/428], Loss: 1.6563
Epoch [3/4], Batch [308/428], Loss: 1.6050
Epoch [3/4], Batch [309/428], Loss: 0.0069
Epoch [3/4], Batch [310/428], Loss: 3.0021
Epoch [3/4], Batch [311/428], Loss: 0.0017
Epoch [3/4], Batch [312/428], Loss: 2.1971
Epoch [3/4], Batch [313/428], Loss: 1.8392
Epoch [3/4], Batch [314/428], Loss: 0.9388
Epoch [3/4], Batch [315/428], Loss: 0.3107
Epoch [3/4], Batch [316/428], Loss: 0.0124
Epoch [3/4], Batch [317/428], Loss: 0.0031
Epoch [3/4], Batch [318/428], Loss: 0.0018
Epoch [3/4], Batch [319/428], Loss: 0.0268
Epoch [3/4], Batch [320/428], Loss: 0.5259
Epoch [3/4], Batch [321/428], Loss: 0.2593
Epoch [3/4], Batch [322/428], Loss: 1.6724
Epoch [3/4], Batch [323/428], Loss: 0.2582
Epoch [3/4], Batch [324/428], Loss: 6.6507
Epoch [3/4], Batch [325/428], Loss: 0.0008
Epoch [3/4], Batch [326/428], Loss: 0.0006
Epoch [3/4], Batch [327/428], Loss: 3.1232
Epoch [3/4], Batch [328/428], Loss: 0.0014
Epoch [3/4], Batch [329/428], Loss: 0.5559
Epoch [3/4], Batch [330/428], Loss: 0.2894
Epoch [3/4], Batch [331/428], Loss: 4.1341
Epoch [3/4], Batch [332/428], Loss: 0.0004
Epoch [3/4], Batch [333/428], Loss: 0.0004
Epoch [3/4], Batch [334/428], Loss: 0.3154
Epoch [3/4], Batch [335/428], Loss: 1.1176
Epoch [3/4], Batch [336/428], Loss: 0.0004
Epoch [3/4], Batch [337/428], Loss: 0.0205
Epoch [3/4], Batch [338/428], Loss: 0.1229
Epoch [3/4], Batch [339/428], Loss: 0.0779
Epoch [3/4], Batch [340/428], Loss: 0.0012
Epoch [3/4], Batch [341/428], Loss: 1.3679
Epoch [3/4], Batch [342/428], Loss: 0.0005
Epoch [3/4], Batch [343/428], Loss: 0.1177
Epoch [3/4], Batch [344/428], Loss: 1.4098
Epoch [3/4], Batch [345/428], Loss: 0.8155
Epoch [3/4], Batch [346/428], Loss: 1.9290
Epoch [3/4], Batch [347/428], Loss: 0.0003
Epoch [3/4], Batch [348/428], Loss: 0.0320
Epoch [3/4], Batch [349/428], Loss: 0.0219
Epoch [3/4], Batch [350/428], Loss: 0.0171
Epoch [3/4], Batch [351/428], Loss: 0.0006
Epoch [3/4], Batch [352/428], Loss: 0.0003
Epoch [3/4], Batch [353/428], Loss: 0.2546
Epoch [3/4], Batch [354/428], Loss: 0.0626
Epoch [3/4], Batch [355/428], Loss: 0.0450
Epoch [3/4], Batch [356/428], Loss: 1.3229
Epoch [3/4], Batch [357/428], Loss: 0.1455
Epoch [3/4], Batch [358/428], Loss: 0.0004
Epoch [3/4], Batch [359/428], Loss: 0.0004
Epoch [3/4], Batch [360/428], Loss: 0.5903
Epoch [3/4], Batch [361/428], Loss: 3.0061
Epoch [3/4], Batch [362/428], Loss: 0.0003
Epoch [3/4], Batch [363/428], Loss: 0.4240
Epoch [3/4], Batch [364/428], Loss: 6.8198
Epoch [3/4], Batch [365/428], Loss: 0.2828
Epoch [3/4], Batch [366/428], Loss: 0.0002
Epoch [3/4], Batch [367/428], Loss: 0.8996
Epoch [3/4], Batch [368/428], Loss: 0.0001
Epoch [3/4], Batch [369/428], Loss: 0.0008
Epoch [3/4], Batch [370/428], Loss: 0.0003
Epoch [3/4], Batch [371/428], Loss: 0.9118
Epoch [3/4], Batch [372/428], Loss: 0.0022
Epoch [3/4], Batch [373/428], Loss: 0.0002
Epoch [3/4], Batch [374/428], Loss: 2.9584
Epoch [3/4], Batch [375/428], Loss: 0.0003
Epoch [3/4], Batch [376/428], Loss: 4.3064
Epoch [3/4], Batch [377/428], Loss: 0.0002
Epoch [3/4], Batch [378/428], Loss: 0.0028
Epoch [3/4], Batch [379/428], Loss: 0.0154
Epoch [3/4], Batch [380/428], Loss: 0.0016
Epoch [3/4], Batch [381/428], Loss: 4.0815
Epoch [3/4], Batch [382/428], Loss: 0.7217
Epoch [3/4], Batch [383/428], Loss: 0.0003
Epoch [3/4], Batch [384/428], Loss: 0.0002
Epoch [3/4], Batch [385/428], Loss: 0.6489
Epoch [3/4], Batch [386/428], Loss: 0.0001
Epoch [3/4], Batch [387/428], Loss: 0.0942
Epoch [3/4], Batch [388/428], Loss: 0.6068
Epoch [3/4], Batch [389/428], Loss: 1.5153
Epoch [3/4], Batch [390/428], Loss: 0.0060
Epoch [3/4], Batch [391/428], Loss: 3.9339
Epoch [3/4], Batch [392/428], Loss: 0.2877
Epoch [3/4], Batch [393/428], Loss: 0.0168
Epoch [3/4], Batch [394/428], Loss: 1.1604
Epoch [3/4], Batch [395/428], Loss: 0.3439
Epoch [3/4], Batch [396/428], Loss: 0.0039
Epoch [3/4], Batch [397/428], Loss: 0.0176
Epoch [3/4], Batch [398/428], Loss: 0.0002
Epoch [3/4], Batch [399/428], Loss: 1.9542
Epoch [3/4], Batch [400/428], Loss: 0.0157
Epoch [3/4], Batch [401/428], Loss: 2.2583
Epoch [3/4], Batch [402/428], Loss: 3.6861
Epoch [3/4], Batch [403/428], Loss: 0.0028
Epoch [3/4], Batch [404/428], Loss: 0.0001
Epoch [3/4], Batch [405/428], Loss: 0.1097
Epoch [3/4], Batch [406/428], Loss: 0.0383
Epoch [3/4], Batch [407/428], Loss: 4.4218
Epoch [3/4], Batch [408/428], Loss: 0.0004
Epoch [3/4], Batch [409/428], Loss: 0.0243
Epoch [3/4], Batch [410/428], Loss: 6.1146
Epoch [3/4], Batch [411/428], Loss: 4.1613
Epoch [3/4], Batch [412/428], Loss: 0.0211
Epoch [3/4], Batch [413/428], Loss: 0.0245
Epoch [3/4], Batch [414/428], Loss: 2.8506
Epoch [3/4], Batch [415/428], Loss: 1.4404
Epoch [3/4], Batch [416/428], Loss: 0.0161
Epoch [3/4], Batch [417/428], Loss: 0.0002
Epoch [3/4], Batch [418/428], Loss: 0.1888
Epoch [3/4], Batch [419/428], Loss: 0.0437
Epoch [3/4], Batch [420/428], Loss: 2.5164
Epoch [3/4], Batch [421/428], Loss: 0.0002
Epoch [3/4], Batch [422/428], Loss: 0.0387
Epoch [3/4], Batch [423/428], Loss: 0.0048
Epoch [3/4], Batch [424/428], Loss: 8.1926
Epoch [3/4], Batch [425/428], Loss: 0.0477
Epoch [3/4], Batch [426/428], Loss: 0.2756
Epoch [3/4], Batch [427/428], Loss: 0.2010
Epoch [3/4], Batch [428/428], Loss: 0.0048
Epoch [3] Training Time: 213.57 seconds
Epoch [3/4], Average Loss: 1.2386, Training Accuracy: 0.5794
Epoch [3], Validation Loss: 1.1410, Validation Accuracy: 0.6938
Epoch [3] Validation Time: 7.36 seconds
--------------------------------------------------
Epoch [4/4], Batch [1/428], Loss: 0.3022
Epoch [4/4], Batch [2/428], Loss: 0.1601
Epoch [4/4], Batch [3/428], Loss: 0.5441
Epoch [4/4], Batch [4/428], Loss: 0.0001
Epoch [4/4], Batch [5/428], Loss: 0.8871
Epoch [4/4], Batch [6/428], Loss: 1.3916
Epoch [4/4], Batch [7/428], Loss: 0.4180
Epoch [4/4], Batch [8/428], Loss: 0.2896
Epoch [4/4], Batch [9/428], Loss: 0.1209
Epoch [4/4], Batch [10/428], Loss: 0.0003
Epoch [4/4], Batch [11/428], Loss: 1.9572
Epoch [4/4], Batch [12/428], Loss: 0.1286
Epoch [4/4], Batch [13/428], Loss: 0.0001
Epoch [4/4], Batch [14/428], Loss: 0.0047
Epoch [4/4], Batch [15/428], Loss: 0.6287
Epoch [4/4], Batch [16/428], Loss: 0.7086
Epoch [4/4], Batch [17/428], Loss: 0.0003
Epoch [4/4], Batch [18/428], Loss: 0.0002
Epoch [4/4], Batch [19/428], Loss: 0.0968
Epoch [4/4], Batch [20/428], Loss: 0.0287
Epoch [4/4], Batch [21/428], Loss: 0.2828
Epoch [4/4], Batch [22/428], Loss: 0.0001
Epoch [4/4], Batch [23/428], Loss: 0.0026
Epoch [4/4], Batch [24/428], Loss: 0.0056
Epoch [4/4], Batch [25/428], Loss: 0.0002
Epoch [4/4], Batch [26/428], Loss: 0.0002
Epoch [4/4], Batch [27/428], Loss: 6.1765
Epoch [4/4], Batch [28/428], Loss: 0.3168
Epoch [4/4], Batch [29/428], Loss: 0.0116
Epoch [4/4], Batch [30/428], Loss: 0.0005
Epoch [4/4], Batch [31/428], Loss: 0.0003
Epoch [4/4], Batch [32/428], Loss: 6.8050
Epoch [4/4], Batch [33/428], Loss: 0.0001
Epoch [4/4], Batch [34/428], Loss: 0.6029
Epoch [4/4], Batch [35/428], Loss: 0.2240
Epoch [4/4], Batch [36/428], Loss: 0.0262
Epoch [4/4], Batch [37/428], Loss: 0.0017
Epoch [4/4], Batch [38/428], Loss: 7.9927
Epoch [4/4], Batch [39/428], Loss: 0.0001
Epoch [4/4], Batch [40/428], Loss: 5.4539
Epoch [4/4], Batch [41/428], Loss: 1.1785
Epoch [4/4], Batch [42/428], Loss: 0.0015
Epoch [4/4], Batch [43/428], Loss: 0.0062
Epoch [4/4], Batch [44/428], Loss: 0.0011
Epoch [4/4], Batch [45/428], Loss: 0.1037
Epoch [4/4], Batch [46/428], Loss: 0.0052
Epoch [4/4], Batch [47/428], Loss: 0.0002
Epoch [4/4], Batch [48/428], Loss: 0.0025
Epoch [4/4], Batch [49/428], Loss: 1.4040
Epoch [4/4], Batch [50/428], Loss: 0.0540
Epoch [4/4], Batch [51/428], Loss: 0.0029
Epoch [4/4], Batch [52/428], Loss: 0.3777
Epoch [4/4], Batch [53/428], Loss: 0.0426
Epoch [4/4], Batch [54/428], Loss: 0.2245
Epoch [4/4], Batch [55/428], Loss: 0.0002
Epoch [4/4], Batch [56/428], Loss: 0.7061
Epoch [4/4], Batch [57/428], Loss: 0.4611
Epoch [4/4], Batch [58/428], Loss: 0.0350
Epoch [4/4], Batch [59/428], Loss: 7.0715
Epoch [4/4], Batch [60/428], Loss: 0.2549
Epoch [4/4], Batch [61/428], Loss: 0.0002
Epoch [4/4], Batch [62/428], Loss: 1.1174
Epoch [4/4], Batch [63/428], Loss: 0.8844
Epoch [4/4], Batch [64/428], Loss: 0.1778
Epoch [4/4], Batch [65/428], Loss: 0.0002
Epoch [4/4], Batch [66/428], Loss: 0.1741
Epoch [4/4], Batch [67/428], Loss: 0.1154
Epoch [4/4], Batch [68/428], Loss: 0.0044
Epoch [4/4], Batch [69/428], Loss: 0.0016
Epoch [4/4], Batch [70/428], Loss: 0.0004
Epoch [4/4], Batch [71/428], Loss: 0.4320
Epoch [4/4], Batch [72/428], Loss: 0.0642
Epoch [4/4], Batch [73/428], Loss: 0.0003
Epoch [4/4], Batch [74/428], Loss: 0.0042
Epoch [4/4], Batch [75/428], Loss: 2.0730
Epoch [4/4], Batch [76/428], Loss: 0.0018
Epoch [4/4], Batch [77/428], Loss: 0.0103
Epoch [4/4], Batch [78/428], Loss: 0.0002
Epoch [4/4], Batch [79/428], Loss: 0.0083
Epoch [4/4], Batch [80/428], Loss: 0.0089
Epoch [4/4], Batch [81/428], Loss: 0.0005
Epoch [4/4], Batch [82/428], Loss: 0.0029
Epoch [4/4], Batch [83/428], Loss: 0.0002
Epoch [4/4], Batch [84/428], Loss: 0.0244
Epoch [4/4], Batch [85/428], Loss: 0.0469
Epoch [4/4], Batch [86/428], Loss: 0.0002
Epoch [4/4], Batch [87/428], Loss: 0.0002
Epoch [4/4], Batch [88/428], Loss: 0.0003
Epoch [4/4], Batch [89/428], Loss: 0.0008
Epoch [4/4], Batch [90/428], Loss: 0.0971
Epoch [4/4], Batch [91/428], Loss: 2.1911
Epoch [4/4], Batch [92/428], Loss: 0.0002
Epoch [4/4], Batch [93/428], Loss: 0.0002
Epoch [4/4], Batch [94/428], Loss: 0.1800
Epoch [4/4], Batch [95/428], Loss: 0.0004
Epoch [4/4], Batch [96/428], Loss: 0.0002
Epoch [4/4], Batch [97/428], Loss: 1.6548
Epoch [4/4], Batch [98/428], Loss: 1.4377
Epoch [4/4], Batch [99/428], Loss: 0.0002
Epoch [4/4], Batch [100/428], Loss: 1.6210
Epoch [4/4], Batch [101/428], Loss: 0.0001
Epoch [4/4], Batch [102/428], Loss: 0.0681
Epoch [4/4], Batch [103/428], Loss: 0.0002
Epoch [4/4], Batch [104/428], Loss: 0.7051
Epoch [4/4], Batch [105/428], Loss: 0.1064
Epoch [4/4], Batch [106/428], Loss: 0.3346
Epoch [4/4], Batch [107/428], Loss: 0.1508
Epoch [4/4], Batch [108/428], Loss: 0.0002
Epoch [4/4], Batch [109/428], Loss: 0.0657
Epoch [4/4], Batch [110/428], Loss: 0.0001
Epoch [4/4], Batch [111/428], Loss: 0.0010
Epoch [4/4], Batch [112/428], Loss: 0.1086
Epoch [4/4], Batch [113/428], Loss: 1.4677
Epoch [4/4], Batch [114/428], Loss: 2.1285
Epoch [4/4], Batch [115/428], Loss: 4.8848
Epoch [4/4], Batch [116/428], Loss: 0.0015
Epoch [4/4], Batch [117/428], Loss: 0.2834
Epoch [4/4], Batch [118/428], Loss: 0.1264
Epoch [4/4], Batch [119/428], Loss: 0.0427
Epoch [4/4], Batch [120/428], Loss: 0.0476
Epoch [4/4], Batch [121/428], Loss: 0.0061
Epoch [4/4], Batch [122/428], Loss: 0.0353
Epoch [4/4], Batch [123/428], Loss: 0.0246
Epoch [4/4], Batch [124/428], Loss: 2.2422
Epoch [4/4], Batch [125/428], Loss: 0.0003
Epoch [4/4], Batch [126/428], Loss: 0.1886
Epoch [4/4], Batch [127/428], Loss: 0.0081
Epoch [4/4], Batch [128/428], Loss: 0.4438
Epoch [4/4], Batch [129/428], Loss: 0.0270
Epoch [4/4], Batch [130/428], Loss: 3.1965
Epoch [4/4], Batch [131/428], Loss: 0.0914
Epoch [4/4], Batch [132/428], Loss: 0.4797
Epoch [4/4], Batch [133/428], Loss: 0.0147
Epoch [4/4], Batch [134/428], Loss: 0.0004
Epoch [4/4], Batch [135/428], Loss: 0.0045
Epoch [4/4], Batch [136/428], Loss: 0.0134
Epoch [4/4], Batch [137/428], Loss: 0.0002
Epoch [4/4], Batch [138/428], Loss: 0.0003
Epoch [4/4], Batch [139/428], Loss: 0.0011
Epoch [4/4], Batch [140/428], Loss: 0.0434
Epoch [4/4], Batch [141/428], Loss: 2.8545
Epoch [4/4], Batch [142/428], Loss: 0.0243
Epoch [4/4], Batch [143/428], Loss: 0.0045
Epoch [4/4], Batch [144/428], Loss: 0.5790
Epoch [4/4], Batch [145/428], Loss: 0.0002
Epoch [4/4], Batch [146/428], Loss: 0.7473
Epoch [4/4], Batch [147/428], Loss: 0.2519
Epoch [4/4], Batch [148/428], Loss: 0.0937
Epoch [4/4], Batch [149/428], Loss: 0.0041
Epoch [4/4], Batch [150/428], Loss: 0.0025
Epoch [4/4], Batch [151/428], Loss: 0.0010
Epoch [4/4], Batch [152/428], Loss: 0.9129
Epoch [4/4], Batch [153/428], Loss: 3.0647
Epoch [4/4], Batch [154/428], Loss: 0.0013
Epoch [4/4], Batch [155/428], Loss: 0.3747
Epoch [4/4], Batch [156/428], Loss: 0.0006
Epoch [4/4], Batch [157/428], Loss: 0.0528
Epoch [4/4], Batch [158/428], Loss: 0.1387
Epoch [4/4], Batch [159/428], Loss: 1.2140
Epoch [4/4], Batch [160/428], Loss: 0.0288
Epoch [4/4], Batch [161/428], Loss: 0.0319
Epoch [4/4], Batch [162/428], Loss: 0.3071
Epoch [4/4], Batch [163/428], Loss: 0.0195
Epoch [4/4], Batch [164/428], Loss: 0.0003
Epoch [4/4], Batch [165/428], Loss: 1.1095
Epoch [4/4], Batch [166/428], Loss: 0.1153
Epoch [4/4], Batch [167/428], Loss: 0.0018
Epoch [4/4], Batch [168/428], Loss: 0.0012
Epoch [4/4], Batch [169/428], Loss: 0.0102
Epoch [4/4], Batch [170/428], Loss: 1.1125
Epoch [4/4], Batch [171/428], Loss: 0.3741
Epoch [4/4], Batch [172/428], Loss: 0.4364
Epoch [4/4], Batch [173/428], Loss: 0.0494
Epoch [4/4], Batch [174/428], Loss: 0.0055
Epoch [4/4], Batch [175/428], Loss: 0.0006
Epoch [4/4], Batch [176/428], Loss: 0.0021
Epoch [4/4], Batch [177/428], Loss: 0.0002
Epoch [4/4], Batch [178/428], Loss: 0.0628
Epoch [4/4], Batch [179/428], Loss: 0.1321
Epoch [4/4], Batch [180/428], Loss: 0.0574
Epoch [4/4], Batch [181/428], Loss: 0.0005
Epoch [4/4], Batch [182/428], Loss: 0.0037
Epoch [4/4], Batch [183/428], Loss: 0.0004
Epoch [4/4], Batch [184/428], Loss: 0.1628
Epoch [4/4], Batch [185/428], Loss: 0.1157
Epoch [4/4], Batch [186/428], Loss: 0.0004
Epoch [4/4], Batch [187/428], Loss: 0.0050
Epoch [4/4], Batch [188/428], Loss: 2.2265
Epoch [4/4], Batch [189/428], Loss: 3.2301
Epoch [4/4], Batch [190/428], Loss: 0.0002
Epoch [4/4], Batch [191/428], Loss: 0.0002
Epoch [4/4], Batch [192/428], Loss: 0.0465
Epoch [4/4], Batch [193/428], Loss: 0.2123
Epoch [4/4], Batch [194/428], Loss: 0.0001
Epoch [4/4], Batch [195/428], Loss: 1.3694
Epoch [4/4], Batch [196/428], Loss: 0.0262
Epoch [4/4], Batch [197/428], Loss: 0.0943
Epoch [4/4], Batch [198/428], Loss: 0.0104
Epoch [4/4], Batch [199/428], Loss: 0.0007
Epoch [4/4], Batch [200/428], Loss: 0.0002
Epoch [4/4], Batch [201/428], Loss: 0.0019
Epoch [4/4], Batch [202/428], Loss: 0.0001
Epoch [4/4], Batch [203/428], Loss: 0.0003
Epoch [4/4], Batch [204/428], Loss: 0.0080
Epoch [4/4], Batch [205/428], Loss: 0.0094
Epoch [4/4], Batch [206/428], Loss: 4.0522
Epoch [4/4], Batch [207/428], Loss: 0.0157
Epoch [4/4], Batch [208/428], Loss: 2.1661
Epoch [4/4], Batch [209/428], Loss: 0.0063
Epoch [4/4], Batch [210/428], Loss: 0.0014
Epoch [4/4], Batch [211/428], Loss: 0.0042
Epoch [4/4], Batch [212/428], Loss: 0.0942
Epoch [4/4], Batch [213/428], Loss: 1.0826
Epoch [4/4], Batch [214/428], Loss: 0.0004
Epoch [4/4], Batch [215/428], Loss: 0.0589
Epoch [4/4], Batch [216/428], Loss: 0.0009
Epoch [4/4], Batch [217/428], Loss: 2.1343
Epoch [4/4], Batch [218/428], Loss: 0.0007
Epoch [4/4], Batch [219/428], Loss: 0.0153
Epoch [4/4], Batch [220/428], Loss: 0.5239
Epoch [4/4], Batch [221/428], Loss: 0.2960
Epoch [4/4], Batch [222/428], Loss: 0.0002
Epoch [4/4], Batch [223/428], Loss: 0.0363
Epoch [4/4], Batch [224/428], Loss: 0.1361
Epoch [4/4], Batch [225/428], Loss: 0.0124
Epoch [4/4], Batch [226/428], Loss: 0.0250
Epoch [4/4], Batch [227/428], Loss: 0.0050
Epoch [4/4], Batch [228/428], Loss: 3.0225
Epoch [4/4], Batch [229/428], Loss: 0.0009
Epoch [4/4], Batch [230/428], Loss: 0.0004
Epoch [4/4], Batch [231/428], Loss: 0.0252
Epoch [4/4], Batch [232/428], Loss: 0.0038
Epoch [4/4], Batch [233/428], Loss: 0.0102
Epoch [4/4], Batch [234/428], Loss: 0.0045
Epoch [4/4], Batch [235/428], Loss: 0.0003
Epoch [4/4], Batch [236/428], Loss: 0.0441
Epoch [4/4], Batch [237/428], Loss: 2.0773
Epoch [4/4], Batch [238/428], Loss: 0.0002
Epoch [4/4], Batch [239/428], Loss: 0.0492
Epoch [4/4], Batch [240/428], Loss: 0.3593
Epoch [4/4], Batch [241/428], Loss: 0.2430
Epoch [4/4], Batch [242/428], Loss: 0.0053
Epoch [4/4], Batch [243/428], Loss: 0.0002
Epoch [4/4], Batch [244/428], Loss: 0.0013
Epoch [4/4], Batch [245/428], Loss: 0.0343
Epoch [4/4], Batch [246/428], Loss: 0.0087
Epoch [4/4], Batch [247/428], Loss: 0.0047
Epoch [4/4], Batch [248/428], Loss: 0.0003
Epoch [4/4], Batch [249/428], Loss: 0.0241
Epoch [4/4], Batch [250/428], Loss: 0.0002
Epoch [4/4], Batch [251/428], Loss: 0.5206
Epoch [4/4], Batch [252/428], Loss: 0.1939
Epoch [4/4], Batch [253/428], Loss: 0.0261
Epoch [4/4], Batch [254/428], Loss: 0.0002
Epoch [4/4], Batch [255/428], Loss: 1.2158
Epoch [4/4], Batch [256/428], Loss: 0.0001
Epoch [4/4], Batch [257/428], Loss: 0.0109
Epoch [4/4], Batch [258/428], Loss: 0.1138
Epoch [4/4], Batch [259/428], Loss: 0.0380
Epoch [4/4], Batch [260/428], Loss: 0.0003
Epoch [4/4], Batch [261/428], Loss: 0.0130
Epoch [4/4], Batch [262/428], Loss: 0.1554
Epoch [4/4], Batch [263/428], Loss: 0.1003
Epoch [4/4], Batch [264/428], Loss: 0.0271
Epoch [4/4], Batch [265/428], Loss: 0.0001
Epoch [4/4], Batch [266/428], Loss: 0.0002
Epoch [4/4], Batch [267/428], Loss: 0.3698
Epoch [4/4], Batch [268/428], Loss: 0.0088
Epoch [4/4], Batch [269/428], Loss: 0.0014
Epoch [4/4], Batch [270/428], Loss: 0.0004
Epoch [4/4], Batch [271/428], Loss: 0.0003
Epoch [4/4], Batch [272/428], Loss: 0.0002
Epoch [4/4], Batch [273/428], Loss: 0.0001
Epoch [4/4], Batch [274/428], Loss: 0.0106
Epoch [4/4], Batch [275/428], Loss: 0.0015
Epoch [4/4], Batch [276/428], Loss: 0.0013
Epoch [4/4], Batch [277/428], Loss: 0.0050
Epoch [4/4], Batch [278/428], Loss: 0.0002
Epoch [4/4], Batch [279/428], Loss: 0.0005
Epoch [4/4], Batch [280/428], Loss: 0.0006
Epoch [4/4], Batch [281/428], Loss: 0.0001
Epoch [4/4], Batch [282/428], Loss: 0.0002
Epoch [4/4], Batch [283/428], Loss: 0.0002
Epoch [4/4], Batch [284/428], Loss: 0.0005
Epoch [4/4], Batch [285/428], Loss: 3.2501
Epoch [4/4], Batch [286/428], Loss: 2.3138
Epoch [4/4], Batch [287/428], Loss: 0.0279
Epoch [4/4], Batch [288/428], Loss: 0.0798
Epoch [4/4], Batch [289/428], Loss: 0.0107
Epoch [4/4], Batch [290/428], Loss: 0.0151
Epoch [4/4], Batch [291/428], Loss: 0.0011
Epoch [4/4], Batch [292/428], Loss: 0.0009
Epoch [4/4], Batch [293/428], Loss: 0.0001
Epoch [4/4], Batch [294/428], Loss: 3.8797
Epoch [4/4], Batch [295/428], Loss: 0.0002
Epoch [4/4], Batch [296/428], Loss: 0.0002
Epoch [4/4], Batch [297/428], Loss: 0.0040
Epoch [4/4], Batch [298/428], Loss: 0.0059
Epoch [4/4], Batch [299/428], Loss: 0.0006
Epoch [4/4], Batch [300/428], Loss: 0.0106
Epoch [4/4], Batch [301/428], Loss: 0.0409
Epoch [4/4], Batch [302/428], Loss: 0.9168
Epoch [4/4], Batch [303/428], Loss: 2.2128
Epoch [4/4], Batch [304/428], Loss: 0.0007
Epoch [4/4], Batch [305/428], Loss: 0.4518
Epoch [4/4], Batch [306/428], Loss: 6.8984
Epoch [4/4], Batch [307/428], Loss: 0.0002
Epoch [4/4], Batch [308/428], Loss: 0.0016
Epoch [4/4], Batch [309/428], Loss: 0.0005
Epoch [4/4], Batch [310/428], Loss: 0.0002
Epoch [4/4], Batch [311/428], Loss: 0.0015
Epoch [4/4], Batch [312/428], Loss: 0.0058
Epoch [4/4], Batch [313/428], Loss: 0.0004
Epoch [4/4], Batch [314/428], Loss: 0.0018
Epoch [4/4], Batch [315/428], Loss: 0.0002
Epoch [4/4], Batch [316/428], Loss: 0.9113
Epoch [4/4], Batch [317/428], Loss: 0.0006
Epoch [4/4], Batch [318/428], Loss: 0.0063
Epoch [4/4], Batch [319/428], Loss: 0.0017
Epoch [4/4], Batch [320/428], Loss: 0.0074
Epoch [4/4], Batch [321/428], Loss: 0.1470
Epoch [4/4], Batch [322/428], Loss: 0.0060
Epoch [4/4], Batch [323/428], Loss: 0.0654
Epoch [4/4], Batch [324/428], Loss: 0.0002
Epoch [4/4], Batch [325/428], Loss: 3.9127
Epoch [4/4], Batch [326/428], Loss: 0.0004
Epoch [4/4], Batch [327/428], Loss: 0.0150
Epoch [4/4], Batch [328/428], Loss: 0.0156
Epoch [4/4], Batch [329/428], Loss: 0.0266
Epoch [4/4], Batch [330/428], Loss: 0.0036
Epoch [4/4], Batch [331/428], Loss: 0.2708
Epoch [4/4], Batch [332/428], Loss: 0.1104
Epoch [4/4], Batch [333/428], Loss: 0.0249
Epoch [4/4], Batch [334/428], Loss: 0.0002
Epoch [4/4], Batch [335/428], Loss: 1.9735
Epoch [4/4], Batch [336/428], Loss: 0.0003
Epoch [4/4], Batch [337/428], Loss: 1.1346
Epoch [4/4], Batch [338/428], Loss: 0.0033
Epoch [4/4], Batch [339/428], Loss: 0.0282
Epoch [4/4], Batch [340/428], Loss: 0.0014
Epoch [4/4], Batch [341/428], Loss: 0.0032
Epoch [4/4], Batch [342/428], Loss: 0.0008
Epoch [4/4], Batch [343/428], Loss: 0.0023
Epoch [4/4], Batch [344/428], Loss: 0.0001
Epoch [4/4], Batch [345/428], Loss: 0.0027
Epoch [4/4], Batch [346/428], Loss: 0.0281
Epoch [4/4], Batch [347/428], Loss: 0.0006
Epoch [4/4], Batch [348/428], Loss: 0.0062
Epoch [4/4], Batch [349/428], Loss: 0.0006
Epoch [4/4], Batch [350/428], Loss: 0.7352
Epoch [4/4], Batch [351/428], Loss: 0.0005
Epoch [4/4], Batch [352/428], Loss: 0.0061
Epoch [4/4], Batch [353/428], Loss: 0.0002
Epoch [4/4], Batch [354/428], Loss: 0.0012
Epoch [4/4], Batch [355/428], Loss: 0.0080
Epoch [4/4], Batch [356/428], Loss: 0.0002
Epoch [4/4], Batch [357/428], Loss: 0.0320
Epoch [4/4], Batch [358/428], Loss: 0.0211
Epoch [4/4], Batch [359/428], Loss: 0.0016
Epoch [4/4], Batch [360/428], Loss: 0.0064
Epoch [4/4], Batch [361/428], Loss: 0.0001
Epoch [4/4], Batch [362/428], Loss: 0.0015
Epoch [4/4], Batch [363/428], Loss: 0.0033
Epoch [4/4], Batch [364/428], Loss: 0.0032
Epoch [4/4], Batch [365/428], Loss: 0.0002
Epoch [4/4], Batch [366/428], Loss: 0.0004
Epoch [4/4], Batch [367/428], Loss: 0.0841
Epoch [4/4], Batch [368/428], Loss: 0.0001
Epoch [4/4], Batch [369/428], Loss: 3.9598
Epoch [4/4], Batch [370/428], Loss: 0.0017
Epoch [4/4], Batch [371/428], Loss: 0.0001
Epoch [4/4], Batch [372/428], Loss: 0.0001
Epoch [4/4], Batch [373/428], Loss: 0.0011
Epoch [4/4], Batch [374/428], Loss: 0.0001
Epoch [4/4], Batch [375/428], Loss: 0.0020
Epoch [4/4], Batch [376/428], Loss: 0.0026
Epoch [4/4], Batch [377/428], Loss: 0.0072
Epoch [4/4], Batch [378/428], Loss: 0.0252
Epoch [4/4], Batch [379/428], Loss: 0.0058
Epoch [4/4], Batch [380/428], Loss: 2.8407
Epoch [4/4], Batch [381/428], Loss: 0.0011
Epoch [4/4], Batch [382/428], Loss: 0.0452
Epoch [4/4], Batch [383/428], Loss: 0.0007
Epoch [4/4], Batch [384/428], Loss: 0.0001
Epoch [4/4], Batch [385/428], Loss: 0.0026
Epoch [4/4], Batch [386/428], Loss: 0.0001
Epoch [4/4], Batch [387/428], Loss: 2.2223
Epoch [4/4], Batch [388/428], Loss: 0.0007
Epoch [4/4], Batch [389/428], Loss: 0.0006
Epoch [4/4], Batch [390/428], Loss: 5.6597
Epoch [4/4], Batch [391/428], Loss: 0.0009
Epoch [4/4], Batch [392/428], Loss: 0.0010
Epoch [4/4], Batch [393/428], Loss: 0.0102
Epoch [4/4], Batch [394/428], Loss: 0.0017
Epoch [4/4], Batch [395/428], Loss: 0.0288
Epoch [4/4], Batch [396/428], Loss: 0.0155
Epoch [4/4], Batch [397/428], Loss: 0.0007
Epoch [4/4], Batch [398/428], Loss: 0.0009
Epoch [4/4], Batch [399/428], Loss: 0.0004
Epoch [4/4], Batch [400/428], Loss: 0.0002
Epoch [4/4], Batch [401/428], Loss: 0.0004
Epoch [4/4], Batch [402/428], Loss: 0.0009
Epoch [4/4], Batch [403/428], Loss: 0.0008
Epoch [4/4], Batch [404/428], Loss: 0.0010
Epoch [4/4], Batch [405/428], Loss: 0.0002
Epoch [4/4], Batch [406/428], Loss: 0.0170
Epoch [4/4], Batch [407/428], Loss: 0.0068
Epoch [4/4], Batch [408/428], Loss: 3.6796
Epoch [4/4], Batch [409/428], Loss: 0.8189
Epoch [4/4], Batch [410/428], Loss: 5.1817
Epoch [4/4], Batch [411/428], Loss: 0.0013
Epoch [4/4], Batch [412/428], Loss: 0.2243
Epoch [4/4], Batch [413/428], Loss: 0.1190
Epoch [4/4], Batch [414/428], Loss: 0.0053
Epoch [4/4], Batch [415/428], Loss: 0.0230
Epoch [4/4], Batch [416/428], Loss: 0.0029
Epoch [4/4], Batch [417/428], Loss: 0.0419
Epoch [4/4], Batch [418/428], Loss: 8.0218
Epoch [4/4], Batch [419/428], Loss: 0.0021
Epoch [4/4], Batch [420/428], Loss: 0.0013
Epoch [4/4], Batch [421/428], Loss: 0.0002
Epoch [4/4], Batch [422/428], Loss: 0.0001
Epoch [4/4], Batch [423/428], Loss: 0.0002
Epoch [4/4], Batch [424/428], Loss: 3.8845
Epoch [4/4], Batch [425/428], Loss: 0.0002
Epoch [4/4], Batch [426/428], Loss: 0.0003
Epoch [4/4], Batch [427/428], Loss: 0.2840
Epoch [4/4], Batch [428/428], Loss: 0.0828
Epoch [4] Training Time: 213.69 seconds
Epoch [4/4], Average Loss: 0.4329, Training Accuracy: 0.8692
Epoch [4], Validation Loss: 1.1500, Validation Accuracy: 0.7232
Epoch [4] Validation Time: 7.28 seconds
--------------------------------------------------

Running trial 4 with config: {'batch_size': 1, 'lr': 1.2692055682895207e-06, 'num_epochs': 7, 'unfreeze_epoch': 0, 'max_length': 64000, 'device': device(type='cpu')}
Epoch 1: Unfreezing feature extractor layers...
Epoch [1/7], Batch [1/428], Loss: 3.7503
Epoch [1/7], Batch [2/428], Loss: 2.7725
Epoch [1/7], Batch [3/428], Loss: 1.3238
Epoch [1/7], Batch [4/428], Loss: 2.9910
Epoch [1/7], Batch [5/428], Loss: 3.1297
Epoch [1/7], Batch [6/428], Loss: 2.5515
Epoch [1/7], Batch [7/428], Loss: 1.8785
Epoch [1/7], Batch [8/428], Loss: 0.6155
Epoch [1/7], Batch [9/428], Loss: 3.4357
Epoch [1/7], Batch [10/428], Loss: 3.2853
Epoch [1/7], Batch [11/428], Loss: 2.3184
Epoch [1/7], Batch [12/428], Loss: 2.8685
Epoch [1/7], Batch [13/428], Loss: 0.4582
Epoch [1/7], Batch [14/428], Loss: 0.6217
Epoch [1/7], Batch [15/428], Loss: 1.8731
Epoch [1/7], Batch [16/428], Loss: 1.8436
Epoch [1/7], Batch [17/428], Loss: 3.5393
Epoch [1/7], Batch [18/428], Loss: 0.5018
Epoch [1/7], Batch [19/428], Loss: 2.8652
Epoch [1/7], Batch [20/428], Loss: 2.2476
Epoch [1/7], Batch [21/428], Loss: 0.9710
Epoch [1/7], Batch [22/428], Loss: 3.8725
Epoch [1/7], Batch [23/428], Loss: 3.0561
Epoch [1/7], Batch [24/428], Loss: 2.7515
Epoch [1/7], Batch [25/428], Loss: 2.7729
Epoch [1/7], Batch [26/428], Loss: 2.1360
Epoch [1/7], Batch [27/428], Loss: 2.2990
Epoch [1/7], Batch [28/428], Loss: 2.5426
Epoch [1/7], Batch [29/428], Loss: 2.5716
Epoch [1/7], Batch [30/428], Loss: 3.1736
Epoch [1/7], Batch [31/428], Loss: 1.2889
Epoch [1/7], Batch [32/428], Loss: 1.7377
Epoch [1/7], Batch [33/428], Loss: 0.6160
Epoch [1/7], Batch [34/428], Loss: 2.2618
Epoch [1/7], Batch [35/428], Loss: 3.7720
Epoch [1/7], Batch [36/428], Loss: 3.4041
Epoch [1/7], Batch [37/428], Loss: 3.9229
Epoch [1/7], Batch [38/428], Loss: 2.1933
Epoch [1/7], Batch [39/428], Loss: 3.1789
Epoch [1/7], Batch [40/428], Loss: 2.0988
Epoch [1/7], Batch [41/428], Loss: 0.7500
Epoch [1/7], Batch [42/428], Loss: 1.9630
Epoch [1/7], Batch [43/428], Loss: 2.2906
Epoch [1/7], Batch [44/428], Loss: 1.6377
Epoch [1/7], Batch [45/428], Loss: 1.8387
Epoch [1/7], Batch [46/428], Loss: 1.2557
Epoch [1/7], Batch [47/428], Loss: 0.5325
Epoch [1/7], Batch [48/428], Loss: 1.9102
Epoch [1/7], Batch [49/428], Loss: 1.3577
Epoch [1/7], Batch [50/428], Loss: 2.2067
Epoch [1/7], Batch [51/428], Loss: 1.9174
Epoch [1/7], Batch [52/428], Loss: 2.4007
Epoch [1/7], Batch [53/428], Loss: 3.0646
Epoch [1/7], Batch [54/428], Loss: 2.1921
Epoch [1/7], Batch [55/428], Loss: 1.8622
Epoch [1/7], Batch [56/428], Loss: 2.8595
Epoch [1/7], Batch [57/428], Loss: 3.3960
Epoch [1/7], Batch [58/428], Loss: 1.5479
Epoch [1/7], Batch [59/428], Loss: 3.0468
Epoch [1/7], Batch [60/428], Loss: 1.8531
Epoch [1/7], Batch [61/428], Loss: 2.3006
Epoch [1/7], Batch [62/428], Loss: 1.5943
Epoch [1/7], Batch [63/428], Loss: 2.5710
Epoch [1/7], Batch [64/428], Loss: 2.0148
Epoch [1/7], Batch [65/428], Loss: 3.3657
Epoch [1/7], Batch [66/428], Loss: 1.9467
Epoch [1/7], Batch [67/428], Loss: 2.4607
Epoch [1/7], Batch [68/428], Loss: 1.6958
Epoch [1/7], Batch [69/428], Loss: 2.6249
Epoch [1/7], Batch [70/428], Loss: 1.6871
Epoch [1/7], Batch [71/428], Loss: 2.8122
Epoch [1/7], Batch [72/428], Loss: 2.7085
Epoch [1/7], Batch [73/428], Loss: 2.5729
Epoch [1/7], Batch [74/428], Loss: 1.6611
Epoch [1/7], Batch [75/428], Loss: 1.7962
Epoch [1/7], Batch [76/428], Loss: 1.4033
Epoch [1/7], Batch [77/428], Loss: 1.8100
Epoch [1/7], Batch [78/428], Loss: 2.7193
Epoch [1/7], Batch [79/428], Loss: 0.7246
Epoch [1/7], Batch [80/428], Loss: 1.4373
Epoch [1/7], Batch [81/428], Loss: 1.6834
Epoch [1/7], Batch [82/428], Loss: 1.8197
Epoch [1/7], Batch [83/428], Loss: 2.4442
Epoch [1/7], Batch [84/428], Loss: 2.1661
Epoch [1/7], Batch [85/428], Loss: 1.4815
Epoch [1/7], Batch [86/428], Loss: 1.5266
Epoch [1/7], Batch [87/428], Loss: 1.8193
Epoch [1/7], Batch [88/428], Loss: 1.6338
Epoch [1/7], Batch [89/428], Loss: 1.7566
Epoch [1/7], Batch [90/428], Loss: 1.5416
Epoch [1/7], Batch [91/428], Loss: 1.8519
Epoch [1/7], Batch [92/428], Loss: 1.2681
Epoch [1/7], Batch [93/428], Loss: 2.4286
Epoch [1/7], Batch [94/428], Loss: 2.5422
Epoch [1/7], Batch [95/428], Loss: 1.5581
Epoch [1/7], Batch [96/428], Loss: 1.8401
Epoch [1/7], Batch [97/428], Loss: 0.7857
Epoch [1/7], Batch [98/428], Loss: 3.5768
Epoch [1/7], Batch [99/428], Loss: 2.8513
Epoch [1/7], Batch [100/428], Loss: 2.7949
Epoch [1/7], Batch [101/428], Loss: 1.1525
Epoch [1/7], Batch [102/428], Loss: 1.5841
Epoch [1/7], Batch [103/428], Loss: 2.8842
Epoch [1/7], Batch [104/428], Loss: 2.1671
Epoch [1/7], Batch [105/428], Loss: 1.1242
Epoch [1/7], Batch [106/428], Loss: 1.9276
Epoch [1/7], Batch [107/428], Loss: 2.9782
Epoch [1/7], Batch [108/428], Loss: 1.5556
Epoch [1/7], Batch [109/428], Loss: 0.4315
Epoch [1/7], Batch [110/428], Loss: 3.2337
Epoch [1/7], Batch [111/428], Loss: 3.0401
Epoch [1/7], Batch [112/428], Loss: 3.5065
Epoch [1/7], Batch [113/428], Loss: 1.7895
Epoch [1/7], Batch [114/428], Loss: 0.9972
Epoch [1/7], Batch [115/428], Loss: 1.1941
Epoch [1/7], Batch [116/428], Loss: 0.9758
Epoch [1/7], Batch [117/428], Loss: 3.1058
Epoch [1/7], Batch [118/428], Loss: 1.6270
Epoch [1/7], Batch [119/428], Loss: 1.0070
Epoch [1/7], Batch [120/428], Loss: 1.6515
Epoch [1/7], Batch [121/428], Loss: 1.1834
Epoch [1/7], Batch [122/428], Loss: 1.6781
Epoch [1/7], Batch [123/428], Loss: 0.9384
Epoch [1/7], Batch [124/428], Loss: 2.8588
Epoch [1/7], Batch [125/428], Loss: 1.8938
Epoch [1/7], Batch [126/428], Loss: 1.6221
Epoch [1/7], Batch [127/428], Loss: 1.9302
Epoch [1/7], Batch [128/428], Loss: 0.9373
Epoch [1/7], Batch [129/428], Loss: 3.3404
Epoch [1/7], Batch [130/428], Loss: 0.4195
Epoch [1/7], Batch [131/428], Loss: 2.8816
Epoch [1/7], Batch [132/428], Loss: 2.5326
Epoch [1/7], Batch [133/428], Loss: 3.2615
Epoch [1/7], Batch [134/428], Loss: 1.5333
Epoch [1/7], Batch [135/428], Loss: 1.7563
Epoch [1/7], Batch [136/428], Loss: 2.6326
Epoch [1/7], Batch [137/428], Loss: 2.4878
Epoch [1/7], Batch [138/428], Loss: 1.8025
Epoch [1/7], Batch [139/428], Loss: 0.7320
Epoch [1/7], Batch [140/428], Loss: 1.9328
Epoch [1/7], Batch [141/428], Loss: 2.7743
Epoch [1/7], Batch [142/428], Loss: 0.8575
Epoch [1/7], Batch [143/428], Loss: 0.7571
Epoch [1/7], Batch [144/428], Loss: 2.2202
Epoch [1/7], Batch [145/428], Loss: 3.0107
Epoch [1/7], Batch [146/428], Loss: 2.2327
Epoch [1/7], Batch [147/428], Loss: 2.7687
Epoch [1/7], Batch [148/428], Loss: 2.9549
Epoch [1/7], Batch [149/428], Loss: 0.7539
Epoch [1/7], Batch [150/428], Loss: 0.6984
Epoch [1/7], Batch [151/428], Loss: 0.6587
Epoch [1/7], Batch [152/428], Loss: 1.3983
Epoch [1/7], Batch [153/428], Loss: 1.5136
Epoch [1/7], Batch [154/428], Loss: 1.8209
Epoch [1/7], Batch [155/428], Loss: 0.8390
Epoch [1/7], Batch [156/428], Loss: 2.1023
Epoch [1/7], Batch [157/428], Loss: 2.8306
Epoch [1/7], Batch [158/428], Loss: 1.1249
Epoch [1/7], Batch [159/428], Loss: 1.7296
Epoch [1/7], Batch [160/428], Loss: 2.0673
Epoch [1/7], Batch [161/428], Loss: 2.0242
Epoch [1/7], Batch [162/428], Loss: 1.3228
Epoch [1/7], Batch [163/428], Loss: 1.5833
Epoch [1/7], Batch [164/428], Loss: 0.7120
Epoch [1/7], Batch [165/428], Loss: 2.8342
Epoch [1/7], Batch [166/428], Loss: 2.0568
Epoch [1/7], Batch [167/428], Loss: 1.7891
Epoch [1/7], Batch [168/428], Loss: 1.2123
Epoch [1/7], Batch [169/428], Loss: 0.6374
Epoch [1/7], Batch [170/428], Loss: 0.6430
Epoch [1/7], Batch [171/428], Loss: 0.6159
Epoch [1/7], Batch [172/428], Loss: 2.0319
Epoch [1/7], Batch [173/428], Loss: 1.6387
Epoch [1/7], Batch [174/428], Loss: 1.3144
Epoch [1/7], Batch [175/428], Loss: 1.2202
Epoch [1/7], Batch [176/428], Loss: 1.2955
Epoch [1/7], Batch [177/428], Loss: 2.2696
Epoch [1/7], Batch [178/428], Loss: 0.5596
Epoch [1/7], Batch [179/428], Loss: 2.5348
Epoch [1/7], Batch [180/428], Loss: 1.8686
Epoch [1/7], Batch [181/428], Loss: 0.8273
Epoch [1/7], Batch [182/428], Loss: 0.8212
Epoch [1/7], Batch [183/428], Loss: 1.0021
Epoch [1/7], Batch [184/428], Loss: 0.4372
Epoch [1/7], Batch [185/428], Loss: 1.9335
Epoch [1/7], Batch [186/428], Loss: 0.6921
Epoch [1/7], Batch [187/428], Loss: 1.0341
Epoch [1/7], Batch [188/428], Loss: 1.7304
Epoch [1/7], Batch [189/428], Loss: 1.4982
Epoch [1/7], Batch [190/428], Loss: 1.6253
Epoch [1/7], Batch [191/428], Loss: 1.3910
Epoch [1/7], Batch [192/428], Loss: 2.3621
Epoch [1/7], Batch [193/428], Loss: 1.8402
Epoch [1/7], Batch [194/428], Loss: 3.3046
Epoch [1/7], Batch [195/428], Loss: 1.6415
Epoch [1/7], Batch [196/428], Loss: 2.9174
Epoch [1/7], Batch [197/428], Loss: 2.1099
Epoch [1/7], Batch [198/428], Loss: 2.4744
Epoch [1/7], Batch [199/428], Loss: 0.9199
Epoch [1/7], Batch [200/428], Loss: 1.5718
Epoch [1/7], Batch [201/428], Loss: 0.4824
Epoch [1/7], Batch [202/428], Loss: 2.0833
Epoch [1/7], Batch [203/428], Loss: 2.3171
Epoch [1/7], Batch [204/428], Loss: 2.1998
Epoch [1/7], Batch [205/428], Loss: 0.4929
Epoch [1/7], Batch [206/428], Loss: 0.6187
Epoch [1/7], Batch [207/428], Loss: 3.1895
Epoch [1/7], Batch [208/428], Loss: 0.7830
Epoch [1/7], Batch [209/428], Loss: 1.5607
Epoch [1/7], Batch [210/428], Loss: 2.3080
Epoch [1/7], Batch [211/428], Loss: 0.5089
Epoch [1/7], Batch [212/428], Loss: 3.0450
Epoch [1/7], Batch [213/428], Loss: 1.6587
Epoch [1/7], Batch [214/428], Loss: 0.5710
Epoch [1/7], Batch [215/428], Loss: 2.8098
Epoch [1/7], Batch [216/428], Loss: 1.7128
Epoch [1/7], Batch [217/428], Loss: 1.5790
Epoch [1/7], Batch [218/428], Loss: 1.5102
Epoch [1/7], Batch [219/428], Loss: 0.3646
Epoch [1/7], Batch [220/428], Loss: 1.9359
Epoch [1/7], Batch [221/428], Loss: 0.4878
Epoch [1/7], Batch [222/428], Loss: 0.5304
Epoch [1/7], Batch [223/428], Loss: 0.6948
Epoch [1/7], Batch [224/428], Loss: 0.4581
Epoch [1/7], Batch [225/428], Loss: 1.7040
Epoch [1/7], Batch [226/428], Loss: 0.9745
Epoch [1/7], Batch [227/428], Loss: 0.5387
Epoch [1/7], Batch [228/428], Loss: 0.5698
Epoch [1/7], Batch [229/428], Loss: 1.8679
Epoch [1/7], Batch [230/428], Loss: 0.3961
Epoch [1/7], Batch [231/428], Loss: 2.2976
Epoch [1/7], Batch [232/428], Loss: 0.4795
Epoch [1/7], Batch [233/428], Loss: 2.0104
Epoch [1/7], Batch [234/428], Loss: 2.0595
Epoch [1/7], Batch [235/428], Loss: 1.8101
Epoch [1/7], Batch [236/428], Loss: 0.2310
Epoch [1/7], Batch [237/428], Loss: 0.2500
Epoch [1/7], Batch [238/428], Loss: 2.3253
Epoch [1/7], Batch [239/428], Loss: 2.2202
Epoch [1/7], Batch [240/428], Loss: 0.1709
Epoch [1/7], Batch [241/428], Loss: 2.9907
Epoch [1/7], Batch [242/428], Loss: 2.1064
Epoch [1/7], Batch [243/428], Loss: 1.7365
Epoch [1/7], Batch [244/428], Loss: 1.0982
Epoch [1/7], Batch [245/428], Loss: 2.3692
Epoch [1/7], Batch [246/428], Loss: 0.8137
Epoch [1/7], Batch [247/428], Loss: 0.1276
Epoch [1/7], Batch [248/428], Loss: 2.1434
Epoch [1/7], Batch [249/428], Loss: 0.6062
Epoch [1/7], Batch [250/428], Loss: 0.4947
Epoch [1/7], Batch [251/428], Loss: 1.9057
Epoch [1/7], Batch [252/428], Loss: 2.6038
Epoch [1/7], Batch [253/428], Loss: 0.4850
Epoch [1/7], Batch [254/428], Loss: 0.3791
Epoch [1/7], Batch [255/428], Loss: 1.6982
Epoch [1/7], Batch [256/428], Loss: 2.6765
Epoch [1/7], Batch [257/428], Loss: 0.5072
Epoch [1/7], Batch [258/428], Loss: 0.0897
Epoch [1/7], Batch [259/428], Loss: 0.5741
Epoch [1/7], Batch [260/428], Loss: 1.4406
Epoch [1/7], Batch [261/428], Loss: 1.3492
Epoch [1/7], Batch [262/428], Loss: 3.7004
Epoch [1/7], Batch [263/428], Loss: 0.3702
Epoch [1/7], Batch [264/428], Loss: 3.1703
Epoch [1/7], Batch [265/428], Loss: 0.2934
Epoch [1/7], Batch [266/428], Loss: 0.1734
Epoch [1/7], Batch [267/428], Loss: 2.1504
Epoch [1/7], Batch [268/428], Loss: 1.8600
Epoch [1/7], Batch [269/428], Loss: 2.4849
Epoch [1/7], Batch [270/428], Loss: 2.5963
Epoch [1/7], Batch [271/428], Loss: 1.7747
Epoch [1/7], Batch [272/428], Loss: 1.9406
Epoch [1/7], Batch [273/428], Loss: 2.8406
Epoch [1/7], Batch [274/428], Loss: 0.1347
Epoch [1/7], Batch [275/428], Loss: 0.0776
Epoch [1/7], Batch [276/428], Loss: 0.5497
Epoch [1/7], Batch [277/428], Loss: 3.0654
Epoch [1/7], Batch [278/428], Loss: 0.1185
Epoch [1/7], Batch [279/428], Loss: 1.3980
Epoch [1/7], Batch [280/428], Loss: 2.2731
Epoch [1/7], Batch [281/428], Loss: 0.6340
Epoch [1/7], Batch [282/428], Loss: 1.7545
Epoch [1/7], Batch [283/428], Loss: 3.0124
Epoch [1/7], Batch [284/428], Loss: 2.2266
Epoch [1/7], Batch [285/428], Loss: 2.5969
Epoch [1/7], Batch [286/428], Loss: 2.2425
Epoch [1/7], Batch [287/428], Loss: 1.8519
Epoch [1/7], Batch [288/428], Loss: 0.3438
Epoch [1/7], Batch [289/428], Loss: 2.4327
Epoch [1/7], Batch [290/428], Loss: 0.2532
Epoch [1/7], Batch [291/428], Loss: 2.0386
Epoch [1/7], Batch [292/428], Loss: 0.4032
Epoch [1/7], Batch [293/428], Loss: 2.9615
Epoch [1/7], Batch [294/428], Loss: 1.7917
Epoch [1/7], Batch [295/428], Loss: 0.2657
Epoch [1/7], Batch [296/428], Loss: 0.2581
Epoch [1/7], Batch [297/428], Loss: 2.1738
Epoch [1/7], Batch [298/428], Loss: 0.3647
Epoch [1/7], Batch [299/428], Loss: 2.0775
Epoch [1/7], Batch [300/428], Loss: 1.8963
Epoch [1/7], Batch [301/428], Loss: 0.1442
Epoch [1/7], Batch [302/428], Loss: 1.3742
Epoch [1/7], Batch [303/428], Loss: 1.9899
Epoch [1/7], Batch [304/428], Loss: 0.2176
Epoch [1/7], Batch [305/428], Loss: 0.1860
Epoch [1/7], Batch [306/428], Loss: 0.8296
Epoch [1/7], Batch [307/428], Loss: 0.2838
Epoch [1/7], Batch [308/428], Loss: 1.7528
Epoch [1/7], Batch [309/428], Loss: 0.2085
Epoch [1/7], Batch [310/428], Loss: 0.2336
Epoch [1/7], Batch [311/428], Loss: 1.8437
Epoch [1/7], Batch [312/428], Loss: 2.1715
Epoch [1/7], Batch [313/428], Loss: 0.2392
Epoch [1/7], Batch [314/428], Loss: 2.5155
Epoch [1/7], Batch [315/428], Loss: 3.3991
Epoch [1/7], Batch [316/428], Loss: 1.6456
Epoch [1/7], Batch [317/428], Loss: 0.3983
Epoch [1/7], Batch [318/428], Loss: 0.3338
Epoch [1/7], Batch [319/428], Loss: 2.2573
Epoch [1/7], Batch [320/428], Loss: 2.0159
Epoch [1/7], Batch [321/428], Loss: 2.3449
Epoch [1/7], Batch [322/428], Loss: 0.2341
Epoch [1/7], Batch [323/428], Loss: 0.1303
Epoch [1/7], Batch [324/428], Loss: 0.2946
Epoch [1/7], Batch [325/428], Loss: 3.1457
Epoch [1/7], Batch [326/428], Loss: 1.2297
Epoch [1/7], Batch [327/428], Loss: 0.3145
Epoch [1/7], Batch [328/428], Loss: 2.5415
Epoch [1/7], Batch [329/428], Loss: 2.2928
Epoch [1/7], Batch [330/428], Loss: 3.7293
Epoch [1/7], Batch [331/428], Loss: 0.1642
Epoch [1/7], Batch [332/428], Loss: 2.8183
Epoch [1/7], Batch [333/428], Loss: 0.8020
Epoch [1/7], Batch [334/428], Loss: 2.0425
Epoch [1/7], Batch [335/428], Loss: 2.2260
Epoch [1/7], Batch [336/428], Loss: 2.5524
Epoch [1/7], Batch [337/428], Loss: 0.0494
Epoch [1/7], Batch [338/428], Loss: 2.7529
Epoch [1/7], Batch [339/428], Loss: 2.4373
Epoch [1/7], Batch [340/428], Loss: 1.3113
Epoch [1/7], Batch [341/428], Loss: 2.2088
Epoch [1/7], Batch [342/428], Loss: 0.1828
Epoch [1/7], Batch [343/428], Loss: 0.8027
Epoch [1/7], Batch [344/428], Loss: 2.6992
Epoch [1/7], Batch [345/428], Loss: 0.1166
Epoch [1/7], Batch [346/428], Loss: 2.3204
Epoch [1/7], Batch [347/428], Loss: 1.8199
Epoch [1/7], Batch [348/428], Loss: 1.1021
Epoch [1/7], Batch [349/428], Loss: 1.2548
Epoch [1/7], Batch [350/428], Loss: 0.0533
Epoch [1/7], Batch [351/428], Loss: 0.3274
Epoch [1/7], Batch [352/428], Loss: 0.0919
Epoch [1/7], Batch [353/428], Loss: 0.8657
Epoch [1/7], Batch [354/428], Loss: 0.0483
Epoch [1/7], Batch [355/428], Loss: 0.1175
Epoch [1/7], Batch [356/428], Loss: 0.3851
Epoch [1/7], Batch [357/428], Loss: 1.5052
Epoch [1/7], Batch [358/428], Loss: 2.3079
Epoch [1/7], Batch [359/428], Loss: 1.5949
Epoch [1/7], Batch [360/428], Loss: 0.1170
Epoch [1/7], Batch [361/428], Loss: 2.8376
Epoch [1/7], Batch [362/428], Loss: 0.7208
Epoch [1/7], Batch [363/428], Loss: 2.6016
Epoch [1/7], Batch [364/428], Loss: 1.8386
Epoch [1/7], Batch [365/428], Loss: 0.0980
Epoch [1/7], Batch [366/428], Loss: 0.9261
Epoch [1/7], Batch [367/428], Loss: 0.2941
Epoch [1/7], Batch [368/428], Loss: 2.2264
Epoch [1/7], Batch [369/428], Loss: 2.4951
Epoch [1/7], Batch [370/428], Loss: 1.2574
Epoch [1/7], Batch [371/428], Loss: 0.2167
Epoch [1/7], Batch [372/428], Loss: 0.2421
Epoch [1/7], Batch [373/428], Loss: 2.3109
Epoch [1/7], Batch [374/428], Loss: 1.1749
Epoch [1/7], Batch [375/428], Loss: 1.3282
Epoch [1/7], Batch [376/428], Loss: 1.5089
Epoch [1/7], Batch [377/428], Loss: 0.0828
Epoch [1/7], Batch [378/428], Loss: 0.2294
Epoch [1/7], Batch [379/428], Loss: 3.8904
Epoch [1/7], Batch [380/428], Loss: 1.8192
Epoch [1/7], Batch [381/428], Loss: 0.1957
Epoch [1/7], Batch [382/428], Loss: 2.9775
Epoch [1/7], Batch [383/428], Loss: 0.3894
Epoch [1/7], Batch [384/428], Loss: 3.3008
Epoch [1/7], Batch [385/428], Loss: 0.0778
Epoch [1/7], Batch [386/428], Loss: 0.6724
Epoch [1/7], Batch [387/428], Loss: 1.5267
Epoch [1/7], Batch [388/428], Loss: 0.0533
Epoch [1/7], Batch [389/428], Loss: 1.4606
Epoch [1/7], Batch [390/428], Loss: 2.3072
Epoch [1/7], Batch [391/428], Loss: 1.6054
Epoch [1/7], Batch [392/428], Loss: 1.2747
Epoch [1/7], Batch [393/428], Loss: 0.3287
Epoch [1/7], Batch [394/428], Loss: 1.7085
Epoch [1/7], Batch [395/428], Loss: 2.2044
Epoch [1/7], Batch [396/428], Loss: 0.6802
Epoch [1/7], Batch [397/428], Loss: 2.2398
Epoch [1/7], Batch [398/428], Loss: 0.3708
Epoch [1/7], Batch [399/428], Loss: 0.4415
Epoch [1/7], Batch [400/428], Loss: 1.5973
Epoch [1/7], Batch [401/428], Loss: 2.2714
Epoch [1/7], Batch [402/428], Loss: 2.7756
Epoch [1/7], Batch [403/428], Loss: 3.2864
Epoch [1/7], Batch [404/428], Loss: 0.0988
Epoch [1/7], Batch [405/428], Loss: 2.2322
Epoch [1/7], Batch [406/428], Loss: 1.7407
Epoch [1/7], Batch [407/428], Loss: 1.5306
Epoch [1/7], Batch [408/428], Loss: 0.0825
Epoch [1/7], Batch [409/428], Loss: 0.0466
Epoch [1/7], Batch [410/428], Loss: 0.1620
Epoch [1/7], Batch [411/428], Loss: 0.1242
Epoch [1/7], Batch [412/428], Loss: 1.1430
Epoch [1/7], Batch [413/428], Loss: 1.0929
Epoch [1/7], Batch [414/428], Loss: 1.4783
Epoch [1/7], Batch [415/428], Loss: 0.1038
Epoch [1/7], Batch [416/428], Loss: 1.9288
Epoch [1/7], Batch [417/428], Loss: 1.2454
Epoch [1/7], Batch [418/428], Loss: 2.8327
Epoch [1/7], Batch [419/428], Loss: 2.0716
Epoch [1/7], Batch [420/428], Loss: 1.3044
Epoch [1/7], Batch [421/428], Loss: 0.4678
Epoch [1/7], Batch [422/428], Loss: 2.4995
Epoch [1/7], Batch [423/428], Loss: 0.2715
Epoch [1/7], Batch [424/428], Loss: 0.0261
Epoch [1/7], Batch [425/428], Loss: 0.2889
Epoch [1/7], Batch [426/428], Loss: 2.5895
Epoch [1/7], Batch [427/428], Loss: 3.1394
Epoch [1/7], Batch [428/428], Loss: 2.5097
Epoch [1] Training Time: 269.69 seconds
Epoch [1/7], Average Loss: 1.6475, Training Accuracy: 0.3762
Epoch [1], Validation Loss: 1.4221, Validation Accuracy: 0.4574
Epoch [1] Validation Time: 9.47 seconds
--------------------------------------------------
Epoch [2/7], Batch [1/428], Loss: 1.2965
Epoch [2/7], Batch [2/428], Loss: 1.0606
Epoch [2/7], Batch [3/428], Loss: 0.0233
Epoch [2/7], Batch [4/428], Loss: 0.0199
Epoch [2/7], Batch [5/428], Loss: 0.1509
Epoch [2/7], Batch [6/428], Loss: 1.0339
Epoch [2/7], Batch [7/428], Loss: 0.2444
Epoch [2/7], Batch [8/428], Loss: 1.8053
Epoch [2/7], Batch [9/428], Loss: 3.5869
Epoch [2/7], Batch [10/428], Loss: 1.3720
Epoch [2/7], Batch [11/428], Loss: 0.0144
Epoch [2/7], Batch [12/428], Loss: 1.4927
Epoch [2/7], Batch [13/428], Loss: 1.1009
Epoch [2/7], Batch [14/428], Loss: 0.6616
Epoch [2/7], Batch [15/428], Loss: 1.5899
Epoch [2/7], Batch [16/428], Loss: 0.3334
Epoch [2/7], Batch [17/428], Loss: 3.2211
Epoch [2/7], Batch [18/428], Loss: 0.0451
Epoch [2/7], Batch [19/428], Loss: 0.3924
Epoch [2/7], Batch [20/428], Loss: 0.1649
Epoch [2/7], Batch [21/428], Loss: 3.2445
Epoch [2/7], Batch [22/428], Loss: 0.6901
Epoch [2/7], Batch [23/428], Loss: 2.8302
Epoch [2/7], Batch [24/428], Loss: 0.1684
Epoch [2/7], Batch [25/428], Loss: 3.2030
Epoch [2/7], Batch [26/428], Loss: 0.0259
Epoch [2/7], Batch [27/428], Loss: 1.0814
Epoch [2/7], Batch [28/428], Loss: 3.0902
Epoch [2/7], Batch [29/428], Loss: 1.6925
Epoch [2/7], Batch [30/428], Loss: 1.0583
Epoch [2/7], Batch [31/428], Loss: 2.0681
Epoch [2/7], Batch [32/428], Loss: 0.0119
Epoch [2/7], Batch [33/428], Loss: 0.0080
Epoch [2/7], Batch [34/428], Loss: 0.0644
Epoch [2/7], Batch [35/428], Loss: 1.2595
Epoch [2/7], Batch [36/428], Loss: 1.9300
Epoch [2/7], Batch [37/428], Loss: 0.0157
Epoch [2/7], Batch [38/428], Loss: 1.3042
Epoch [2/7], Batch [39/428], Loss: 2.9626
Epoch [2/7], Batch [40/428], Loss: 1.7531
Epoch [2/7], Batch [41/428], Loss: 1.1020
Epoch [2/7], Batch [42/428], Loss: 1.4777
Epoch [2/7], Batch [43/428], Loss: 0.1959
Epoch [2/7], Batch [44/428], Loss: 0.6374
Epoch [2/7], Batch [45/428], Loss: 0.4206
Epoch [2/7], Batch [46/428], Loss: 0.2191
Epoch [2/7], Batch [47/428], Loss: 3.5139
Epoch [2/7], Batch [48/428], Loss: 0.0048
Epoch [2/7], Batch [49/428], Loss: 0.0056
Epoch [2/7], Batch [50/428], Loss: 2.1051
Epoch [2/7], Batch [51/428], Loss: 1.4138
Epoch [2/7], Batch [52/428], Loss: 2.7046
Epoch [2/7], Batch [53/428], Loss: 0.0092
Epoch [2/7], Batch [54/428], Loss: 0.7300
Epoch [2/7], Batch [55/428], Loss: 0.0977
Epoch [2/7], Batch [56/428], Loss: 1.6136
Epoch [2/7], Batch [57/428], Loss: 1.5916
Epoch [2/7], Batch [58/428], Loss: 0.0261
Epoch [2/7], Batch [59/428], Loss: 3.3599
Epoch [2/7], Batch [60/428], Loss: 0.0044
Epoch [2/7], Batch [61/428], Loss: 0.5953
Epoch [2/7], Batch [62/428], Loss: 4.8506
Epoch [2/7], Batch [63/428], Loss: 0.9171
Epoch [2/7], Batch [64/428], Loss: 1.7119
Epoch [2/7], Batch [65/428], Loss: 0.0445
Epoch [2/7], Batch [66/428], Loss: 2.0844
Epoch [2/7], Batch [67/428], Loss: 2.8078
Epoch [2/7], Batch [68/428], Loss: 0.7225
Epoch [2/7], Batch [69/428], Loss: 2.1700
Epoch [2/7], Batch [70/428], Loss: 1.1920
Epoch [2/7], Batch [71/428], Loss: 0.2142
Epoch [2/7], Batch [72/428], Loss: 3.4012
Epoch [2/7], Batch [73/428], Loss: 0.2395
Epoch [2/7], Batch [74/428], Loss: 0.4951
Epoch [2/7], Batch [75/428], Loss: 0.9958
Epoch [2/7], Batch [76/428], Loss: 3.2577
Epoch [2/7], Batch [77/428], Loss: 1.6958
Epoch [2/7], Batch [78/428], Loss: 3.6956
Epoch [2/7], Batch [79/428], Loss: 0.8079
Epoch [2/7], Batch [80/428], Loss: 3.4658
Epoch [2/7], Batch [81/428], Loss: 3.1083
Epoch [2/7], Batch [82/428], Loss: 0.1324
Epoch [2/7], Batch [83/428], Loss: 0.1322
Epoch [2/7], Batch [84/428], Loss: 1.9538
Epoch [2/7], Batch [85/428], Loss: 0.6791
Epoch [2/7], Batch [86/428], Loss: 3.2377
Epoch [2/7], Batch [87/428], Loss: 2.0191
Epoch [2/7], Batch [88/428], Loss: 0.5999
Epoch [2/7], Batch [89/428], Loss: 0.0058
Epoch [2/7], Batch [90/428], Loss: 1.5366
Epoch [2/7], Batch [91/428], Loss: 0.0481
Epoch [2/7], Batch [92/428], Loss: 1.1060
Epoch [2/7], Batch [93/428], Loss: 0.4763
Epoch [2/7], Batch [94/428], Loss: 1.1257
Epoch [2/7], Batch [95/428], Loss: 0.0599
Epoch [2/7], Batch [96/428], Loss: 1.8864
Epoch [2/7], Batch [97/428], Loss: 1.0549
Epoch [2/7], Batch [98/428], Loss: 0.0207
Epoch [2/7], Batch [99/428], Loss: 0.2382
Epoch [2/7], Batch [100/428], Loss: 0.0078
Epoch [2/7], Batch [101/428], Loss: 1.6656
Epoch [2/7], Batch [102/428], Loss: 2.1307
Epoch [2/7], Batch [103/428], Loss: 0.5364
Epoch [2/7], Batch [104/428], Loss: 1.3353
Epoch [2/7], Batch [105/428], Loss: 0.0193
Epoch [2/7], Batch [106/428], Loss: 0.1989
Epoch [2/7], Batch [107/428], Loss: 1.1142
Epoch [2/7], Batch [108/428], Loss: 0.5546
Epoch [2/7], Batch [109/428], Loss: 0.0143
Epoch [2/7], Batch [110/428], Loss: 0.0161
Epoch [2/7], Batch [111/428], Loss: 1.3242
Epoch [2/7], Batch [112/428], Loss: 0.0521
Epoch [2/7], Batch [113/428], Loss: 0.0629
Epoch [2/7], Batch [114/428], Loss: 2.0342
Epoch [2/7], Batch [115/428], Loss: 0.0116
Epoch [2/7], Batch [116/428], Loss: 0.6233
Epoch [2/7], Batch [117/428], Loss: 1.1555
Epoch [2/7], Batch [118/428], Loss: 3.2395
Epoch [2/7], Batch [119/428], Loss: 1.0895
Epoch [2/7], Batch [120/428], Loss: 2.7962
Epoch [2/7], Batch [121/428], Loss: 1.8793
Epoch [2/7], Batch [122/428], Loss: 1.7217
Epoch [2/7], Batch [123/428], Loss: 3.7752
Epoch [2/7], Batch [124/428], Loss: 0.8739
Epoch [2/7], Batch [125/428], Loss: 0.0858
Epoch [2/7], Batch [126/428], Loss: 0.0494
Epoch [2/7], Batch [127/428], Loss: 0.0063
Epoch [2/7], Batch [128/428], Loss: 1.1705
Epoch [2/7], Batch [129/428], Loss: 1.6416
Epoch [2/7], Batch [130/428], Loss: 0.7360
Epoch [2/7], Batch [131/428], Loss: 1.2603
Epoch [2/7], Batch [132/428], Loss: 1.2037
Epoch [2/7], Batch [133/428], Loss: 0.0046
Epoch [2/7], Batch [134/428], Loss: 1.5998
Epoch [2/7], Batch [135/428], Loss: 1.2864
Epoch [2/7], Batch [136/428], Loss: 0.7494
Epoch [2/7], Batch [137/428], Loss: 0.1748
Epoch [2/7], Batch [138/428], Loss: 0.0096
Epoch [2/7], Batch [139/428], Loss: 1.1277
Epoch [2/7], Batch [140/428], Loss: 0.4601
Epoch [2/7], Batch [141/428], Loss: 0.6755
Epoch [2/7], Batch [142/428], Loss: 1.4248
Epoch [2/7], Batch [143/428], Loss: 1.7377
Epoch [2/7], Batch [144/428], Loss: 2.0046
Epoch [2/7], Batch [145/428], Loss: 0.8701
Epoch [2/7], Batch [146/428], Loss: 1.9903
Epoch [2/7], Batch [147/428], Loss: 1.7431
Epoch [2/7], Batch [148/428], Loss: 1.1998
Epoch [2/7], Batch [149/428], Loss: 1.6713
Epoch [2/7], Batch [150/428], Loss: 0.0058
Epoch [2/7], Batch [151/428], Loss: 0.0028
Epoch [2/7], Batch [152/428], Loss: 0.5430
Epoch [2/7], Batch [153/428], Loss: 0.0221
Epoch [2/7], Batch [154/428], Loss: 1.4387
Epoch [2/7], Batch [155/428], Loss: 5.2390
Epoch [2/7], Batch [156/428], Loss: 0.6984
Epoch [2/7], Batch [157/428], Loss: 3.3052
Epoch [2/7], Batch [158/428], Loss: 0.1942
Epoch [2/7], Batch [159/428], Loss: 0.2272
Epoch [2/7], Batch [160/428], Loss: 2.6478
Epoch [2/7], Batch [161/428], Loss: 0.1855
Epoch [2/7], Batch [162/428], Loss: 1.9184
Epoch [2/7], Batch [163/428], Loss: 0.6830
Epoch [2/7], Batch [164/428], Loss: 0.6698
Epoch [2/7], Batch [165/428], Loss: 1.1916
Epoch [2/7], Batch [166/428], Loss: 0.1420
Epoch [2/7], Batch [167/428], Loss: 0.4134
Epoch [2/7], Batch [168/428], Loss: 0.7017
Epoch [2/7], Batch [169/428], Loss: 1.8347
Epoch [2/7], Batch [170/428], Loss: 0.0900
Epoch [2/7], Batch [171/428], Loss: 0.2303
Epoch [2/7], Batch [172/428], Loss: 1.7205
Epoch [2/7], Batch [173/428], Loss: 1.2338
Epoch [2/7], Batch [174/428], Loss: 0.6320
Epoch [2/7], Batch [175/428], Loss: 2.0807
Epoch [2/7], Batch [176/428], Loss: 0.8652
Epoch [2/7], Batch [177/428], Loss: 1.2584
Epoch [2/7], Batch [178/428], Loss: 0.1045
Epoch [2/7], Batch [179/428], Loss: 1.3834
Epoch [2/7], Batch [180/428], Loss: 0.0877
Epoch [2/7], Batch [181/428], Loss: 0.7242
Epoch [2/7], Batch [182/428], Loss: 0.0455
Epoch [2/7], Batch [183/428], Loss: 1.0979
Epoch [2/7], Batch [184/428], Loss: 0.2607
Epoch [2/7], Batch [185/428], Loss: 0.0346
Epoch [2/7], Batch [186/428], Loss: 0.4740
Epoch [2/7], Batch [187/428], Loss: 0.7126
Epoch [2/7], Batch [188/428], Loss: 0.6107
Epoch [2/7], Batch [189/428], Loss: 0.0827
Epoch [2/7], Batch [190/428], Loss: 0.1129
Epoch [2/7], Batch [191/428], Loss: 0.2943
Epoch [2/7], Batch [192/428], Loss: 0.1337
Epoch [2/7], Batch [193/428], Loss: 0.0380
Epoch [2/7], Batch [194/428], Loss: 0.0061
Epoch [2/7], Batch [195/428], Loss: 1.9890
Epoch [2/7], Batch [196/428], Loss: 0.6454
Epoch [2/7], Batch [197/428], Loss: 0.3324
Epoch [2/7], Batch [198/428], Loss: 0.0013
Epoch [2/7], Batch [199/428], Loss: 2.5088
Epoch [2/7], Batch [200/428], Loss: 0.0019
Epoch [2/7], Batch [201/428], Loss: 2.1216
Epoch [2/7], Batch [202/428], Loss: 0.0897
Epoch [2/7], Batch [203/428], Loss: 0.2715
Epoch [2/7], Batch [204/428], Loss: 0.2680
Epoch [2/7], Batch [205/428], Loss: 3.0481
Epoch [2/7], Batch [206/428], Loss: 0.7635
Epoch [2/7], Batch [207/428], Loss: 2.0938
Epoch [2/7], Batch [208/428], Loss: 0.6673
Epoch [2/7], Batch [209/428], Loss: 0.8572
Epoch [2/7], Batch [210/428], Loss: 0.0029
Epoch [2/7], Batch [211/428], Loss: 0.0208
Epoch [2/7], Batch [212/428], Loss: 0.0054
Epoch [2/7], Batch [213/428], Loss: 2.3567
Epoch [2/7], Batch [214/428], Loss: 2.3885
Epoch [2/7], Batch [215/428], Loss: 0.0199
Epoch [2/7], Batch [216/428], Loss: 0.0017
Epoch [2/7], Batch [217/428], Loss: 0.0019
Epoch [2/7], Batch [218/428], Loss: 1.9215
Epoch [2/7], Batch [219/428], Loss: 0.0215
Epoch [2/7], Batch [220/428], Loss: 1.8847
Epoch [2/7], Batch [221/428], Loss: 2.0257
Epoch [2/7], Batch [222/428], Loss: 0.6179
Epoch [2/7], Batch [223/428], Loss: 0.8397
Epoch [2/7], Batch [224/428], Loss: 0.8497
Epoch [2/7], Batch [225/428], Loss: 1.6483
Epoch [2/7], Batch [226/428], Loss: 4.3587
Epoch [2/7], Batch [227/428], Loss: 0.5009
Epoch [2/7], Batch [228/428], Loss: 0.4015
Epoch [2/7], Batch [229/428], Loss: 0.0040
Epoch [2/7], Batch [230/428], Loss: 0.0188
Epoch [2/7], Batch [231/428], Loss: 0.4553
Epoch [2/7], Batch [232/428], Loss: 1.1454
Epoch [2/7], Batch [233/428], Loss: 1.8096
Epoch [2/7], Batch [234/428], Loss: 0.0019
Epoch [2/7], Batch [235/428], Loss: 0.0248
Epoch [2/7], Batch [236/428], Loss: 3.1274
Epoch [2/7], Batch [237/428], Loss: 0.5657
Epoch [2/7], Batch [238/428], Loss: 0.0277
Epoch [2/7], Batch [239/428], Loss: 1.8256
Epoch [2/7], Batch [240/428], Loss: 0.0193
Epoch [2/7], Batch [241/428], Loss: 2.0879
Epoch [2/7], Batch [242/428], Loss: 0.1685
Epoch [2/7], Batch [243/428], Loss: 0.0045
Epoch [2/7], Batch [244/428], Loss: 2.3671
Epoch [2/7], Batch [245/428], Loss: 0.0480
Epoch [2/7], Batch [246/428], Loss: 3.0666
Epoch [2/7], Batch [247/428], Loss: 0.0791
Epoch [2/7], Batch [248/428], Loss: 1.8638
Epoch [2/7], Batch [249/428], Loss: 1.0296
Epoch [2/7], Batch [250/428], Loss: 0.5925
Epoch [2/7], Batch [251/428], Loss: 2.1318
Epoch [2/7], Batch [252/428], Loss: 1.4857
Epoch [2/7], Batch [253/428], Loss: 0.3383
Epoch [2/7], Batch [254/428], Loss: 0.0085
Epoch [2/7], Batch [255/428], Loss: 0.5403
Epoch [2/7], Batch [256/428], Loss: 3.3305
Epoch [2/7], Batch [257/428], Loss: 0.0197
Epoch [2/7], Batch [258/428], Loss: 0.0022
Epoch [2/7], Batch [259/428], Loss: 0.0017
Epoch [2/7], Batch [260/428], Loss: 0.0013
Epoch [2/7], Batch [261/428], Loss: 0.2749
Epoch [2/7], Batch [262/428], Loss: 3.7676
Epoch [2/7], Batch [263/428], Loss: 0.6620
Epoch [2/7], Batch [264/428], Loss: 1.2285
Epoch [2/7], Batch [265/428], Loss: 4.0375
Epoch [2/7], Batch [266/428], Loss: 0.7380
Epoch [2/7], Batch [267/428], Loss: 0.3606
Epoch [2/7], Batch [268/428], Loss: 1.5825
Epoch [2/7], Batch [269/428], Loss: 2.0415
Epoch [2/7], Batch [270/428], Loss: 0.0007
Epoch [2/7], Batch [271/428], Loss: 0.9858
Epoch [2/7], Batch [272/428], Loss: 0.0096
Epoch [2/7], Batch [273/428], Loss: 2.4885
Epoch [2/7], Batch [274/428], Loss: 0.0046
Epoch [2/7], Batch [275/428], Loss: 3.8452
Epoch [2/7], Batch [276/428], Loss: 0.0106
Epoch [2/7], Batch [277/428], Loss: 0.0009
Epoch [2/7], Batch [278/428], Loss: 0.9899
Epoch [2/7], Batch [279/428], Loss: 7.0705
Epoch [2/7], Batch [280/428], Loss: 4.8166
Epoch [2/7], Batch [281/428], Loss: 2.0203
Epoch [2/7], Batch [282/428], Loss: 4.2108
Epoch [2/7], Batch [283/428], Loss: 0.0025
Epoch [2/7], Batch [284/428], Loss: 1.5038
Epoch [2/7], Batch [285/428], Loss: 1.2730
Epoch [2/7], Batch [286/428], Loss: 0.0020
Epoch [2/7], Batch [287/428], Loss: 0.0395
Epoch [2/7], Batch [288/428], Loss: 0.0154
Epoch [2/7], Batch [289/428], Loss: 0.0026
Epoch [2/7], Batch [290/428], Loss: 0.0004
Epoch [2/7], Batch [291/428], Loss: 0.0004
Epoch [2/7], Batch [292/428], Loss: 1.1552
Epoch [2/7], Batch [293/428], Loss: 0.4094
Epoch [2/7], Batch [294/428], Loss: 0.0014
Epoch [2/7], Batch [295/428], Loss: 2.2552
Epoch [2/7], Batch [296/428], Loss: 2.2382
Epoch [2/7], Batch [297/428], Loss: 0.0026
Epoch [2/7], Batch [298/428], Loss: 0.0431
Epoch [2/7], Batch [299/428], Loss: 0.8835
Epoch [2/7], Batch [300/428], Loss: 0.2775
Epoch [2/7], Batch [301/428], Loss: 6.4493
Epoch [2/7], Batch [302/428], Loss: 0.0005
Epoch [2/7], Batch [303/428], Loss: 0.0005
Epoch [2/7], Batch [304/428], Loss: 1.3777
Epoch [2/7], Batch [305/428], Loss: 0.0529
Epoch [2/7], Batch [306/428], Loss: 0.5014
Epoch [2/7], Batch [307/428], Loss: 1.4683
Epoch [2/7], Batch [308/428], Loss: 1.8168
Epoch [2/7], Batch [309/428], Loss: 0.4128
Epoch [2/7], Batch [310/428], Loss: 0.8335
Epoch [2/7], Batch [311/428], Loss: 2.7491
Epoch [2/7], Batch [312/428], Loss: 0.0211
Epoch [2/7], Batch [313/428], Loss: 5.2739
Epoch [2/7], Batch [314/428], Loss: 0.0042
Epoch [2/7], Batch [315/428], Loss: 4.1059
Epoch [2/7], Batch [316/428], Loss: 0.1008
Epoch [2/7], Batch [317/428], Loss: 3.0849
Epoch [2/7], Batch [318/428], Loss: 0.9142
Epoch [2/7], Batch [319/428], Loss: 1.4726
Epoch [2/7], Batch [320/428], Loss: 3.5231
Epoch [2/7], Batch [321/428], Loss: 2.1518
Epoch [2/7], Batch [322/428], Loss: 1.4770
Epoch [2/7], Batch [323/428], Loss: 0.0059
Epoch [2/7], Batch [324/428], Loss: 2.1751
Epoch [2/7], Batch [325/428], Loss: 1.6663
Epoch [2/7], Batch [326/428], Loss: 1.4052
Epoch [2/7], Batch [327/428], Loss: 0.9754
Epoch [2/7], Batch [328/428], Loss: 0.0025
Epoch [2/7], Batch [329/428], Loss: 0.0260
Epoch [2/7], Batch [330/428], Loss: 0.0049
Epoch [2/7], Batch [331/428], Loss: 0.6179
Epoch [2/7], Batch [332/428], Loss: 0.1215
Epoch [2/7], Batch [333/428], Loss: 0.0004
Epoch [2/7], Batch [334/428], Loss: 0.0011
Epoch [2/7], Batch [335/428], Loss: 1.1720
Epoch [2/7], Batch [336/428], Loss: 0.0003
Epoch [2/7], Batch [337/428], Loss: 0.2368
Epoch [2/7], Batch [338/428], Loss: 2.6433
Epoch [2/7], Batch [339/428], Loss: 1.5213
Epoch [2/7], Batch [340/428], Loss: 0.9924
Epoch [2/7], Batch [341/428], Loss: 0.0043
Epoch [2/7], Batch [342/428], Loss: 1.0771
Epoch [2/7], Batch [343/428], Loss: 0.0261
Epoch [2/7], Batch [344/428], Loss: 1.1025
Epoch [2/7], Batch [345/428], Loss: 0.0720
Epoch [2/7], Batch [346/428], Loss: 1.2779
Epoch [2/7], Batch [347/428], Loss: 2.6174
Epoch [2/7], Batch [348/428], Loss: 0.0067
Epoch [2/7], Batch [349/428], Loss: 1.8941
Epoch [2/7], Batch [350/428], Loss: 1.8916
Epoch [2/7], Batch [351/428], Loss: 0.0005
Epoch [2/7], Batch [352/428], Loss: 0.0153
Epoch [2/7], Batch [353/428], Loss: 1.0891
Epoch [2/7], Batch [354/428], Loss: 3.2335
Epoch [2/7], Batch [355/428], Loss: 1.0688
Epoch [2/7], Batch [356/428], Loss: 1.3160
Epoch [2/7], Batch [357/428], Loss: 0.0131
Epoch [2/7], Batch [358/428], Loss: 0.0151
Epoch [2/7], Batch [359/428], Loss: 0.0003
Epoch [2/7], Batch [360/428], Loss: 1.1551
Epoch [2/7], Batch [361/428], Loss: 1.7735
Epoch [2/7], Batch [362/428], Loss: 0.3353
Epoch [2/7], Batch [363/428], Loss: 0.0008
Epoch [2/7], Batch [364/428], Loss: 0.0221
Epoch [2/7], Batch [365/428], Loss: 2.4823
Epoch [2/7], Batch [366/428], Loss: 0.3415
Epoch [2/7], Batch [367/428], Loss: 0.0010
Epoch [2/7], Batch [368/428], Loss: 0.3967
Epoch [2/7], Batch [369/428], Loss: 1.8269
Epoch [2/7], Batch [370/428], Loss: 3.3919
Epoch [2/7], Batch [371/428], Loss: 0.0013
Epoch [2/7], Batch [372/428], Loss: 0.5810
Epoch [2/7], Batch [373/428], Loss: 0.0003
Epoch [2/7], Batch [374/428], Loss: 2.4398
Epoch [2/7], Batch [375/428], Loss: 0.8843
Epoch [2/7], Batch [376/428], Loss: 0.0356
Epoch [2/7], Batch [377/428], Loss: 1.6097
Epoch [2/7], Batch [378/428], Loss: 0.6575
Epoch [2/7], Batch [379/428], Loss: 0.8157
Epoch [2/7], Batch [380/428], Loss: 0.0440
Epoch [2/7], Batch [381/428], Loss: 0.8516
Epoch [2/7], Batch [382/428], Loss: 0.9641
Epoch [2/7], Batch [383/428], Loss: 0.2787
Epoch [2/7], Batch [384/428], Loss: 1.0258
Epoch [2/7], Batch [385/428], Loss: 1.0676
Epoch [2/7], Batch [386/428], Loss: 2.8541
Epoch [2/7], Batch [387/428], Loss: 0.0622
Epoch [2/7], Batch [388/428], Loss: 0.0597
Epoch [2/7], Batch [389/428], Loss: 0.9441
Epoch [2/7], Batch [390/428], Loss: 2.7922
Epoch [2/7], Batch [391/428], Loss: 0.0043
Epoch [2/7], Batch [392/428], Loss: 0.4226
Epoch [2/7], Batch [393/428], Loss: 2.9664
Epoch [2/7], Batch [394/428], Loss: 0.0227
Epoch [2/7], Batch [395/428], Loss: 0.0202
Epoch [2/7], Batch [396/428], Loss: 1.7738
Epoch [2/7], Batch [397/428], Loss: 0.4647
Epoch [2/7], Batch [398/428], Loss: 0.0931
Epoch [2/7], Batch [399/428], Loss: 0.0017
Epoch [2/7], Batch [400/428], Loss: 0.9952
Epoch [2/7], Batch [401/428], Loss: 0.2668
Epoch [2/7], Batch [402/428], Loss: 0.0028
Epoch [2/7], Batch [403/428], Loss: 0.4570
Epoch [2/7], Batch [404/428], Loss: 0.0006
Epoch [2/7], Batch [405/428], Loss: 0.9593
Epoch [2/7], Batch [406/428], Loss: 0.6226
Epoch [2/7], Batch [407/428], Loss: 0.0014
Epoch [2/7], Batch [408/428], Loss: 3.6813
Epoch [2/7], Batch [409/428], Loss: 0.0005
Epoch [2/7], Batch [410/428], Loss: 0.0394
Epoch [2/7], Batch [411/428], Loss: 0.2943
Epoch [2/7], Batch [412/428], Loss: 0.0028
Epoch [2/7], Batch [413/428], Loss: 0.0116
Epoch [2/7], Batch [414/428], Loss: 0.0003
Epoch [2/7], Batch [415/428], Loss: 0.4069
Epoch [2/7], Batch [416/428], Loss: 2.2867
Epoch [2/7], Batch [417/428], Loss: 3.3822
Epoch [2/7], Batch [418/428], Loss: 1.1942
Epoch [2/7], Batch [419/428], Loss: 1.7743
Epoch [2/7], Batch [420/428], Loss: 2.7271
Epoch [2/7], Batch [421/428], Loss: 0.2611
Epoch [2/7], Batch [422/428], Loss: 1.1700
Epoch [2/7], Batch [423/428], Loss: 0.1036
Epoch [2/7], Batch [424/428], Loss: 0.5355
Epoch [2/7], Batch [425/428], Loss: 0.8260
Epoch [2/7], Batch [426/428], Loss: 0.0084
Epoch [2/7], Batch [427/428], Loss: 0.0725
Epoch [2/7], Batch [428/428], Loss: 0.9234
Epoch [2] Training Time: 264.42 seconds
Epoch [2/7], Average Loss: 1.0634, Training Accuracy: 0.6121
Epoch [2], Validation Loss: 1.1673, Validation Accuracy: 0.5761
Epoch [2] Validation Time: 9.13 seconds
--------------------------------------------------
Epoch [3/7], Batch [1/428], Loss: 0.2241
Epoch [3/7], Batch [2/428], Loss: 0.0222
Epoch [3/7], Batch [3/428], Loss: 0.0133
Epoch [3/7], Batch [4/428], Loss: 0.4094
Epoch [3/7], Batch [5/428], Loss: 1.8327
Epoch [3/7], Batch [6/428], Loss: 0.0211
Epoch [3/7], Batch [7/428], Loss: 2.0661
Epoch [3/7], Batch [8/428], Loss: 1.0211
Epoch [3/7], Batch [9/428], Loss: 0.7346
Epoch [3/7], Batch [10/428], Loss: 0.2198
Epoch [3/7], Batch [11/428], Loss: 2.5933
Epoch [3/7], Batch [12/428], Loss: 0.8464
Epoch [3/7], Batch [13/428], Loss: 0.6599
Epoch [3/7], Batch [14/428], Loss: 1.1329
Epoch [3/7], Batch [15/428], Loss: 0.7567
Epoch [3/7], Batch [16/428], Loss: 0.0019
Epoch [3/7], Batch [17/428], Loss: 2.5523
Epoch [3/7], Batch [18/428], Loss: 0.7156
Epoch [3/7], Batch [19/428], Loss: 0.0056
Epoch [3/7], Batch [20/428], Loss: 0.0002
Epoch [3/7], Batch [21/428], Loss: 0.6046
Epoch [3/7], Batch [22/428], Loss: 0.7557
Epoch [3/7], Batch [23/428], Loss: 1.3939
Epoch [3/7], Batch [24/428], Loss: 0.0004
Epoch [3/7], Batch [25/428], Loss: 0.0016
Epoch [3/7], Batch [26/428], Loss: 0.0010
Epoch [3/7], Batch [27/428], Loss: 0.5528
Epoch [3/7], Batch [28/428], Loss: 1.1047
Epoch [3/7], Batch [29/428], Loss: 0.0188
Epoch [3/7], Batch [30/428], Loss: 0.0012
Epoch [3/7], Batch [31/428], Loss: 0.1059
Epoch [3/7], Batch [32/428], Loss: 0.7245
Epoch [3/7], Batch [33/428], Loss: 0.0001
Epoch [3/7], Batch [34/428], Loss: 0.0002
Epoch [3/7], Batch [35/428], Loss: 0.4885
Epoch [3/7], Batch [36/428], Loss: 0.0002
Epoch [3/7], Batch [37/428], Loss: 0.0003
Epoch [3/7], Batch [38/428], Loss: 1.7931
Epoch [3/7], Batch [39/428], Loss: 1.2719
Epoch [3/7], Batch [40/428], Loss: 0.6880
Epoch [3/7], Batch [41/428], Loss: 0.0113
Epoch [3/7], Batch [42/428], Loss: 0.0111
Epoch [3/7], Batch [43/428], Loss: 0.1795
Epoch [3/7], Batch [44/428], Loss: 0.0003
Epoch [3/7], Batch [45/428], Loss: 0.0001
Epoch [3/7], Batch [46/428], Loss: 0.1876
Epoch [3/7], Batch [47/428], Loss: 1.0238
Epoch [3/7], Batch [48/428], Loss: 0.0187
Epoch [3/7], Batch [49/428], Loss: 4.8334
Epoch [3/7], Batch [50/428], Loss: 0.2560
Epoch [3/7], Batch [51/428], Loss: 0.0135
Epoch [3/7], Batch [52/428], Loss: 0.0254
Epoch [3/7], Batch [53/428], Loss: 0.9515
Epoch [3/7], Batch [54/428], Loss: 0.0128
Epoch [3/7], Batch [55/428], Loss: 1.5090
Epoch [3/7], Batch [56/428], Loss: 0.5235
Epoch [3/7], Batch [57/428], Loss: 0.0006
Epoch [3/7], Batch [58/428], Loss: 1.2472
Epoch [3/7], Batch [59/428], Loss: 0.8439
Epoch [3/7], Batch [60/428], Loss: 2.0267
Epoch [3/7], Batch [61/428], Loss: 0.8563
Epoch [3/7], Batch [62/428], Loss: 0.0387
Epoch [3/7], Batch [63/428], Loss: 0.3384
Epoch [3/7], Batch [64/428], Loss: 0.0004
Epoch [3/7], Batch [65/428], Loss: 0.0724
Epoch [3/7], Batch [66/428], Loss: 0.0002
Epoch [3/7], Batch [67/428], Loss: 0.6125
Epoch [3/7], Batch [68/428], Loss: 1.1588
Epoch [3/7], Batch [69/428], Loss: 0.9078
Epoch [3/7], Batch [70/428], Loss: 2.5876
Epoch [3/7], Batch [71/428], Loss: 0.6294
Epoch [3/7], Batch [72/428], Loss: 0.0006
Epoch [3/7], Batch [73/428], Loss: 0.0025
Epoch [3/7], Batch [74/428], Loss: 0.6574
Epoch [3/7], Batch [75/428], Loss: 0.0002
Epoch [3/7], Batch [76/428], Loss: 0.0278
Epoch [3/7], Batch [77/428], Loss: 0.0007
Epoch [3/7], Batch [78/428], Loss: 0.0410
Epoch [3/7], Batch [79/428], Loss: 0.0020
Epoch [3/7], Batch [80/428], Loss: 0.1351
Epoch [3/7], Batch [81/428], Loss: 0.4103
Epoch [3/7], Batch [82/428], Loss: 0.0004
Epoch [3/7], Batch [83/428], Loss: 2.8120
Epoch [3/7], Batch [84/428], Loss: 0.5618
Epoch [3/7], Batch [85/428], Loss: 3.3310
Epoch [3/7], Batch [86/428], Loss: 1.2874
Epoch [3/7], Batch [87/428], Loss: 0.4118
Epoch [3/7], Batch [88/428], Loss: 0.0001
Epoch [3/7], Batch [89/428], Loss: 0.0292
Epoch [3/7], Batch [90/428], Loss: 0.0005
Epoch [3/7], Batch [91/428], Loss: 0.3367
Epoch [3/7], Batch [92/428], Loss: 0.3057
Epoch [3/7], Batch [93/428], Loss: 1.0260
Epoch [3/7], Batch [94/428], Loss: 0.0013
Epoch [3/7], Batch [95/428], Loss: 4.0783
Epoch [3/7], Batch [96/428], Loss: 0.0005
Epoch [3/7], Batch [97/428], Loss: 0.5348
Epoch [3/7], Batch [98/428], Loss: 1.5162
Epoch [3/7], Batch [99/428], Loss: 1.6823
Epoch [3/7], Batch [100/428], Loss: 0.0005
Epoch [3/7], Batch [101/428], Loss: 0.4418
Epoch [3/7], Batch [102/428], Loss: 0.3746
Epoch [3/7], Batch [103/428], Loss: 0.2174
Epoch [3/7], Batch [104/428], Loss: 3.7712
Epoch [3/7], Batch [105/428], Loss: 1.5966
Epoch [3/7], Batch [106/428], Loss: 0.1832
Epoch [3/7], Batch [107/428], Loss: 0.0077
Epoch [3/7], Batch [108/428], Loss: 0.0001
Epoch [3/7], Batch [109/428], Loss: 0.8382
Epoch [3/7], Batch [110/428], Loss: 0.0011
Epoch [3/7], Batch [111/428], Loss: 0.4789
Epoch [3/7], Batch [112/428], Loss: 0.2265
Epoch [3/7], Batch [113/428], Loss: 0.0598
Epoch [3/7], Batch [114/428], Loss: 0.0007
Epoch [3/7], Batch [115/428], Loss: 0.9694
Epoch [3/7], Batch [116/428], Loss: 1.1142
Epoch [3/7], Batch [117/428], Loss: 0.0091
Epoch [3/7], Batch [118/428], Loss: 1.3205
Epoch [3/7], Batch [119/428], Loss: 0.9077
Epoch [3/7], Batch [120/428], Loss: 0.6880
Epoch [3/7], Batch [121/428], Loss: 0.2746
Epoch [3/7], Batch [122/428], Loss: 1.3203
Epoch [3/7], Batch [123/428], Loss: 0.0046
Epoch [3/7], Batch [124/428], Loss: 0.0006
Epoch [3/7], Batch [125/428], Loss: 3.6599
Epoch [3/7], Batch [126/428], Loss: 1.2568
Epoch [3/7], Batch [127/428], Loss: 0.0208
Epoch [3/7], Batch [128/428], Loss: 2.6199
Epoch [3/7], Batch [129/428], Loss: 1.2688
Epoch [3/7], Batch [130/428], Loss: 0.0544
Epoch [3/7], Batch [131/428], Loss: 1.2285
Epoch [3/7], Batch [132/428], Loss: 0.9005
Epoch [3/7], Batch [133/428], Loss: 2.2514
Epoch [3/7], Batch [134/428], Loss: 0.9977
Epoch [3/7], Batch [135/428], Loss: 0.3017
Epoch [3/7], Batch [136/428], Loss: 0.8470
Epoch [3/7], Batch [137/428], Loss: 0.0001
Epoch [3/7], Batch [138/428], Loss: 0.0005
Epoch [3/7], Batch [139/428], Loss: 0.0159
Epoch [3/7], Batch [140/428], Loss: 0.0029
Epoch [3/7], Batch [141/428], Loss: 0.0080
Epoch [3/7], Batch [142/428], Loss: 0.0002
Epoch [3/7], Batch [143/428], Loss: 0.8352
Epoch [3/7], Batch [144/428], Loss: 0.0053
Epoch [3/7], Batch [145/428], Loss: 0.5228
Epoch [3/7], Batch [146/428], Loss: 0.5518
Epoch [3/7], Batch [147/428], Loss: 0.0003
Epoch [3/7], Batch [148/428], Loss: 0.3556
Epoch [3/7], Batch [149/428], Loss: 0.3510
Epoch [3/7], Batch [150/428], Loss: 4.9224
Epoch [3/7], Batch [151/428], Loss: 1.5775
Epoch [3/7], Batch [152/428], Loss: 3.0190
Epoch [3/7], Batch [153/428], Loss: 0.2856
Epoch [3/7], Batch [154/428], Loss: 6.1229
Epoch [3/7], Batch [155/428], Loss: 0.6597
Epoch [3/7], Batch [156/428], Loss: 0.8141
Epoch [3/7], Batch [157/428], Loss: 0.3466
Epoch [3/7], Batch [158/428], Loss: 5.2076
Epoch [3/7], Batch [159/428], Loss: 1.4912
Epoch [3/7], Batch [160/428], Loss: 0.0967
Epoch [3/7], Batch [161/428], Loss: 2.3172
Epoch [3/7], Batch [162/428], Loss: 0.4952
Epoch [3/7], Batch [163/428], Loss: 2.0946
Epoch [3/7], Batch [164/428], Loss: 0.8317
Epoch [3/7], Batch [165/428], Loss: 0.0006
Epoch [3/7], Batch [166/428], Loss: 0.2695
Epoch [3/7], Batch [167/428], Loss: 0.4601
Epoch [3/7], Batch [168/428], Loss: 1.3530
Epoch [3/7], Batch [169/428], Loss: 0.0335
Epoch [3/7], Batch [170/428], Loss: 0.6207
Epoch [3/7], Batch [171/428], Loss: 0.3446
Epoch [3/7], Batch [172/428], Loss: 0.0003
Epoch [3/7], Batch [173/428], Loss: 0.9287
Epoch [3/7], Batch [174/428], Loss: 1.1060
Epoch [3/7], Batch [175/428], Loss: 0.6293
Epoch [3/7], Batch [176/428], Loss: 1.0852
Epoch [3/7], Batch [177/428], Loss: 1.9265
Epoch [3/7], Batch [178/428], Loss: 0.3731
Epoch [3/7], Batch [179/428], Loss: 0.0008
Epoch [3/7], Batch [180/428], Loss: 0.6876
Epoch [3/7], Batch [181/428], Loss: 0.5871
Epoch [3/7], Batch [182/428], Loss: 0.7942
Epoch [3/7], Batch [183/428], Loss: 0.0028
Epoch [3/7], Batch [184/428], Loss: 2.8160
Epoch [3/7], Batch [185/428], Loss: 1.4950
Epoch [3/7], Batch [186/428], Loss: 0.0041
Epoch [3/7], Batch [187/428], Loss: 0.4782
Epoch [3/7], Batch [188/428], Loss: 1.4894
Epoch [3/7], Batch [189/428], Loss: 0.0005
Epoch [3/7], Batch [190/428], Loss: 0.0803
Epoch [3/7], Batch [191/428], Loss: 0.0003
Epoch [3/7], Batch [192/428], Loss: 0.1823
Epoch [3/7], Batch [193/428], Loss: 0.6588
Epoch [3/7], Batch [194/428], Loss: 0.4900
Epoch [3/7], Batch [195/428], Loss: 0.4384
Epoch [3/7], Batch [196/428], Loss: 0.0006
Epoch [3/7], Batch [197/428], Loss: 1.1897
Epoch [3/7], Batch [198/428], Loss: 1.0995
Epoch [3/7], Batch [199/428], Loss: 4.9883
Epoch [3/7], Batch [200/428], Loss: 1.8117
Epoch [3/7], Batch [201/428], Loss: 0.9413
Epoch [3/7], Batch [202/428], Loss: 0.0578
Epoch [3/7], Batch [203/428], Loss: 2.6738
Epoch [3/7], Batch [204/428], Loss: 0.0881
Epoch [3/7], Batch [205/428], Loss: 0.0079
Epoch [3/7], Batch [206/428], Loss: 0.5606
Epoch [3/7], Batch [207/428], Loss: 0.4821
Epoch [3/7], Batch [208/428], Loss: 0.0022
Epoch [3/7], Batch [209/428], Loss: 0.0025
Epoch [3/7], Batch [210/428], Loss: 0.3868
Epoch [3/7], Batch [211/428], Loss: 0.0020
Epoch [3/7], Batch [212/428], Loss: 0.0007
Epoch [3/7], Batch [213/428], Loss: 0.0140
Epoch [3/7], Batch [214/428], Loss: 3.7578
Epoch [3/7], Batch [215/428], Loss: 0.1906
Epoch [3/7], Batch [216/428], Loss: 0.0008
Epoch [3/7], Batch [217/428], Loss: 0.0005
Epoch [3/7], Batch [218/428], Loss: 0.0047
Epoch [3/7], Batch [219/428], Loss: 0.3063
Epoch [3/7], Batch [220/428], Loss: 0.0002
Epoch [3/7], Batch [221/428], Loss: 0.3922
Epoch [3/7], Batch [222/428], Loss: 0.0109
Epoch [3/7], Batch [223/428], Loss: 0.0443
Epoch [3/7], Batch [224/428], Loss: 0.4468
Epoch [3/7], Batch [225/428], Loss: 0.0015
Epoch [3/7], Batch [226/428], Loss: 0.1456
Epoch [3/7], Batch [227/428], Loss: 0.0026
Epoch [3/7], Batch [228/428], Loss: 1.2152
Epoch [3/7], Batch [229/428], Loss: 0.2110
Epoch [3/7], Batch [230/428], Loss: 0.0002
Epoch [3/7], Batch [231/428], Loss: 0.0039
Epoch [3/7], Batch [232/428], Loss: 1.0598
Epoch [3/7], Batch [233/428], Loss: 0.7454
Epoch [3/7], Batch [234/428], Loss: 1.2022
Epoch [3/7], Batch [235/428], Loss: 0.1893
Epoch [3/7], Batch [236/428], Loss: 0.7172
Epoch [3/7], Batch [237/428], Loss: 0.0834
Epoch [3/7], Batch [238/428], Loss: 0.1713
Epoch [3/7], Batch [239/428], Loss: 0.0165
Epoch [3/7], Batch [240/428], Loss: 0.5324
Epoch [3/7], Batch [241/428], Loss: 0.7765
Epoch [3/7], Batch [242/428], Loss: 1.0111
Epoch [3/7], Batch [243/428], Loss: 0.0164
Epoch [3/7], Batch [244/428], Loss: 0.0044
Epoch [3/7], Batch [245/428], Loss: 1.6435
Epoch [3/7], Batch [246/428], Loss: 0.0002
Epoch [3/7], Batch [247/428], Loss: 1.6243
Epoch [3/7], Batch [248/428], Loss: 0.0003
Epoch [3/7], Batch [249/428], Loss: 0.0023
Epoch [3/7], Batch [250/428], Loss: 0.0036
Epoch [3/7], Batch [251/428], Loss: 0.0004
Epoch [3/7], Batch [252/428], Loss: 1.3712
Epoch [3/7], Batch [253/428], Loss: 1.5900
Epoch [3/7], Batch [254/428], Loss: 1.7777
Epoch [3/7], Batch [255/428], Loss: 0.0012
Epoch [3/7], Batch [256/428], Loss: 0.0449
Epoch [3/7], Batch [257/428], Loss: 0.1012
Epoch [3/7], Batch [258/428], Loss: 0.1502
Epoch [3/7], Batch [259/428], Loss: 3.2678
Epoch [3/7], Batch [260/428], Loss: 0.0006
Epoch [3/7], Batch [261/428], Loss: 0.7014
Epoch [3/7], Batch [262/428], Loss: 0.1763
Epoch [3/7], Batch [263/428], Loss: 0.9259
Epoch [3/7], Batch [264/428], Loss: 0.7847
Epoch [3/7], Batch [265/428], Loss: 0.2231
Epoch [3/7], Batch [266/428], Loss: 1.5113
Epoch [3/7], Batch [267/428], Loss: 0.0038
Epoch [3/7], Batch [268/428], Loss: 0.7694
Epoch [3/7], Batch [269/428], Loss: 0.0042
Epoch [3/7], Batch [270/428], Loss: 0.0001
Epoch [3/7], Batch [271/428], Loss: 0.5515
Epoch [3/7], Batch [272/428], Loss: 0.0035
Epoch [3/7], Batch [273/428], Loss: 0.4100
Epoch [3/7], Batch [274/428], Loss: 0.4664
Epoch [3/7], Batch [275/428], Loss: 0.1462
Epoch [3/7], Batch [276/428], Loss: 0.8470
Epoch [3/7], Batch [277/428], Loss: 1.5842
Epoch [3/7], Batch [278/428], Loss: 0.0001
Epoch [3/7], Batch [279/428], Loss: 3.2652
Epoch [3/7], Batch [280/428], Loss: 3.3325
Epoch [3/7], Batch [281/428], Loss: 0.7140
Epoch [3/7], Batch [282/428], Loss: 0.0003
Epoch [3/7], Batch [283/428], Loss: 1.1082
Epoch [3/7], Batch [284/428], Loss: 3.4797
Epoch [3/7], Batch [285/428], Loss: 0.0001
Epoch [3/7], Batch [286/428], Loss: 0.4559
Epoch [3/7], Batch [287/428], Loss: 0.1171
Epoch [3/7], Batch [288/428], Loss: 0.0103
Epoch [3/7], Batch [289/428], Loss: 0.0175
Epoch [3/7], Batch [290/428], Loss: 0.0003
Epoch [3/7], Batch [291/428], Loss: 1.4258
Epoch [3/7], Batch [292/428], Loss: 0.1450
Epoch [3/7], Batch [293/428], Loss: 0.0004
Epoch [3/7], Batch [294/428], Loss: 0.0006
Epoch [3/7], Batch [295/428], Loss: 0.0001
Epoch [3/7], Batch [296/428], Loss: 5.9847
Epoch [3/7], Batch [297/428], Loss: 0.0002
Epoch [3/7], Batch [298/428], Loss: 0.0029
Epoch [3/7], Batch [299/428], Loss: 1.5537
Epoch [3/7], Batch [300/428], Loss: 0.0369
Epoch [3/7], Batch [301/428], Loss: 0.8794
Epoch [3/7], Batch [302/428], Loss: 0.0005
Epoch [3/7], Batch [303/428], Loss: 1.5810
Epoch [3/7], Batch [304/428], Loss: 0.4696
Epoch [3/7], Batch [305/428], Loss: 0.0005
Epoch [3/7], Batch [306/428], Loss: 0.0146
Epoch [3/7], Batch [307/428], Loss: 0.0297
Epoch [3/7], Batch [308/428], Loss: 3.2129
Epoch [3/7], Batch [309/428], Loss: 0.2640
Epoch [3/7], Batch [310/428], Loss: 0.0066
Epoch [3/7], Batch [311/428], Loss: 0.0772
Epoch [3/7], Batch [312/428], Loss: 0.0003
Epoch [3/7], Batch [313/428], Loss: 0.3898
Epoch [3/7], Batch [314/428], Loss: 0.0138
Epoch [3/7], Batch [315/428], Loss: 0.3332
Epoch [3/7], Batch [316/428], Loss: 0.8489
Epoch [3/7], Batch [317/428], Loss: 0.6675
Epoch [3/7], Batch [318/428], Loss: 0.1328
Epoch [3/7], Batch [319/428], Loss: 0.0003
Epoch [3/7], Batch [320/428], Loss: 0.1358
Epoch [3/7], Batch [321/428], Loss: 0.0707
Epoch [3/7], Batch [322/428], Loss: 0.0011
Epoch [3/7], Batch [323/428], Loss: 0.0011
Epoch [3/7], Batch [324/428], Loss: 0.0171
Epoch [3/7], Batch [325/428], Loss: 0.5297
Epoch [3/7], Batch [326/428], Loss: 1.1159
Epoch [3/7], Batch [327/428], Loss: 0.0530
Epoch [3/7], Batch [328/428], Loss: 0.0005
Epoch [3/7], Batch [329/428], Loss: 3.6891
Epoch [3/7], Batch [330/428], Loss: 0.3506
Epoch [3/7], Batch [331/428], Loss: 0.0052
Epoch [3/7], Batch [332/428], Loss: 0.0002
Epoch [3/7], Batch [333/428], Loss: 0.1317
Epoch [3/7], Batch [334/428], Loss: 2.4390
Epoch [3/7], Batch [335/428], Loss: 0.1821
Epoch [3/7], Batch [336/428], Loss: 0.6255
Epoch [3/7], Batch [337/428], Loss: 0.0933
Epoch [3/7], Batch [338/428], Loss: 1.7871
Epoch [3/7], Batch [339/428], Loss: 1.6404
Epoch [3/7], Batch [340/428], Loss: 0.9705
Epoch [3/7], Batch [341/428], Loss: 0.1175
Epoch [3/7], Batch [342/428], Loss: 1.7109
Epoch [3/7], Batch [343/428], Loss: 0.0004
Epoch [3/7], Batch [344/428], Loss: 0.0011
Epoch [3/7], Batch [345/428], Loss: 0.0002
Epoch [3/7], Batch [346/428], Loss: 0.0032
Epoch [3/7], Batch [347/428], Loss: 3.4717
Epoch [3/7], Batch [348/428], Loss: 2.3262
Epoch [3/7], Batch [349/428], Loss: 1.2994
Epoch [3/7], Batch [350/428], Loss: 0.0627
Epoch [3/7], Batch [351/428], Loss: 0.2397
Epoch [3/7], Batch [352/428], Loss: 0.5999
Epoch [3/7], Batch [353/428], Loss: 0.7367
Epoch [3/7], Batch [354/428], Loss: 0.0141
Epoch [3/7], Batch [355/428], Loss: 0.6195
Epoch [3/7], Batch [356/428], Loss: 1.3122
Epoch [3/7], Batch [357/428], Loss: 0.6433
Epoch [3/7], Batch [358/428], Loss: 2.5437
Epoch [3/7], Batch [359/428], Loss: 0.0002
Epoch [3/7], Batch [360/428], Loss: 0.0026
Epoch [3/7], Batch [361/428], Loss: 0.1043
Epoch [3/7], Batch [362/428], Loss: 0.2405
Epoch [3/7], Batch [363/428], Loss: 2.6098
Epoch [3/7], Batch [364/428], Loss: 1.3695
Epoch [3/7], Batch [365/428], Loss: 0.5197
Epoch [3/7], Batch [366/428], Loss: 0.0009
Epoch [3/7], Batch [367/428], Loss: 0.0008
Epoch [3/7], Batch [368/428], Loss: 1.1619
Epoch [3/7], Batch [369/428], Loss: 0.1192
Epoch [3/7], Batch [370/428], Loss: 0.1107
Epoch [3/7], Batch [371/428], Loss: 1.3623
Epoch [3/7], Batch [372/428], Loss: 0.4369
Epoch [3/7], Batch [373/428], Loss: 2.5414
Epoch [3/7], Batch [374/428], Loss: 1.3447
Epoch [3/7], Batch [375/428], Loss: 0.0810
Epoch [3/7], Batch [376/428], Loss: 0.0002
Epoch [3/7], Batch [377/428], Loss: 1.1008
Epoch [3/7], Batch [378/428], Loss: 0.0008
Epoch [3/7], Batch [379/428], Loss: 0.0145
Epoch [3/7], Batch [380/428], Loss: 0.0642
Epoch [3/7], Batch [381/428], Loss: 0.6990
Epoch [3/7], Batch [382/428], Loss: 0.0108
Epoch [3/7], Batch [383/428], Loss: 0.9196
Epoch [3/7], Batch [384/428], Loss: 0.3362
Epoch [3/7], Batch [385/428], Loss: 0.0257
Epoch [3/7], Batch [386/428], Loss: 1.3351
Epoch [3/7], Batch [387/428], Loss: 0.0003
Epoch [3/7], Batch [388/428], Loss: 0.2631
Epoch [3/7], Batch [389/428], Loss: 0.2715
Epoch [3/7], Batch [390/428], Loss: 0.0021
Epoch [3/7], Batch [391/428], Loss: 0.0820
Epoch [3/7], Batch [392/428], Loss: 3.0222
Epoch [3/7], Batch [393/428], Loss: 0.1054
Epoch [3/7], Batch [394/428], Loss: 0.6534
Epoch [3/7], Batch [395/428], Loss: 2.8196
Epoch [3/7], Batch [396/428], Loss: 0.1255
Epoch [3/7], Batch [397/428], Loss: 2.3881
Epoch [3/7], Batch [398/428], Loss: 0.0799
Epoch [3/7], Batch [399/428], Loss: 0.1356
Epoch [3/7], Batch [400/428], Loss: 0.0916
Epoch [3/7], Batch [401/428], Loss: 0.0594
Epoch [3/7], Batch [402/428], Loss: 1.5738
Epoch [3/7], Batch [403/428], Loss: 1.0853
Epoch [3/7], Batch [404/428], Loss: 0.0001
Epoch [3/7], Batch [405/428], Loss: 0.7918
Epoch [3/7], Batch [406/428], Loss: 2.2756
Epoch [3/7], Batch [407/428], Loss: 0.0010
Epoch [3/7], Batch [408/428], Loss: 0.0006
Epoch [3/7], Batch [409/428], Loss: 0.0150
Epoch [3/7], Batch [410/428], Loss: 0.4222
Epoch [3/7], Batch [411/428], Loss: 0.0006
Epoch [3/7], Batch [412/428], Loss: 0.0003
Epoch [3/7], Batch [413/428], Loss: 0.5249
Epoch [3/7], Batch [414/428], Loss: 0.0997
Epoch [3/7], Batch [415/428], Loss: 0.0003
Epoch [3/7], Batch [416/428], Loss: 0.1058
Epoch [3/7], Batch [417/428], Loss: 0.2082
Epoch [3/7], Batch [418/428], Loss: 0.0004
Epoch [3/7], Batch [419/428], Loss: 0.0006
Epoch [3/7], Batch [420/428], Loss: 0.0002
Epoch [3/7], Batch [421/428], Loss: 1.1084
Epoch [3/7], Batch [422/428], Loss: 0.3010
Epoch [3/7], Batch [423/428], Loss: 0.0003
Epoch [3/7], Batch [424/428], Loss: 2.3922
Epoch [3/7], Batch [425/428], Loss: 0.0017
Epoch [3/7], Batch [426/428], Loss: 0.6254
Epoch [3/7], Batch [427/428], Loss: 0.1063
Epoch [3/7], Batch [428/428], Loss: 1.4906
Epoch [3] Training Time: 272.13 seconds
Epoch [3/7], Average Loss: 0.6916, Training Accuracy: 0.7523
Epoch [3], Validation Loss: 1.1990, Validation Accuracy: 0.6417
Epoch [3] Validation Time: 9.13 seconds
--------------------------------------------------
Epoch [4/7], Batch [1/428], Loss: 0.1437
Epoch [4/7], Batch [2/428], Loss: 0.9128
Epoch [4/7], Batch [3/428], Loss: 0.3724
Epoch [4/7], Batch [4/428], Loss: 0.0004
Epoch [4/7], Batch [5/428], Loss: 3.1389
Epoch [4/7], Batch [6/428], Loss: 0.0024
Epoch [4/7], Batch [7/428], Loss: 0.0001
Epoch [4/7], Batch [8/428], Loss: 3.5128
Epoch [4/7], Batch [9/428], Loss: 0.0013
Epoch [4/7], Batch [10/428], Loss: 0.3118
Epoch [4/7], Batch [11/428], Loss: 0.0001
Epoch [4/7], Batch [12/428], Loss: 0.1358
Epoch [4/7], Batch [13/428], Loss: 0.0006
Epoch [4/7], Batch [14/428], Loss: 1.9014
Epoch [4/7], Batch [15/428], Loss: 0.5795
Epoch [4/7], Batch [16/428], Loss: 0.0001
Epoch [4/7], Batch [17/428], Loss: 3.6163
Epoch [4/7], Batch [18/428], Loss: 0.2493
Epoch [4/7], Batch [19/428], Loss: 1.2921
Epoch [4/7], Batch [20/428], Loss: 0.0750
Epoch [4/7], Batch [21/428], Loss: 0.5674
Epoch [4/7], Batch [22/428], Loss: 1.5878
Epoch [4/7], Batch [23/428], Loss: 0.0034
Epoch [4/7], Batch [24/428], Loss: 2.3689
Epoch [4/7], Batch [25/428], Loss: 0.0002
Epoch [4/7], Batch [26/428], Loss: 0.0015
Epoch [4/7], Batch [27/428], Loss: 0.0976
Epoch [4/7], Batch [28/428], Loss: 0.0018
Epoch [4/7], Batch [29/428], Loss: 1.8681
Epoch [4/7], Batch [30/428], Loss: 0.5189
Epoch [4/7], Batch [31/428], Loss: 0.1363
Epoch [4/7], Batch [32/428], Loss: 0.2661
Epoch [4/7], Batch [33/428], Loss: 0.0765
Epoch [4/7], Batch [34/428], Loss: 0.0507
Epoch [4/7], Batch [35/428], Loss: 0.0275
Epoch [4/7], Batch [36/428], Loss: 1.9774
Epoch [4/7], Batch [37/428], Loss: 0.0002
Epoch [4/7], Batch [38/428], Loss: 0.6111
Epoch [4/7], Batch [39/428], Loss: 0.6128
Epoch [4/7], Batch [40/428], Loss: 0.0737
Epoch [4/7], Batch [41/428], Loss: 0.0007
Epoch [4/7], Batch [42/428], Loss: 0.0109
Epoch [4/7], Batch [43/428], Loss: 0.0044
Epoch [4/7], Batch [44/428], Loss: 0.6588
Epoch [4/7], Batch [45/428], Loss: 0.5804
Epoch [4/7], Batch [46/428], Loss: 1.2657
Epoch [4/7], Batch [47/428], Loss: 1.5389
Epoch [4/7], Batch [48/428], Loss: 0.5848
Epoch [4/7], Batch [49/428], Loss: 0.1518
Epoch [4/7], Batch [50/428], Loss: 0.0943
Epoch [4/7], Batch [51/428], Loss: 0.6514
Epoch [4/7], Batch [52/428], Loss: 0.0003
Epoch [4/7], Batch [53/428], Loss: 0.1931
Epoch [4/7], Batch [54/428], Loss: 0.3835
Epoch [4/7], Batch [55/428], Loss: 0.0049
Epoch [4/7], Batch [56/428], Loss: 0.9528
Epoch [4/7], Batch [57/428], Loss: 0.9670
Epoch [4/7], Batch [58/428], Loss: 0.0004
Epoch [4/7], Batch [59/428], Loss: 0.0456
Epoch [4/7], Batch [60/428], Loss: 0.4855
Epoch [4/7], Batch [61/428], Loss: 0.7116
Epoch [4/7], Batch [62/428], Loss: 1.8707
Epoch [4/7], Batch [63/428], Loss: 0.6163
Epoch [4/7], Batch [64/428], Loss: 0.0467
Epoch [4/7], Batch [65/428], Loss: 0.0001
Epoch [4/7], Batch [66/428], Loss: 0.0016
Epoch [4/7], Batch [67/428], Loss: 1.2518
Epoch [4/7], Batch [68/428], Loss: 0.0303
Epoch [4/7], Batch [69/428], Loss: 0.0001
Epoch [4/7], Batch [70/428], Loss: 1.3947
Epoch [4/7], Batch [71/428], Loss: 0.1687
Epoch [4/7], Batch [72/428], Loss: 0.0006
Epoch [4/7], Batch [73/428], Loss: 0.0001
Epoch [4/7], Batch [74/428], Loss: 0.0166
Epoch [4/7], Batch [75/428], Loss: 0.0002
Epoch [4/7], Batch [76/428], Loss: 0.3024
Epoch [4/7], Batch [77/428], Loss: 0.0004
Epoch [4/7], Batch [78/428], Loss: 0.0374
Epoch [4/7], Batch [79/428], Loss: 0.0004
Epoch [4/7], Batch [80/428], Loss: 0.0010
Epoch [4/7], Batch [81/428], Loss: 0.0001
Epoch [4/7], Batch [82/428], Loss: 2.1307
Epoch [4/7], Batch [83/428], Loss: 0.8498
Epoch [4/7], Batch [84/428], Loss: 3.6514
Epoch [4/7], Batch [85/428], Loss: 0.0002
Epoch [4/7], Batch [86/428], Loss: 0.0351
Epoch [4/7], Batch [87/428], Loss: 0.0691
Epoch [4/7], Batch [88/428], Loss: 0.0029
Epoch [4/7], Batch [89/428], Loss: 1.6073
Epoch [4/7], Batch [90/428], Loss: 0.6622
Epoch [4/7], Batch [91/428], Loss: 0.0844
Epoch [4/7], Batch [92/428], Loss: 0.2721
Epoch [4/7], Batch [93/428], Loss: 0.0013
Epoch [4/7], Batch [94/428], Loss: 0.9345
Epoch [4/7], Batch [95/428], Loss: 0.3445
Epoch [4/7], Batch [96/428], Loss: 0.2842
Epoch [4/7], Batch [97/428], Loss: 0.0864
Epoch [4/7], Batch [98/428], Loss: 0.9463
Epoch [4/7], Batch [99/428], Loss: 2.1399
Epoch [4/7], Batch [100/428], Loss: 2.8981
Epoch [4/7], Batch [101/428], Loss: 0.6495
Epoch [4/7], Batch [102/428], Loss: 0.1497
Epoch [4/7], Batch [103/428], Loss: 0.0818
Epoch [4/7], Batch [104/428], Loss: 0.1559
Epoch [4/7], Batch [105/428], Loss: 2.0551
Epoch [4/7], Batch [106/428], Loss: 0.3181
Epoch [4/7], Batch [107/428], Loss: 0.7254
Epoch [4/7], Batch [108/428], Loss: 0.0285
Epoch [4/7], Batch [109/428], Loss: 0.3957
Epoch [4/7], Batch [110/428], Loss: 0.0010
Epoch [4/7], Batch [111/428], Loss: 0.5671
Epoch [4/7], Batch [112/428], Loss: 0.0005
Epoch [4/7], Batch [113/428], Loss: 0.0040
Epoch [4/7], Batch [114/428], Loss: 0.0338
Epoch [4/7], Batch [115/428], Loss: 0.9529
Epoch [4/7], Batch [116/428], Loss: 0.0040
Epoch [4/7], Batch [117/428], Loss: 0.0122
Epoch [4/7], Batch [118/428], Loss: 0.0041
Epoch [4/7], Batch [119/428], Loss: 0.2446
Epoch [4/7], Batch [120/428], Loss: 1.1238
Epoch [4/7], Batch [121/428], Loss: 2.8011
Epoch [4/7], Batch [122/428], Loss: 0.6169
Epoch [4/7], Batch [123/428], Loss: 0.0003
Epoch [4/7], Batch [124/428], Loss: 0.0766
Epoch [4/7], Batch [125/428], Loss: 0.0008
Epoch [4/7], Batch [126/428], Loss: 0.0613
Epoch [4/7], Batch [127/428], Loss: 0.0034
Epoch [4/7], Batch [128/428], Loss: 0.1013
Epoch [4/7], Batch [129/428], Loss: 0.0004
Epoch [4/7], Batch [130/428], Loss: 3.2648
Epoch [4/7], Batch [131/428], Loss: 0.0001
Epoch [4/7], Batch [132/428], Loss: 0.2328
Epoch [4/7], Batch [133/428], Loss: 0.2858
Epoch [4/7], Batch [134/428], Loss: 3.5679
Epoch [4/7], Batch [135/428], Loss: 1.1453
Epoch [4/7], Batch [136/428], Loss: 0.0269
Epoch [4/7], Batch [137/428], Loss: 0.0730
Epoch [4/7], Batch [138/428], Loss: 0.0001
Epoch [4/7], Batch [139/428], Loss: 0.3461
Epoch [4/7], Batch [140/428], Loss: 0.0972
Epoch [4/7], Batch [141/428], Loss: 0.0550
Epoch [4/7], Batch [142/428], Loss: 0.0486
Epoch [4/7], Batch [143/428], Loss: 0.0068
Epoch [4/7], Batch [144/428], Loss: 0.0006
Epoch [4/7], Batch [145/428], Loss: 0.1404
Epoch [4/7], Batch [146/428], Loss: 0.3859
Epoch [4/7], Batch [147/428], Loss: 0.0001
Epoch [4/7], Batch [148/428], Loss: 3.0521
Epoch [4/7], Batch [149/428], Loss: 1.8995
Epoch [4/7], Batch [150/428], Loss: 0.9135
Epoch [4/7], Batch [151/428], Loss: 0.0316
Epoch [4/7], Batch [152/428], Loss: 0.0171
Epoch [4/7], Batch [153/428], Loss: 0.0130
Epoch [4/7], Batch [154/428], Loss: 0.0000
Epoch [4/7], Batch [155/428], Loss: 0.0008
Epoch [4/7], Batch [156/428], Loss: 0.1383
Epoch [4/7], Batch [157/428], Loss: 0.4416
Epoch [4/7], Batch [158/428], Loss: 0.0058
Epoch [4/7], Batch [159/428], Loss: 0.0122
Epoch [4/7], Batch [160/428], Loss: 1.3001
Epoch [4/7], Batch [161/428], Loss: 3.7833
Epoch [4/7], Batch [162/428], Loss: 0.4090
Epoch [4/7], Batch [163/428], Loss: 0.0005
Epoch [4/7], Batch [164/428], Loss: 0.0005
Epoch [4/7], Batch [165/428], Loss: 0.0704
Epoch [4/7], Batch [166/428], Loss: 0.3010
Epoch [4/7], Batch [167/428], Loss: 0.0073
Epoch [4/7], Batch [168/428], Loss: 0.0627
Epoch [4/7], Batch [169/428], Loss: 0.0036
Epoch [4/7], Batch [170/428], Loss: 0.0331
Epoch [4/7], Batch [171/428], Loss: 0.0719
Epoch [4/7], Batch [172/428], Loss: 0.0005
Epoch [4/7], Batch [173/428], Loss: 0.0084
Epoch [4/7], Batch [174/428], Loss: 0.8837
Epoch [4/7], Batch [175/428], Loss: 0.6970
Epoch [4/7], Batch [176/428], Loss: 0.0004
Epoch [4/7], Batch [177/428], Loss: 0.0322
Epoch [4/7], Batch [178/428], Loss: 0.1773
Epoch [4/7], Batch [179/428], Loss: 0.0004
Epoch [4/7], Batch [180/428], Loss: 0.0679
Epoch [4/7], Batch [181/428], Loss: 0.0001
Epoch [4/7], Batch [182/428], Loss: 0.0016
Epoch [4/7], Batch [183/428], Loss: 0.7774
Epoch [4/7], Batch [184/428], Loss: 0.2039
Epoch [4/7], Batch [185/428], Loss: 1.9488
Epoch [4/7], Batch [186/428], Loss: 1.5810
Epoch [4/7], Batch [187/428], Loss: 2.0043
Epoch [4/7], Batch [188/428], Loss: 0.4665
Epoch [4/7], Batch [189/428], Loss: 0.0008
Epoch [4/7], Batch [190/428], Loss: 0.1390
Epoch [4/7], Batch [191/428], Loss: 9.4204
Epoch [4/7], Batch [192/428], Loss: 0.0045
Epoch [4/7], Batch [193/428], Loss: 4.2841
Epoch [4/7], Batch [194/428], Loss: 1.2159
Epoch [4/7], Batch [195/428], Loss: 0.0002
Epoch [4/7], Batch [196/428], Loss: 0.0126
Epoch [4/7], Batch [197/428], Loss: 0.0001
Epoch [4/7], Batch [198/428], Loss: 0.0001
Epoch [4/7], Batch [199/428], Loss: 2.4294
Epoch [4/7], Batch [200/428], Loss: 0.0319
Epoch [4/7], Batch [201/428], Loss: 2.0752
Epoch [4/7], Batch [202/428], Loss: 0.1638
Epoch [4/7], Batch [203/428], Loss: 0.0002
Epoch [4/7], Batch [204/428], Loss: 0.0011
Epoch [4/7], Batch [205/428], Loss: 0.0017
Epoch [4/7], Batch [206/428], Loss: 0.0001
Epoch [4/7], Batch [207/428], Loss: 0.2942
Epoch [4/7], Batch [208/428], Loss: 0.7140
Epoch [4/7], Batch [209/428], Loss: 0.0005
Epoch [4/7], Batch [210/428], Loss: 0.0371
Epoch [4/7], Batch [211/428], Loss: 0.0004
Epoch [4/7], Batch [212/428], Loss: 0.0064
Epoch [4/7], Batch [213/428], Loss: 0.0617
Epoch [4/7], Batch [214/428], Loss: 0.0012
Epoch [4/7], Batch [215/428], Loss: 0.0888
Epoch [4/7], Batch [216/428], Loss: 0.1010
Epoch [4/7], Batch [217/428], Loss: 0.0006
Epoch [4/7], Batch [218/428], Loss: 3.5999
Epoch [4/7], Batch [219/428], Loss: 0.0035
Epoch [4/7], Batch [220/428], Loss: 0.9132
Epoch [4/7], Batch [221/428], Loss: 0.0001
Epoch [4/7], Batch [222/428], Loss: 0.3584
Epoch [4/7], Batch [223/428], Loss: 0.0199
Epoch [4/7], Batch [224/428], Loss: 0.0111
Epoch [4/7], Batch [225/428], Loss: 0.0122
Epoch [4/7], Batch [226/428], Loss: 0.0085
Epoch [4/7], Batch [227/428], Loss: 0.0792
Epoch [4/7], Batch [228/428], Loss: 0.0002
Epoch [4/7], Batch [229/428], Loss: 0.0006
Epoch [4/7], Batch [230/428], Loss: 0.1352
Epoch [4/7], Batch [231/428], Loss: 0.0159
Epoch [4/7], Batch [232/428], Loss: 1.4270
Epoch [4/7], Batch [233/428], Loss: 0.0108
Epoch [4/7], Batch [234/428], Loss: 0.0246
Epoch [4/7], Batch [235/428], Loss: 0.4671
Epoch [4/7], Batch [236/428], Loss: 0.0002
Epoch [4/7], Batch [237/428], Loss: 0.0024
Epoch [4/7], Batch [238/428], Loss: 0.0001
Epoch [4/7], Batch [239/428], Loss: 5.0243
Epoch [4/7], Batch [240/428], Loss: 0.6345
Epoch [4/7], Batch [241/428], Loss: 0.8499
Epoch [4/7], Batch [242/428], Loss: 0.5157
Epoch [4/7], Batch [243/428], Loss: 1.0568
Epoch [4/7], Batch [244/428], Loss: 0.8893
Epoch [4/7], Batch [245/428], Loss: 0.0001
Epoch [4/7], Batch [246/428], Loss: 0.0192
Epoch [4/7], Batch [247/428], Loss: 1.6969
Epoch [4/7], Batch [248/428], Loss: 0.2075
Epoch [4/7], Batch [249/428], Loss: 0.0066
Epoch [4/7], Batch [250/428], Loss: 0.0010
Epoch [4/7], Batch [251/428], Loss: 0.2048
Epoch [4/7], Batch [252/428], Loss: 0.4047
Epoch [4/7], Batch [253/428], Loss: 0.0005
Epoch [4/7], Batch [254/428], Loss: 0.0005
Epoch [4/7], Batch [255/428], Loss: 0.0027
Epoch [4/7], Batch [256/428], Loss: 0.2502
Epoch [4/7], Batch [257/428], Loss: 0.0030
Epoch [4/7], Batch [258/428], Loss: 0.1497
Epoch [4/7], Batch [259/428], Loss: 0.0104
Epoch [4/7], Batch [260/428], Loss: 0.0209
Epoch [4/7], Batch [261/428], Loss: 0.0005
Epoch [4/7], Batch [262/428], Loss: 0.0001
Epoch [4/7], Batch [263/428], Loss: 0.7634
Epoch [4/7], Batch [264/428], Loss: 0.1008
Epoch [4/7], Batch [265/428], Loss: 0.0001
Epoch [4/7], Batch [266/428], Loss: 0.0005
Epoch [4/7], Batch [267/428], Loss: 0.0755
Epoch [4/7], Batch [268/428], Loss: 0.0289
Epoch [4/7], Batch [269/428], Loss: 0.0730
Epoch [4/7], Batch [270/428], Loss: 1.9822
Epoch [4/7], Batch [271/428], Loss: 2.6514
Epoch [4/7], Batch [272/428], Loss: 0.0039
Epoch [4/7], Batch [273/428], Loss: 0.0541
Epoch [4/7], Batch [274/428], Loss: 0.2987
Epoch [4/7], Batch [275/428], Loss: 0.4031
Epoch [4/7], Batch [276/428], Loss: 0.2141
Epoch [4/7], Batch [277/428], Loss: 0.6646
Epoch [4/7], Batch [278/428], Loss: 0.4310
Epoch [4/7], Batch [279/428], Loss: 0.0489
Epoch [4/7], Batch [280/428], Loss: 0.0020
Epoch [4/7], Batch [281/428], Loss: 0.5481
Epoch [4/7], Batch [282/428], Loss: 0.0001
Epoch [4/7], Batch [283/428], Loss: 0.0008
Epoch [4/7], Batch [284/428], Loss: 0.5234
Epoch [4/7], Batch [285/428], Loss: 0.0060
Epoch [4/7], Batch [286/428], Loss: 0.0003
Epoch [4/7], Batch [287/428], Loss: 0.0001
Epoch [4/7], Batch [288/428], Loss: 0.0003
Epoch [4/7], Batch [289/428], Loss: 0.2801
Epoch [4/7], Batch [290/428], Loss: 0.0001
Epoch [4/7], Batch [291/428], Loss: 0.0017
Epoch [4/7], Batch [292/428], Loss: 0.1659
Epoch [4/7], Batch [293/428], Loss: 0.0087
Epoch [4/7], Batch [294/428], Loss: 0.0001
Epoch [4/7], Batch [295/428], Loss: 0.0004
Epoch [4/7], Batch [296/428], Loss: 2.3082
Epoch [4/7], Batch [297/428], Loss: 0.0001
Epoch [4/7], Batch [298/428], Loss: 0.0068
Epoch [4/7], Batch [299/428], Loss: 1.1382
Epoch [4/7], Batch [300/428], Loss: 0.2822
Epoch [4/7], Batch [301/428], Loss: 0.0726
Epoch [4/7], Batch [302/428], Loss: 0.0002
Epoch [4/7], Batch [303/428], Loss: 0.0104
Epoch [4/7], Batch [304/428], Loss: 1.7423
Epoch [4/7], Batch [305/428], Loss: 1.4351
Epoch [4/7], Batch [306/428], Loss: 0.0002
Epoch [4/7], Batch [307/428], Loss: 0.0002
Epoch [4/7], Batch [308/428], Loss: 1.6086
Epoch [4/7], Batch [309/428], Loss: 0.0005
Epoch [4/7], Batch [310/428], Loss: 0.2362
Epoch [4/7], Batch [311/428], Loss: 0.0002
Epoch [4/7], Batch [312/428], Loss: 0.4902
Epoch [4/7], Batch [313/428], Loss: 0.0001
Epoch [4/7], Batch [314/428], Loss: 0.2680
Epoch [4/7], Batch [315/428], Loss: 0.5729
Epoch [4/7], Batch [316/428], Loss: 4.0903
Epoch [4/7], Batch [317/428], Loss: 0.0057
Epoch [4/7], Batch [318/428], Loss: 0.4068
Epoch [4/7], Batch [319/428], Loss: 1.1321
Epoch [4/7], Batch [320/428], Loss: 0.0209
Epoch [4/7], Batch [321/428], Loss: 1.0856
Epoch [4/7], Batch [322/428], Loss: 0.1125
Epoch [4/7], Batch [323/428], Loss: 0.5548
Epoch [4/7], Batch [324/428], Loss: 0.0039
Epoch [4/7], Batch [325/428], Loss: 0.0581
Epoch [4/7], Batch [326/428], Loss: 0.1263
Epoch [4/7], Batch [327/428], Loss: 0.0054
Epoch [4/7], Batch [328/428], Loss: 0.0134
Epoch [4/7], Batch [329/428], Loss: 0.2849
Epoch [4/7], Batch [330/428], Loss: 0.0565
Epoch [4/7], Batch [331/428], Loss: 0.2558
Epoch [4/7], Batch [332/428], Loss: 0.0109
Epoch [4/7], Batch [333/428], Loss: 4.5946
Epoch [4/7], Batch [334/428], Loss: 0.0018
Epoch [4/7], Batch [335/428], Loss: 0.1089
Epoch [4/7], Batch [336/428], Loss: 0.0424
Epoch [4/7], Batch [337/428], Loss: 0.1494
Epoch [4/7], Batch [338/428], Loss: 0.0748
Epoch [4/7], Batch [339/428], Loss: 0.0036
Epoch [4/7], Batch [340/428], Loss: 0.0304
Epoch [4/7], Batch [341/428], Loss: 0.0722
Epoch [4/7], Batch [342/428], Loss: 0.0001
Epoch [4/7], Batch [343/428], Loss: 0.0771
Epoch [4/7], Batch [344/428], Loss: 0.0001
Epoch [4/7], Batch [345/428], Loss: 0.2482
Epoch [4/7], Batch [346/428], Loss: 1.0017
Epoch [4/7], Batch [347/428], Loss: 1.8274
Epoch [4/7], Batch [348/428], Loss: 0.0005
Epoch [4/7], Batch [349/428], Loss: 0.1515
Epoch [4/7], Batch [350/428], Loss: 0.0018
Epoch [4/7], Batch [351/428], Loss: 1.3889
Epoch [4/7], Batch [352/428], Loss: 0.0002
Epoch [4/7], Batch [353/428], Loss: 0.0001
Epoch [4/7], Batch [354/428], Loss: 0.0009
Epoch [4/7], Batch [355/428], Loss: 0.0034
Epoch [4/7], Batch [356/428], Loss: 0.0002
Epoch [4/7], Batch [357/428], Loss: 0.8263
Epoch [4/7], Batch [358/428], Loss: 0.0403
Epoch [4/7], Batch [359/428], Loss: 0.5861
Epoch [4/7], Batch [360/428], Loss: 0.0001
Epoch [4/7], Batch [361/428], Loss: 0.0008
Epoch [4/7], Batch [362/428], Loss: 0.0002
Epoch [4/7], Batch [363/428], Loss: 0.0007
Epoch [4/7], Batch [364/428], Loss: 0.0004
Epoch [4/7], Batch [365/428], Loss: 0.0009
Epoch [4/7], Batch [366/428], Loss: 1.3068
Epoch [4/7], Batch [367/428], Loss: 0.0004
Epoch [4/7], Batch [368/428], Loss: 0.0004
Epoch [4/7], Batch [369/428], Loss: 0.0294
Epoch [4/7], Batch [370/428], Loss: 0.4728
Epoch [4/7], Batch [371/428], Loss: 0.3552
Epoch [4/7], Batch [372/428], Loss: 1.0232
Epoch [4/7], Batch [373/428], Loss: 0.0006
Epoch [4/7], Batch [374/428], Loss: 2.1654
Epoch [4/7], Batch [375/428], Loss: 0.0007
Epoch [4/7], Batch [376/428], Loss: 0.0701
Epoch [4/7], Batch [377/428], Loss: 0.9848
Epoch [4/7], Batch [378/428], Loss: 0.0006
Epoch [4/7], Batch [379/428], Loss: 0.4179
Epoch [4/7], Batch [380/428], Loss: 0.9275
Epoch [4/7], Batch [381/428], Loss: 0.0001
Epoch [4/7], Batch [382/428], Loss: 0.2879
Epoch [4/7], Batch [383/428], Loss: 0.0001
Epoch [4/7], Batch [384/428], Loss: 0.1532
Epoch [4/7], Batch [385/428], Loss: 0.2504
Epoch [4/7], Batch [386/428], Loss: 0.4626
Epoch [4/7], Batch [387/428], Loss: 0.0006
Epoch [4/7], Batch [388/428], Loss: 0.0008
Epoch [4/7], Batch [389/428], Loss: 0.7383
Epoch [4/7], Batch [390/428], Loss: 0.0001
Epoch [4/7], Batch [391/428], Loss: 0.1417
Epoch [4/7], Batch [392/428], Loss: 0.7134
Epoch [4/7], Batch [393/428], Loss: 0.0001
Epoch [4/7], Batch [394/428], Loss: 0.0192
Epoch [4/7], Batch [395/428], Loss: 0.0153
Epoch [4/7], Batch [396/428], Loss: 0.6847
Epoch [4/7], Batch [397/428], Loss: 0.6515
Epoch [4/7], Batch [398/428], Loss: 0.2347
Epoch [4/7], Batch [399/428], Loss: 0.4644
Epoch [4/7], Batch [400/428], Loss: 0.0003
Epoch [4/7], Batch [401/428], Loss: 0.0356
Epoch [4/7], Batch [402/428], Loss: 0.0004
Epoch [4/7], Batch [403/428], Loss: 0.0001
Epoch [4/7], Batch [404/428], Loss: 0.0983
Epoch [4/7], Batch [405/428], Loss: 0.1569
Epoch [4/7], Batch [406/428], Loss: 0.0021
Epoch [4/7], Batch [407/428], Loss: 0.0546
Epoch [4/7], Batch [408/428], Loss: 0.0010
Epoch [4/7], Batch [409/428], Loss: 0.1601
Epoch [4/7], Batch [410/428], Loss: 1.9157
Epoch [4/7], Batch [411/428], Loss: 0.0946
Epoch [4/7], Batch [412/428], Loss: 0.0717
Epoch [4/7], Batch [413/428], Loss: 0.0554
Epoch [4/7], Batch [414/428], Loss: 0.0167
Epoch [4/7], Batch [415/428], Loss: 0.0224
Epoch [4/7], Batch [416/428], Loss: 0.2449
Epoch [4/7], Batch [417/428], Loss: 0.0369
Epoch [4/7], Batch [418/428], Loss: 0.0004
Epoch [4/7], Batch [419/428], Loss: 2.9688
Epoch [4/7], Batch [420/428], Loss: 0.1559
Epoch [4/7], Batch [421/428], Loss: 0.0110
Epoch [4/7], Batch [422/428], Loss: 1.7430
Epoch [4/7], Batch [423/428], Loss: 0.3283
Epoch [4/7], Batch [424/428], Loss: 0.0006
Epoch [4/7], Batch [425/428], Loss: 0.1490
Epoch [4/7], Batch [426/428], Loss: 0.0001
Epoch [4/7], Batch [427/428], Loss: 0.0464
Epoch [4/7], Batch [428/428], Loss: 2.1462
Epoch [4] Training Time: 252.34 seconds
Epoch [4/7], Average Loss: 0.4756, Training Accuracy: 0.8294
Epoch [4], Validation Loss: 0.8022, Validation Accuracy: 0.7039
Epoch [4] Validation Time: 9.01 seconds
--------------------------------------------------
Epoch [5/7], Batch [1/428], Loss: 0.1487
Epoch [5/7], Batch [2/428], Loss: 0.0006
Epoch [5/7], Batch [3/428], Loss: 0.0001
Epoch [5/7], Batch [4/428], Loss: 0.0094
Epoch [5/7], Batch [5/428], Loss: 0.3204
Epoch [5/7], Batch [6/428], Loss: 1.0604
Epoch [5/7], Batch [7/428], Loss: 0.2483
Epoch [5/7], Batch [8/428], Loss: 0.0250
Epoch [5/7], Batch [9/428], Loss: 0.0061
Epoch [5/7], Batch [10/428], Loss: 0.0302
Epoch [5/7], Batch [11/428], Loss: 0.1675
Epoch [5/7], Batch [12/428], Loss: 0.0142
Epoch [5/7], Batch [13/428], Loss: 0.0004
Epoch [5/7], Batch [14/428], Loss: 0.0050
Epoch [5/7], Batch [15/428], Loss: 0.1045
Epoch [5/7], Batch [16/428], Loss: 0.0058
Epoch [5/7], Batch [17/428], Loss: 0.0008
Epoch [5/7], Batch [18/428], Loss: 0.0240
Epoch [5/7], Batch [19/428], Loss: 0.0147
Epoch [5/7], Batch [20/428], Loss: 0.0130
Epoch [5/7], Batch [21/428], Loss: 0.0002
Epoch [5/7], Batch [22/428], Loss: 0.0001
Epoch [5/7], Batch [23/428], Loss: 1.5134
Epoch [5/7], Batch [24/428], Loss: 0.1049
Epoch [5/7], Batch [25/428], Loss: 0.0021
Epoch [5/7], Batch [26/428], Loss: 0.0006
Epoch [5/7], Batch [27/428], Loss: 0.9498
Epoch [5/7], Batch [28/428], Loss: 0.0004
Epoch [5/7], Batch [29/428], Loss: 0.0004
Epoch [5/7], Batch [30/428], Loss: 0.3335
Epoch [5/7], Batch [31/428], Loss: 0.0042
Epoch [5/7], Batch [32/428], Loss: 0.4285
Epoch [5/7], Batch [33/428], Loss: 0.0002
Epoch [5/7], Batch [34/428], Loss: 0.0001
Epoch [5/7], Batch [35/428], Loss: 0.0006
Epoch [5/7], Batch [36/428], Loss: 0.1395
Epoch [5/7], Batch [37/428], Loss: 0.0004
Epoch [5/7], Batch [38/428], Loss: 0.0019
Epoch [5/7], Batch [39/428], Loss: 1.2115
Epoch [5/7], Batch [40/428], Loss: 0.1567
Epoch [5/7], Batch [41/428], Loss: 0.0521
Epoch [5/7], Batch [42/428], Loss: 2.9685
Epoch [5/7], Batch [43/428], Loss: 0.4020
Epoch [5/7], Batch [44/428], Loss: 0.1334
Epoch [5/7], Batch [45/428], Loss: 0.0071
Epoch [5/7], Batch [46/428], Loss: 0.0129
Epoch [5/7], Batch [47/428], Loss: 3.3966
Epoch [5/7], Batch [48/428], Loss: 0.2567
Epoch [5/7], Batch [49/428], Loss: 0.0002
Epoch [5/7], Batch [50/428], Loss: 0.0001
Epoch [5/7], Batch [51/428], Loss: 0.0001
Epoch [5/7], Batch [52/428], Loss: 0.0974
Epoch [5/7], Batch [53/428], Loss: 0.0035
Epoch [5/7], Batch [54/428], Loss: 0.0008
Epoch [5/7], Batch [55/428], Loss: 0.0004
Epoch [5/7], Batch [56/428], Loss: 0.0003
Epoch [5/7], Batch [57/428], Loss: 0.5168
Epoch [5/7], Batch [58/428], Loss: 0.0001
Epoch [5/7], Batch [59/428], Loss: 0.0002
Epoch [5/7], Batch [60/428], Loss: 0.0204
Epoch [5/7], Batch [61/428], Loss: 0.0005
Epoch [5/7], Batch [62/428], Loss: 0.0003
Epoch [5/7], Batch [63/428], Loss: 0.6755
Epoch [5/7], Batch [64/428], Loss: 0.0008
Epoch [5/7], Batch [65/428], Loss: 0.0024
Epoch [5/7], Batch [66/428], Loss: 0.0002
Epoch [5/7], Batch [67/428], Loss: 0.0701
Epoch [5/7], Batch [68/428], Loss: 0.0151
Epoch [5/7], Batch [69/428], Loss: 0.2211
Epoch [5/7], Batch [70/428], Loss: 0.0290
Epoch [5/7], Batch [71/428], Loss: 0.0144
Epoch [5/7], Batch [72/428], Loss: 0.2032
Epoch [5/7], Batch [73/428], Loss: 0.0306
Epoch [5/7], Batch [74/428], Loss: 0.0002
Epoch [5/7], Batch [75/428], Loss: 2.8119
Epoch [5/7], Batch [76/428], Loss: 1.0234
Epoch [5/7], Batch [77/428], Loss: 0.0888
Epoch [5/7], Batch [78/428], Loss: 0.0188
Epoch [5/7], Batch [79/428], Loss: 0.1089
Epoch [5/7], Batch [80/428], Loss: 0.0343
Epoch [5/7], Batch [81/428], Loss: 0.3183
Epoch [5/7], Batch [82/428], Loss: 1.1334
Epoch [5/7], Batch [83/428], Loss: 0.0001
Epoch [5/7], Batch [84/428], Loss: 3.5834
Epoch [5/7], Batch [85/428], Loss: 0.0003
Epoch [5/7], Batch [86/428], Loss: 0.3900
Epoch [5/7], Batch [87/428], Loss: 0.0423
Epoch [5/7], Batch [88/428], Loss: 0.2105
Epoch [5/7], Batch [89/428], Loss: 0.0004
Epoch [5/7], Batch [90/428], Loss: 0.0026
Epoch [5/7], Batch [91/428], Loss: 0.0001
Epoch [5/7], Batch [92/428], Loss: 0.0004
Epoch [5/7], Batch [93/428], Loss: 0.0007
Epoch [5/7], Batch [94/428], Loss: 0.0897
Epoch [5/7], Batch [95/428], Loss: 1.9734
Epoch [5/7], Batch [96/428], Loss: 0.0042
Epoch [5/7], Batch [97/428], Loss: 1.1230
Epoch [5/7], Batch [98/428], Loss: 0.0013
Epoch [5/7], Batch [99/428], Loss: 0.0670
Epoch [5/7], Batch [100/428], Loss: 0.0336
Epoch [5/7], Batch [101/428], Loss: 0.8045
Epoch [5/7], Batch [102/428], Loss: 0.0003
Epoch [5/7], Batch [103/428], Loss: 0.0199
Epoch [5/7], Batch [104/428], Loss: 0.0033
Epoch [5/7], Batch [105/428], Loss: 0.0243
Epoch [5/7], Batch [106/428], Loss: 0.0007
Epoch [5/7], Batch [107/428], Loss: 0.3491
Epoch [5/7], Batch [108/428], Loss: 0.1274
Epoch [5/7], Batch [109/428], Loss: 0.6331
Epoch [5/7], Batch [110/428], Loss: 0.0113
Epoch [5/7], Batch [111/428], Loss: 0.0001
Epoch [5/7], Batch [112/428], Loss: 3.0932
Epoch [5/7], Batch [113/428], Loss: 0.0001
Epoch [5/7], Batch [114/428], Loss: 0.0001
Epoch [5/7], Batch [115/428], Loss: 0.0026
Epoch [5/7], Batch [116/428], Loss: 1.1663
Epoch [5/7], Batch [117/428], Loss: 1.0843
Epoch [5/7], Batch [118/428], Loss: 3.5856
Epoch [5/7], Batch [119/428], Loss: 0.0004
Epoch [5/7], Batch [120/428], Loss: 0.0003
Epoch [5/7], Batch [121/428], Loss: 0.0002
Epoch [5/7], Batch [122/428], Loss: 0.0036
Epoch [5/7], Batch [123/428], Loss: 0.6561
Epoch [5/7], Batch [124/428], Loss: 0.0009
Epoch [5/7], Batch [125/428], Loss: 0.5396
Epoch [5/7], Batch [126/428], Loss: 0.2062
Epoch [5/7], Batch [127/428], Loss: 0.0001
Epoch [5/7], Batch [128/428], Loss: 0.4321
Epoch [5/7], Batch [129/428], Loss: 0.0312
Epoch [5/7], Batch [130/428], Loss: 0.1895
Epoch [5/7], Batch [131/428], Loss: 0.0036
Epoch [5/7], Batch [132/428], Loss: 0.2011
Epoch [5/7], Batch [133/428], Loss: 0.1537
Epoch [5/7], Batch [134/428], Loss: 0.0754
Epoch [5/7], Batch [135/428], Loss: 0.0001
Epoch [5/7], Batch [136/428], Loss: 0.0001
Epoch [5/7], Batch [137/428], Loss: 0.0005
Epoch [5/7], Batch [138/428], Loss: 0.0061
Epoch [5/7], Batch [139/428], Loss: 3.3117
Epoch [5/7], Batch [140/428], Loss: 0.3324
Epoch [5/7], Batch [141/428], Loss: 2.0290
Epoch [5/7], Batch [142/428], Loss: 0.8632
Epoch [5/7], Batch [143/428], Loss: 0.1419
Epoch [5/7], Batch [144/428], Loss: 0.0009
Epoch [5/7], Batch [145/428], Loss: 0.0112
Epoch [5/7], Batch [146/428], Loss: 0.0001
Epoch [5/7], Batch [147/428], Loss: 0.6316
Epoch [5/7], Batch [148/428], Loss: 0.7296
Epoch [5/7], Batch [149/428], Loss: 0.0837
Epoch [5/7], Batch [150/428], Loss: 0.0025
Epoch [5/7], Batch [151/428], Loss: 0.0015
Epoch [5/7], Batch [152/428], Loss: 0.0922
Epoch [5/7], Batch [153/428], Loss: 0.0001
Epoch [5/7], Batch [154/428], Loss: 0.9947
Epoch [5/7], Batch [155/428], Loss: 0.1304
Epoch [5/7], Batch [156/428], Loss: 0.0421
Epoch [5/7], Batch [157/428], Loss: 1.2263
Epoch [5/7], Batch [158/428], Loss: 0.0001
Epoch [5/7], Batch [159/428], Loss: 0.0006
Epoch [5/7], Batch [160/428], Loss: 0.0563
Epoch [5/7], Batch [161/428], Loss: 1.9958
Epoch [5/7], Batch [162/428], Loss: 2.6662
Epoch [5/7], Batch [163/428], Loss: 0.0044
Epoch [5/7], Batch [164/428], Loss: 0.0086
Epoch [5/7], Batch [165/428], Loss: 0.0039
Epoch [5/7], Batch [166/428], Loss: 0.3381
Epoch [5/7], Batch [167/428], Loss: 0.0178
Epoch [5/7], Batch [168/428], Loss: 0.0315
Epoch [5/7], Batch [169/428], Loss: 0.9503
Epoch [5/7], Batch [170/428], Loss: 0.0004
Epoch [5/7], Batch [171/428], Loss: 0.0390
Epoch [5/7], Batch [172/428], Loss: 0.1096
Epoch [5/7], Batch [173/428], Loss: 0.0002
Epoch [5/7], Batch [174/428], Loss: 0.1224
Epoch [5/7], Batch [175/428], Loss: 0.8461
Epoch [5/7], Batch [176/428], Loss: 0.0090
Epoch [5/7], Batch [177/428], Loss: 0.0001
Epoch [5/7], Batch [178/428], Loss: 0.6641
Epoch [5/7], Batch [179/428], Loss: 4.7037
Epoch [5/7], Batch [180/428], Loss: 0.0214
Epoch [5/7], Batch [181/428], Loss: 0.0211
Epoch [5/7], Batch [182/428], Loss: 0.0955
Epoch [5/7], Batch [183/428], Loss: 0.0209
Epoch [5/7], Batch [184/428], Loss: 0.6937
Epoch [5/7], Batch [185/428], Loss: 0.0008
Epoch [5/7], Batch [186/428], Loss: 0.0012
Epoch [5/7], Batch [187/428], Loss: 0.0082
Epoch [5/7], Batch [188/428], Loss: 0.0005
Epoch [5/7], Batch [189/428], Loss: 0.0030
Epoch [5/7], Batch [190/428], Loss: 0.0309
Epoch [5/7], Batch [191/428], Loss: 0.0536
Epoch [5/7], Batch [192/428], Loss: 0.0008
Epoch [5/7], Batch [193/428], Loss: 0.0013
Epoch [5/7], Batch [194/428], Loss: 0.1661
Epoch [5/7], Batch [195/428], Loss: 0.0699
Epoch [5/7], Batch [196/428], Loss: 0.0624
Epoch [5/7], Batch [197/428], Loss: 0.0002
Epoch [5/7], Batch [198/428], Loss: 0.0001
Epoch [5/7], Batch [199/428], Loss: 0.1073
Epoch [5/7], Batch [200/428], Loss: 0.0006
Epoch [5/7], Batch [201/428], Loss: 0.0053
Epoch [5/7], Batch [202/428], Loss: 0.0507
Epoch [5/7], Batch [203/428], Loss: 0.0239
Epoch [5/7], Batch [204/428], Loss: 0.0117
Epoch [5/7], Batch [205/428], Loss: 0.0002
Epoch [5/7], Batch [206/428], Loss: 0.4516
Epoch [5/7], Batch [207/428], Loss: 0.0080
Epoch [5/7], Batch [208/428], Loss: 0.0011
Epoch [5/7], Batch [209/428], Loss: 0.0001
Epoch [5/7], Batch [210/428], Loss: 0.1391
Epoch [5/7], Batch [211/428], Loss: 4.8901
Epoch [5/7], Batch [212/428], Loss: 0.0004
Epoch [5/7], Batch [213/428], Loss: 0.0001
Epoch [5/7], Batch [214/428], Loss: 0.0142
Epoch [5/7], Batch [215/428], Loss: 0.1092
Epoch [5/7], Batch [216/428], Loss: 0.1084
Epoch [5/7], Batch [217/428], Loss: 0.8071
Epoch [5/7], Batch [218/428], Loss: 0.0000
Epoch [5/7], Batch [219/428], Loss: 0.0004
Epoch [5/7], Batch [220/428], Loss: 0.0001
Epoch [5/7], Batch [221/428], Loss: 0.2780
Epoch [5/7], Batch [222/428], Loss: 0.1571
Epoch [5/7], Batch [223/428], Loss: 0.2673
Epoch [5/7], Batch [224/428], Loss: 0.0034
Epoch [5/7], Batch [225/428], Loss: 0.1314
Epoch [5/7], Batch [226/428], Loss: 0.0653
Epoch [5/7], Batch [227/428], Loss: 0.0053
Epoch [5/7], Batch [228/428], Loss: 0.0033
Epoch [5/7], Batch [229/428], Loss: 0.1807
Epoch [5/7], Batch [230/428], Loss: 0.0864
Epoch [5/7], Batch [231/428], Loss: 1.1139
Epoch [5/7], Batch [232/428], Loss: 0.0623
Epoch [5/7], Batch [233/428], Loss: 0.0106
Epoch [5/7], Batch [234/428], Loss: 0.0029
Epoch [5/7], Batch [235/428], Loss: 0.0001
Epoch [5/7], Batch [236/428], Loss: 0.0001
Epoch [5/7], Batch [237/428], Loss: 0.1144
Epoch [5/7], Batch [238/428], Loss: 1.9991
Epoch [5/7], Batch [239/428], Loss: 0.0001
Epoch [5/7], Batch [240/428], Loss: 0.0001
Epoch [5/7], Batch [241/428], Loss: 0.8177
Epoch [5/7], Batch [242/428], Loss: 0.3925
Epoch [5/7], Batch [243/428], Loss: 0.5939
Epoch [5/7], Batch [244/428], Loss: 0.0095
Epoch [5/7], Batch [245/428], Loss: 3.9098
Epoch [5/7], Batch [246/428], Loss: 0.0082
Epoch [5/7], Batch [247/428], Loss: 0.0487
Epoch [5/7], Batch [248/428], Loss: 0.9077
Epoch [5/7], Batch [249/428], Loss: 0.4995
Epoch [5/7], Batch [250/428], Loss: 0.4114
Epoch [5/7], Batch [251/428], Loss: 1.4001
Epoch [5/7], Batch [252/428], Loss: 0.0004
Epoch [5/7], Batch [253/428], Loss: 0.0004
Epoch [5/7], Batch [254/428], Loss: 0.0006
Epoch [5/7], Batch [255/428], Loss: 0.0021
Epoch [5/7], Batch [256/428], Loss: 0.0495
Epoch [5/7], Batch [257/428], Loss: 0.0041
Epoch [5/7], Batch [258/428], Loss: 0.1443
Epoch [5/7], Batch [259/428], Loss: 0.0338
Epoch [5/7], Batch [260/428], Loss: 0.0669
Epoch [5/7], Batch [261/428], Loss: 0.0995
Epoch [5/7], Batch [262/428], Loss: 0.0001
Epoch [5/7], Batch [263/428], Loss: 0.3928
Epoch [5/7], Batch [264/428], Loss: 0.4366
Epoch [5/7], Batch [265/428], Loss: 0.0533
Epoch [5/7], Batch [266/428], Loss: 1.3066
Epoch [5/7], Batch [267/428], Loss: 1.5914
Epoch [5/7], Batch [268/428], Loss: 0.0557
Epoch [5/7], Batch [269/428], Loss: 0.0001
Epoch [5/7], Batch [270/428], Loss: 0.0096
Epoch [5/7], Batch [271/428], Loss: 5.8519
Epoch [5/7], Batch [272/428], Loss: 0.0002
Epoch [5/7], Batch [273/428], Loss: 0.0053
Epoch [5/7], Batch [274/428], Loss: 0.0010
Epoch [5/7], Batch [275/428], Loss: 0.0002
Epoch [5/7], Batch [276/428], Loss: 0.0008
Epoch [5/7], Batch [277/428], Loss: 0.0930
Epoch [5/7], Batch [278/428], Loss: 1.0056
Epoch [5/7], Batch [279/428], Loss: 0.0094
Epoch [5/7], Batch [280/428], Loss: 1.4199
Epoch [5/7], Batch [281/428], Loss: 0.0001
Epoch [5/7], Batch [282/428], Loss: 0.0016
Epoch [5/7], Batch [283/428], Loss: 0.1061
Epoch [5/7], Batch [284/428], Loss: 0.0080
Epoch [5/7], Batch [285/428], Loss: 0.0002
Epoch [5/7], Batch [286/428], Loss: 0.0001
Epoch [5/7], Batch [287/428], Loss: 0.0708
Epoch [5/7], Batch [288/428], Loss: 0.0073
Epoch [5/7], Batch [289/428], Loss: 0.0080
Epoch [5/7], Batch [290/428], Loss: 0.5339
Epoch [5/7], Batch [291/428], Loss: 0.0015
Epoch [5/7], Batch [292/428], Loss: 0.4205
Epoch [5/7], Batch [293/428], Loss: 0.0431
Epoch [5/7], Batch [294/428], Loss: 0.0014
Epoch [5/7], Batch [295/428], Loss: 0.0002
Epoch [5/7], Batch [296/428], Loss: 0.0263
Epoch [5/7], Batch [297/428], Loss: 0.0003
Epoch [5/7], Batch [298/428], Loss: 0.9710
Epoch [5/7], Batch [299/428], Loss: 0.0001
Epoch [5/7], Batch [300/428], Loss: 4.0214
Epoch [5/7], Batch [301/428], Loss: 5.0214
Epoch [5/7], Batch [302/428], Loss: 0.0110
Epoch [5/7], Batch [303/428], Loss: 0.0326
Epoch [5/7], Batch [304/428], Loss: 0.0043
Epoch [5/7], Batch [305/428], Loss: 2.0037
Epoch [5/7], Batch [306/428], Loss: 0.7579
Epoch [5/7], Batch [307/428], Loss: 0.0045
Epoch [5/7], Batch [308/428], Loss: 0.0391
Epoch [5/7], Batch [309/428], Loss: 0.0948
Epoch [5/7], Batch [310/428], Loss: 0.1038
Epoch [5/7], Batch [311/428], Loss: 0.0721
Epoch [5/7], Batch [312/428], Loss: 0.7851
Epoch [5/7], Batch [313/428], Loss: 0.0017
Epoch [5/7], Batch [314/428], Loss: 0.0003
Epoch [5/7], Batch [315/428], Loss: 0.0000
Epoch [5/7], Batch [316/428], Loss: 0.1440
Epoch [5/7], Batch [317/428], Loss: 0.0006
Epoch [5/7], Batch [318/428], Loss: 0.1199
Epoch [5/7], Batch [319/428], Loss: 0.0011
Epoch [5/7], Batch [320/428], Loss: 0.0795
Epoch [5/7], Batch [321/428], Loss: 0.0013
Epoch [5/7], Batch [322/428], Loss: 0.0039
Epoch [5/7], Batch [323/428], Loss: 0.0009
Epoch [5/7], Batch [324/428], Loss: 0.6482
Epoch [5/7], Batch [325/428], Loss: 0.0306
Epoch [5/7], Batch [326/428], Loss: 1.0099
Epoch [5/7], Batch [327/428], Loss: 0.0006
Epoch [5/7], Batch [328/428], Loss: 0.0001
Epoch [5/7], Batch [329/428], Loss: 0.0011
Epoch [5/7], Batch [330/428], Loss: 0.0332
Epoch [5/7], Batch [331/428], Loss: 0.0001
Epoch [5/7], Batch [332/428], Loss: 0.0228
Epoch [5/7], Batch [333/428], Loss: 0.0000
Epoch [5/7], Batch [334/428], Loss: 0.1885
Epoch [5/7], Batch [335/428], Loss: 0.0596
Epoch [5/7], Batch [336/428], Loss: 0.0045
Epoch [5/7], Batch [337/428], Loss: 0.1309
Epoch [5/7], Batch [338/428], Loss: 0.1646
Epoch [5/7], Batch [339/428], Loss: 0.0011
Epoch [5/7], Batch [340/428], Loss: 2.9955
Epoch [5/7], Batch [341/428], Loss: 0.0001
Epoch [5/7], Batch [342/428], Loss: 0.0001
Epoch [5/7], Batch [343/428], Loss: 0.2550
Epoch [5/7], Batch [344/428], Loss: 0.0967
Epoch [5/7], Batch [345/428], Loss: 0.0004
Epoch [5/7], Batch [346/428], Loss: 0.0340
Epoch [5/7], Batch [347/428], Loss: 0.0001
Epoch [5/7], Batch [348/428], Loss: 0.0016
Epoch [5/7], Batch [349/428], Loss: 0.0039
Epoch [5/7], Batch [350/428], Loss: 0.1503
Epoch [5/7], Batch [351/428], Loss: 0.1018
Epoch [5/7], Batch [352/428], Loss: 0.0005
Epoch [5/7], Batch [353/428], Loss: 0.0023
Epoch [5/7], Batch [354/428], Loss: 0.2035
Epoch [5/7], Batch [355/428], Loss: 0.0001
Epoch [5/7], Batch [356/428], Loss: 0.0228
Epoch [5/7], Batch [357/428], Loss: 0.9220
Epoch [5/7], Batch [358/428], Loss: 0.0001
Epoch [5/7], Batch [359/428], Loss: 0.0014
Epoch [5/7], Batch [360/428], Loss: 0.0001
Epoch [5/7], Batch [361/428], Loss: 0.0135
Epoch [5/7], Batch [362/428], Loss: 0.3120
Epoch [5/7], Batch [363/428], Loss: 0.2545
Epoch [5/7], Batch [364/428], Loss: 0.0081
Epoch [5/7], Batch [365/428], Loss: 0.0719
Epoch [5/7], Batch [366/428], Loss: 0.0017
Epoch [5/7], Batch [367/428], Loss: 0.1705
Epoch [5/7], Batch [368/428], Loss: 0.0061
Epoch [5/7], Batch [369/428], Loss: 0.0001
Epoch [5/7], Batch [370/428], Loss: 0.0220
Epoch [5/7], Batch [371/428], Loss: 0.1082
Epoch [5/7], Batch [372/428], Loss: 0.0008
Epoch [5/7], Batch [373/428], Loss: 0.0005
Epoch [5/7], Batch [374/428], Loss: 0.0440
Epoch [5/7], Batch [375/428], Loss: 0.0000
Epoch [5/7], Batch [376/428], Loss: 0.0237
Epoch [5/7], Batch [377/428], Loss: 1.1306
Epoch [5/7], Batch [378/428], Loss: 0.0004
Epoch [5/7], Batch [379/428], Loss: 0.0002
Epoch [5/7], Batch [380/428], Loss: 0.0002
Epoch [5/7], Batch [381/428], Loss: 0.0230
Epoch [5/7], Batch [382/428], Loss: 0.1131
Epoch [5/7], Batch [383/428], Loss: 0.0139
Epoch [5/7], Batch [384/428], Loss: 0.0673
Epoch [5/7], Batch [385/428], Loss: 0.0131
Epoch [5/7], Batch [386/428], Loss: 0.0034
Epoch [5/7], Batch [387/428], Loss: 0.0001
Epoch [5/7], Batch [388/428], Loss: 0.2498
Epoch [5/7], Batch [389/428], Loss: 0.0296
Epoch [5/7], Batch [390/428], Loss: 0.0428
Epoch [5/7], Batch [391/428], Loss: 2.1411
Epoch [5/7], Batch [392/428], Loss: 0.1071
Epoch [5/7], Batch [393/428], Loss: 0.0665
Epoch [5/7], Batch [394/428], Loss: 0.2609
Epoch [5/7], Batch [395/428], Loss: 0.0010
Epoch [5/7], Batch [396/428], Loss: 0.7344
Epoch [5/7], Batch [397/428], Loss: 0.0002
Epoch [5/7], Batch [398/428], Loss: 0.0006
Epoch [5/7], Batch [399/428], Loss: 0.0034
Epoch [5/7], Batch [400/428], Loss: 0.0825
Epoch [5/7], Batch [401/428], Loss: 0.0612
Epoch [5/7], Batch [402/428], Loss: 0.3625
Epoch [5/7], Batch [403/428], Loss: 0.2108
Epoch [5/7], Batch [404/428], Loss: 0.0002
Epoch [5/7], Batch [405/428], Loss: 0.0005
Epoch [5/7], Batch [406/428], Loss: 0.0217
Epoch [5/7], Batch [407/428], Loss: 0.0004
Epoch [5/7], Batch [408/428], Loss: 0.0030
Epoch [5/7], Batch [409/428], Loss: 0.3421
Epoch [5/7], Batch [410/428], Loss: 0.0509
Epoch [5/7], Batch [411/428], Loss: 0.0000
Epoch [5/7], Batch [412/428], Loss: 0.0024
Epoch [5/7], Batch [413/428], Loss: 0.7765
Epoch [5/7], Batch [414/428], Loss: 0.0001
Epoch [5/7], Batch [415/428], Loss: 0.0616
Epoch [5/7], Batch [416/428], Loss: 0.0761
Epoch [5/7], Batch [417/428], Loss: 1.0161
Epoch [5/7], Batch [418/428], Loss: 0.0051
Epoch [5/7], Batch [419/428], Loss: 0.0141
Epoch [5/7], Batch [420/428], Loss: 0.7746
Epoch [5/7], Batch [421/428], Loss: 0.0002
Epoch [5/7], Batch [422/428], Loss: 0.0004
Epoch [5/7], Batch [423/428], Loss: 0.0405
Epoch [5/7], Batch [424/428], Loss: 0.1780
Epoch [5/7], Batch [425/428], Loss: 0.0348
Epoch [5/7], Batch [426/428], Loss: 0.2478
Epoch [5/7], Batch [427/428], Loss: 0.4854
Epoch [5/7], Batch [428/428], Loss: 0.0014
Epoch [5] Training Time: 235.63 seconds
Epoch [5/7], Average Loss: 0.3117, Training Accuracy: 0.8902
Epoch [5], Validation Loss: 0.7102, Validation Accuracy: 0.7397
Epoch [5] Validation Time: 9.02 seconds
--------------------------------------------------
Epoch [6/7], Batch [1/428], Loss: 0.0001
Epoch [6/7], Batch [2/428], Loss: 0.0033
Epoch [6/7], Batch [3/428], Loss: 2.1447
Epoch [6/7], Batch [4/428], Loss: 0.0001
Epoch [6/7], Batch [5/428], Loss: 0.1411
Epoch [6/7], Batch [6/428], Loss: 0.0320
Epoch [6/7], Batch [7/428], Loss: 0.0198
Epoch [6/7], Batch [8/428], Loss: 0.0002
Epoch [6/7], Batch [9/428], Loss: 0.0013
Epoch [6/7], Batch [10/428], Loss: 0.0138
Epoch [6/7], Batch [11/428], Loss: 0.0026
Epoch [6/7], Batch [12/428], Loss: 0.0000
Epoch [6/7], Batch [13/428], Loss: 1.7275
Epoch [6/7], Batch [14/428], Loss: 0.0081
Epoch [6/7], Batch [15/428], Loss: 0.0885
Epoch [6/7], Batch [16/428], Loss: 0.0001
Epoch [6/7], Batch [17/428], Loss: 0.0000
Epoch [6/7], Batch [18/428], Loss: 0.0506
Epoch [6/7], Batch [19/428], Loss: 0.1121
Epoch [6/7], Batch [20/428], Loss: 0.0020
Epoch [6/7], Batch [21/428], Loss: 0.0056
Epoch [6/7], Batch [22/428], Loss: 0.0005
Epoch [6/7], Batch [23/428], Loss: 0.5492
Epoch [6/7], Batch [24/428], Loss: 0.6164
Epoch [6/7], Batch [25/428], Loss: 0.0003
Epoch [6/7], Batch [26/428], Loss: 0.0002
Epoch [6/7], Batch [27/428], Loss: 0.3203
Epoch [6/7], Batch [28/428], Loss: 0.0001
Epoch [6/7], Batch [29/428], Loss: 0.7754
Epoch [6/7], Batch [30/428], Loss: 0.0001
Epoch [6/7], Batch [31/428], Loss: 0.0001
Epoch [6/7], Batch [32/428], Loss: 0.0001
Epoch [6/7], Batch [33/428], Loss: 0.0144
Epoch [6/7], Batch [34/428], Loss: 0.3036
Epoch [6/7], Batch [35/428], Loss: 0.0026
Epoch [6/7], Batch [36/428], Loss: 0.0032
Epoch [6/7], Batch [37/428], Loss: 0.0001
Epoch [6/7], Batch [38/428], Loss: 0.0120
Epoch [6/7], Batch [39/428], Loss: 0.1061
Epoch [6/7], Batch [40/428], Loss: 0.0002
Epoch [6/7], Batch [41/428], Loss: 0.0075
Epoch [6/7], Batch [42/428], Loss: 0.0003
Epoch [6/7], Batch [43/428], Loss: 0.1364
Epoch [6/7], Batch [44/428], Loss: 0.1629
Epoch [6/7], Batch [45/428], Loss: 0.0898
Epoch [6/7], Batch [46/428], Loss: 0.0136
Epoch [6/7], Batch [47/428], Loss: 0.1489
Epoch [6/7], Batch [48/428], Loss: 0.2811
Epoch [6/7], Batch [49/428], Loss: 0.0004
Epoch [6/7], Batch [50/428], Loss: 0.0002
Epoch [6/7], Batch [51/428], Loss: 0.1559
Epoch [6/7], Batch [52/428], Loss: 0.0008
Epoch [6/7], Batch [53/428], Loss: 0.2184
Epoch [6/7], Batch [54/428], Loss: 0.0321
Epoch [6/7], Batch [55/428], Loss: 0.0462
Epoch [6/7], Batch [56/428], Loss: 0.0108
Epoch [6/7], Batch [57/428], Loss: 1.1470
Epoch [6/7], Batch [58/428], Loss: 0.0001
Epoch [6/7], Batch [59/428], Loss: 0.0052
Epoch [6/7], Batch [60/428], Loss: 0.0003
Epoch [6/7], Batch [61/428], Loss: 2.3364
Epoch [6/7], Batch [62/428], Loss: 0.1132
Epoch [6/7], Batch [63/428], Loss: 0.0188
Epoch [6/7], Batch [64/428], Loss: 0.0027
Epoch [6/7], Batch [65/428], Loss: 0.0001
Epoch [6/7], Batch [66/428], Loss: 0.0031
Epoch [6/7], Batch [67/428], Loss: 0.0008
Epoch [6/7], Batch [68/428], Loss: 0.0001
Epoch [6/7], Batch [69/428], Loss: 0.0026
Epoch [6/7], Batch [70/428], Loss: 0.4755
Epoch [6/7], Batch [71/428], Loss: 0.0179
Epoch [6/7], Batch [72/428], Loss: 0.0002
Epoch [6/7], Batch [73/428], Loss: 0.3716
Epoch [6/7], Batch [74/428], Loss: 0.0005
Epoch [6/7], Batch [75/428], Loss: 0.0759
Epoch [6/7], Batch [76/428], Loss: 0.2617
Epoch [6/7], Batch [77/428], Loss: 0.0009
Epoch [6/7], Batch [78/428], Loss: 0.1324
Epoch [6/7], Batch [79/428], Loss: 0.0055
Epoch [6/7], Batch [80/428], Loss: 0.0035
Epoch [6/7], Batch [81/428], Loss: 0.0004
Epoch [6/7], Batch [82/428], Loss: 0.0352
Epoch [6/7], Batch [83/428], Loss: 0.0003
Epoch [6/7], Batch [84/428], Loss: 0.0007
Epoch [6/7], Batch [85/428], Loss: 0.1155
Epoch [6/7], Batch [86/428], Loss: 0.0002
Epoch [6/7], Batch [87/428], Loss: 0.0009
Epoch [6/7], Batch [88/428], Loss: 0.0011
Epoch [6/7], Batch [89/428], Loss: 0.0021
Epoch [6/7], Batch [90/428], Loss: 1.2747
Epoch [6/7], Batch [91/428], Loss: 0.1756
Epoch [6/7], Batch [92/428], Loss: 0.0006
Epoch [6/7], Batch [93/428], Loss: 0.0325
Epoch [6/7], Batch [94/428], Loss: 0.0625
Epoch [6/7], Batch [95/428], Loss: 0.0002
Epoch [6/7], Batch [96/428], Loss: 0.0400
Epoch [6/7], Batch [97/428], Loss: 0.0130
Epoch [6/7], Batch [98/428], Loss: 0.0073
Epoch [6/7], Batch [99/428], Loss: 0.1010
Epoch [6/7], Batch [100/428], Loss: 2.1632
Epoch [6/7], Batch [101/428], Loss: 0.1443
Epoch [6/7], Batch [102/428], Loss: 0.1181
Epoch [6/7], Batch [103/428], Loss: 0.0001
Epoch [6/7], Batch [104/428], Loss: 0.0035
Epoch [6/7], Batch [105/428], Loss: 0.0002
Epoch [6/7], Batch [106/428], Loss: 0.2622
Epoch [6/7], Batch [107/428], Loss: 0.0003
Epoch [6/7], Batch [108/428], Loss: 0.8189
Epoch [6/7], Batch [109/428], Loss: 0.0007
Epoch [6/7], Batch [110/428], Loss: 0.0091
Epoch [6/7], Batch [111/428], Loss: 0.0001
Epoch [6/7], Batch [112/428], Loss: 0.0770
Epoch [6/7], Batch [113/428], Loss: 0.0001
Epoch [6/7], Batch [114/428], Loss: 0.0083
Epoch [6/7], Batch [115/428], Loss: 0.0999
Epoch [6/7], Batch [116/428], Loss: 0.0001
Epoch [6/7], Batch [117/428], Loss: 3.0848
Epoch [6/7], Batch [118/428], Loss: 0.1584
Epoch [6/7], Batch [119/428], Loss: 0.1216
Epoch [6/7], Batch [120/428], Loss: 1.1209
Epoch [6/7], Batch [121/428], Loss: 3.2158
Epoch [6/7], Batch [122/428], Loss: 0.0115
Epoch [6/7], Batch [123/428], Loss: 0.0322
Epoch [6/7], Batch [124/428], Loss: 0.0011
Epoch [6/7], Batch [125/428], Loss: 0.1500
Epoch [6/7], Batch [126/428], Loss: 0.0047
Epoch [6/7], Batch [127/428], Loss: 0.0001
Epoch [6/7], Batch [128/428], Loss: 0.0002
Epoch [6/7], Batch [129/428], Loss: 0.8689
Epoch [6/7], Batch [130/428], Loss: 0.0003
Epoch [6/7], Batch [131/428], Loss: 0.0007
Epoch [6/7], Batch [132/428], Loss: 0.0001
Epoch [6/7], Batch [133/428], Loss: 0.0311
Epoch [6/7], Batch [134/428], Loss: 0.0021
Epoch [6/7], Batch [135/428], Loss: 0.0041
Epoch [6/7], Batch [136/428], Loss: 0.0013
Epoch [6/7], Batch [137/428], Loss: 0.0002
Epoch [6/7], Batch [138/428], Loss: 0.0011
Epoch [6/7], Batch [139/428], Loss: 0.0556
Epoch [6/7], Batch [140/428], Loss: 0.0136
Epoch [6/7], Batch [141/428], Loss: 0.2439
Epoch [6/7], Batch [142/428], Loss: 0.0004
Epoch [6/7], Batch [143/428], Loss: 0.0114
Epoch [6/7], Batch [144/428], Loss: 0.0001
Epoch [6/7], Batch [145/428], Loss: 0.0290
Epoch [6/7], Batch [146/428], Loss: 0.2468
Epoch [6/7], Batch [147/428], Loss: 0.0362
Epoch [6/7], Batch [148/428], Loss: 0.0005
Epoch [6/7], Batch [149/428], Loss: 0.0005
Epoch [6/7], Batch [150/428], Loss: 0.0039
Epoch [6/7], Batch [151/428], Loss: 0.0024
Epoch [6/7], Batch [152/428], Loss: 0.6440
Epoch [6/7], Batch [153/428], Loss: 0.0011
Epoch [6/7], Batch [154/428], Loss: 0.0487
Epoch [6/7], Batch [155/428], Loss: 0.0012
Epoch [6/7], Batch [156/428], Loss: 0.4109
Epoch [6/7], Batch [157/428], Loss: 0.0029
Epoch [6/7], Batch [158/428], Loss: 0.0796
Epoch [6/7], Batch [159/428], Loss: 0.4766
Epoch [6/7], Batch [160/428], Loss: 0.0000
Epoch [6/7], Batch [161/428], Loss: 0.0001
Epoch [6/7], Batch [162/428], Loss: 0.0323
Epoch [6/7], Batch [163/428], Loss: 0.0002
Epoch [6/7], Batch [164/428], Loss: 0.0001
Epoch [6/7], Batch [165/428], Loss: 0.0043
Epoch [6/7], Batch [166/428], Loss: 0.0149
Epoch [6/7], Batch [167/428], Loss: 5.3793
Epoch [6/7], Batch [168/428], Loss: 0.0003
Epoch [6/7], Batch [169/428], Loss: 0.0000
Epoch [6/7], Batch [170/428], Loss: 0.0022
Epoch [6/7], Batch [171/428], Loss: 0.0001
Epoch [6/7], Batch [172/428], Loss: 0.1266
Epoch [6/7], Batch [173/428], Loss: 1.4440
Epoch [6/7], Batch [174/428], Loss: 0.3222
Epoch [6/7], Batch [175/428], Loss: 0.0211
Epoch [6/7], Batch [176/428], Loss: 0.0006
Epoch [6/7], Batch [177/428], Loss: 0.0001
Epoch [6/7], Batch [178/428], Loss: 0.1695
Epoch [6/7], Batch [179/428], Loss: 0.0024
Epoch [6/7], Batch [180/428], Loss: 0.0001
Epoch [6/7], Batch [181/428], Loss: 0.0006
Epoch [6/7], Batch [182/428], Loss: 0.0288
Epoch [6/7], Batch [183/428], Loss: 0.0714
Epoch [6/7], Batch [184/428], Loss: 0.0662
Epoch [6/7], Batch [185/428], Loss: 0.0243
Epoch [6/7], Batch [186/428], Loss: 0.0015
Epoch [6/7], Batch [187/428], Loss: 0.0007
Epoch [6/7], Batch [188/428], Loss: 0.0007
Epoch [6/7], Batch [189/428], Loss: 0.0002
Epoch [6/7], Batch [190/428], Loss: 0.0001
Epoch [6/7], Batch [191/428], Loss: 0.0036
Epoch [6/7], Batch [192/428], Loss: 0.0003
Epoch [6/7], Batch [193/428], Loss: 0.0000
Epoch [6/7], Batch [194/428], Loss: 0.0009
Epoch [6/7], Batch [195/428], Loss: 0.0343
Epoch [6/7], Batch [196/428], Loss: 0.0002
Epoch [6/7], Batch [197/428], Loss: 0.0288
Epoch [6/7], Batch [198/428], Loss: 0.0013
Epoch [6/7], Batch [199/428], Loss: 0.0001
Epoch [6/7], Batch [200/428], Loss: 0.0001
Epoch [6/7], Batch [201/428], Loss: 0.0007
Epoch [6/7], Batch [202/428], Loss: 0.0270
Epoch [6/7], Batch [203/428], Loss: 0.0064
Epoch [6/7], Batch [204/428], Loss: 0.0856
Epoch [6/7], Batch [205/428], Loss: 0.0003
Epoch [6/7], Batch [206/428], Loss: 0.0402
Epoch [6/7], Batch [207/428], Loss: 0.0242
Epoch [6/7], Batch [208/428], Loss: 0.1719
Epoch [6/7], Batch [209/428], Loss: 0.0005
Epoch [6/7], Batch [210/428], Loss: 0.0361
Epoch [6/7], Batch [211/428], Loss: 0.0117
Epoch [6/7], Batch [212/428], Loss: 0.0002
Epoch [6/7], Batch [213/428], Loss: 0.3652
Epoch [6/7], Batch [214/428], Loss: 0.1578
Epoch [6/7], Batch [215/428], Loss: 0.3816
Epoch [6/7], Batch [216/428], Loss: 0.0116
Epoch [6/7], Batch [217/428], Loss: 0.0788
Epoch [6/7], Batch [218/428], Loss: 0.0779
Epoch [6/7], Batch [219/428], Loss: 0.0214
Epoch [6/7], Batch [220/428], Loss: 0.0128
Epoch [6/7], Batch [221/428], Loss: 0.0331
Epoch [6/7], Batch [222/428], Loss: 0.8516
Epoch [6/7], Batch [223/428], Loss: 0.0001
Epoch [6/7], Batch [224/428], Loss: 0.0672
Epoch [6/7], Batch [225/428], Loss: 0.0457
Epoch [6/7], Batch [226/428], Loss: 0.1993
Epoch [6/7], Batch [227/428], Loss: 0.1831
Epoch [6/7], Batch [228/428], Loss: 0.0067
Epoch [6/7], Batch [229/428], Loss: 0.1539
Epoch [6/7], Batch [230/428], Loss: 0.0116
Epoch [6/7], Batch [231/428], Loss: 0.0210
Epoch [6/7], Batch [232/428], Loss: 0.0001
Epoch [6/7], Batch [233/428], Loss: 0.1389
Epoch [6/7], Batch [234/428], Loss: 0.0082
Epoch [6/7], Batch [235/428], Loss: 0.4581
Epoch [6/7], Batch [236/428], Loss: 0.0082
Epoch [6/7], Batch [237/428], Loss: 0.0827
Epoch [6/7], Batch [238/428], Loss: 0.5496
Epoch [6/7], Batch [239/428], Loss: 0.0134
Epoch [6/7], Batch [240/428], Loss: 6.0873
Epoch [6/7], Batch [241/428], Loss: 0.0007
Epoch [6/7], Batch [242/428], Loss: 0.0051
Epoch [6/7], Batch [243/428], Loss: 0.2696
Epoch [6/7], Batch [244/428], Loss: 0.2623
Epoch [6/7], Batch [245/428], Loss: 0.0002
Epoch [6/7], Batch [246/428], Loss: 0.0083
Epoch [6/7], Batch [247/428], Loss: 0.0002
Epoch [6/7], Batch [248/428], Loss: 0.1137
Epoch [6/7], Batch [249/428], Loss: 0.0000
Epoch [6/7], Batch [250/428], Loss: 0.0299
Epoch [6/7], Batch [251/428], Loss: 0.0069
Epoch [6/7], Batch [252/428], Loss: 0.0003
Epoch [6/7], Batch [253/428], Loss: 0.0017
Epoch [6/7], Batch [254/428], Loss: 0.0224
Epoch [6/7], Batch [255/428], Loss: 0.0923
Epoch [6/7], Batch [256/428], Loss: 0.0301
Epoch [6/7], Batch [257/428], Loss: 0.0007
Epoch [6/7], Batch [258/428], Loss: 0.0451
Epoch [6/7], Batch [259/428], Loss: 0.0142
Epoch [6/7], Batch [260/428], Loss: 0.0327
Epoch [6/7], Batch [261/428], Loss: 1.7217
Epoch [6/7], Batch [262/428], Loss: 0.0084
Epoch [6/7], Batch [263/428], Loss: 0.6117
Epoch [6/7], Batch [264/428], Loss: 0.2994
Epoch [6/7], Batch [265/428], Loss: 0.0642
Epoch [6/7], Batch [266/428], Loss: 0.0010
Epoch [6/7], Batch [267/428], Loss: 0.1077
Epoch [6/7], Batch [268/428], Loss: 0.1617
Epoch [6/7], Batch [269/428], Loss: 0.0078
Epoch [6/7], Batch [270/428], Loss: 0.0258
Epoch [6/7], Batch [271/428], Loss: 0.0027
Epoch [6/7], Batch [272/428], Loss: 0.0002
Epoch [6/7], Batch [273/428], Loss: 0.0013
Epoch [6/7], Batch [274/428], Loss: 0.0089
Epoch [6/7], Batch [275/428], Loss: 0.0531
Epoch [6/7], Batch [276/428], Loss: 0.1218
Epoch [6/7], Batch [277/428], Loss: 0.0153
Epoch [6/7], Batch [278/428], Loss: 0.0700
Epoch [6/7], Batch [279/428], Loss: 0.0095
Epoch [6/7], Batch [280/428], Loss: 0.0107
Epoch [6/7], Batch [281/428], Loss: 0.0004
Epoch [6/7], Batch [282/428], Loss: 0.0010
Epoch [6/7], Batch [283/428], Loss: 1.0633
Epoch [6/7], Batch [284/428], Loss: 0.0146
Epoch [6/7], Batch [285/428], Loss: 0.0084
Epoch [6/7], Batch [286/428], Loss: 0.0065
Epoch [6/7], Batch [287/428], Loss: 0.1013
Epoch [6/7], Batch [288/428], Loss: 0.0012
Epoch [6/7], Batch [289/428], Loss: 0.0241
Epoch [6/7], Batch [290/428], Loss: 0.4190
Epoch [6/7], Batch [291/428], Loss: 0.0028
Epoch [6/7], Batch [292/428], Loss: 0.0042
Epoch [6/7], Batch [293/428], Loss: 0.2323
Epoch [6/7], Batch [294/428], Loss: 0.0029
Epoch [6/7], Batch [295/428], Loss: 1.2347
Epoch [6/7], Batch [296/428], Loss: 0.0055
Epoch [6/7], Batch [297/428], Loss: 0.5036
Epoch [6/7], Batch [298/428], Loss: 0.0005
Epoch [6/7], Batch [299/428], Loss: 0.0020
Epoch [6/7], Batch [300/428], Loss: 0.0010
Epoch [6/7], Batch [301/428], Loss: 0.0208
Epoch [6/7], Batch [302/428], Loss: 0.0624
Epoch [6/7], Batch [303/428], Loss: 0.0005
Epoch [6/7], Batch [304/428], Loss: 0.0130
Epoch [6/7], Batch [305/428], Loss: 0.0026
Epoch [6/7], Batch [306/428], Loss: 0.0256
Epoch [6/7], Batch [307/428], Loss: 0.9668
Epoch [6/7], Batch [308/428], Loss: 0.0001
Epoch [6/7], Batch [309/428], Loss: 0.0916
Epoch [6/7], Batch [310/428], Loss: 0.3639
Epoch [6/7], Batch [311/428], Loss: 0.0000
Epoch [6/7], Batch [312/428], Loss: 0.0002
Epoch [6/7], Batch [313/428], Loss: 0.0001
Epoch [6/7], Batch [314/428], Loss: 0.0001
Epoch [6/7], Batch [315/428], Loss: 0.0097
Epoch [6/7], Batch [316/428], Loss: 0.2221
Epoch [6/7], Batch [317/428], Loss: 0.0011
Epoch [6/7], Batch [318/428], Loss: 0.0904
Epoch [6/7], Batch [319/428], Loss: 0.0001
Epoch [6/7], Batch [320/428], Loss: 1.3809
Epoch [6/7], Batch [321/428], Loss: 0.0019
Epoch [6/7], Batch [322/428], Loss: 0.0001
Epoch [6/7], Batch [323/428], Loss: 0.0003
Epoch [6/7], Batch [324/428], Loss: 0.0124
Epoch [6/7], Batch [325/428], Loss: 0.8980
Epoch [6/7], Batch [326/428], Loss: 0.0013
Epoch [6/7], Batch [327/428], Loss: 0.0032
Epoch [6/7], Batch [328/428], Loss: 0.0001
Epoch [6/7], Batch [329/428], Loss: 0.0008
Epoch [6/7], Batch [330/428], Loss: 0.5743
Epoch [6/7], Batch [331/428], Loss: 0.0266
Epoch [6/7], Batch [332/428], Loss: 0.0073
Epoch [6/7], Batch [333/428], Loss: 0.3553
Epoch [6/7], Batch [334/428], Loss: 0.2591
Epoch [6/7], Batch [335/428], Loss: 0.0001
Epoch [6/7], Batch [336/428], Loss: 0.0022
Epoch [6/7], Batch [337/428], Loss: 0.0024
Epoch [6/7], Batch [338/428], Loss: 0.0204
Epoch [6/7], Batch [339/428], Loss: 0.0672
Epoch [6/7], Batch [340/428], Loss: 0.2143
Epoch [6/7], Batch [341/428], Loss: 0.0012
Epoch [6/7], Batch [342/428], Loss: 0.0002
Epoch [6/7], Batch [343/428], Loss: 0.0092
Epoch [6/7], Batch [344/428], Loss: 0.0891
Epoch [6/7], Batch [345/428], Loss: 0.0007
Epoch [6/7], Batch [346/428], Loss: 0.0003
Epoch [6/7], Batch [347/428], Loss: 0.0490
Epoch [6/7], Batch [348/428], Loss: 0.0007
Epoch [6/7], Batch [349/428], Loss: 0.0000
Epoch [6/7], Batch [350/428], Loss: 0.0028
Epoch [6/7], Batch [351/428], Loss: 0.0034
Epoch [6/7], Batch [352/428], Loss: 0.0012
Epoch [6/7], Batch [353/428], Loss: 0.1951
Epoch [6/7], Batch [354/428], Loss: 3.4267
Epoch [6/7], Batch [355/428], Loss: 0.0001
Epoch [6/7], Batch [356/428], Loss: 0.0023
Epoch [6/7], Batch [357/428], Loss: 0.0000
Epoch [6/7], Batch [358/428], Loss: 0.0020
Epoch [6/7], Batch [359/428], Loss: 0.5603
Epoch [6/7], Batch [360/428], Loss: 0.0320
Epoch [6/7], Batch [361/428], Loss: 0.0313
Epoch [6/7], Batch [362/428], Loss: 0.0481
Epoch [6/7], Batch [363/428], Loss: 0.0003
Epoch [6/7], Batch [364/428], Loss: 1.6681
Epoch [6/7], Batch [365/428], Loss: 0.1671
Epoch [6/7], Batch [366/428], Loss: 0.0361
Epoch [6/7], Batch [367/428], Loss: 0.1663
Epoch [6/7], Batch [368/428], Loss: 0.0035
Epoch [6/7], Batch [369/428], Loss: 0.2239
Epoch [6/7], Batch [370/428], Loss: 0.8945
Epoch [6/7], Batch [371/428], Loss: 0.0325
Epoch [6/7], Batch [372/428], Loss: 0.0155
Epoch [6/7], Batch [373/428], Loss: 0.0000
Epoch [6/7], Batch [374/428], Loss: 0.0005
Epoch [6/7], Batch [375/428], Loss: 0.0320
Epoch [6/7], Batch [376/428], Loss: 0.0129
Epoch [6/7], Batch [377/428], Loss: 0.0026
Epoch [6/7], Batch [378/428], Loss: 0.0002
Epoch [6/7], Batch [379/428], Loss: 0.3268
Epoch [6/7], Batch [380/428], Loss: 0.4019
Epoch [6/7], Batch [381/428], Loss: 0.0001
Epoch [6/7], Batch [382/428], Loss: 0.0077
Epoch [6/7], Batch [383/428], Loss: 0.1752
Epoch [6/7], Batch [384/428], Loss: 0.0561
Epoch [6/7], Batch [385/428], Loss: 0.0001
Epoch [6/7], Batch [386/428], Loss: 0.1023
Epoch [6/7], Batch [387/428], Loss: 0.0001
Epoch [6/7], Batch [388/428], Loss: 0.0044
Epoch [6/7], Batch [389/428], Loss: 0.0030
Epoch [6/7], Batch [390/428], Loss: 3.9993
Epoch [6/7], Batch [391/428], Loss: 0.3364
Epoch [6/7], Batch [392/428], Loss: 0.2484
Epoch [6/7], Batch [393/428], Loss: 0.0003
Epoch [6/7], Batch [394/428], Loss: 0.0080
Epoch [6/7], Batch [395/428], Loss: 0.0032
Epoch [6/7], Batch [396/428], Loss: 0.0561
Epoch [6/7], Batch [397/428], Loss: 0.0001
Epoch [6/7], Batch [398/428], Loss: 0.0020
Epoch [6/7], Batch [399/428], Loss: 0.7898
Epoch [6/7], Batch [400/428], Loss: 0.0001
Epoch [6/7], Batch [401/428], Loss: 0.0060
Epoch [6/7], Batch [402/428], Loss: 0.0001
Epoch [6/7], Batch [403/428], Loss: 0.1370
Epoch [6/7], Batch [404/428], Loss: 2.0464
Epoch [6/7], Batch [405/428], Loss: 0.0003
Epoch [6/7], Batch [406/428], Loss: 1.4065
Epoch [6/7], Batch [407/428], Loss: 0.0275
Epoch [6/7], Batch [408/428], Loss: 0.0001
Epoch [6/7], Batch [409/428], Loss: 0.0177
Epoch [6/7], Batch [410/428], Loss: 0.0030
Epoch [6/7], Batch [411/428], Loss: 0.0012
Epoch [6/7], Batch [412/428], Loss: 2.6995
Epoch [6/7], Batch [413/428], Loss: 0.0761
Epoch [6/7], Batch [414/428], Loss: 0.0562
Epoch [6/7], Batch [415/428], Loss: 0.7412
Epoch [6/7], Batch [416/428], Loss: 0.0005
Epoch [6/7], Batch [417/428], Loss: 0.0010
Epoch [6/7], Batch [418/428], Loss: 0.1128
Epoch [6/7], Batch [419/428], Loss: 0.0002
Epoch [6/7], Batch [420/428], Loss: 0.0000
Epoch [6/7], Batch [421/428], Loss: 0.0002
Epoch [6/7], Batch [422/428], Loss: 0.0003
Epoch [6/7], Batch [423/428], Loss: 0.0003
Epoch [6/7], Batch [424/428], Loss: 0.0616
Epoch [6/7], Batch [425/428], Loss: 0.0001
Epoch [6/7], Batch [426/428], Loss: 0.0404
Epoch [6/7], Batch [427/428], Loss: 0.0445
Epoch [6/7], Batch [428/428], Loss: 0.0005
Epoch [6] Training Time: 238.60 seconds
Epoch [6/7], Average Loss: 0.1952, Training Accuracy: 0.9322
Epoch [6], Validation Loss: 0.6761, Validation Accuracy: 0.7570
Epoch [6] Validation Time: 8.99 seconds
--------------------------------------------------
Epoch [7/7], Batch [1/428], Loss: 0.0159
Epoch [7/7], Batch [2/428], Loss: 0.2185
Epoch [7/7], Batch [3/428], Loss: 0.0017
Epoch [7/7], Batch [4/428], Loss: 0.0000
Epoch [7/7], Batch [5/428], Loss: 0.0037
Epoch [7/7], Batch [6/428], Loss: 0.0006
Epoch [7/7], Batch [7/428], Loss: 0.0001
Epoch [7/7], Batch [8/428], Loss: 0.0001
Epoch [7/7], Batch [9/428], Loss: 0.0032
Epoch [7/7], Batch [10/428], Loss: 0.0016
Epoch [7/7], Batch [11/428], Loss: 0.0114
Epoch [7/7], Batch [12/428], Loss: 0.0003
Epoch [7/7], Batch [13/428], Loss: 0.0003
Epoch [7/7], Batch [14/428], Loss: 0.0000
Epoch [7/7], Batch [15/428], Loss: 0.0001
Epoch [7/7], Batch [16/428], Loss: 0.1668
Epoch [7/7], Batch [17/428], Loss: 0.0048
Epoch [7/7], Batch [18/428], Loss: 0.2418
Epoch [7/7], Batch [19/428], Loss: 5.3946
Epoch [7/7], Batch [20/428], Loss: 0.1245
Epoch [7/7], Batch [21/428], Loss: 0.0001
Epoch [7/7], Batch [22/428], Loss: 0.0009
Epoch [7/7], Batch [23/428], Loss: 0.0001
Epoch [7/7], Batch [24/428], Loss: 0.0143
Epoch [7/7], Batch [25/428], Loss: 0.0110
Epoch [7/7], Batch [26/428], Loss: 0.0003
Epoch [7/7], Batch [27/428], Loss: 0.0901
Epoch [7/7], Batch [28/428], Loss: 0.0017
Epoch [7/7], Batch [29/428], Loss: 0.1737
Epoch [7/7], Batch [30/428], Loss: 0.0015
Epoch [7/7], Batch [31/428], Loss: 5.0340
Epoch [7/7], Batch [32/428], Loss: 0.0001
Epoch [7/7], Batch [33/428], Loss: 0.0002
Epoch [7/7], Batch [34/428], Loss: 0.0020
Epoch [7/7], Batch [35/428], Loss: 0.0002
Epoch [7/7], Batch [36/428], Loss: 0.0135
Epoch [7/7], Batch [37/428], Loss: 0.0002
Epoch [7/7], Batch [38/428], Loss: 0.0218
Epoch [7/7], Batch [39/428], Loss: 0.0130
Epoch [7/7], Batch [40/428], Loss: 0.0087
Epoch [7/7], Batch [41/428], Loss: 0.0011
Epoch [7/7], Batch [42/428], Loss: 0.9519
Epoch [7/7], Batch [43/428], Loss: 0.0112
Epoch [7/7], Batch [44/428], Loss: 0.0005
Epoch [7/7], Batch [45/428], Loss: 0.3578
Epoch [7/7], Batch [46/428], Loss: 0.0030
Epoch [7/7], Batch [47/428], Loss: 0.0001
Epoch [7/7], Batch [48/428], Loss: 0.0145
Epoch [7/7], Batch [49/428], Loss: 0.0001
Epoch [7/7], Batch [50/428], Loss: 0.0028
Epoch [7/7], Batch [51/428], Loss: 0.0052
Epoch [7/7], Batch [52/428], Loss: 0.0085
Epoch [7/7], Batch [53/428], Loss: 0.0310
Epoch [7/7], Batch [54/428], Loss: 0.0091
Epoch [7/7], Batch [55/428], Loss: 0.0188
Epoch [7/7], Batch [56/428], Loss: 0.0054
Epoch [7/7], Batch [57/428], Loss: 0.0291
Epoch [7/7], Batch [58/428], Loss: 0.0301
Epoch [7/7], Batch [59/428], Loss: 0.0178
Epoch [7/7], Batch [60/428], Loss: 0.0010
Epoch [7/7], Batch [61/428], Loss: 0.1297
Epoch [7/7], Batch [62/428], Loss: 0.0019
Epoch [7/7], Batch [63/428], Loss: 0.0001
Epoch [7/7], Batch [64/428], Loss: 0.0001
Epoch [7/7], Batch [65/428], Loss: 0.0001
Epoch [7/7], Batch [66/428], Loss: 0.0008
Epoch [7/7], Batch [67/428], Loss: 0.8717
Epoch [7/7], Batch [68/428], Loss: 1.9572
Epoch [7/7], Batch [69/428], Loss: 0.0020
Epoch [7/7], Batch [70/428], Loss: 0.0034
Epoch [7/7], Batch [71/428], Loss: 0.0508
Epoch [7/7], Batch [72/428], Loss: 0.1939
Epoch [7/7], Batch [73/428], Loss: 0.0223
Epoch [7/7], Batch [74/428], Loss: 0.0014
Epoch [7/7], Batch [75/428], Loss: 0.2564
Epoch [7/7], Batch [76/428], Loss: 0.0003
Epoch [7/7], Batch [77/428], Loss: 0.0008
Epoch [7/7], Batch [78/428], Loss: 0.0770
Epoch [7/7], Batch [79/428], Loss: 0.0000
Epoch [7/7], Batch [80/428], Loss: 0.0007
Epoch [7/7], Batch [81/428], Loss: 0.0988
Epoch [7/7], Batch [82/428], Loss: 0.0422
Epoch [7/7], Batch [83/428], Loss: 0.0024
Epoch [7/7], Batch [84/428], Loss: 0.0035
Epoch [7/7], Batch [85/428], Loss: 0.2099
Epoch [7/7], Batch [86/428], Loss: 0.0071
Epoch [7/7], Batch [87/428], Loss: 0.0041
Epoch [7/7], Batch [88/428], Loss: 0.0110
Epoch [7/7], Batch [89/428], Loss: 0.0000
Epoch [7/7], Batch [90/428], Loss: 0.0002
Epoch [7/7], Batch [91/428], Loss: 0.0026
Epoch [7/7], Batch [92/428], Loss: 0.1653
Epoch [7/7], Batch [93/428], Loss: 0.0028
Epoch [7/7], Batch [94/428], Loss: 0.0071
Epoch [7/7], Batch [95/428], Loss: 0.0024
Epoch [7/7], Batch [96/428], Loss: 0.4244
Epoch [7/7], Batch [97/428], Loss: 0.1183
Epoch [7/7], Batch [98/428], Loss: 0.1137
Epoch [7/7], Batch [99/428], Loss: 0.0034
Epoch [7/7], Batch [100/428], Loss: 0.0421
Epoch [7/7], Batch [101/428], Loss: 0.0088
Epoch [7/7], Batch [102/428], Loss: 0.0002
Epoch [7/7], Batch [103/428], Loss: 0.0001
Epoch [7/7], Batch [104/428], Loss: 0.0000
Epoch [7/7], Batch [105/428], Loss: 0.0001
Epoch [7/7], Batch [106/428], Loss: 0.0234
Epoch [7/7], Batch [107/428], Loss: 0.8003
Epoch [7/7], Batch [108/428], Loss: 0.0396
Epoch [7/7], Batch [109/428], Loss: 0.0020
Epoch [7/7], Batch [110/428], Loss: 0.0000
Epoch [7/7], Batch [111/428], Loss: 0.0019
Epoch [7/7], Batch [112/428], Loss: 1.7656
Epoch [7/7], Batch [113/428], Loss: 0.0000
Epoch [7/7], Batch [114/428], Loss: 0.0024
Epoch [7/7], Batch [115/428], Loss: 0.1890
Epoch [7/7], Batch [116/428], Loss: 0.0759
Epoch [7/7], Batch [117/428], Loss: 0.0008
Epoch [7/7], Batch [118/428], Loss: 0.0004
Epoch [7/7], Batch [119/428], Loss: 0.0003
Epoch [7/7], Batch [120/428], Loss: 0.0001
Epoch [7/7], Batch [121/428], Loss: 0.0032
Epoch [7/7], Batch [122/428], Loss: 0.0001
Epoch [7/7], Batch [123/428], Loss: 0.5323
Epoch [7/7], Batch [124/428], Loss: 0.0692
Epoch [7/7], Batch [125/428], Loss: 0.0013
Epoch [7/7], Batch [126/428], Loss: 0.0436
Epoch [7/7], Batch [127/428], Loss: 0.0000
Epoch [7/7], Batch [128/428], Loss: 0.0001
Epoch [7/7], Batch [129/428], Loss: 0.0095
Epoch [7/7], Batch [130/428], Loss: 1.9084
Epoch [7/7], Batch [131/428], Loss: 0.0006
Epoch [7/7], Batch [132/428], Loss: 0.0146
Epoch [7/7], Batch [133/428], Loss: 2.6815
Epoch [7/7], Batch [134/428], Loss: 0.0088
Epoch [7/7], Batch [135/428], Loss: 0.0194
Epoch [7/7], Batch [136/428], Loss: 0.8625
Epoch [7/7], Batch [137/428], Loss: 0.0004
Epoch [7/7], Batch [138/428], Loss: 0.0293
Epoch [7/7], Batch [139/428], Loss: 3.1669
Epoch [7/7], Batch [140/428], Loss: 0.3403
Epoch [7/7], Batch [141/428], Loss: 0.0067
Epoch [7/7], Batch [142/428], Loss: 0.0675
Epoch [7/7], Batch [143/428], Loss: 0.0003
Epoch [7/7], Batch [144/428], Loss: 0.0544
Epoch [7/7], Batch [145/428], Loss: 0.0001
Epoch [7/7], Batch [146/428], Loss: 0.0276
Epoch [7/7], Batch [147/428], Loss: 0.0002
Epoch [7/7], Batch [148/428], Loss: 0.0018
Epoch [7/7], Batch [149/428], Loss: 0.0178
Epoch [7/7], Batch [150/428], Loss: 0.0492
Epoch [7/7], Batch [151/428], Loss: 0.0001
Epoch [7/7], Batch [152/428], Loss: 0.0062
Epoch [7/7], Batch [153/428], Loss: 0.0005
Epoch [7/7], Batch [154/428], Loss: 0.0016
Epoch [7/7], Batch [155/428], Loss: 0.0000
Epoch [7/7], Batch [156/428], Loss: 0.0328
Epoch [7/7], Batch [157/428], Loss: 0.0078
Epoch [7/7], Batch [158/428], Loss: 0.0202
Epoch [7/7], Batch [159/428], Loss: 0.0001
Epoch [7/7], Batch [160/428], Loss: 0.0009
Epoch [7/7], Batch [161/428], Loss: 1.4646
Epoch [7/7], Batch [162/428], Loss: 1.5540
Epoch [7/7], Batch [163/428], Loss: 0.0021
Epoch [7/7], Batch [164/428], Loss: 0.0001
Epoch [7/7], Batch [165/428], Loss: 0.0003
Epoch [7/7], Batch [166/428], Loss: 0.0531
Epoch [7/7], Batch [167/428], Loss: 0.0002
Epoch [7/7], Batch [168/428], Loss: 0.0117
Epoch [7/7], Batch [169/428], Loss: 0.0239
Epoch [7/7], Batch [170/428], Loss: 0.0183
Epoch [7/7], Batch [171/428], Loss: 1.5972
Epoch [7/7], Batch [172/428], Loss: 0.0387
Epoch [7/7], Batch [173/428], Loss: 0.1638
Epoch [7/7], Batch [174/428], Loss: 0.0011
Epoch [7/7], Batch [175/428], Loss: 0.0021
Epoch [7/7], Batch [176/428], Loss: 0.0002
Epoch [7/7], Batch [177/428], Loss: 0.0001
Epoch [7/7], Batch [178/428], Loss: 0.0047
Epoch [7/7], Batch [179/428], Loss: 0.0350
Epoch [7/7], Batch [180/428], Loss: 0.0579
Epoch [7/7], Batch [181/428], Loss: 0.0179
Epoch [7/7], Batch [182/428], Loss: 1.6421
Epoch [7/7], Batch [183/428], Loss: 0.0001
Epoch [7/7], Batch [184/428], Loss: 0.4723
Epoch [7/7], Batch [185/428], Loss: 0.0095
Epoch [7/7], Batch [186/428], Loss: 0.0485
Epoch [7/7], Batch [187/428], Loss: 0.0038
Epoch [7/7], Batch [188/428], Loss: 0.0464
Epoch [7/7], Batch [189/428], Loss: 0.0001
Epoch [7/7], Batch [190/428], Loss: 0.0008
Epoch [7/7], Batch [191/428], Loss: 0.0002
Epoch [7/7], Batch [192/428], Loss: 0.0102
Epoch [7/7], Batch [193/428], Loss: 0.0004
Epoch [7/7], Batch [194/428], Loss: 0.0016
Epoch [7/7], Batch [195/428], Loss: 0.0036
Epoch [7/7], Batch [196/428], Loss: 0.0007
Epoch [7/7], Batch [197/428], Loss: 0.0001
Epoch [7/7], Batch [198/428], Loss: 0.0002
Epoch [7/7], Batch [199/428], Loss: 0.0099
Epoch [7/7], Batch [200/428], Loss: 0.0997
Epoch [7/7], Batch [201/428], Loss: 0.0297
Epoch [7/7], Batch [202/428], Loss: 0.0248
Epoch [7/7], Batch [203/428], Loss: 0.0086
Epoch [7/7], Batch [204/428], Loss: 0.0013
Epoch [7/7], Batch [205/428], Loss: 0.0480
Epoch [7/7], Batch [206/428], Loss: 0.0143
Epoch [7/7], Batch [207/428], Loss: 0.0022
Epoch [7/7], Batch [208/428], Loss: 0.0001
Epoch [7/7], Batch [209/428], Loss: 0.0135
Epoch [7/7], Batch [210/428], Loss: 0.0049
Epoch [7/7], Batch [211/428], Loss: 1.5100
Epoch [7/7], Batch [212/428], Loss: 0.0175
Epoch [7/7], Batch [213/428], Loss: 0.0153
Epoch [7/7], Batch [214/428], Loss: 0.0006
Epoch [7/7], Batch [215/428], Loss: 0.0013[INFO 06-13 18:47:07] ax.service.ax_client: Completed trial 4 with data: {'objective': (np.float64(-0.770635), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 18:47:07] ax.service.ax_client: Generated new trial 5 with parameters {'lr': 0.000436, 'num_epochs': 5, 'unfreeze_epoch': 4, 'max_length': 112000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [7/7], Batch [216/428], Loss: 0.0006
Epoch [7/7], Batch [217/428], Loss: 0.0000
Epoch [7/7], Batch [218/428], Loss: 0.0012
Epoch [7/7], Batch [219/428], Loss: 0.0411
Epoch [7/7], Batch [220/428], Loss: 0.0001
Epoch [7/7], Batch [221/428], Loss: 0.0024
Epoch [7/7], Batch [222/428], Loss: 0.0057
Epoch [7/7], Batch [223/428], Loss: 0.0003
Epoch [7/7], Batch [224/428], Loss: 4.3081
Epoch [7/7], Batch [225/428], Loss: 0.0223
Epoch [7/7], Batch [226/428], Loss: 0.0000
Epoch [7/7], Batch [227/428], Loss: 0.1751
Epoch [7/7], Batch [228/428], Loss: 0.0001
Epoch [7/7], Batch [229/428], Loss: 0.0047
Epoch [7/7], Batch [230/428], Loss: 0.0006
Epoch [7/7], Batch [231/428], Loss: 0.0001
Epoch [7/7], Batch [232/428], Loss: 0.0001
Epoch [7/7], Batch [233/428], Loss: 0.0213
Epoch [7/7], Batch [234/428], Loss: 0.1817
Epoch [7/7], Batch [235/428], Loss: 0.0006
Epoch [7/7], Batch [236/428], Loss: 0.0032
Epoch [7/7], Batch [237/428], Loss: 0.0002
Epoch [7/7], Batch [238/428], Loss: 0.0000
Epoch [7/7], Batch [239/428], Loss: 0.1634
Epoch [7/7], Batch [240/428], Loss: 0.0004
Epoch [7/7], Batch [241/428], Loss: 0.0027
Epoch [7/7], Batch [242/428], Loss: 0.0280
Epoch [7/7], Batch [243/428], Loss: 0.0048
Epoch [7/7], Batch [244/428], Loss: 0.0002
Epoch [7/7], Batch [245/428], Loss: 0.0062
Epoch [7/7], Batch [246/428], Loss: 0.0021
Epoch [7/7], Batch [247/428], Loss: 0.1292
Epoch [7/7], Batch [248/428], Loss: 0.0126
Epoch [7/7], Batch [249/428], Loss: 0.0003
Epoch [7/7], Batch [250/428], Loss: 0.0020
Epoch [7/7], Batch [251/428], Loss: 0.0006
Epoch [7/7], Batch [252/428], Loss: 0.0016
Epoch [7/7], Batch [253/428], Loss: 0.0115
Epoch [7/7], Batch [254/428], Loss: 0.0345
Epoch [7/7], Batch [255/428], Loss: 0.0000
Epoch [7/7], Batch [256/428], Loss: 0.0064
Epoch [7/7], Batch [257/428], Loss: 0.0293
Epoch [7/7], Batch [258/428], Loss: 0.0482
Epoch [7/7], Batch [259/428], Loss: 0.0000
Epoch [7/7], Batch [260/428], Loss: 0.0004
Epoch [7/7], Batch [261/428], Loss: 0.1135
Epoch [7/7], Batch [262/428], Loss: 0.1070
Epoch [7/7], Batch [263/428], Loss: 0.2052
Epoch [7/7], Batch [264/428], Loss: 0.2811
Epoch [7/7], Batch [265/428], Loss: 0.0001
Epoch [7/7], Batch [266/428], Loss: 0.0000
Epoch [7/7], Batch [267/428], Loss: 0.0058
Epoch [7/7], Batch [268/428], Loss: 0.1012
Epoch [7/7], Batch [269/428], Loss: 0.0003
Epoch [7/7], Batch [270/428], Loss: 0.0289
Epoch [7/7], Batch [271/428], Loss: 0.0004
Epoch [7/7], Batch [272/428], Loss: 0.0500
Epoch [7/7], Batch [273/428], Loss: 0.0086
Epoch [7/7], Batch [274/428], Loss: 0.3831
Epoch [7/7], Batch [275/428], Loss: 0.0066
Epoch [7/7], Batch [276/428], Loss: 0.2474
Epoch [7/7], Batch [277/428], Loss: 0.0976
Epoch [7/7], Batch [278/428], Loss: 0.0003
Epoch [7/7], Batch [279/428], Loss: 0.2201
Epoch [7/7], Batch [280/428], Loss: 0.0195
Epoch [7/7], Batch [281/428], Loss: 0.0002
Epoch [7/7], Batch [282/428], Loss: 0.0184
Epoch [7/7], Batch [283/428], Loss: 0.0000
Epoch [7/7], Batch [284/428], Loss: 0.0376
Epoch [7/7], Batch [285/428], Loss: 0.0036
Epoch [7/7], Batch [286/428], Loss: 0.0027
Epoch [7/7], Batch [287/428], Loss: 0.8428
Epoch [7/7], Batch [288/428], Loss: 0.0004
Epoch [7/7], Batch [289/428], Loss: 0.0001
Epoch [7/7], Batch [290/428], Loss: 0.5571
Epoch [7/7], Batch [291/428], Loss: 0.0937
Epoch [7/7], Batch [292/428], Loss: 0.0002
Epoch [7/7], Batch [293/428], Loss: 0.0005
Epoch [7/7], Batch [294/428], Loss: 0.1067
Epoch [7/7], Batch [295/428], Loss: 0.0081
Epoch [7/7], Batch [296/428], Loss: 0.1215
Epoch [7/7], Batch [297/428], Loss: 0.0826
Epoch [7/7], Batch [298/428], Loss: 6.2636
Epoch [7/7], Batch [299/428], Loss: 0.0000
Epoch [7/7], Batch [300/428], Loss: 0.4867
Epoch [7/7], Batch [301/428], Loss: 0.0176
Epoch [7/7], Batch [302/428], Loss: 0.0018
Epoch [7/7], Batch [303/428], Loss: 0.3354
Epoch [7/7], Batch [304/428], Loss: 0.1383
Epoch [7/7], Batch [305/428], Loss: 0.0189
Epoch [7/7], Batch [306/428], Loss: 0.0185
Epoch [7/7], Batch [307/428], Loss: 0.0001
Epoch [7/7], Batch [308/428], Loss: 0.0077
Epoch [7/7], Batch [309/428], Loss: 0.0020
Epoch [7/7], Batch [310/428], Loss: 0.3768
Epoch [7/7], Batch [311/428], Loss: 0.0456
Epoch [7/7], Batch [312/428], Loss: 0.0003
Epoch [7/7], Batch [313/428], Loss: 0.0840
Epoch [7/7], Batch [314/428], Loss: 0.0281
Epoch [7/7], Batch [315/428], Loss: 0.4350
Epoch [7/7], Batch [316/428], Loss: 0.0118
Epoch [7/7], Batch [317/428], Loss: 0.0003
Epoch [7/7], Batch [318/428], Loss: 0.0011
Epoch [7/7], Batch [319/428], Loss: 0.0624
Epoch [7/7], Batch [320/428], Loss: 0.0478
Epoch [7/7], Batch [321/428], Loss: 0.0002
Epoch [7/7], Batch [322/428], Loss: 0.0151
Epoch [7/7], Batch [323/428], Loss: 0.0103
Epoch [7/7], Batch [324/428], Loss: 0.0001
Epoch [7/7], Batch [325/428], Loss: 0.0012
Epoch [7/7], Batch [326/428], Loss: 0.0162
Epoch [7/7], Batch [327/428], Loss: 0.0016
Epoch [7/7], Batch [328/428], Loss: 0.0064
Epoch [7/7], Batch [329/428], Loss: 0.0000
Epoch [7/7], Batch [330/428], Loss: 0.1423
Epoch [7/7], Batch [331/428], Loss: 0.0228
Epoch [7/7], Batch [332/428], Loss: 0.0327
Epoch [7/7], Batch [333/428], Loss: 0.0092
Epoch [7/7], Batch [334/428], Loss: 0.0001
Epoch [7/7], Batch [335/428], Loss: 0.0047
Epoch [7/7], Batch [336/428], Loss: 0.0003
Epoch [7/7], Batch [337/428], Loss: 0.0017
Epoch [7/7], Batch [338/428], Loss: 0.0022
Epoch [7/7], Batch [339/428], Loss: 0.1152
Epoch [7/7], Batch [340/428], Loss: 0.0000
Epoch [7/7], Batch [341/428], Loss: 0.0212
Epoch [7/7], Batch [342/428], Loss: 0.8926
Epoch [7/7], Batch [343/428], Loss: 0.0016
Epoch [7/7], Batch [344/428], Loss: 0.0008
Epoch [7/7], Batch [345/428], Loss: 0.0002
Epoch [7/7], Batch [346/428], Loss: 0.0001
Epoch [7/7], Batch [347/428], Loss: 0.0034
Epoch [7/7], Batch [348/428], Loss: 0.0158
Epoch [7/7], Batch [349/428], Loss: 0.0086
Epoch [7/7], Batch [350/428], Loss: 0.0000
Epoch [7/7], Batch [351/428], Loss: 0.0980
Epoch [7/7], Batch [352/428], Loss: 0.0004
Epoch [7/7], Batch [353/428], Loss: 0.1901
Epoch [7/7], Batch [354/428], Loss: 0.7095
Epoch [7/7], Batch [355/428], Loss: 0.0072
Epoch [7/7], Batch [356/428], Loss: 0.0131
Epoch [7/7], Batch [357/428], Loss: 0.0137
Epoch [7/7], Batch [358/428], Loss: 0.0000
Epoch [7/7], Batch [359/428], Loss: 0.0012
Epoch [7/7], Batch [360/428], Loss: 0.0993
Epoch [7/7], Batch [361/428], Loss: 0.0001
Epoch [7/7], Batch [362/428], Loss: 0.0008
Epoch [7/7], Batch [363/428], Loss: 0.0297
Epoch [7/7], Batch [364/428], Loss: 0.5074
Epoch [7/7], Batch [365/428], Loss: 0.0001
Epoch [7/7], Batch [366/428], Loss: 0.6067
Epoch [7/7], Batch [367/428], Loss: 0.1067
Epoch [7/7], Batch [368/428], Loss: 0.0832
Epoch [7/7], Batch [369/428], Loss: 0.0064
Epoch [7/7], Batch [370/428], Loss: 0.0156
Epoch [7/7], Batch [371/428], Loss: 0.0842
Epoch [7/7], Batch [372/428], Loss: 0.0315
Epoch [7/7], Batch [373/428], Loss: 0.0002
Epoch [7/7], Batch [374/428], Loss: 0.0806
Epoch [7/7], Batch [375/428], Loss: 0.2534
Epoch [7/7], Batch [376/428], Loss: 0.0618
Epoch [7/7], Batch [377/428], Loss: 0.0098
Epoch [7/7], Batch [378/428], Loss: 0.0093
Epoch [7/7], Batch [379/428], Loss: 0.0009
Epoch [7/7], Batch [380/428], Loss: 2.3001
Epoch [7/7], Batch [381/428], Loss: 0.0300
Epoch [7/7], Batch [382/428], Loss: 0.0116
Epoch [7/7], Batch [383/428], Loss: 0.0043
Epoch [7/7], Batch [384/428], Loss: 0.0237
Epoch [7/7], Batch [385/428], Loss: 4.5375
Epoch [7/7], Batch [386/428], Loss: 1.3915
Epoch [7/7], Batch [387/428], Loss: 0.0043
Epoch [7/7], Batch [388/428], Loss: 0.0000
Epoch [7/7], Batch [389/428], Loss: 0.0192
Epoch [7/7], Batch [390/428], Loss: 0.1405
Epoch [7/7], Batch [391/428], Loss: 0.0002
Epoch [7/7], Batch [392/428], Loss: 0.0245
Epoch [7/7], Batch [393/428], Loss: 0.0004
Epoch [7/7], Batch [394/428], Loss: 0.0118
Epoch [7/7], Batch [395/428], Loss: 0.1396
Epoch [7/7], Batch [396/428], Loss: 0.0000
Epoch [7/7], Batch [397/428], Loss: 0.0001
Epoch [7/7], Batch [398/428], Loss: 0.0022
Epoch [7/7], Batch [399/428], Loss: 0.0923
Epoch [7/7], Batch [400/428], Loss: 0.0157
Epoch [7/7], Batch [401/428], Loss: 0.3397
Epoch [7/7], Batch [402/428], Loss: 0.1690
Epoch [7/7], Batch [403/428], Loss: 0.0006
Epoch [7/7], Batch [404/428], Loss: 0.0001
Epoch [7/7], Batch [405/428], Loss: 0.0089
Epoch [7/7], Batch [406/428], Loss: 0.0001
Epoch [7/7], Batch [407/428], Loss: 0.0008
Epoch [7/7], Batch [408/428], Loss: 0.0370
Epoch [7/7], Batch [409/428], Loss: 0.0001
Epoch [7/7], Batch [410/428], Loss: 0.0007
Epoch [7/7], Batch [411/428], Loss: 0.0469
Epoch [7/7], Batch [412/428], Loss: 0.0658
Epoch [7/7], Batch [413/428], Loss: 0.0000
Epoch [7/7], Batch [414/428], Loss: 0.0094
Epoch [7/7], Batch [415/428], Loss: 0.0630
Epoch [7/7], Batch [416/428], Loss: 0.1199
Epoch [7/7], Batch [417/428], Loss: 0.0077
Epoch [7/7], Batch [418/428], Loss: 0.2158
Epoch [7/7], Batch [419/428], Loss: 0.0306
Epoch [7/7], Batch [420/428], Loss: 2.9275
Epoch [7/7], Batch [421/428], Loss: 0.0212
Epoch [7/7], Batch [422/428], Loss: 0.0011
Epoch [7/7], Batch [423/428], Loss: 0.0126
Epoch [7/7], Batch [424/428], Loss: 0.0002
Epoch [7/7], Batch [425/428], Loss: 0.0030
Epoch [7/7], Batch [426/428], Loss: 0.0002
Epoch [7/7], Batch [427/428], Loss: 0.1211
Epoch [7/7], Batch [428/428], Loss: 0.5635
Epoch [7] Training Time: 237.41 seconds
Epoch [7/7], Average Loss: 0.1756, Training Accuracy: 0.9486
Epoch [7], Validation Loss: 0.6921, Validation Accuracy: 0.7706
Epoch [7] Validation Time: 9.04 seconds
--------------------------------------------------

Running trial 5 with config: {'batch_size': 1, 'lr': 0.0004361002812039365, 'num_epochs': 5, 'unfreeze_epoch': 4, 'max_length': 112000, 'device': device(type='cpu')}
Epoch [1/5], Batch [1/428], Loss: 0.6930
Epoch [1/5], Batch [2/428], Loss: 2.4918
Epoch [1/5], Batch [3/428], Loss: 2.2294
Epoch [1/5], Batch [4/428], Loss: 2.3212
Epoch [1/5], Batch [5/428], Loss: 2.5582
Epoch [1/5], Batch [6/428], Loss: 2.8514
Epoch [1/5], Batch [7/428], Loss: 1.2125
Epoch [1/5], Batch [8/428], Loss: 3.5268
Epoch [1/5], Batch [9/428], Loss: 1.0974
Epoch [1/5], Batch [10/428], Loss: 2.6244
Epoch [1/5], Batch [11/428], Loss: 0.6830
Epoch [1/5], Batch [12/428], Loss: 0.9803
Epoch [1/5], Batch [13/428], Loss: 3.2783
Epoch [1/5], Batch [14/428], Loss: 2.8806
Epoch [1/5], Batch [15/428], Loss: 1.4580
Epoch [1/5], Batch [16/428], Loss: 2.3711
Epoch [1/5], Batch [17/428], Loss: 0.4612
Epoch [1/5], Batch [18/428], Loss: 2.9086
Epoch [1/5], Batch [19/428], Loss: 2.9734
Epoch [1/5], Batch [20/428], Loss: 1.9092
Epoch [1/5], Batch [21/428], Loss: 2.6248
Epoch [1/5], Batch [22/428], Loss: 1.9015
Epoch [1/5], Batch [23/428], Loss: 2.4959
Epoch [1/5], Batch [24/428], Loss: 0.9919
Epoch [1/5], Batch [25/428], Loss: 1.4714
Epoch [1/5], Batch [26/428], Loss: 0.7045
Epoch [1/5], Batch [27/428], Loss: 0.9276
Epoch [1/5], Batch [28/428], Loss: 2.8670
Epoch [1/5], Batch [29/428], Loss: 0.8982
Epoch [1/5], Batch [30/428], Loss: 2.1282
Epoch [1/5], Batch [31/428], Loss: 2.2397
Epoch [1/5], Batch [32/428], Loss: 0.9195
Epoch [1/5], Batch [33/428], Loss: 1.0010
Epoch [1/5], Batch [34/428], Loss: 2.1025
Epoch [1/5], Batch [35/428], Loss: 3.4413
Epoch [1/5], Batch [36/428], Loss: 2.2218
Epoch [1/5], Batch [37/428], Loss: 4.3195
Epoch [1/5], Batch [38/428], Loss: 2.1941
Epoch [1/5], Batch [39/428], Loss: 3.0291
Epoch [1/5], Batch [40/428], Loss: 2.2108
Epoch [1/5], Batch [41/428], Loss: 2.0656
Epoch [1/5], Batch [42/428], Loss: 0.6132
Epoch [1/5], Batch [43/428], Loss: 0.1344
Epoch [1/5], Batch [44/428], Loss: 1.4812
Epoch [1/5], Batch [45/428], Loss: 2.5149
Epoch [1/5], Batch [46/428], Loss: 3.0260
Epoch [1/5], Batch [47/428], Loss: 0.1092
Epoch [1/5], Batch [48/428], Loss: 0.6375
Epoch [1/5], Batch [49/428], Loss: 1.5610
Epoch [1/5], Batch [50/428], Loss: 2.8493
Epoch [1/5], Batch [51/428], Loss: 1.5320
Epoch [1/5], Batch [52/428], Loss: 1.0057
Epoch [1/5], Batch [53/428], Loss: 2.7195
Epoch [1/5], Batch [54/428], Loss: 0.5580
Epoch [1/5], Batch [55/428], Loss: 1.2721
Epoch [1/5], Batch [56/428], Loss: 1.5818
Epoch [1/5], Batch [57/428], Loss: 1.1826
Epoch [1/5], Batch [58/428], Loss: 2.0300
Epoch [1/5], Batch [59/428], Loss: 2.9903
Epoch [1/5], Batch [60/428], Loss: 0.2242
Epoch [1/5], Batch [61/428], Loss: 1.7225
Epoch [1/5], Batch [62/428], Loss: 3.5488
Epoch [1/5], Batch [63/428], Loss: 0.1607
Epoch [1/5], Batch [64/428], Loss: 0.0566
Epoch [1/5], Batch [65/428], Loss: 0.6645
Epoch [1/5], Batch [66/428], Loss: 1.2778
Epoch [1/5], Batch [67/428], Loss: 1.0530
Epoch [1/5], Batch [68/428], Loss: 3.2574
Epoch [1/5], Batch [69/428], Loss: 2.9083
Epoch [1/5], Batch [70/428], Loss: 0.2009
Epoch [1/5], Batch [71/428], Loss: 0.1972
Epoch [1/5], Batch [72/428], Loss: 0.6424
Epoch [1/5], Batch [73/428], Loss: 1.5363
Epoch [1/5], Batch [74/428], Loss: 0.7825
Epoch [1/5], Batch [75/428], Loss: 2.8405
Epoch [1/5], Batch [76/428], Loss: 0.0412
Epoch [1/5], Batch [77/428], Loss: 1.4113
Epoch [1/5], Batch [78/428], Loss: 0.8037
Epoch [1/5], Batch [79/428], Loss: 1.2459
Epoch [1/5], Batch [80/428], Loss: 0.6520
Epoch [1/5], Batch [81/428], Loss: 2.8198
Epoch [1/5], Batch [82/428], Loss: 0.1166
Epoch [1/5], Batch [83/428], Loss: 2.2741
Epoch [1/5], Batch [84/428], Loss: 1.5716
Epoch [1/5], Batch [85/428], Loss: 2.5644
Epoch [1/5], Batch [86/428], Loss: 1.7423
Epoch [1/5], Batch [87/428], Loss: 0.0501
Epoch [1/5], Batch [88/428], Loss: 0.3225
Epoch [1/5], Batch [89/428], Loss: 4.6810
Epoch [1/5], Batch [90/428], Loss: 3.6776
Epoch [1/5], Batch [91/428], Loss: 2.3557
Epoch [1/5], Batch [92/428], Loss: 0.0167
Epoch [1/5], Batch [93/428], Loss: 2.1102
Epoch [1/5], Batch [94/428], Loss: 2.2813
Epoch [1/5], Batch [95/428], Loss: 1.8692
Epoch [1/5], Batch [96/428], Loss: 1.9413
Epoch [1/5], Batch [97/428], Loss: 0.6870
Epoch [1/5], Batch [98/428], Loss: 1.7463
Epoch [1/5], Batch [99/428], Loss: 3.5049
Epoch [1/5], Batch [100/428], Loss: 0.7022
Epoch [1/5], Batch [101/428], Loss: 2.4670
Epoch [1/5], Batch [102/428], Loss: 0.1159
Epoch [1/5], Batch [103/428], Loss: 0.4015
Epoch [1/5], Batch [104/428], Loss: 1.8562
Epoch [1/5], Batch [105/428], Loss: 1.1342
Epoch [1/5], Batch [106/428], Loss: 0.8275
Epoch [1/5], Batch [107/428], Loss: 0.1066
Epoch [1/5], Batch [108/428], Loss: 0.6026
Epoch [1/5], Batch [109/428], Loss: 0.0469
Epoch [1/5], Batch [110/428], Loss: 0.2260
Epoch [1/5], Batch [111/428], Loss: 1.0449
Epoch [1/5], Batch [112/428], Loss: 0.9944
Epoch [1/5], Batch [113/428], Loss: 1.2618
Epoch [1/5], Batch [114/428], Loss: 0.0010
Epoch [1/5], Batch [115/428], Loss: 0.9542
Epoch [1/5], Batch [116/428], Loss: 1.8275
Epoch [1/5], Batch [117/428], Loss: 0.7709
Epoch [1/5], Batch [118/428], Loss: 1.3291
Epoch [1/5], Batch [119/428], Loss: 0.1498
Epoch [1/5], Batch [120/428], Loss: 0.4068
Epoch [1/5], Batch [121/428], Loss: 1.4665
Epoch [1/5], Batch [122/428], Loss: 0.3073
Epoch [1/5], Batch [123/428], Loss: 0.0675
Epoch [1/5], Batch [124/428], Loss: 2.6530
Epoch [1/5], Batch [125/428], Loss: 2.3217
Epoch [1/5], Batch [126/428], Loss: 2.3563
Epoch [1/5], Batch [127/428], Loss: 0.1648
Epoch [1/5], Batch [128/428], Loss: 2.9384
Epoch [1/5], Batch [129/428], Loss: 1.3267
Epoch [1/5], Batch [130/428], Loss: 3.3485
Epoch [1/5], Batch [131/428], Loss: 0.0020
Epoch [1/5], Batch [132/428], Loss: 0.4328
Epoch [1/5], Batch [133/428], Loss: 0.0484
Epoch [1/5], Batch [134/428], Loss: 2.9477
Epoch [1/5], Batch [135/428], Loss: 0.0701
Epoch [1/5], Batch [136/428], Loss: 2.2759
Epoch [1/5], Batch [137/428], Loss: 4.2656
Epoch [1/5], Batch [138/428], Loss: 0.0587
Epoch [1/5], Batch [139/428], Loss: 0.9666
Epoch [1/5], Batch [140/428], Loss: 0.0216
Epoch [1/5], Batch [141/428], Loss: 2.7972
Epoch [1/5], Batch [142/428], Loss: 0.0005
Epoch [1/5], Batch [143/428], Loss: 1.1393
Epoch [1/5], Batch [144/428], Loss: 0.5118
Epoch [1/5], Batch [145/428], Loss: 0.0009
Epoch [1/5], Batch [146/428], Loss: 0.0005
Epoch [1/5], Batch [147/428], Loss: 0.5695
Epoch [1/5], Batch [148/428], Loss: 0.4307
Epoch [1/5], Batch [149/428], Loss: 2.8009
Epoch [1/5], Batch [150/428], Loss: 0.0350
Epoch [1/5], Batch [151/428], Loss: 0.2139
Epoch [1/5], Batch [152/428], Loss: 1.7525
Epoch [1/5], Batch [153/428], Loss: 0.0219
Epoch [1/5], Batch [154/428], Loss: 1.8281
Epoch [1/5], Batch [155/428], Loss: 4.8459
Epoch [1/5], Batch [156/428], Loss: 3.2963
Epoch [1/5], Batch [157/428], Loss: 6.1421
Epoch [1/5], Batch [158/428], Loss: 2.0715
Epoch [1/5], Batch [159/428], Loss: 0.2274
Epoch [1/5], Batch [160/428], Loss: 3.4381
Epoch [1/5], Batch [161/428], Loss: 1.6466
Epoch [1/5], Batch [162/428], Loss: 0.0384
Epoch [1/5], Batch [163/428], Loss: 0.0005
Epoch [1/5], Batch [164/428], Loss: 2.9520
Epoch [1/5], Batch [165/428], Loss: 2.4555
Epoch [1/5], Batch [166/428], Loss: 0.0083
Epoch [1/5], Batch [167/428], Loss: 0.0717
Epoch [1/5], Batch [168/428], Loss: 2.2512
Epoch [1/5], Batch [169/428], Loss: 1.7424
Epoch [1/5], Batch [170/428], Loss: 3.4374
Epoch [1/5], Batch [171/428], Loss: 0.7622
Epoch [1/5], Batch [172/428], Loss: 0.9687
Epoch [1/5], Batch [173/428], Loss: 0.0003
Epoch [1/5], Batch [174/428], Loss: 0.0056
Epoch [1/5], Batch [175/428], Loss: 0.0003
Epoch [1/5], Batch [176/428], Loss: 1.9941
Epoch [1/5], Batch [177/428], Loss: 2.2258
Epoch [1/5], Batch [178/428], Loss: 0.1213
Epoch [1/5], Batch [179/428], Loss: 0.9705
Epoch [1/5], Batch [180/428], Loss: 0.2736
Epoch [1/5], Batch [181/428], Loss: 0.0114
Epoch [1/5], Batch [182/428], Loss: 0.0137
Epoch [1/5], Batch [183/428], Loss: 0.1718
Epoch [1/5], Batch [184/428], Loss: 2.4547
Epoch [1/5], Batch [185/428], Loss: 0.0431
Epoch [1/5], Batch [186/428], Loss: 0.0003
Epoch [1/5], Batch [187/428], Loss: 5.9241
Epoch [1/5], Batch [188/428], Loss: 1.3825
Epoch [1/5], Batch [189/428], Loss: 0.5158
Epoch [1/5], Batch [190/428], Loss: 0.0001
Epoch [1/5], Batch [191/428], Loss: 0.1898
Epoch [1/5], Batch [192/428], Loss: 1.4039
Epoch [1/5], Batch [193/428], Loss: 0.0001
Epoch [1/5], Batch [194/428], Loss: 0.0528
Epoch [1/5], Batch [195/428], Loss: 1.2454
Epoch [1/5], Batch [196/428], Loss: 2.6161
Epoch [1/5], Batch [197/428], Loss: 0.3029
Epoch [1/5], Batch [198/428], Loss: 0.9473
Epoch [1/5], Batch [199/428], Loss: 1.2760
Epoch [1/5], Batch [200/428], Loss: 2.6519
Epoch [1/5], Batch [201/428], Loss: 0.4463
Epoch [1/5], Batch [202/428], Loss: 1.5392
Epoch [1/5], Batch [203/428], Loss: 0.9587
Epoch [1/5], Batch [204/428], Loss: 0.1327
Epoch [1/5], Batch [205/428], Loss: 0.9267
Epoch [1/5], Batch [206/428], Loss: 2.7932
Epoch [1/5], Batch [207/428], Loss: 1.5883
Epoch [1/5], Batch [208/428], Loss: 3.1542
Epoch [1/5], Batch [209/428], Loss: 1.0775
Epoch [1/5], Batch [210/428], Loss: 1.7711
Epoch [1/5], Batch [211/428], Loss: 1.5349
Epoch [1/5], Batch [212/428], Loss: 0.0512
Epoch [1/5], Batch [213/428], Loss: 1.7340
Epoch [1/5], Batch [214/428], Loss: 0.4879
Epoch [1/5], Batch [215/428], Loss: 1.0531
Epoch [1/5], Batch [216/428], Loss: 3.3388
Epoch [1/5], Batch [217/428], Loss: 3.3531
Epoch [1/5], Batch [218/428], Loss: 0.0008
Epoch [1/5], Batch [219/428], Loss: 0.0387
Epoch [1/5], Batch [220/428], Loss: 0.6314
Epoch [1/5], Batch [221/428], Loss: 0.0002
Epoch [1/5], Batch [222/428], Loss: 2.2977
Epoch [1/5], Batch [223/428], Loss: 1.1715
Epoch [1/5], Batch [224/428], Loss: 0.0001
Epoch [1/5], Batch [225/428], Loss: 0.0000
Epoch [1/5], Batch [226/428], Loss: 0.1071
Epoch [1/5], Batch [227/428], Loss: 0.5256
Epoch [1/5], Batch [228/428], Loss: 0.6158
Epoch [1/5], Batch [229/428], Loss: 0.0231
Epoch [1/5], Batch [230/428], Loss: 1.8585
Epoch [1/5], Batch [231/428], Loss: 0.1691
Epoch [1/5], Batch [232/428], Loss: 0.2557
Epoch [1/5], Batch [233/428], Loss: 2.2451
Epoch [1/5], Batch [234/428], Loss: 0.5866
Epoch [1/5], Batch [235/428], Loss: 0.0938
Epoch [1/5], Batch [236/428], Loss: 0.5178
Epoch [1/5], Batch [237/428], Loss: 0.0617
Epoch [1/5], Batch [238/428], Loss: 0.5595
Epoch [1/5], Batch [239/428], Loss: 2.8385
Epoch [1/5], Batch [240/428], Loss: 0.1505
Epoch [1/5], Batch [241/428], Loss: 1.8251
Epoch [1/5], Batch [242/428], Loss: 0.2684
Epoch [1/5], Batch [243/428], Loss: 0.0003
Epoch [1/5], Batch [244/428], Loss: 3.0903
Epoch [1/5], Batch [245/428], Loss: 0.0232
Epoch [1/5], Batch [246/428], Loss: 0.0001
Epoch [1/5], Batch [247/428], Loss: 1.8183
Epoch [1/5], Batch [248/428], Loss: 5.5533
Epoch [1/5], Batch [249/428], Loss: 5.2594
Epoch [1/5], Batch [250/428], Loss: 0.2705
Epoch [1/5], Batch [251/428], Loss: 0.0519
Epoch [1/5], Batch [252/428], Loss: 2.1032
Epoch [1/5], Batch [253/428], Loss: 0.0003
Epoch [1/5], Batch [254/428], Loss: 1.1805
Epoch [1/5], Batch [255/428], Loss: 2.6663
Epoch [1/5], Batch [256/428], Loss: 0.0006
Epoch [1/5], Batch [257/428], Loss: 5.7006
Epoch [1/5], Batch [258/428], Loss: 9.9460
Epoch [1/5], Batch [259/428], Loss: 2.4078
Epoch [1/5], Batch [260/428], Loss: 0.0001
Epoch [1/5], Batch [261/428], Loss: 1.1919
Epoch [1/5], Batch [262/428], Loss: 3.9441
Epoch [1/5], Batch [263/428], Loss: 0.0515
Epoch [1/5], Batch [264/428], Loss: 0.0225
Epoch [1/5], Batch [265/428], Loss: 0.0002
Epoch [1/5], Batch [266/428], Loss: 0.0025
Epoch [1/5], Batch [267/428], Loss: 0.6660
Epoch [1/5], Batch [268/428], Loss: 2.0712
Epoch [1/5], Batch [269/428], Loss: 5.5115
Epoch [1/5], Batch [270/428], Loss: 7.3118
Epoch [1/5], Batch [271/428], Loss: 1.3871
Epoch [1/5], Batch [272/428], Loss: 2.3536
Epoch [1/5], Batch [273/428], Loss: 0.0353
Epoch [1/5], Batch [274/428], Loss: 0.4278
Epoch [1/5], Batch [275/428], Loss: 0.0860
Epoch [1/5], Batch [276/428], Loss: 5.3329
Epoch [1/5], Batch [277/428], Loss: 1.5319
Epoch [1/5], Batch [278/428], Loss: 0.0290
Epoch [1/5], Batch [279/428], Loss: 0.0042
Epoch [1/5], Batch [280/428], Loss: 2.2964
Epoch [1/5], Batch [281/428], Loss: 3.5801
Epoch [1/5], Batch [282/428], Loss: 3.3895
Epoch [1/5], Batch [283/428], Loss: 5.4337
Epoch [1/5], Batch [284/428], Loss: 0.0010
Epoch [1/5], Batch [285/428], Loss: 0.0501
Epoch [1/5], Batch [286/428], Loss: 1.7343
Epoch [1/5], Batch [287/428], Loss: 0.7023
Epoch [1/5], Batch [288/428], Loss: 1.8023
Epoch [1/5], Batch [289/428], Loss: 5.0674
Epoch [1/5], Batch [290/428], Loss: 0.0018
Epoch [1/5], Batch [291/428], Loss: 0.0040
Epoch [1/5], Batch [292/428], Loss: 5.7979
Epoch [1/5], Batch [293/428], Loss: 0.0226
Epoch [1/5], Batch [294/428], Loss: 3.9535
Epoch [1/5], Batch [295/428], Loss: 0.0082
Epoch [1/5], Batch [296/428], Loss: 0.0563
Epoch [1/5], Batch [297/428], Loss: 1.3315
Epoch [1/5], Batch [298/428], Loss: 4.5407
Epoch [1/5], Batch [299/428], Loss: 0.3242
Epoch [1/5], Batch [300/428], Loss: 3.6215
Epoch [1/5], Batch [301/428], Loss: 2.0840
Epoch [1/5], Batch [302/428], Loss: 2.9392
Epoch [1/5], Batch [303/428], Loss: 2.5073
Epoch [1/5], Batch [304/428], Loss: 3.3519
Epoch [1/5], Batch [305/428], Loss: 0.5770
Epoch [1/5], Batch [306/428], Loss: 0.0820
Epoch [1/5], Batch [307/428], Loss: 4.2526
Epoch [1/5], Batch [308/428], Loss: 0.3145
Epoch [1/5], Batch [309/428], Loss: 0.0020
Epoch [1/5], Batch [310/428], Loss: 2.1992
Epoch [1/5], Batch [311/428], Loss: 3.1722
Epoch [1/5], Batch [312/428], Loss: 1.6219
Epoch [1/5], Batch [313/428], Loss: 0.8127
Epoch [1/5], Batch [314/428], Loss: 0.1514
Epoch [1/5], Batch [315/428], Loss: 0.4658
Epoch [1/5], Batch [316/428], Loss: 0.7994
Epoch [1/5], Batch [317/428], Loss: 1.2720
Epoch [1/5], Batch [318/428], Loss: 0.0002
Epoch [1/5], Batch [319/428], Loss: 0.4670
Epoch [1/5], Batch [320/428], Loss: 0.0038
Epoch [1/5], Batch [321/428], Loss: 1.4610
Epoch [1/5], Batch [322/428], Loss: 0.0002
Epoch [1/5], Batch [323/428], Loss: 0.0065
Epoch [1/5], Batch [324/428], Loss: 1.2320
Epoch [1/5], Batch [325/428], Loss: 0.2258
Epoch [1/5], Batch [326/428], Loss: 0.9750
Epoch [1/5], Batch [327/428], Loss: 1.6122
Epoch [1/5], Batch [328/428], Loss: 1.2243
Epoch [1/5], Batch [329/428], Loss: 1.2515
Epoch [1/5], Batch [330/428], Loss: 1.2372
Epoch [1/5], Batch [331/428], Loss: 0.5290
Epoch [1/5], Batch [332/428], Loss: 0.0001
Epoch [1/5], Batch [333/428], Loss: 1.2626
Epoch [1/5], Batch [334/428], Loss: 1.1025
Epoch [1/5], Batch [335/428], Loss: 1.3016
Epoch [1/5], Batch [336/428], Loss: 0.0281
Epoch [1/5], Batch [337/428], Loss: 0.1190
Epoch [1/5], Batch [338/428], Loss: 1.2221
Epoch [1/5], Batch [339/428], Loss: 3.0033
Epoch [1/5], Batch [340/428], Loss: 0.0001
Epoch [1/5], Batch [341/428], Loss: 0.7268
Epoch [1/5], Batch [342/428], Loss: 0.7579
Epoch [1/5], Batch [343/428], Loss: 0.0002
Epoch [1/5], Batch [344/428], Loss: 5.7038
Epoch [1/5], Batch [345/428], Loss: 2.3771
Epoch [1/5], Batch [346/428], Loss: 0.0961
Epoch [1/5], Batch [347/428], Loss: 1.8899
Epoch [1/5], Batch [348/428], Loss: 0.0009
Epoch [1/5], Batch [349/428], Loss: 0.0853
Epoch [1/5], Batch [350/428], Loss: 0.8094
Epoch [1/5], Batch [351/428], Loss: 0.4501
Epoch [1/5], Batch [352/428], Loss: 1.0087
Epoch [1/5], Batch [353/428], Loss: 0.5629
Epoch [1/5], Batch [354/428], Loss: 3.6123
Epoch [1/5], Batch [355/428], Loss: 2.9751
Epoch [1/5], Batch [356/428], Loss: 0.0010
Epoch [1/5], Batch [357/428], Loss: 0.0208
Epoch [1/5], Batch [358/428], Loss: 3.9760
Epoch [1/5], Batch [359/428], Loss: 1.0589
Epoch [1/5], Batch [360/428], Loss: 1.5751
Epoch [1/5], Batch [361/428], Loss: 0.1047
Epoch [1/5], Batch [362/428], Loss: 1.8936
Epoch [1/5], Batch [363/428], Loss: 0.0002
Epoch [1/5], Batch [364/428], Loss: 0.2542
Epoch [1/5], Batch [365/428], Loss: 1.7311
Epoch [1/5], Batch [366/428], Loss: 0.1770
Epoch [1/5], Batch [367/428], Loss: 2.3633
Epoch [1/5], Batch [368/428], Loss: 0.8031
Epoch [1/5], Batch [369/428], Loss: 0.4639
Epoch [1/5], Batch [370/428], Loss: 0.4602
Epoch [1/5], Batch [371/428], Loss: 1.4505
Epoch [1/5], Batch [372/428], Loss: 4.2421
Epoch [1/5], Batch [373/428], Loss: 0.1707
Epoch [1/5], Batch [374/428], Loss: 1.2338
Epoch [1/5], Batch [375/428], Loss: 0.0006
Epoch [1/5], Batch [376/428], Loss: 1.3458
Epoch [1/5], Batch [377/428], Loss: 0.3099
Epoch [1/5], Batch [378/428], Loss: 0.2161
Epoch [1/5], Batch [379/428], Loss: 0.5706
Epoch [1/5], Batch [380/428], Loss: 2.4033
Epoch [1/5], Batch [381/428], Loss: 4.1663
Epoch [1/5], Batch [382/428], Loss: 1.0653
Epoch [1/5], Batch [383/428], Loss: 0.0034
Epoch [1/5], Batch [384/428], Loss: 1.2061
Epoch [1/5], Batch [385/428], Loss: 0.1655
Epoch [1/5], Batch [386/428], Loss: 0.6083
Epoch [1/5], Batch [387/428], Loss: 1.1049
Epoch [1/5], Batch [388/428], Loss: 1.5342
Epoch [1/5], Batch [389/428], Loss: 2.9751
Epoch [1/5], Batch [390/428], Loss: 0.0069
Epoch [1/5], Batch [391/428], Loss: 0.0471
Epoch [1/5], Batch [392/428], Loss: 1.4754
Epoch [1/5], Batch [393/428], Loss: 2.8364
Epoch [1/5], Batch [394/428], Loss: 0.6429
Epoch [1/5], Batch [395/428], Loss: 0.6080
Epoch [1/5], Batch [396/428], Loss: 1.5605
Epoch [1/5], Batch [397/428], Loss: 0.5149
Epoch [1/5], Batch [398/428], Loss: 0.8451
Epoch [1/5], Batch [399/428], Loss: 3.5431
Epoch [1/5], Batch [400/428], Loss: 2.4288
Epoch [1/5], Batch [401/428], Loss: 0.8601
Epoch [1/5], Batch [402/428], Loss: 0.0000
Epoch [1/5], Batch [403/428], Loss: 0.3749
Epoch [1/5], Batch [404/428], Loss: 1.2072
Epoch [1/5], Batch [405/428], Loss: 0.2554
Epoch [1/5], Batch [406/428], Loss: 0.0013
Epoch [1/5], Batch [407/428], Loss: 1.4117
Epoch [1/5], Batch [408/428], Loss: 0.1744
Epoch [1/5], Batch [409/428], Loss: 3.0248
Epoch [1/5], Batch [410/428], Loss: 2.7729
Epoch [1/5], Batch [411/428], Loss: 2.4902
Epoch [1/5], Batch [412/428], Loss: 2.9201
Epoch [1/5], Batch [413/428], Loss: 2.3392
Epoch [1/5], Batch [414/428], Loss: 0.0003
Epoch [1/5], Batch [415/428], Loss: 0.4596
Epoch [1/5], Batch [416/428], Loss: 0.5540
Epoch [1/5], Batch [417/428], Loss: 0.4123
Epoch [1/5], Batch [418/428], Loss: 1.4148
Epoch [1/5], Batch [419/428], Loss: 0.2859
Epoch [1/5], Batch [420/428], Loss: 2.4728
Epoch [1/5], Batch [421/428], Loss: 0.0222
Epoch [1/5], Batch [422/428], Loss: 2.3050
Epoch [1/5], Batch [423/428], Loss: 0.4497
Epoch [1/5], Batch [424/428], Loss: 0.4325
Epoch [1/5], Batch [425/428], Loss: 0.0703
Epoch [1/5], Batch [426/428], Loss: 4.6286
Epoch [1/5], Batch [427/428], Loss: 1.1669
Epoch [1/5], Batch [428/428], Loss: 1.9815
Epoch [1] Training Time: 229.93 seconds
Epoch [1/5], Average Loss: 1.4188, Training Accuracy: 0.5280
Epoch [1], Validation Loss: 1.4540, Validation Accuracy: 0.4626
Epoch [1] Validation Time: 14.16 seconds
--------------------------------------------------
Epoch [2/5], Batch [1/428], Loss: 0.0001
Epoch [2/5], Batch [2/428], Loss: 0.4858
Epoch [2/5], Batch [3/428], Loss: 0.3712
Epoch [2/5], Batch [4/428], Loss: 4.8323
Epoch [2/5], Batch [5/428], Loss: 1.2480
Epoch [2/5], Batch [6/428], Loss: 0.0000
Epoch [2/5], Batch [7/428], Loss: 1.4196
Epoch [2/5], Batch [8/428], Loss: 0.1037
Epoch [2/5], Batch [9/428], Loss: 0.1066
Epoch [2/5], Batch [10/428], Loss: 0.7205
Epoch [2/5], Batch [11/428], Loss: 0.0000
Epoch [2/5], Batch [12/428], Loss: 0.0003
Epoch [2/5], Batch [13/428], Loss: 0.6612
Epoch [2/5], Batch [14/428], Loss: 1.1764
Epoch [2/5], Batch [15/428], Loss: 1.2858
Epoch [2/5], Batch [16/428], Loss: 1.0824
Epoch [2/5], Batch [17/428], Loss: 1.4607
Epoch [2/5], Batch [18/428], Loss: 0.6953
Epoch [2/5], Batch [19/428], Loss: 3.1303
Epoch [2/5], Batch [20/428], Loss: 5.0645
Epoch [2/5], Batch [21/428], Loss: 0.0010
Epoch [2/5], Batch [22/428], Loss: 0.1758
Epoch [2/5], Batch [23/428], Loss: 1.2425
Epoch [2/5], Batch [24/428], Loss: 0.0574
Epoch [2/5], Batch [25/428], Loss: 0.3057
Epoch [2/5], Batch [26/428], Loss: 0.0002
Epoch [2/5], Batch [27/428], Loss: 0.2075
Epoch [2/5], Batch [28/428], Loss: 0.0194
Epoch [2/5], Batch [29/428], Loss: 1.1170
Epoch [2/5], Batch [30/428], Loss: 1.2708
Epoch [2/5], Batch [31/428], Loss: 2.7139
Epoch [2/5], Batch [32/428], Loss: 0.0001
Epoch [2/5], Batch [33/428], Loss: 1.9373
Epoch [2/5], Batch [34/428], Loss: 0.0601
Epoch [2/5], Batch [35/428], Loss: 1.2797
Epoch [2/5], Batch [36/428], Loss: 2.7966
Epoch [2/5], Batch [37/428], Loss: 0.3850
Epoch [2/5], Batch [38/428], Loss: 0.0720
Epoch [2/5], Batch [39/428], Loss: 0.3436
Epoch [2/5], Batch [40/428], Loss: 0.1288
Epoch [2/5], Batch [41/428], Loss: 0.0010
Epoch [2/5], Batch [42/428], Loss: 1.6258
Epoch [2/5], Batch [43/428], Loss: 1.4090
Epoch [2/5], Batch [44/428], Loss: 0.7830
Epoch [2/5], Batch [45/428], Loss: 4.8297
Epoch [2/5], Batch [46/428], Loss: 2.0081
Epoch [2/5], Batch [47/428], Loss: 0.0001
Epoch [2/5], Batch [48/428], Loss: 11.2643
Epoch [2/5], Batch [49/428], Loss: 0.0522
Epoch [2/5], Batch [50/428], Loss: 0.0005
Epoch [2/5], Batch [51/428], Loss: 0.0001
Epoch [2/5], Batch [52/428], Loss: 0.0491
Epoch [2/5], Batch [53/428], Loss: 0.9251
Epoch [2/5], Batch [54/428], Loss: 0.2988
Epoch [2/5], Batch [55/428], Loss: 0.1685
Epoch [2/5], Batch [56/428], Loss: 2.8087
Epoch [2/5], Batch [57/428], Loss: 0.9231
Epoch [2/5], Batch [58/428], Loss: 0.8044
Epoch [2/5], Batch [59/428], Loss: 0.0001
Epoch [2/5], Batch [60/428], Loss: 0.1775
Epoch [2/5], Batch [61/428], Loss: 0.9746
Epoch [2/5], Batch [62/428], Loss: 1.4600
Epoch [2/5], Batch [63/428], Loss: 0.5573
Epoch [2/5], Batch [64/428], Loss: 0.7682
Epoch [2/5], Batch [65/428], Loss: 1.0312
Epoch [2/5], Batch [66/428], Loss: 0.0008
Epoch [2/5], Batch [67/428], Loss: 2.0816
Epoch [2/5], Batch [68/428], Loss: 0.0328
Epoch [2/5], Batch [69/428], Loss: 1.6919
Epoch [2/5], Batch [70/428], Loss: 3.1568
Epoch [2/5], Batch [71/428], Loss: 4.4314
Epoch [2/5], Batch [72/428], Loss: 0.0300
Epoch [2/5], Batch [73/428], Loss: 0.5502
Epoch [2/5], Batch [74/428], Loss: 1.3194
Epoch [2/5], Batch [75/428], Loss: 0.0917
Epoch [2/5], Batch [76/428], Loss: 0.1151
Epoch [2/5], Batch [77/428], Loss: 1.6177
Epoch [2/5], Batch [78/428], Loss: 0.9783
Epoch [2/5], Batch [79/428], Loss: 0.0501
Epoch [2/5], Batch [80/428], Loss: 0.5673
Epoch [2/5], Batch [81/428], Loss: 0.0175
Epoch [2/5], Batch [82/428], Loss: 1.4313
Epoch [2/5], Batch [83/428], Loss: 1.7696
Epoch [2/5], Batch [84/428], Loss: 0.0143
Epoch [2/5], Batch [85/428], Loss: 0.2037
Epoch [2/5], Batch [86/428], Loss: 5.3246
Epoch [2/5], Batch [87/428], Loss: 2.9122
Epoch [2/5], Batch [88/428], Loss: 0.1404
Epoch [2/5], Batch [89/428], Loss: 0.0002
Epoch [2/5], Batch [90/428], Loss: 0.3024
Epoch [2/5], Batch [91/428], Loss: 2.8026
Epoch [2/5], Batch [92/428], Loss: 1.8858
Epoch [2/5], Batch [93/428], Loss: 0.1447
Epoch [2/5], Batch [94/428], Loss: 0.0800
Epoch [2/5], Batch [95/428], Loss: 0.0637
Epoch [2/5], Batch [96/428], Loss: 0.1201
Epoch [2/5], Batch [97/428], Loss: 2.7121
Epoch [2/5], Batch [98/428], Loss: 0.0018
Epoch [2/5], Batch [99/428], Loss: 0.4251
Epoch [2/5], Batch [100/428], Loss: 1.7520
Epoch [2/5], Batch [101/428], Loss: 0.1802
Epoch [2/5], Batch [102/428], Loss: 1.7996
Epoch [2/5], Batch [103/428], Loss: 0.1893
Epoch [2/5], Batch [104/428], Loss: 4.0816
Epoch [2/5], Batch [105/428], Loss: 3.7527
Epoch [2/5], Batch [106/428], Loss: 1.7280
Epoch [2/5], Batch [107/428], Loss: 0.0091
Epoch [2/5], Batch [108/428], Loss: 2.1685
Epoch [2/5], Batch [109/428], Loss: 0.0001
Epoch [2/5], Batch [110/428], Loss: 1.4422
Epoch [2/5], Batch [111/428], Loss: 1.2559
Epoch [2/5], Batch [112/428], Loss: 0.2260
Epoch [2/5], Batch [113/428], Loss: 0.9890
Epoch [2/5], Batch [114/428], Loss: 1.8342
Epoch [2/5], Batch [115/428], Loss: 4.2349
Epoch [2/5], Batch [116/428], Loss: 1.6690
Epoch [2/5], Batch [117/428], Loss: 1.0931
Epoch [2/5], Batch [118/428], Loss: 1.3845
Epoch [2/5], Batch [119/428], Loss: 0.0002
Epoch [2/5], Batch [120/428], Loss: 0.0070
Epoch [2/5], Batch [121/428], Loss: 1.0675
Epoch [2/5], Batch [122/428], Loss: 2.0881
Epoch [2/5], Batch [123/428], Loss: 0.4107
Epoch [2/5], Batch [124/428], Loss: 1.4450
Epoch [2/5], Batch [125/428], Loss: 1.3695
Epoch [2/5], Batch [126/428], Loss: 0.0001
Epoch [2/5], Batch [127/428], Loss: 0.1923
Epoch [2/5], Batch [128/428], Loss: 0.0494
Epoch [2/5], Batch [129/428], Loss: 0.0815
Epoch [2/5], Batch [130/428], Loss: 2.5403
Epoch [2/5], Batch [131/428], Loss: 5.2815
Epoch [2/5], Batch [132/428], Loss: 0.1867
Epoch [2/5], Batch [133/428], Loss: 0.0001
Epoch [2/5], Batch [134/428], Loss: 1.0753
Epoch [2/5], Batch [135/428], Loss: 0.9241
Epoch [2/5], Batch [136/428], Loss: 0.8439
Epoch [2/5], Batch [137/428], Loss: 0.0077
Epoch [2/5], Batch [138/428], Loss: 1.2262
Epoch [2/5], Batch [139/428], Loss: 0.5080
Epoch [2/5], Batch [140/428], Loss: 1.8679
Epoch [2/5], Batch [141/428], Loss: 0.6457
Epoch [2/5], Batch [142/428], Loss: 0.0645
Epoch [2/5], Batch [143/428], Loss: 3.5983
Epoch [2/5], Batch [144/428], Loss: 3.0473
Epoch [2/5], Batch [145/428], Loss: 0.2863
Epoch [2/5], Batch [146/428], Loss: 0.6025
Epoch [2/5], Batch [147/428], Loss: 4.7489
Epoch [2/5], Batch [148/428], Loss: 0.5558
Epoch [2/5], Batch [149/428], Loss: 0.0000
Epoch [2/5], Batch [150/428], Loss: 2.5315
Epoch [2/5], Batch [151/428], Loss: 0.0012
Epoch [2/5], Batch [152/428], Loss: 0.8900
Epoch [2/5], Batch [153/428], Loss: 0.1511
Epoch [2/5], Batch [154/428], Loss: 0.1516
Epoch [2/5], Batch [155/428], Loss: 1.1180
Epoch [2/5], Batch [156/428], Loss: 6.7133
Epoch [2/5], Batch [157/428], Loss: 1.1556
Epoch [2/5], Batch [158/428], Loss: 0.2032
Epoch [2/5], Batch [159/428], Loss: 0.0007
Epoch [2/5], Batch [160/428], Loss: 3.2803
Epoch [2/5], Batch [161/428], Loss: 0.0000
Epoch [2/5], Batch [162/428], Loss: 0.1164
Epoch [2/5], Batch [163/428], Loss: 0.6442
Epoch [2/5], Batch [164/428], Loss: 0.2099
Epoch [2/5], Batch [165/428], Loss: 0.9921
Epoch [2/5], Batch [166/428], Loss: 2.2106
Epoch [2/5], Batch [167/428], Loss: 0.0827
Epoch [2/5], Batch [168/428], Loss: 1.6947
Epoch [2/5], Batch [169/428], Loss: 1.8308
Epoch [2/5], Batch [170/428], Loss: 6.1122
Epoch [2/5], Batch [171/428], Loss: 0.0181
Epoch [2/5], Batch [172/428], Loss: 0.0516
Epoch [2/5], Batch [173/428], Loss: 1.1452
Epoch [2/5], Batch [174/428], Loss: 2.1036
Epoch [2/5], Batch [175/428], Loss: 0.1206
Epoch [2/5], Batch [176/428], Loss: 0.0010
Epoch [2/5], Batch [177/428], Loss: 0.2552
Epoch [2/5], Batch [178/428], Loss: 0.0148
Epoch [2/5], Batch [179/428], Loss: 0.9613
Epoch [2/5], Batch [180/428], Loss: 0.0088
Epoch [2/5], Batch [181/428], Loss: 0.4450
Epoch [2/5], Batch [182/428], Loss: 1.9414
Epoch [2/5], Batch [183/428], Loss: 0.1545
Epoch [2/5], Batch [184/428], Loss: 0.3529
Epoch [2/5], Batch [185/428], Loss: 0.5370
Epoch [2/5], Batch [186/428], Loss: 0.0790
Epoch [2/5], Batch [187/428], Loss: 0.9502
Epoch [2/5], Batch [188/428], Loss: 1.0228
Epoch [2/5], Batch [189/428], Loss: 1.6145
Epoch [2/5], Batch [190/428], Loss: 0.0001
Epoch [2/5], Batch [191/428], Loss: 0.0772
Epoch [2/5], Batch [192/428], Loss: 1.5716
Epoch [2/5], Batch [193/428], Loss: 1.1713
Epoch [2/5], Batch [194/428], Loss: 3.4736
Epoch [2/5], Batch [195/428], Loss: 0.0001
Epoch [2/5], Batch [196/428], Loss: 0.1359
Epoch [2/5], Batch [197/428], Loss: 0.1175
Epoch [2/5], Batch [198/428], Loss: 0.0000
Epoch [2/5], Batch [199/428], Loss: 0.0416
Epoch [2/5], Batch [200/428], Loss: 0.0523
Epoch [2/5], Batch [201/428], Loss: 0.0103
Epoch [2/5], Batch [202/428], Loss: 0.0003
Epoch [2/5], Batch [203/428], Loss: 1.1966
Epoch [2/5], Batch [204/428], Loss: 1.7929
Epoch [2/5], Batch [205/428], Loss: 0.0231
Epoch [2/5], Batch [206/428], Loss: 12.6033
Epoch [2/5], Batch [207/428], Loss: 0.0262
Epoch [2/5], Batch [208/428], Loss: 0.0545
Epoch [2/5], Batch [209/428], Loss: 4.6376
Epoch [2/5], Batch [210/428], Loss: 0.1857
Epoch [2/5], Batch [211/428], Loss: 0.0804
Epoch [2/5], Batch [212/428], Loss: 0.0099
Epoch [2/5], Batch [213/428], Loss: 1.2034
Epoch [2/5], Batch [214/428], Loss: 0.0674
Epoch [2/5], Batch [215/428], Loss: 0.0964
Epoch [2/5], Batch [216/428], Loss: 2.2534
Epoch [2/5], Batch [217/428], Loss: 0.5922
Epoch [2/5], Batch [218/428], Loss: 1.1530
Epoch [2/5], Batch [219/428], Loss: 1.3161
Epoch [2/5], Batch [220/428], Loss: 0.0161
Epoch [2/5], Batch [221/428], Loss: 2.9224
Epoch [2/5], Batch [222/428], Loss: 2.4845
Epoch [2/5], Batch [223/428], Loss: 3.8677
Epoch [2/5], Batch [224/428], Loss: 0.5475
Epoch [2/5], Batch [225/428], Loss: 0.0000
Epoch [2/5], Batch [226/428], Loss: 0.0094
Epoch [2/5], Batch [227/428], Loss: 2.2365
Epoch [2/5], Batch [228/428], Loss: 5.3984
Epoch [2/5], Batch [229/428], Loss: 0.4840
Epoch [2/5], Batch [230/428], Loss: 0.0002
Epoch [2/5], Batch [231/428], Loss: 0.0061
Epoch [2/5], Batch [232/428], Loss: 5.3378
Epoch [2/5], Batch [233/428], Loss: 0.0000
Epoch [2/5], Batch [234/428], Loss: 3.6436
Epoch [2/5], Batch [235/428], Loss: 1.6236
Epoch [2/5], Batch [236/428], Loss: 6.0192
Epoch [2/5], Batch [237/428], Loss: 2.4914
Epoch [2/5], Batch [238/428], Loss: 0.0272
Epoch [2/5], Batch [239/428], Loss: 0.9709
Epoch [2/5], Batch [240/428], Loss: 0.1842
Epoch [2/5], Batch [241/428], Loss: 0.0613
Epoch [2/5], Batch [242/428], Loss: 0.6580
Epoch [2/5], Batch [243/428], Loss: 0.0074
Epoch [2/5], Batch [244/428], Loss: 0.0178
Epoch [2/5], Batch [245/428], Loss: 1.4033
Epoch [2/5], Batch [246/428], Loss: 0.7733
Epoch [2/5], Batch [247/428], Loss: 0.0000
Epoch [2/5], Batch [248/428], Loss: 0.0000
Epoch [2/5], Batch [249/428], Loss: 3.7919
Epoch [2/5], Batch [250/428], Loss: 2.0085
Epoch [2/5], Batch [251/428], Loss: 1.7459
Epoch [2/5], Batch [252/428], Loss: 0.5475
Epoch [2/5], Batch [253/428], Loss: 4.4916
Epoch [2/5], Batch [254/428], Loss: 0.0453
Epoch [2/5], Batch [255/428], Loss: 0.0000
Epoch [2/5], Batch [256/428], Loss: 2.5848
Epoch [2/5], Batch [257/428], Loss: 1.9178
Epoch [2/5], Batch [258/428], Loss: 1.8874
Epoch [2/5], Batch [259/428], Loss: 1.3347
Epoch [2/5], Batch [260/428], Loss: 1.4418
Epoch [2/5], Batch [261/428], Loss: 0.5492
Epoch [2/5], Batch [262/428], Loss: 1.8452
Epoch [2/5], Batch [263/428], Loss: 1.0010
Epoch [2/5], Batch [264/428], Loss: 0.0714
Epoch [2/5], Batch [265/428], Loss: 0.6250
Epoch [2/5], Batch [266/428], Loss: 0.0311
Epoch [2/5], Batch [267/428], Loss: 1.2395
Epoch [2/5], Batch [268/428], Loss: 0.0091
Epoch [2/5], Batch [269/428], Loss: 1.0397
Epoch [2/5], Batch [270/428], Loss: 0.0289
Epoch [2/5], Batch [271/428], Loss: 2.7215
Epoch [2/5], Batch [272/428], Loss: 2.4582
Epoch [2/5], Batch [273/428], Loss: 0.0513
Epoch [2/5], Batch [274/428], Loss: 0.0064
Epoch [2/5], Batch [275/428], Loss: 3.2075
Epoch [2/5], Batch [276/428], Loss: 0.0293
Epoch [2/5], Batch [277/428], Loss: 1.4468
Epoch [2/5], Batch [278/428], Loss: 0.3134
Epoch [2/5], Batch [279/428], Loss: 0.1166
Epoch [2/5], Batch [280/428], Loss: 0.7988
Epoch [2/5], Batch [281/428], Loss: 6.9638
Epoch [2/5], Batch [282/428], Loss: 0.0000
Epoch [2/5], Batch [283/428], Loss: 7.1771
Epoch [2/5], Batch [284/428], Loss: 0.9699
Epoch [2/5], Batch [285/428], Loss: 0.0143
Epoch [2/5], Batch [286/428], Loss: 2.1887
Epoch [2/5], Batch [287/428], Loss: 3.2173
Epoch [2/5], Batch [288/428], Loss: 0.1664
Epoch [2/5], Batch [289/428], Loss: 0.5323
Epoch [2/5], Batch [290/428], Loss: 3.5162
Epoch [2/5], Batch [291/428], Loss: 3.0108
Epoch [2/5], Batch [292/428], Loss: 1.3466
Epoch [2/5], Batch [293/428], Loss: 1.3165
Epoch [2/5], Batch [294/428], Loss: 0.0559
Epoch [2/5], Batch [295/428], Loss: 2.9663
Epoch [2/5], Batch [296/428], Loss: 0.0249
Epoch [2/5], Batch [297/428], Loss: 5.2306
Epoch [2/5], Batch [298/428], Loss: 0.5671
Epoch [2/5], Batch [299/428], Loss: 0.0005
Epoch [2/5], Batch [300/428], Loss: 0.9498
Epoch [2/5], Batch [301/428], Loss: 1.8774
Epoch [2/5], Batch [302/428], Loss: 5.6721
Epoch [2/5], Batch [303/428], Loss: 0.7693
Epoch [2/5], Batch [304/428], Loss: 1.5872
Epoch [2/5], Batch [305/428], Loss: 1.4693
Epoch [2/5], Batch [306/428], Loss: 2.4349
Epoch [2/5], Batch [307/428], Loss: 0.0002
Epoch [2/5], Batch [308/428], Loss: 0.5680
Epoch [2/5], Batch [309/428], Loss: 1.5669
Epoch [2/5], Batch [310/428], Loss: 0.0001
Epoch [2/5], Batch [311/428], Loss: 1.3560
Epoch [2/5], Batch [312/428], Loss: 1.6247
Epoch [2/5], Batch [313/428], Loss: 2.1576
Epoch [2/5], Batch [314/428], Loss: 0.0508
Epoch [2/5], Batch [315/428], Loss: 3.6289
Epoch [2/5], Batch [316/428], Loss: 0.6728
Epoch [2/5], Batch [317/428], Loss: 2.9222
Epoch [2/5], Batch [318/428], Loss: 0.0052
Epoch [2/5], Batch [319/428], Loss: 1.3121
Epoch [2/5], Batch [320/428], Loss: 0.6456
Epoch [2/5], Batch [321/428], Loss: 1.4228
Epoch [2/5], Batch [322/428], Loss: 0.0047
Epoch [2/5], Batch [323/428], Loss: 1.3534
Epoch [2/5], Batch [324/428], Loss: 2.7482
Epoch [2/5], Batch [325/428], Loss: 1.4474
Epoch [2/5], Batch [326/428], Loss: 0.0000
Epoch [2/5], Batch [327/428], Loss: 0.9917
Epoch [2/5], Batch [328/428], Loss: 0.0962
Epoch [2/5], Batch [329/428], Loss: 1.4867
Epoch [2/5], Batch [330/428], Loss: 0.4550
Epoch [2/5], Batch [331/428], Loss: 0.7225
Epoch [2/5], Batch [332/428], Loss: 0.6872
Epoch [2/5], Batch [333/428], Loss: 0.0001
Epoch [2/5], Batch [334/428], Loss: 0.0000
Epoch [2/5], Batch [335/428], Loss: 0.0029
Epoch [2/5], Batch [336/428], Loss: 0.0004
Epoch [2/5], Batch [337/428], Loss: 0.0000
Epoch [2/5], Batch [338/428], Loss: 0.0000
Epoch [2/5], Batch [339/428], Loss: 1.0848
Epoch [2/5], Batch [340/428], Loss: 0.0444
Epoch [2/5], Batch [341/428], Loss: 0.1043
Epoch [2/5], Batch [342/428], Loss: 0.1122
Epoch [2/5], Batch [343/428], Loss: 1.6042
Epoch [2/5], Batch [344/428], Loss: 0.0000
Epoch [2/5], Batch [345/428], Loss: 0.6697
Epoch [2/5], Batch [346/428], Loss: 0.0236
Epoch [2/5], Batch [347/428], Loss: 1.3766
Epoch [2/5], Batch [348/428], Loss: 1.1067
Epoch [2/5], Batch [349/428], Loss: 0.2722
Epoch [2/5], Batch [350/428], Loss: 0.2710
Epoch [2/5], Batch [351/428], Loss: 0.9669
Epoch [2/5], Batch [352/428], Loss: 0.0000
Epoch [2/5], Batch [353/428], Loss: 0.0017
Epoch [2/5], Batch [354/428], Loss: 0.0000
Epoch [2/5], Batch [355/428], Loss: 1.4460
Epoch [2/5], Batch [356/428], Loss: 0.1719
Epoch [2/5], Batch [357/428], Loss: 0.0002
Epoch [2/5], Batch [358/428], Loss: 1.0210
Epoch [2/5], Batch [359/428], Loss: 3.5490
Epoch [2/5], Batch [360/428], Loss: 0.2565
Epoch [2/5], Batch [361/428], Loss: 0.2697
Epoch [2/5], Batch [362/428], Loss: 2.5147
Epoch [2/5], Batch [363/428], Loss: 0.5716
Epoch [2/5], Batch [364/428], Loss: 0.3940
Epoch [2/5], Batch [365/428], Loss: 4.1715
Epoch [2/5], Batch [366/428], Loss: 0.7425
Epoch [2/5], Batch [367/428], Loss: 0.0239
Epoch [2/5], Batch [368/428], Loss: 0.0323
Epoch [2/5], Batch [369/428], Loss: 0.2015
Epoch [2/5], Batch [370/428], Loss: 1.6626
Epoch [2/5], Batch [371/428], Loss: 2.2208
Epoch [2/5], Batch [372/428], Loss: 0.0000
Epoch [2/5], Batch [373/428], Loss: 0.0410
Epoch [2/5], Batch [374/428], Loss: 2.5158
Epoch [2/5], Batch [375/428], Loss: 3.6653
Epoch [2/5], Batch [376/428], Loss: 0.0242
Epoch [2/5], Batch [377/428], Loss: 0.1055
Epoch [2/5], Batch [378/428], Loss: 0.1927
Epoch [2/5], Batch [379/428], Loss: 0.0826
Epoch [2/5], Batch [380/428], Loss: 1.4768
Epoch [2/5], Batch [381/428], Loss: 0.1471
Epoch [2/5], Batch [382/428], Loss: 0.0050
Epoch [2/5], Batch [383/428], Loss: 3.5933
Epoch [2/5], Batch [384/428], Loss: 2.2282
Epoch [2/5], Batch [385/428], Loss: 0.1730
Epoch [2/5], Batch [386/428], Loss: 4.7837
Epoch [2/5], Batch [387/428], Loss: 1.9833
Epoch [2/5], Batch [388/428], Loss: 0.0582
Epoch [2/5], Batch [389/428], Loss: 0.1817
Epoch [2/5], Batch [390/428], Loss: 0.5157
Epoch [2/5], Batch [391/428], Loss: 1.9796
Epoch [2/5], Batch [392/428], Loss: 0.0000
Epoch [2/5], Batch [393/428], Loss: 0.4022
Epoch [2/5], Batch [394/428], Loss: 0.8278
Epoch [2/5], Batch [395/428], Loss: 0.0089
Epoch [2/5], Batch [396/428], Loss: 0.0092
Epoch [2/5], Batch [397/428], Loss: 0.1481
Epoch [2/5], Batch [398/428], Loss: 1.3184
Epoch [2/5], Batch [399/428], Loss: 3.2028
Epoch [2/5], Batch [400/428], Loss: 0.8819
Epoch [2/5], Batch [401/428], Loss: 2.5751
Epoch [2/5], Batch [402/428], Loss: 0.0000
Epoch [2/5], Batch [403/428], Loss: 0.0356
Epoch [2/5], Batch [404/428], Loss: 0.4780
Epoch [2/5], Batch [405/428], Loss: 0.0952
Epoch [2/5], Batch [406/428], Loss: 0.8129
Epoch [2/5], Batch [407/428], Loss: 4.7927
Epoch [2/5], Batch [408/428], Loss: 1.1878
Epoch [2/5], Batch [409/428], Loss: 0.0001
Epoch [2/5], Batch [410/428], Loss: 4.2676
Epoch [2/5], Batch [411/428], Loss: 0.6340
Epoch [2/5], Batch [412/428], Loss: 3.2663
Epoch [2/5], Batch [413/428], Loss: 0.1970
Epoch [2/5], Batch [414/428], Loss: 3.2258
Epoch [2/5], Batch [415/428], Loss: 5.1999
Epoch [2/5], Batch [416/428], Loss: 2.8908
Epoch [2/5], Batch [417/428], Loss: 1.9464
Epoch [2/5], Batch [418/428], Loss: 0.2301
Epoch [2/5], Batch [419/428], Loss: 0.0769
Epoch [2/5], Batch [420/428], Loss: 1.9171
Epoch [2/5], Batch [421/428], Loss: 0.1604
Epoch [2/5], Batch [422/428], Loss: 1.8877
Epoch [2/5], Batch [423/428], Loss: 0.0368
Epoch [2/5], Batch [424/428], Loss: 0.0713
Epoch [2/5], Batch [425/428], Loss: 1.2163
Epoch [2/5], Batch [426/428], Loss: 0.2476
Epoch [2/5], Batch [427/428], Loss: 3.1637
Epoch [2/5], Batch [428/428], Loss: 2.7202
Epoch [2] Training Time: 228.81 seconds
Epoch [2/5], Average Loss: 1.1953, Training Accuracy: 0.6098
Epoch [2], Validation Loss: 1.5202, Validation Accuracy: 0.5110
Epoch [2] Validation Time: 14.08 seconds
--------------------------------------------------
Epoch [3/5], Batch [1/428], Loss: 0.0001
Epoch [3/5], Batch [2/428], Loss: 0.2540
Epoch [3/5], Batch [3/428], Loss: 0.3635
Epoch [3/5], Batch [4/428], Loss: 0.1335
Epoch [3/5], Batch [5/428], Loss: 0.4615
Epoch [3/5], Batch [6/428], Loss: 0.0008
Epoch [3/5], Batch [7/428], Loss: 0.1013
Epoch [3/5], Batch [8/428], Loss: 1.7584
Epoch [3/5], Batch [9/428], Loss: 2.9522
Epoch [3/5], Batch [10/428], Loss: 0.0003
Epoch [3/5], Batch [11/428], Loss: 2.1577
Epoch [3/5], Batch [12/428], Loss: 0.3623
Epoch [3/5], Batch [13/428], Loss: 0.0873
Epoch [3/5], Batch [14/428], Loss: 0.0778
Epoch [3/5], Batch [15/428], Loss: 0.2360
Epoch [3/5], Batch [16/428], Loss: 6.1617
Epoch [3/5], Batch [17/428], Loss: 0.2925
Epoch [3/5], Batch [18/428], Loss: 0.0046
Epoch [3/5], Batch [19/428], Loss: 2.3010
Epoch [3/5], Batch [20/428], Loss: 0.2051
Epoch [3/5], Batch [21/428], Loss: 2.0149
Epoch [3/5], Batch [22/428], Loss: 2.8775
Epoch [3/5], Batch [23/428], Loss: 0.3238
Epoch [3/5], Batch [24/428], Loss: 1.4016
Epoch [3/5], Batch [25/428], Loss: 0.7856
Epoch [3/5], Batch [26/428], Loss: 0.9687
Epoch [3/5], Batch [27/428], Loss: 0.2834
Epoch [3/5], Batch [28/428], Loss: 0.4898
Epoch [3/5], Batch [29/428], Loss: 1.0404
Epoch [3/5], Batch [30/428], Loss: 0.1184
Epoch [3/5], Batch [31/428], Loss: 0.8451
Epoch [3/5], Batch [32/428], Loss: 0.0031
Epoch [3/5], Batch [33/428], Loss: 0.6006
Epoch [3/5], Batch [34/428], Loss: 2.2646
Epoch [3/5], Batch [35/428], Loss: 0.0357
Epoch [3/5], Batch [36/428], Loss: 0.2260
Epoch [3/5], Batch [37/428], Loss: 0.0063
Epoch [3/5], Batch [38/428], Loss: 0.1412
Epoch [3/5], Batch [39/428], Loss: 2.3951
Epoch [3/5], Batch [40/428], Loss: 1.1935
Epoch [3/5], Batch [41/428], Loss: 0.0079
Epoch [3/5], Batch [42/428], Loss: 0.0006
Epoch [3/5], Batch [43/428], Loss: 1.2805
Epoch [3/5], Batch [44/428], Loss: 0.3327
Epoch [3/5], Batch [45/428], Loss: 1.1578
Epoch [3/5], Batch [46/428], Loss: 0.0992
Epoch [3/5], Batch [47/428], Loss: 0.3200
Epoch [3/5], Batch [48/428], Loss: 1.1202
Epoch [3/5], Batch [49/428], Loss: 0.0048
Epoch [3/5], Batch [50/428], Loss: 0.3440
Epoch [3/5], Batch [51/428], Loss: 0.8485
Epoch [3/5], Batch [52/428], Loss: 0.0001
Epoch [3/5], Batch [53/428], Loss: 0.3469
Epoch [3/5], Batch [54/428], Loss: 3.9828
Epoch [3/5], Batch [55/428], Loss: 0.2046
Epoch [3/5], Batch [56/428], Loss: 0.6937
Epoch [3/5], Batch [57/428], Loss: 0.0364
Epoch [3/5], Batch [58/428], Loss: 1.7346
Epoch [3/5], Batch [59/428], Loss: 0.0090
Epoch [3/5], Batch [60/428], Loss: 0.0000
Epoch [3/5], Batch [61/428], Loss: 0.2489
Epoch [3/5], Batch [62/428], Loss: 1.6828
Epoch [3/5], Batch [63/428], Loss: 1.4218
Epoch [3/5], Batch [64/428], Loss: 2.4362
Epoch [3/5], Batch [65/428], Loss: 3.9712
Epoch [3/5], Batch [66/428], Loss: 0.0001
Epoch [3/5], Batch [67/428], Loss: 0.0050
Epoch [3/5], Batch [68/428], Loss: 1.1710
Epoch [3/5], Batch [69/428], Loss: 0.0000
Epoch [3/5], Batch [70/428], Loss: 1.7114
Epoch [3/5], Batch [71/428], Loss: 0.0239
Epoch [3/5], Batch [72/428], Loss: 0.0111
Epoch [3/5], Batch [73/428], Loss: 0.2262
Epoch [3/5], Batch [74/428], Loss: 5.8507
Epoch [3/5], Batch [75/428], Loss: 2.1915
Epoch [3/5], Batch [76/428], Loss: 1.5432
Epoch [3/5], Batch [77/428], Loss: 0.1711
Epoch [3/5], Batch [78/428], Loss: 0.4104
Epoch [3/5], Batch [79/428], Loss: 0.5702
Epoch [3/5], Batch [80/428], Loss: 1.0897
Epoch [3/5], Batch [81/428], Loss: 1.7010
Epoch [3/5], Batch [82/428], Loss: 1.1928
Epoch [3/5], Batch [83/428], Loss: 0.2264
Epoch [3/5], Batch [84/428], Loss: 0.0258
Epoch [3/5], Batch [85/428], Loss: 0.9630
Epoch [3/5], Batch [86/428], Loss: 1.6952
Epoch [3/5], Batch [87/428], Loss: 0.0000
Epoch [3/5], Batch [88/428], Loss: 0.1256
Epoch [3/5], Batch [89/428], Loss: 0.2729
Epoch [3/5], Batch [90/428], Loss: 0.1619
Epoch [3/5], Batch [91/428], Loss: 0.1716
Epoch [3/5], Batch [92/428], Loss: 1.9628
Epoch [3/5], Batch [93/428], Loss: 1.5198
Epoch [3/5], Batch [94/428], Loss: 0.8642
Epoch [3/5], Batch [95/428], Loss: 1.2733
Epoch [3/5], Batch [96/428], Loss: 1.7117
Epoch [3/5], Batch [97/428], Loss: 1.2618
Epoch [3/5], Batch [98/428], Loss: 2.3778
Epoch [3/5], Batch [99/428], Loss: 1.3505
Epoch [3/5], Batch [100/428], Loss: 1.7738
Epoch [3/5], Batch [101/428], Loss: 0.8141
Epoch [3/5], Batch [102/428], Loss: 2.7296
Epoch [3/5], Batch [103/428], Loss: 4.1512
Epoch [3/5], Batch [104/428], Loss: 0.0004
Epoch [3/5], Batch [105/428], Loss: 2.3740
Epoch [3/5], Batch [106/428], Loss: 0.7599
Epoch [3/5], Batch [107/428], Loss: 0.0852
Epoch [3/5], Batch [108/428], Loss: 0.5359
Epoch [3/5], Batch [109/428], Loss: 0.1033
Epoch [3/5], Batch [110/428], Loss: 2.1395
Epoch [3/5], Batch [111/428], Loss: 0.1398
Epoch [3/5], Batch [112/428], Loss: 0.1241
Epoch [3/5], Batch [113/428], Loss: 0.3488
Epoch [3/5], Batch [114/428], Loss: 0.0052
Epoch [3/5], Batch [115/428], Loss: 0.3498
Epoch [3/5], Batch [116/428], Loss: 0.0077
Epoch [3/5], Batch [117/428], Loss: 0.3170
Epoch [3/5], Batch [118/428], Loss: 0.0127
Epoch [3/5], Batch [119/428], Loss: 0.4774
Epoch [3/5], Batch [120/428], Loss: 0.0130
Epoch [3/5], Batch [121/428], Loss: 0.1387
Epoch [3/5], Batch [122/428], Loss: 0.0579
Epoch [3/5], Batch [123/428], Loss: 1.0558
Epoch [3/5], Batch [124/428], Loss: 1.5013
Epoch [3/5], Batch [125/428], Loss: 0.0010
Epoch [3/5], Batch [126/428], Loss: 0.0864
Epoch [3/5], Batch [127/428], Loss: 0.6768
Epoch [3/5], Batch [128/428], Loss: 0.1220
Epoch [3/5], Batch [129/428], Loss: 0.1753
Epoch [3/5], Batch [130/428], Loss: 1.3460
Epoch [3/5], Batch [131/428], Loss: 0.0000
Epoch [3/5], Batch [132/428], Loss: 0.2543
Epoch [3/5], Batch [133/428], Loss: 0.0033
Epoch [3/5], Batch [134/428], Loss: 0.1457
Epoch [3/5], Batch [135/428], Loss: 1.3681
Epoch [3/5], Batch [136/428], Loss: 1.0827
Epoch [3/5], Batch [137/428], Loss: 0.7978
Epoch [3/5], Batch [138/428], Loss: 0.0922
Epoch [3/5], Batch [139/428], Loss: 0.0561
Epoch [3/5], Batch [140/428], Loss: 2.9228
Epoch [3/5], Batch [141/428], Loss: 0.3092
Epoch [3/5], Batch [142/428], Loss: 1.4782
Epoch [3/5], Batch [143/428], Loss: 2.7376
Epoch [3/5], Batch [144/428], Loss: 0.0444
Epoch [3/5], Batch [145/428], Loss: 0.0297
Epoch [3/5], Batch [146/428], Loss: 0.0886
Epoch [3/5], Batch [147/428], Loss: 0.0073
Epoch [3/5], Batch [148/428], Loss: 0.0010
Epoch [3/5], Batch [149/428], Loss: 0.0028
Epoch [3/5], Batch [150/428], Loss: 0.0708
Epoch [3/5], Batch [151/428], Loss: 0.8210
Epoch [3/5], Batch [152/428], Loss: 0.7801
Epoch [3/5], Batch [153/428], Loss: 0.0000
Epoch [3/5], Batch [154/428], Loss: 0.0000
Epoch [3/5], Batch [155/428], Loss: 0.0592
Epoch [3/5], Batch [156/428], Loss: 0.1377
Epoch [3/5], Batch [157/428], Loss: 3.2688
Epoch [3/5], Batch [158/428], Loss: 0.0000
Epoch [3/5], Batch [159/428], Loss: 2.6369
Epoch [3/5], Batch [160/428], Loss: 0.0371
Epoch [3/5], Batch [161/428], Loss: 0.1415
Epoch [3/5], Batch [162/428], Loss: 0.7858
Epoch [3/5], Batch [163/428], Loss: 3.2461
Epoch [3/5], Batch [164/428], Loss: 1.6020
Epoch [3/5], Batch [165/428], Loss: 0.9671
Epoch [3/5], Batch [166/428], Loss: 1.4838
Epoch [3/5], Batch [167/428], Loss: 0.1587
Epoch [3/5], Batch [168/428], Loss: 1.1845
Epoch [3/5], Batch [169/428], Loss: 0.0587
Epoch [3/5], Batch [170/428], Loss: 2.6796
Epoch [3/5], Batch [171/428], Loss: 0.0070
Epoch [3/5], Batch [172/428], Loss: 0.0000
Epoch [3/5], Batch [173/428], Loss: 1.3067
Epoch [3/5], Batch [174/428], Loss: 0.0066
Epoch [3/5], Batch [175/428], Loss: 1.9180
Epoch [3/5], Batch [176/428], Loss: 0.7637
Epoch [3/5], Batch [177/428], Loss: 0.0012
Epoch [3/5], Batch [178/428], Loss: 1.5438
Epoch [3/5], Batch [179/428], Loss: 0.4659
Epoch [3/5], Batch [180/428], Loss: 0.0760
Epoch [3/5], Batch [181/428], Loss: 1.5369
Epoch [3/5], Batch [182/428], Loss: 0.2341
Epoch [3/5], Batch [183/428], Loss: 0.0113
Epoch [3/5], Batch [184/428], Loss: 0.0000
Epoch [3/5], Batch [185/428], Loss: 0.0000
Epoch [3/5], Batch [186/428], Loss: 1.4572
Epoch [3/5], Batch [187/428], Loss: 0.2623
Epoch [3/5], Batch [188/428], Loss: 2.9305
Epoch [3/5], Batch [189/428], Loss: 0.2030
Epoch [3/5], Batch [190/428], Loss: 0.3188
Epoch [3/5], Batch [191/428], Loss: 4.7281
Epoch [3/5], Batch [192/428], Loss: 2.6818
Epoch [3/5], Batch [193/428], Loss: 0.0008
Epoch [3/5], Batch [194/428], Loss: 0.0051
Epoch [3/5], Batch [195/428], Loss: 0.2170
Epoch [3/5], Batch [196/428], Loss: 0.0000
Epoch [3/5], Batch [197/428], Loss: 0.3285
Epoch [3/5], Batch [198/428], Loss: 1.5165
Epoch [3/5], Batch [199/428], Loss: 1.8074
Epoch [3/5], Batch [200/428], Loss: 0.5441
Epoch [3/5], Batch [201/428], Loss: 0.0483
Epoch [3/5], Batch [202/428], Loss: 0.5181
Epoch [3/5], Batch [203/428], Loss: 0.0156
Epoch [3/5], Batch [204/428], Loss: 0.0004
Epoch [3/5], Batch [205/428], Loss: 0.8105
Epoch [3/5], Batch [206/428], Loss: 0.0969
Epoch [3/5], Batch [207/428], Loss: 0.0276
Epoch [3/5], Batch [208/428], Loss: 0.0004
Epoch [3/5], Batch [209/428], Loss: 0.0233
Epoch [3/5], Batch [210/428], Loss: 0.0100
Epoch [3/5], Batch [211/428], Loss: 0.0009
Epoch [3/5], Batch [212/428], Loss: 0.0119
Epoch [3/5], Batch [213/428], Loss: 0.0103
Epoch [3/5], Batch [214/428], Loss: 0.4337
Epoch [3/5], Batch [215/428], Loss: 0.3298
Epoch [3/5], Batch [216/428], Loss: 0.0000
Epoch [3/5], Batch [217/428], Loss: 0.0129
Epoch [3/5], Batch [218/428], Loss: 3.0030
Epoch [3/5], Batch [219/428], Loss: 1.7079
Epoch [3/5], Batch [220/428], Loss: 0.0008
Epoch [3/5], Batch [221/428], Loss: 0.0251
Epoch [3/5], Batch [222/428], Loss: 0.6953
Epoch [3/5], Batch [223/428], Loss: 0.1969
Epoch [3/5], Batch [224/428], Loss: 0.4177
Epoch [3/5], Batch [225/428], Loss: 0.0639
Epoch [3/5], Batch [226/428], Loss: 1.6341
Epoch [3/5], Batch [227/428], Loss: 0.3310
Epoch [3/5], Batch [228/428], Loss: 0.1581
Epoch [3/5], Batch [229/428], Loss: 0.6488
Epoch [3/5], Batch [230/428], Loss: 1.0167
Epoch [3/5], Batch [231/428], Loss: 0.1791
Epoch [3/5], Batch [232/428], Loss: 0.0001
Epoch [3/5], Batch [233/428], Loss: 0.0000
Epoch [3/5], Batch [234/428], Loss: 0.0876
Epoch [3/5], Batch [235/428], Loss: 0.5596
Epoch [3/5], Batch [236/428], Loss: 0.8999
Epoch [3/5], Batch [237/428], Loss: 3.3311
Epoch [3/5], Batch [238/428], Loss: 0.0010
Epoch [3/5], Batch [239/428], Loss: 1.0690
Epoch [3/5], Batch [240/428], Loss: 0.6296
Epoch [3/5], Batch [241/428], Loss: 4.9188
Epoch [3/5], Batch [242/428], Loss: 1.1713
Epoch [3/5], Batch [243/428], Loss: 0.7021
Epoch [3/5], Batch [244/428], Loss: 0.5880
Epoch [3/5], Batch [245/428], Loss: 2.5102
Epoch [3/5], Batch [246/428], Loss: 0.7838
Epoch [3/5], Batch [247/428], Loss: 10.9247
Epoch [3/5], Batch [248/428], Loss: 0.4882
Epoch [3/5], Batch [249/428], Loss: 1.2876
Epoch [3/5], Batch [250/428], Loss: 0.4340
Epoch [3/5], Batch [251/428], Loss: 5.5674
Epoch [3/5], Batch [252/428], Loss: 0.7767
Epoch [3/5], Batch [253/428], Loss: 0.8577
Epoch [3/5], Batch [254/428], Loss: 1.0486
Epoch [3/5], Batch [255/428], Loss: 0.1538
Epoch [3/5], Batch [256/428], Loss: 0.2201
Epoch [3/5], Batch [257/428], Loss: 0.1358
Epoch [3/5], Batch [258/428], Loss: 0.0047
Epoch [3/5], Batch [259/428], Loss: 0.5231
Epoch [3/5], Batch [260/428], Loss: 0.0211
Epoch [3/5], Batch [261/428], Loss: 0.0414
Epoch [3/5], Batch [262/428], Loss: 0.0270
Epoch [3/5], Batch [263/428], Loss: 0.0901
Epoch [3/5], Batch [264/428], Loss: 0.0317
Epoch [3/5], Batch [265/428], Loss: 3.6821
Epoch [3/5], Batch [266/428], Loss: 4.5064
Epoch [3/5], Batch [267/428], Loss: 0.0000
Epoch [3/5], Batch [268/428], Loss: 0.0001
Epoch [3/5], Batch [269/428], Loss: 3.4780
Epoch [3/5], Batch [270/428], Loss: 0.0006
Epoch [3/5], Batch [271/428], Loss: 2.3756
Epoch [3/5], Batch [272/428], Loss: 0.8218
Epoch [3/5], Batch [273/428], Loss: 0.9886
Epoch [3/5], Batch [274/428], Loss: 1.7916
Epoch [3/5], Batch [275/428], Loss: 8.1959
Epoch [3/5], Batch [276/428], Loss: 1.8224
Epoch [3/5], Batch [277/428], Loss: 0.7610
Epoch [3/5], Batch [278/428], Loss: 0.0079
Epoch [3/5], Batch [279/428], Loss: 0.7541
Epoch [3/5], Batch [280/428], Loss: 3.3134
Epoch [3/5], Batch [281/428], Loss: 1.0401
Epoch [3/5], Batch [282/428], Loss: 1.6575
Epoch [3/5], Batch [283/428], Loss: 0.1131
Epoch [3/5], Batch [284/428], Loss: 0.9416
Epoch [3/5], Batch [285/428], Loss: 2.6577
Epoch [3/5], Batch [286/428], Loss: 4.7474
Epoch [3/5], Batch [287/428], Loss: 2.2844
Epoch [3/5], Batch [288/428], Loss: 1.5669
Epoch [3/5], Batch [289/428], Loss: 0.2203
Epoch [3/5], Batch [290/428], Loss: 0.4507
Epoch [3/5], Batch [291/428], Loss: 0.0212
Epoch [3/5], Batch [292/428], Loss: 0.7783
Epoch [3/5], Batch [293/428], Loss: 1.6018
Epoch [3/5], Batch [294/428], Loss: 0.0015
Epoch [3/5], Batch [295/428], Loss: 2.1697
Epoch [3/5], Batch [296/428], Loss: 0.1219
Epoch [3/5], Batch [297/428], Loss: 0.0148
Epoch [3/5], Batch [298/428], Loss: 2.8310
Epoch [3/5], Batch [299/428], Loss: 0.3080
Epoch [3/5], Batch [300/428], Loss: 1.2154
Epoch [3/5], Batch [301/428], Loss: 0.0007
Epoch [3/5], Batch [302/428], Loss: 0.0194
Epoch [3/5], Batch [303/428], Loss: 0.9648
Epoch [3/5], Batch [304/428], Loss: 0.0052
Epoch [3/5], Batch [305/428], Loss: 0.0576
Epoch [3/5], Batch [306/428], Loss: 2.4343
Epoch [3/5], Batch [307/428], Loss: 1.5873
Epoch [3/5], Batch [308/428], Loss: 0.0002
Epoch [3/5], Batch [309/428], Loss: 0.3054
Epoch [3/5], Batch [310/428], Loss: 0.0137
Epoch [3/5], Batch [311/428], Loss: 0.2369
Epoch [3/5], Batch [312/428], Loss: 6.7007
Epoch [3/5], Batch [313/428], Loss: 0.6778
Epoch [3/5], Batch [314/428], Loss: 0.4007
Epoch [3/5], Batch [315/428], Loss: 1.1873
Epoch [3/5], Batch [316/428], Loss: 0.0009
Epoch [3/5], Batch [317/428], Loss: 0.0356
Epoch [3/5], Batch [318/428], Loss: 0.0000
Epoch [3/5], Batch [319/428], Loss: 5.1554
Epoch [3/5], Batch [320/428], Loss: 0.7740
Epoch [3/5], Batch [321/428], Loss: 0.0010
Epoch [3/5], Batch [322/428], Loss: 0.0269
Epoch [3/5], Batch [323/428], Loss: 0.3190
Epoch [3/5], Batch [324/428], Loss: 0.0001
Epoch [3/5], Batch [325/428], Loss: 0.0017
Epoch [3/5], Batch [326/428], Loss: 0.3933
Epoch [3/5], Batch [327/428], Loss: 1.8924
Epoch [3/5], Batch [328/428], Loss: 0.2567
Epoch [3/5], Batch [329/428], Loss: 0.6930
Epoch [3/5], Batch [330/428], Loss: 0.7762
Epoch [3/5], Batch [331/428], Loss: 0.5159
Epoch [3/5], Batch [332/428], Loss: 0.0490
Epoch [3/5], Batch [333/428], Loss: 1.1479
Epoch [3/5], Batch [334/428], Loss: 0.6606
Epoch [3/5], Batch [335/428], Loss: 0.0279
Epoch [3/5], Batch [336/428], Loss: 0.0054
Epoch [3/5], Batch [337/428], Loss: 0.0784
Epoch [3/5], Batch [338/428], Loss: 0.7278
Epoch [3/5], Batch [339/428], Loss: 0.0270
Epoch [3/5], Batch [340/428], Loss: 0.8265
Epoch [3/5], Batch [341/428], Loss: 0.0057
Epoch [3/5], Batch [342/428], Loss: 3.5749
Epoch [3/5], Batch [343/428], Loss: 0.0207
Epoch [3/5], Batch [344/428], Loss: 2.1519
Epoch [3/5], Batch [345/428], Loss: 0.3579
Epoch [3/5], Batch [346/428], Loss: 0.0279
Epoch [3/5], Batch [347/428], Loss: 0.2794
Epoch [3/5], Batch [348/428], Loss: 0.0000
Epoch [3/5], Batch [349/428], Loss: 0.0097
Epoch [3/5], Batch [350/428], Loss: 0.0119
Epoch [3/5], Batch [351/428], Loss: 1.5243
Epoch [3/5], Batch [352/428], Loss: 0.0118
Epoch [3/5], Batch [353/428], Loss: 0.2259
Epoch [3/5], Batch [354/428], Loss: 0.0001
Epoch [3/5], Batch [355/428], Loss: 0.0008
Epoch [3/5], Batch [356/428], Loss: 0.0000
Epoch [3/5], Batch [357/428], Loss: 0.0433
Epoch [3/5], Batch [358/428], Loss: 5.9462
Epoch [3/5], Batch [359/428], Loss: 1.2765
Epoch [3/5], Batch [360/428], Loss: 4.5598
Epoch [3/5], Batch [361/428], Loss: 0.3370
Epoch [3/5], Batch [362/428], Loss: 0.0213
Epoch [3/5], Batch [363/428], Loss: 3.4670
Epoch [3/5], Batch [364/428], Loss: 3.9323
Epoch [3/5], Batch [365/428], Loss: 0.0003
Epoch [3/5], Batch [366/428], Loss: 0.9194
Epoch [3/5], Batch [367/428], Loss: 0.4086
Epoch [3/5], Batch [368/428], Loss: 1.0801
Epoch [3/5], Batch [369/428], Loss: 1.2956
Epoch [3/5], Batch [370/428], Loss: 0.3405
Epoch [3/5], Batch [371/428], Loss: 2.5560
Epoch [3/5], Batch [372/428], Loss: 0.3077
Epoch [3/5], Batch [373/428], Loss: 0.6584
Epoch [3/5], Batch [374/428], Loss: 3.5604
Epoch [3/5], Batch [375/428], Loss: 0.1529
Epoch [3/5], Batch [376/428], Loss: 0.0896
Epoch [3/5], Batch [377/428], Loss: 1.0667
Epoch [3/5], Batch [378/428], Loss: 0.0009
Epoch [3/5], Batch [379/428], Loss: 0.2263
Epoch [3/5], Batch [380/428], Loss: 0.6920
Epoch [3/5], Batch [381/428], Loss: 0.2223
Epoch [3/5], Batch [382/428], Loss: 0.0577
Epoch [3/5], Batch [383/428], Loss: 4.1082
Epoch [3/5], Batch [384/428], Loss: 0.2109
Epoch [3/5], Batch [385/428], Loss: 2.3194
Epoch [3/5], Batch [386/428], Loss: 0.6219
Epoch [3/5], Batch [387/428], Loss: 0.4254
Epoch [3/5], Batch [388/428], Loss: 1.0144
Epoch [3/5], Batch [389/428], Loss: 0.0000
Epoch [3/5], Batch [390/428], Loss: 1.8773
Epoch [3/5], Batch [391/428], Loss: 0.4434
Epoch [3/5], Batch [392/428], Loss: 2.0283
Epoch [3/5], Batch [393/428], Loss: 2.5230
Epoch [3/5], Batch [394/428], Loss: 0.4739
Epoch [3/5], Batch [395/428], Loss: 0.0000
Epoch [3/5], Batch [396/428], Loss: 1.2382
Epoch [3/5], Batch [397/428], Loss: 4.2033
Epoch [3/5], Batch [398/428], Loss: 0.0765
Epoch [3/5], Batch [399/428], Loss: 2.7721
Epoch [3/5], Batch [400/428], Loss: 0.0000
Epoch [3/5], Batch [401/428], Loss: 0.4442
Epoch [3/5], Batch [402/428], Loss: 0.0000
Epoch [3/5], Batch [403/428], Loss: 1.1192
Epoch [3/5], Batch [404/428], Loss: 1.1224
Epoch [3/5], Batch [405/428], Loss: 0.4094
Epoch [3/5], Batch [406/428], Loss: 1.6521
Epoch [3/5], Batch [407/428], Loss: 0.6952
Epoch [3/5], Batch [408/428], Loss: 0.2505
Epoch [3/5], Batch [409/428], Loss: 2.1940
Epoch [3/5], Batch [410/428], Loss: 0.0431
Epoch [3/5], Batch [411/428], Loss: 0.2522
Epoch [3/5], Batch [412/428], Loss: 0.0914
Epoch [3/5], Batch [413/428], Loss: 0.1328
Epoch [3/5], Batch [414/428], Loss: 3.9685
Epoch [3/5], Batch [415/428], Loss: 0.0148
Epoch [3/5], Batch [416/428], Loss: 2.1207
Epoch [3/5], Batch [417/428], Loss: 0.0777
Epoch [3/5], Batch [418/428], Loss: 0.1004
Epoch [3/5], Batch [419/428], Loss: 0.0002
Epoch [3/5], Batch [420/428], Loss: 0.0124
Epoch [3/5], Batch [421/428], Loss: 0.0008
Epoch [3/5], Batch [422/428], Loss: 0.0000
Epoch [3/5], Batch [423/428], Loss: 2.6819
Epoch [3/5], Batch [424/428], Loss: 2.5031
Epoch [3/5], Batch [425/428], Loss: 0.0000
Epoch [3/5], Batch [426/428], Loss: 3.1988
Epoch [3/5], Batch [427/428], Loss: 3.0868
Epoch [3/5], Batch [428/428], Loss: 0.7001
Epoch [3] Training Time: 229.05 seconds
Epoch [3/5], Average Loss: 0.9394, Training Accuracy: 0.6799
Epoch [3], Validation Loss: 1.3966, Validation Accuracy: 0.5633
Epoch [3] Validation Time: 14.19 seconds
--------------------------------------------------
Epoch [4/5], Batch [1/428], Loss: 11.0282
Epoch [4/5], Batch [2/428], Loss: 0.1474
Epoch [4/5], Batch [3/428], Loss: 2.4705
Epoch [4/5], Batch [4/428], Loss: 4.6304
Epoch [4/5], Batch [5/428], Loss: 0.0107
Epoch [4/5], Batch [6/428], Loss: 1.7713
Epoch [4/5], Batch [7/428], Loss: 0.0168
Epoch [4/5], Batch [8/428], Loss: 0.0262
Epoch [4/5], Batch [9/428], Loss: 0.0049
Epoch [4/5], Batch [10/428], Loss: 0.0640
Epoch [4/5], Batch [11/428], Loss: 1.0427
Epoch [4/5], Batch [12/428], Loss: 2.2350
Epoch [4/5], Batch [13/428], Loss: 0.9852
Epoch [4/5], Batch [14/428], Loss: 0.0006
Epoch [4/5], Batch [15/428], Loss: 0.0039
Epoch [4/5], Batch [16/428], Loss: 0.0474
Epoch [4/5], Batch [17/428], Loss: 1.8024
Epoch [4/5], Batch [18/428], Loss: 0.0000
Epoch [4/5], Batch [19/428], Loss: 1.9605
Epoch [4/5], Batch [20/428], Loss: 0.0799
Epoch [4/5], Batch [21/428], Loss: 0.0060
Epoch [4/5], Batch [22/428], Loss: 0.1358
Epoch [4/5], Batch [23/428], Loss: 0.6000
Epoch [4/5], Batch [24/428], Loss: 0.0008
Epoch [4/5], Batch [25/428], Loss: 0.9313
Epoch [4/5], Batch [26/428], Loss: 1.5443
Epoch [4/5], Batch [27/428], Loss: 2.6842
Epoch [4/5], Batch [28/428], Loss: 0.0003
Epoch [4/5], Batch [29/428], Loss: 0.1248
Epoch [4/5], Batch [30/428], Loss: 0.0168
Epoch [4/5], Batch [31/428], Loss: 0.0000
Epoch [4/5], Batch [32/428], Loss: 1.0064
Epoch [4/5], Batch [33/428], Loss: 0.0374
Epoch [4/5], Batch [34/428], Loss: 1.2935
Epoch [4/5], Batch [35/428], Loss: 1.2406
Epoch [4/5], Batch [36/428], Loss: 0.2675
Epoch [4/5], Batch [37/428], Loss: 0.0234
Epoch [4/5], Batch [38/428], Loss: 0.3960
Epoch [4/5], Batch [39/428], Loss: 0.0000
Epoch [4/5], Batch [40/428], Loss: 0.5167
Epoch [4/5], Batch [41/428], Loss: 1.0627
Epoch [4/5], Batch [42/428], Loss: 0.1621
Epoch [4/5], Batch [43/428], Loss: 0.0000
Epoch [4/5], Batch [44/428], Loss: 0.0326
Epoch [4/5], Batch [45/428], Loss: 1.7626
Epoch [4/5], Batch [46/428], Loss: 0.7259
Epoch [4/5], Batch [47/428], Loss: 0.1105
Epoch [4/5], Batch [48/428], Loss: 0.0228
Epoch [4/5], Batch [49/428], Loss: 0.0017
Epoch [4/5], Batch [50/428], Loss: 0.0000
Epoch [4/5], Batch [51/428], Loss: 0.7134
Epoch [4/5], Batch [52/428], Loss: 0.0179
Epoch [4/5], Batch [53/428], Loss: 1.4017
Epoch [4/5], Batch [54/428], Loss: 0.6312
Epoch [4/5], Batch [55/428], Loss: 0.5922
Epoch [4/5], Batch [56/428], Loss: 0.0000
Epoch [4/5], Batch [57/428], Loss: 0.2598
Epoch [4/5], Batch [58/428], Loss: 5.7188
Epoch [4/5], Batch [59/428], Loss: 0.0010
Epoch [4/5], Batch [60/428], Loss: 1.0646
Epoch [4/5], Batch [61/428], Loss: 0.8165
Epoch [4/5], Batch [62/428], Loss: 0.0969
Epoch [4/5], Batch [63/428], Loss: 0.7155
Epoch [4/5], Batch [64/428], Loss: 0.0281
Epoch [4/5], Batch [65/428], Loss: 0.1394
Epoch [4/5], Batch [66/428], Loss: 0.2052
Epoch [4/5], Batch [67/428], Loss: 0.1559
Epoch [4/5], Batch [68/428], Loss: 0.0483
Epoch [4/5], Batch [69/428], Loss: 1.2900
Epoch [4/5], Batch [70/428], Loss: 0.0000
Epoch [4/5], Batch [71/428], Loss: 2.1497
Epoch [4/5], Batch [72/428], Loss: 1.1722
Epoch [4/5], Batch [73/428], Loss: 1.8387
Epoch [4/5], Batch [74/428], Loss: 0.3770
Epoch [4/5], Batch [75/428], Loss: 0.0222
Epoch [4/5], Batch [76/428], Loss: 0.0800
Epoch [4/5], Batch [77/428], Loss: 3.4927
Epoch [4/5], Batch [78/428], Loss: 0.6037
Epoch [4/5], Batch [79/428], Loss: 2.9808
Epoch [4/5], Batch [80/428], Loss: 0.3293
Epoch [4/5], Batch [81/428], Loss: 0.1197
Epoch [4/5], Batch [82/428], Loss: 1.6444
Epoch [4/5], Batch [83/428], Loss: 1.1171
Epoch [4/5], Batch [84/428], Loss: 0.0000
Epoch [4/5], Batch [85/428], Loss: 0.0066
Epoch [4/5], Batch [86/428], Loss: 0.0904
Epoch [4/5], Batch [87/428], Loss: 1.5258
Epoch [4/5], Batch [88/428], Loss: 0.0171
Epoch [4/5], Batch [89/428], Loss: 0.0663
Epoch [4/5], Batch [90/428], Loss: 0.8701
Epoch [4/5], Batch [91/428], Loss: 0.0000
Epoch [4/5], Batch [92/428], Loss: 3.1356
Epoch [4/5], Batch [93/428], Loss: 0.5540
Epoch [4/5], Batch [94/428], Loss: 0.9774
Epoch [4/5], Batch [95/428], Loss: 0.8453
Epoch [4/5], Batch [96/428], Loss: 1.9566
Epoch [4/5], Batch [97/428], Loss: 0.8015
Epoch [4/5], Batch [98/428], Loss: 1.3674
Epoch [4/5], Batch [99/428], Loss: 3.0393
Epoch [4/5], Batch [100/428], Loss: 0.0151
Epoch [4/5], Batch [101/428], Loss: 0.1072
Epoch [4/5], Batch [102/428], Loss: 0.0002
Epoch [4/5], Batch [103/428], Loss: 0.7756
Epoch [4/5], Batch [104/428], Loss: 7.1041
Epoch [4/5], Batch [105/428], Loss: 0.9067
Epoch [4/5], Batch [106/428], Loss: 0.1247
Epoch [4/5], Batch [107/428], Loss: 0.5980
Epoch [4/5], Batch [108/428], Loss: 0.0201
Epoch [4/5], Batch [109/428], Loss: 0.3537
Epoch [4/5], Batch [110/428], Loss: 4.0643
Epoch [4/5], Batch [111/428], Loss: 3.5239
Epoch [4/5], Batch [112/428], Loss: 1.1731
Epoch [4/5], Batch [113/428], Loss: 0.3203
Epoch [4/5], Batch [114/428], Loss: 0.7915
Epoch [4/5], Batch [115/428], Loss: 1.0437
Epoch [4/5], Batch [116/428], Loss: 0.2173
Epoch [4/5], Batch [117/428], Loss: 1.9449
Epoch [4/5], Batch [118/428], Loss: 0.4775
Epoch [4/5], Batch [119/428], Loss: 0.3644
Epoch [4/5], Batch [120/428], Loss: 0.0497
Epoch [4/5], Batch [121/428], Loss: 2.6572
Epoch [4/5], Batch [122/428], Loss: 3.7233
Epoch [4/5], Batch [123/428], Loss: 1.7144
Epoch [4/5], Batch [124/428], Loss: 0.0000
Epoch [4/5], Batch [125/428], Loss: 5.5809
Epoch [4/5], Batch [126/428], Loss: 0.0356
Epoch [4/5], Batch [127/428], Loss: 1.9030
Epoch [4/5], Batch [128/428], Loss: 0.0457
Epoch [4/5], Batch [129/428], Loss: 0.8438
Epoch [4/5], Batch [130/428], Loss: 0.8957
Epoch [4/5], Batch [131/428], Loss: 0.3289
Epoch [4/5], Batch [132/428], Loss: 0.1992
Epoch [4/5], Batch [133/428], Loss: 0.0136
Epoch [4/5], Batch [134/428], Loss: 0.0060
Epoch [4/5], Batch [135/428], Loss: 1.1344
Epoch [4/5], Batch [136/428], Loss: 0.0004
Epoch [4/5], Batch [137/428], Loss: 0.1913
Epoch [4/5], Batch [138/428], Loss: 0.1506
Epoch [4/5], Batch [139/428], Loss: 0.0000
Epoch [4/5], Batch [140/428], Loss: 0.4029
Epoch [4/5], Batch [141/428], Loss: 0.8005
Epoch [4/5], Batch [142/428], Loss: 3.9415
Epoch [4/5], Batch [143/428], Loss: 0.2189
Epoch [4/5], Batch [144/428], Loss: 2.0785
Epoch [4/5], Batch [145/428], Loss: 1.8854
Epoch [4/5], Batch [146/428], Loss: 0.0000
Epoch [4/5], Batch [147/428], Loss: 0.2253
Epoch [4/5], Batch [148/428], Loss: 0.2111
Epoch [4/5], Batch [149/428], Loss: 0.9090
Epoch [4/5], Batch [150/428], Loss: 0.9820
Epoch [4/5], Batch [151/428], Loss: 0.3704
Epoch [4/5], Batch [152/428], Loss: 0.6620
Epoch [4/5], Batch [153/428], Loss: 0.7007
Epoch [4/5], Batch [154/428], Loss: 4.1939
Epoch [4/5], Batch [155/428], Loss: 0.5955
Epoch [4/5], Batch [156/428], Loss: 2.7492
Epoch [4/5], Batch [157/428], Loss: 0.0384
Epoch [4/5], Batch [158/428], Loss: 0.1179
Epoch [4/5], Batch [159/428], Loss: 0.0000
Epoch [4/5], Batch [160/428], Loss: 0.5856
Epoch [4/5], Batch [161/428], Loss: 0.1118
Epoch [4/5], Batch [162/428], Loss: 2.1126
Epoch [4/5], Batch [163/428], Loss: 0.0042
Epoch [4/5], Batch [164/428], Loss: 0.0165
Epoch [4/5], Batch [165/428], Loss: 0.0000
Epoch [4/5], Batch [166/428], Loss: 0.5970
Epoch [4/5], Batch [167/428], Loss: 2.2209
Epoch [4/5], Batch [168/428], Loss: 1.2196
Epoch [4/5], Batch [169/428], Loss: 2.5966
Epoch [4/5], Batch [170/428], Loss: 1.1753
Epoch [4/5], Batch [171/428], Loss: 0.4573
Epoch [4/5], Batch [172/428], Loss: 4.7820
Epoch [4/5], Batch [173/428], Loss: 0.0136
Epoch [4/5], Batch [174/428], Loss: 0.0071
Epoch [4/5], Batch [175/428], Loss: 0.4538
Epoch [4/5], Batch [176/428], Loss: 0.1353
Epoch [4/5], Batch [177/428], Loss: 0.0091
Epoch [4/5], Batch [178/428], Loss: 1.6511
Epoch [4/5], Batch [179/428], Loss: 2.2608
Epoch [4/5], Batch [180/428], Loss: 0.0000
Epoch [4/5], Batch [181/428], Loss: 0.1864
Epoch [4/5], Batch [182/428], Loss: 0.0000
Epoch [4/5], Batch [183/428], Loss: 1.9588
Epoch [4/5], Batch [184/428], Loss: 0.3341
Epoch [4/5], Batch [185/428], Loss: 1.5910
Epoch [4/5], Batch [186/428], Loss: 2.3337
Epoch [4/5], Batch [187/428], Loss: 0.5195
Epoch [4/5], Batch [188/428], Loss: 0.0001
Epoch [4/5], Batch [189/428], Loss: 2.6305
Epoch [4/5], Batch [190/428], Loss: 0.0192
Epoch [4/5], Batch [191/428], Loss: 4.7321
Epoch [4/5], Batch [192/428], Loss: 0.8220
Epoch [4/5], Batch [193/428], Loss: 0.0000
Epoch [4/5], Batch [194/428], Loss: 0.1246
Epoch [4/5], Batch [195/428], Loss: 0.0731
Epoch [4/5], Batch [196/428], Loss: 1.1203
Epoch [4/5], Batch [197/428], Loss: 1.9507
Epoch [4/5], Batch [198/428], Loss: 0.6035
Epoch [4/5], Batch [199/428], Loss: 1.3741
Epoch [4/5], Batch [200/428], Loss: 2.0493
Epoch [4/5], Batch [201/428], Loss: 0.5510
Epoch [4/5], Batch [202/428], Loss: 0.1772
Epoch [4/5], Batch [203/428], Loss: 0.1569
Epoch [4/5], Batch [204/428], Loss: 0.0574[INFO 06-13 19:09:40] ax.service.ax_client: Completed trial 5 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 19:09:40] ax.service.ax_client: Generated new trial 6 with parameters {'lr': 4.3e-05, 'num_epochs': 10, 'unfreeze_epoch': 2, 'max_length': 32000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [4/5], Batch [205/428], Loss: 0.0910
Epoch [4/5], Batch [206/428], Loss: 0.0037
Epoch [4/5], Batch [207/428], Loss: 0.0007
Epoch [4/5], Batch [208/428], Loss: 0.0045
Epoch [4/5], Batch [209/428], Loss: 1.8386
Epoch [4/5], Batch [210/428], Loss: 1.7184
Epoch [4/5], Batch [211/428], Loss: 0.5767
Epoch [4/5], Batch [212/428], Loss: 0.0898
Epoch [4/5], Batch [213/428], Loss: 0.1734
Epoch [4/5], Batch [214/428], Loss: 1.9738
Epoch [4/5], Batch [215/428], Loss: 1.6715
Epoch [4/5], Batch [216/428], Loss: 0.0293
Epoch [4/5], Batch [217/428], Loss: 0.0474
Epoch [4/5], Batch [218/428], Loss: 0.8305
Epoch [4/5], Batch [219/428], Loss: 4.2430
Epoch [4/5], Batch [220/428], Loss: 0.0005
Epoch [4/5], Batch [221/428], Loss: 2.3409
Epoch [4/5], Batch [222/428], Loss: 0.0431
Epoch [4/5], Batch [223/428], Loss: 0.0629
Epoch [4/5], Batch [224/428], Loss: 0.0210
Epoch [4/5], Batch [225/428], Loss: 0.0378
Epoch [4/5], Batch [226/428], Loss: 2.7091
Epoch [4/5], Batch [227/428], Loss: 0.1004
Epoch [4/5], Batch [228/428], Loss: 0.1505
Epoch [4/5], Batch [229/428], Loss: 0.7907
Epoch [4/5], Batch [230/428], Loss: 0.6303
Epoch [4/5], Batch [231/428], Loss: 1.8736
Epoch [4/5], Batch [232/428], Loss: 0.3706
Epoch [4/5], Batch [233/428], Loss: 0.8355
Epoch [4/5], Batch [234/428], Loss: 2.0053
Epoch [4/5], Batch [235/428], Loss: 1.7492
Epoch [4/5], Batch [236/428], Loss: 0.4147
Epoch [4/5], Batch [237/428], Loss: 0.0000
Epoch [4/5], Batch [238/428], Loss: 4.6181
Epoch [4/5], Batch [239/428], Loss: 0.0226
Epoch [4/5], Batch [240/428], Loss: 0.5503
Epoch [4/5], Batch [241/428], Loss: 2.9646
Epoch [4/5], Batch [242/428], Loss: 1.1243
Epoch [4/5], Batch [243/428], Loss: 1.0091
Epoch [4/5], Batch [244/428], Loss: 0.0003
Epoch [4/5], Batch [245/428], Loss: 1.3546
Epoch [4/5], Batch [246/428], Loss: 0.1236
Epoch [4/5], Batch [247/428], Loss: 0.0314
Epoch [4/5], Batch [248/428], Loss: 0.8897
Epoch [4/5], Batch [249/428], Loss: 4.3443
Epoch [4/5], Batch [250/428], Loss: 0.0000
Epoch [4/5], Batch [251/428], Loss: 0.1253
Epoch [4/5], Batch [252/428], Loss: 0.5560
Epoch [4/5], Batch [253/428], Loss: 0.3758
Epoch [4/5], Batch [254/428], Loss: 0.0077
Epoch [4/5], Batch [255/428], Loss: 1.5829
Epoch [4/5], Batch [256/428], Loss: 0.0660
Epoch [4/5], Batch [257/428], Loss: 0.1903
Epoch [4/5], Batch [258/428], Loss: 0.0534
Epoch [4/5], Batch [259/428], Loss: 0.0090
Epoch [4/5], Batch [260/428], Loss: 2.1965
Epoch [4/5], Batch [261/428], Loss: 0.8896
Epoch [4/5], Batch [262/428], Loss: 0.2645
Epoch [4/5], Batch [263/428], Loss: 0.1630
Epoch [4/5], Batch [264/428], Loss: 1.0154
Epoch [4/5], Batch [265/428], Loss: 0.0543
Epoch [4/5], Batch [266/428], Loss: 2.6978
Epoch [4/5], Batch [267/428], Loss: 0.0724
Epoch [4/5], Batch [268/428], Loss: 0.3125
Epoch [4/5], Batch [269/428], Loss: 0.4250
Epoch [4/5], Batch [270/428], Loss: 0.3750
Epoch [4/5], Batch [271/428], Loss: 0.0003
Epoch [4/5], Batch [272/428], Loss: 2.1657
Epoch [4/5], Batch [273/428], Loss: 1.1465
Epoch [4/5], Batch [274/428], Loss: 0.0001
Epoch [4/5], Batch [275/428], Loss: 0.0000
Epoch [4/5], Batch [276/428], Loss: 0.0047
Epoch [4/5], Batch [277/428], Loss: 2.2553
Epoch [4/5], Batch [278/428], Loss: 0.0105
Epoch [4/5], Batch [279/428], Loss: 2.4581
Epoch [4/5], Batch [280/428], Loss: 0.0152
Epoch [4/5], Batch [281/428], Loss: 1.0335
Epoch [4/5], Batch [282/428], Loss: 0.0464
Epoch [4/5], Batch [283/428], Loss: 0.2880
Epoch [4/5], Batch [284/428], Loss: 0.0484
Epoch [4/5], Batch [285/428], Loss: 0.1260
Epoch [4/5], Batch [286/428], Loss: 1.5516
Epoch [4/5], Batch [287/428], Loss: 0.1030
Epoch [4/5], Batch [288/428], Loss: 0.0004
Epoch [4/5], Batch [289/428], Loss: 1.4490
Epoch [4/5], Batch [290/428], Loss: 0.0000
Epoch [4/5], Batch [291/428], Loss: 0.6910
Epoch [4/5], Batch [292/428], Loss: 0.0103
Epoch [4/5], Batch [293/428], Loss: 0.2326
Epoch [4/5], Batch [294/428], Loss: 0.0561
Epoch [4/5], Batch [295/428], Loss: 1.1963
Epoch [4/5], Batch [296/428], Loss: 0.8227
Epoch [4/5], Batch [297/428], Loss: 0.1067
Epoch [4/5], Batch [298/428], Loss: 3.4619
Epoch [4/5], Batch [299/428], Loss: 0.0016
Epoch [4/5], Batch [300/428], Loss: 1.3285
Epoch [4/5], Batch [301/428], Loss: 1.9440
Epoch [4/5], Batch [302/428], Loss: 2.7434
Epoch [4/5], Batch [303/428], Loss: 0.3181
Epoch [4/5], Batch [304/428], Loss: 0.2052
Epoch [4/5], Batch [305/428], Loss: 0.0011
Epoch [4/5], Batch [306/428], Loss: 0.1496
Epoch [4/5], Batch [307/428], Loss: 0.4540
Epoch [4/5], Batch [308/428], Loss: 0.1870
Epoch [4/5], Batch [309/428], Loss: 0.7851
Epoch [4/5], Batch [310/428], Loss: 0.0012
Epoch [4/5], Batch [311/428], Loss: 0.0000
Epoch [4/5], Batch [312/428], Loss: 0.1238
Epoch [4/5], Batch [313/428], Loss: 0.0002
Epoch [4/5], Batch [314/428], Loss: 0.2209
Epoch [4/5], Batch [315/428], Loss: 0.1936
Epoch [4/5], Batch [316/428], Loss: 0.0000
Epoch [4/5], Batch [317/428], Loss: 1.2069
Epoch [4/5], Batch [318/428], Loss: 0.2349
Epoch [4/5], Batch [319/428], Loss: 4.2566
Epoch [4/5], Batch [320/428], Loss: 1.5221
Epoch [4/5], Batch [321/428], Loss: 0.0927
Epoch [4/5], Batch [322/428], Loss: 0.8286
Epoch [4/5], Batch [323/428], Loss: 0.0817
Epoch [4/5], Batch [324/428], Loss: 1.9104
Epoch [4/5], Batch [325/428], Loss: 0.0286
Epoch [4/5], Batch [326/428], Loss: 0.5739
Epoch [4/5], Batch [327/428], Loss: 0.0027
Epoch [4/5], Batch [328/428], Loss: 0.0816
Epoch [4/5], Batch [329/428], Loss: 0.8108
Epoch [4/5], Batch [330/428], Loss: 3.2059
Epoch [4/5], Batch [331/428], Loss: 2.2233
Epoch [4/5], Batch [332/428], Loss: 0.1609
Epoch [4/5], Batch [333/428], Loss: 0.0092
Epoch [4/5], Batch [334/428], Loss: 0.1768
Epoch [4/5], Batch [335/428], Loss: 0.1030
Epoch [4/5], Batch [336/428], Loss: 2.1270
Epoch [4/5], Batch [337/428], Loss: 0.0377
Epoch [4/5], Batch [338/428], Loss: 1.1282
Epoch [4/5], Batch [339/428], Loss: 2.0062
Epoch [4/5], Batch [340/428], Loss: 0.0142
Epoch [4/5], Batch [341/428], Loss: 2.9369
Epoch [4/5], Batch [342/428], Loss: 0.0000
Epoch [4/5], Batch [343/428], Loss: 0.1146
Epoch [4/5], Batch [344/428], Loss: 2.5862
Epoch [4/5], Batch [345/428], Loss: 1.8484
Epoch [4/5], Batch [346/428], Loss: 3.1450
Epoch [4/5], Batch [347/428], Loss: 1.9521
Epoch [4/5], Batch [348/428], Loss: 0.0677
Epoch [4/5], Batch [349/428], Loss: 0.0349
Epoch [4/5], Batch [350/428], Loss: 0.3351
Epoch [4/5], Batch [351/428], Loss: 1.3761
Epoch [4/5], Batch [352/428], Loss: 0.0001
Epoch [4/5], Batch [353/428], Loss: 0.0050
Epoch [4/5], Batch [354/428], Loss: 0.4224
Epoch [4/5], Batch [355/428], Loss: 0.0005
Epoch [4/5], Batch [356/428], Loss: 2.3365
Epoch [4/5], Batch [357/428], Loss: 0.0000
Epoch [4/5], Batch [358/428], Loss: 1.2214
Epoch [4/5], Batch [359/428], Loss: 0.4736
Epoch [4/5], Batch [360/428], Loss: 0.3015
Epoch [4/5], Batch [361/428], Loss: 2.3533
Epoch [4/5], Batch [362/428], Loss: 0.0021
Epoch [4/5], Batch [363/428], Loss: 2.2620
Epoch [4/5], Batch [364/428], Loss: 0.2985
Epoch [4/5], Batch [365/428], Loss: 4.0048
Epoch [4/5], Batch [366/428], Loss: 0.6466
Epoch [4/5], Batch [367/428], Loss: 0.2121
Epoch [4/5], Batch [368/428], Loss: 0.0541
Epoch [4/5], Batch [369/428], Loss: 0.1197
Epoch [4/5], Batch [370/428], Loss: 0.0523
Epoch [4/5], Batch [371/428], Loss: 0.5885
Epoch [4/5], Batch [372/428], Loss: 1.8653
Epoch [4/5], Batch [373/428], Loss: 1.4734
Epoch [4/5], Batch [374/428], Loss: 1.2633
Epoch [4/5], Batch [375/428], Loss: 0.0102
Epoch [4/5], Batch [376/428], Loss: 0.0115
Epoch [4/5], Batch [377/428], Loss: 0.1600
Epoch [4/5], Batch [378/428], Loss: 0.1053
Epoch [4/5], Batch [379/428], Loss: 0.0400
Epoch [4/5], Batch [380/428], Loss: 1.8974
Epoch [4/5], Batch [381/428], Loss: 0.0212
Epoch [4/5], Batch [382/428], Loss: 0.0000
Epoch [4/5], Batch [383/428], Loss: 2.8821
Epoch [4/5], Batch [384/428], Loss: 0.4857
Epoch [4/5], Batch [385/428], Loss: 3.2437
Epoch [4/5], Batch [386/428], Loss: 2.5436
Epoch [4/5], Batch [387/428], Loss: 0.0052
Epoch [4/5], Batch [388/428], Loss: 2.9338
Epoch [4/5], Batch [389/428], Loss: 0.9701
Epoch [4/5], Batch [390/428], Loss: 0.0007
Epoch [4/5], Batch [391/428], Loss: 0.0003
Epoch [4/5], Batch [392/428], Loss: 0.0053
Epoch [4/5], Batch [393/428], Loss: 0.1740
Epoch [4/5], Batch [394/428], Loss: 0.0000
Epoch [4/5], Batch [395/428], Loss: 0.5943
Epoch [4/5], Batch [396/428], Loss: 0.0001
Epoch [4/5], Batch [397/428], Loss: 1.0174
Epoch [4/5], Batch [398/428], Loss: 0.0030
Epoch [4/5], Batch [399/428], Loss: 0.0050
Epoch [4/5], Batch [400/428], Loss: 0.0000
Epoch [4/5], Batch [401/428], Loss: 0.3122
Epoch [4/5], Batch [402/428], Loss: 0.7581
Epoch [4/5], Batch [403/428], Loss: 0.0043
Epoch [4/5], Batch [404/428], Loss: 0.0089
Epoch [4/5], Batch [405/428], Loss: 1.0057
Epoch [4/5], Batch [406/428], Loss: 0.1698
Epoch [4/5], Batch [407/428], Loss: 0.0091
Epoch [4/5], Batch [408/428], Loss: 0.0095
Epoch [4/5], Batch [409/428], Loss: 1.5048
Epoch [4/5], Batch [410/428], Loss: 0.0000
Epoch [4/5], Batch [411/428], Loss: 1.5245
Epoch [4/5], Batch [412/428], Loss: 0.0214
Epoch [4/5], Batch [413/428], Loss: 0.0000
Epoch [4/5], Batch [414/428], Loss: 0.0000
Epoch [4/5], Batch [415/428], Loss: 0.9291
Epoch [4/5], Batch [416/428], Loss: 0.0000
Epoch [4/5], Batch [417/428], Loss: 0.8175
Epoch [4/5], Batch [418/428], Loss: 1.2710
Epoch [4/5], Batch [419/428], Loss: 1.2898
Epoch [4/5], Batch [420/428], Loss: 0.1145
Epoch [4/5], Batch [421/428], Loss: 0.3215
Epoch [4/5], Batch [422/428], Loss: 6.4540
Epoch [4/5], Batch [423/428], Loss: 2.6772
Epoch [4/5], Batch [424/428], Loss: 0.0000
Epoch [4/5], Batch [425/428], Loss: 2.7182
Epoch [4/5], Batch [426/428], Loss: 0.1482
Epoch [4/5], Batch [427/428], Loss: 0.4549
Epoch [4/5], Batch [428/428], Loss: 1.4897
Epoch [4] Training Time: 230.59 seconds
Epoch [4/5], Average Loss: 0.8844, Training Accuracy: 0.6916
Epoch [4], Validation Loss: 1.4660, Validation Accuracy: 0.6261
Epoch [4] Validation Time: 14.22 seconds
--------------------------------------------------
Epoch 5: Unfreezing feature extractor layers...
Epoch [5/5], Batch [1/428], Loss: 0.0027
Epoch [5/5], Batch [2/428], Loss: 0.0000
Epoch [5/5], Batch [3/428], Loss: 24.1925
Epoch [5/5], Batch [4/428], Loss: 16.7269
Epoch [5/5], Batch [5/428], Loss: 16.5634
Epoch [5/5], Batch [6/428], Loss: 0.3865
Epoch [5/5], Batch [7/428], Loss: 21.7373
Epoch [5/5], Batch [8/428], Loss: 0.1416
Epoch [5/5], Batch [9/428], Loss: 17.9497
Epoch [5/5], Batch [10/428], Loss: 0.0000
Epoch [5/5], Batch [11/428], Loss: 20.7823
Epoch [5/5], Batch [12/428], Loss: 0.0212
Epoch [5/5], Batch [13/428], Loss: 0.0082
Epoch [5/5], Batch [14/428], Loss: 8.5134
Epoch [5/5], Batch [15/428], Loss: 12.7056
Epoch [5/5], Batch [16/428], Loss: 15.8577
Epoch [5/5], Batch [17/428], Loss: 3.8144
Epoch [5/5], Batch [18/428], Loss: 10.2345
Epoch [5/5], Batch [19/428], Loss: 6.8162
Epoch [5/5], Batch [20/428], Loss: 6.6472
Epoch [5/5], Batch [21/428], Loss: 8.1042
Epoch [5/5], Batch [22/428], Loss: 11.1268
Epoch [5/5], Batch [23/428], Loss: 7.5530
Epoch [5/5], Batch [24/428], Loss: 1.7913
Epoch [5/5], Batch [25/428], Loss: 5.2963
Epoch [5/5], Batch [26/428], Loss: 0.2822
Epoch [5/5], Batch [27/428], Loss: 4.4271
Epoch [5/5], Batch [28/428], Loss: 4.6966
Epoch [5/5], Batch [29/428], Loss: 2.4196
Epoch [5/5], Batch [30/428], Loss: 1.4447
Epoch [5/5], Batch [31/428], Loss: 16.8225
Epoch [5/5], Batch [32/428], Loss: 7.8406
Epoch [5/5], Batch [33/428], Loss: 1.4751
Epoch [5/5], Batch [34/428], Loss: 0.9277
Epoch [5/5], Batch [35/428], Loss: 3.4699
Epoch [5/5], Batch [36/428], Loss: 2.3272
Epoch [5/5], Batch [37/428], Loss: 2.2414
Epoch [5/5], Batch [38/428], Loss: 4.2478
Epoch [5/5], Batch [39/428], Loss: 6.9628
Epoch [5/5], Batch [40/428], Loss: 1.3325
Epoch [5/5], Batch [41/428], Loss: 0.7587
Epoch [5/5], Batch [42/428], Loss: 4.3989
Epoch [5/5], Batch [43/428], Loss: 0.1297
Epoch [5/5], Batch [44/428], Loss: 5.2993
Epoch [5/5], Batch [45/428], Loss: 5.9933
Epoch [5/5], Batch [46/428], Loss: 5.4384
Epoch [5/5], Batch [47/428], Loss: 7.1721
Epoch [5/5], Batch [48/428], Loss: 2.8091
Epoch [5/5], Batch [49/428], Loss: 3.3517
Epoch [5/5], Batch [50/428], Loss: 0.7555
Epoch [5/5], Batch [51/428], Loss: 6.4528
Epoch [5/5], Batch [52/428], Loss: 2.3405
Epoch [5/5], Batch [53/428], Loss: 0.2558
Epoch [5/5], Batch [54/428], Loss: 2.0996
Epoch [5/5], Batch [55/428], Loss: 9.4418
Epoch [5/5], Batch [56/428], Loss: 2.9250
Epoch [5/5], Batch [57/428], Loss: 7.7509
Epoch [5/5], Batch [58/428], Loss: 1.6096
Epoch [5/5], Batch [59/428], Loss: 7.0274
Epoch [5/5], Batch [60/428], Loss: 3.4013
Epoch [5/5], Batch [61/428], Loss: 1.7527
Epoch [5/5], Batch [62/428], Loss: 0.3809
Epoch [5/5], Batch [63/428], Loss: 2.2310
Epoch [5/5], Batch [64/428], Loss: 2.2973
Epoch [5/5], Batch [65/428], Loss: 0.6226
Epoch [5/5], Batch [66/428], Loss: 2.1880
Epoch [5/5], Batch [67/428], Loss: 1.8126
Epoch [5/5], Batch [68/428], Loss: 1.2905
Epoch [5/5], Batch [69/428], Loss: 6.3587
Epoch [5/5], Batch [70/428], Loss: 6.2641
Epoch [5/5], Batch [71/428], Loss: 0.5965
Epoch [5/5], Batch [72/428], Loss: 2.9380
Epoch [5/5], Batch [73/428], Loss: 3.4377
Epoch [5/5], Batch [74/428], Loss: 0.3102
Epoch [5/5], Batch [75/428], Loss: 4.4931
Epoch [5/5], Batch [76/428], Loss: 5.0166
Epoch [5/5], Batch [77/428], Loss: 0.2714
Epoch [5/5], Batch [78/428], Loss: 0.2346
Epoch [5/5], Batch [79/428], Loss: 4.0726
Epoch [5/5], Batch [80/428], Loss: 3.8176
Epoch [5/5], Batch [81/428], Loss: 0.1907
Epoch [5/5], Batch [82/428], Loss: 5.7586
Epoch [5/5], Batch [83/428], Loss: 0.2119
Epoch [5/5], Batch [84/428], Loss: 5.6501
Epoch [5/5], Batch [85/428], Loss: 5.7016
Epoch [5/5], Batch [86/428], Loss: 0.2205
Epoch [5/5], Batch [87/428], Loss: 0.1716
Epoch [5/5], Batch [88/428], Loss: 4.1641
Epoch [5/5], Batch [89/428], Loss: 4.8076
Epoch [5/5], Batch [90/428], Loss: 3.9453
Epoch [5/5], Batch [91/428], Loss: 0.1543
Epoch [5/5], Batch [92/428], Loss: 7.6037
Epoch [5/5], Batch [93/428], Loss: 3.7820
Epoch [5/5], Batch [94/428], Loss: 4.2689
Epoch [5/5], Batch [95/428], Loss: 1.5274
Epoch [5/5], Batch [96/428], Loss: 2.3708
Epoch [5/5], Batch [97/428], Loss: 5.2434
Epoch [5/5], Batch [98/428], Loss: 3.4872
Epoch [5/5], Batch [99/428], Loss: 2.2790
Epoch [5/5], Batch [100/428], Loss: 3.1404
Epoch [5/5], Batch [101/428], Loss: 3.7220
Epoch [5/5], Batch [102/428], Loss: 3.7721
Epoch [5/5], Batch [103/428], Loss: 3.6298
Epoch [5/5], Batch [104/428], Loss: 3.2407
Epoch [5/5], Batch [105/428], Loss: 0.6174
Epoch [5/5], Batch [106/428], Loss: 2.2068
Epoch [5/5], Batch [107/428], Loss: 2.8843
Epoch [5/5], Batch [108/428], Loss: 4.4483
Epoch [5/5], Batch [109/428], Loss: 4.4537
Epoch [5/5], Batch [110/428], Loss: 1.4335
Epoch [5/5], Batch [111/428], Loss: 1.5137
Epoch [5/5], Batch [112/428], Loss: 4.5921
Epoch [5/5], Batch [113/428], Loss: 1.0868
Epoch [5/5], Batch [114/428], Loss: 1.1190
Epoch [5/5], Batch [115/428], Loss: 1.2928
Epoch [5/5], Batch [116/428], Loss: 3.8724
Epoch [5/5], Batch [117/428], Loss: 4.8644
Epoch [5/5], Batch [118/428], Loss: 2.8858
Epoch [5/5], Batch [119/428], Loss: 2.3365
Epoch [5/5], Batch [120/428], Loss: 1.6399
Epoch [5/5], Batch [121/428], Loss: 1.8432
Epoch [5/5], Batch [122/428], Loss: 0.8660
Epoch [5/5], Batch [123/428], Loss: 5.0064
Epoch [5/5], Batch [124/428], Loss: 3.4348
Epoch [5/5], Batch [125/428], Loss: 3.5316
Epoch [5/5], Batch [126/428], Loss: 0.4335
Epoch [5/5], Batch [127/428], Loss: 3.6931
Epoch [5/5], Batch [128/428], Loss: 3.7188
Epoch [5/5], Batch [129/428], Loss: 3.2144
Epoch [5/5], Batch [130/428], Loss: 2.9341
Epoch [5/5], Batch [131/428], Loss: 1.9942
Epoch [5/5], Batch [132/428], Loss: 1.5774
Epoch [5/5], Batch [133/428], Loss: 2.8309
Epoch [5/5], Batch [134/428], Loss: 3.1932
Epoch [5/5], Batch [135/428], Loss: 1.5664
Epoch [5/5], Batch [136/428], Loss: 2.8741
Epoch [5/5], Batch [137/428], Loss: 1.0053
Epoch [5/5], Batch [138/428], Loss: 3.2690
Epoch [5/5], Batch [139/428], Loss: 1.0989
Epoch [5/5], Batch [140/428], Loss: 0.8973
Epoch [5/5], Batch [141/428], Loss: 2.9879
Epoch [5/5], Batch [142/428], Loss: 1.9308
Epoch [5/5], Batch [143/428], Loss: 3.0455
Epoch [5/5], Batch [144/428], Loss: 0.4991
Epoch [5/5], Batch [145/428], Loss: 4.5696
Epoch [5/5], Batch [146/428], Loss: 0.4346
Epoch [5/5], Batch [147/428], Loss: 2.7687
Epoch [5/5], Batch [148/428], Loss: 2.9881
Epoch [5/5], Batch [149/428], Loss: 0.3583
Epoch [5/5], Batch [150/428], Loss: 4.1834
Epoch [5/5], Batch [151/428], Loss: 2.9291
Epoch [5/5], Batch [152/428], Loss: 3.8614
Epoch [5/5], Batch [153/428], Loss: 0.5156
Epoch [5/5], Batch [154/428], Loss: 3.5620
Epoch [5/5], Batch [155/428], Loss: 4.0795
Epoch [5/5], Batch [156/428], Loss: 2.2569
Epoch [5/5], Batch [157/428], Loss: 0.9113
Epoch [5/5], Batch [158/428], Loss: 0.9946
Epoch [5/5], Batch [159/428], Loss: 2.6605
Epoch [5/5], Batch [160/428], Loss: 0.8898
Epoch [5/5], Batch [161/428], Loss: 2.5127
Epoch [5/5], Batch [162/428], Loss: 2.0505
Epoch [5/5], Batch [163/428], Loss: 1.9879
Epoch [5/5], Batch [164/428], Loss: 0.8590
Epoch [5/5], Batch [165/428], Loss: 3.9082
Epoch [5/5], Batch [166/428], Loss: 3.9090
Epoch [5/5], Batch [167/428], Loss: 2.9626
Epoch [5/5], Batch [168/428], Loss: 3.2545
Epoch [5/5], Batch [169/428], Loss: 2.1902
Epoch [5/5], Batch [170/428], Loss: 1.9328
Epoch [5/5], Batch [171/428], Loss: 1.4777
Epoch [5/5], Batch [172/428], Loss: 0.9801
Epoch [5/5], Batch [173/428], Loss: 2.6383
Epoch [5/5], Batch [174/428], Loss: 3.0972
Epoch [5/5], Batch [175/428], Loss: 3.2558
Epoch [5/5], Batch [176/428], Loss: 2.4344
Epoch [5/5], Batch [177/428], Loss: 2.8924
Epoch [5/5], Batch [178/428], Loss: 4.7485
Epoch [5/5], Batch [179/428], Loss: 3.5957
Epoch [5/5], Batch [180/428], Loss: 3.1807
Epoch [5/5], Batch [181/428], Loss: 1.1659
Epoch [5/5], Batch [182/428], Loss: 4.2008
Epoch [5/5], Batch [183/428], Loss: 2.6459
Epoch [5/5], Batch [184/428], Loss: 1.8179
Epoch [5/5], Batch [185/428], Loss: 4.9176
Epoch [5/5], Batch [186/428], Loss: 0.7838
Epoch [5/5], Batch [187/428], Loss: 0.9647
Epoch [5/5], Batch [188/428], Loss: 0.9899
Epoch [5/5], Batch [189/428], Loss: 3.3685
Epoch [5/5], Batch [190/428], Loss: 4.3932
Epoch [5/5], Batch [191/428], Loss: 2.8144
Epoch [5/5], Batch [192/428], Loss: 3.5214
Epoch [5/5], Batch [193/428], Loss: 3.5104
Epoch [5/5], Batch [194/428], Loss: 1.3415
Epoch [5/5], Batch [195/428], Loss: 0.8755
Epoch [5/5], Batch [196/428], Loss: 2.2199
Epoch [5/5], Batch [197/428], Loss: 3.8354
Epoch [5/5], Batch [198/428], Loss: 2.0089
Epoch [5/5], Batch [199/428], Loss: 3.6945
Epoch [5/5], Batch [200/428], Loss: 3.2420
Epoch [5/5], Batch [201/428], Loss: 1.1530
Epoch [5/5], Batch [202/428], Loss: 3.0163
Epoch [5/5], Batch [203/428], Loss: 0.5437
Epoch [5/5], Batch [204/428], Loss: 2.4812
Epoch [5/5], Batch [205/428], Loss: 2.3210
Epoch [5/5], Batch [206/428], Loss: 6.1257
Epoch [5/5], Batch [207/428], Loss: 2.6145
Epoch [5/5], Batch [208/428], Loss: 3.8278
Epoch [5/5], Batch [209/428], Loss: 3.8108
Epoch [5/5], Batch [210/428], Loss: 6.4581
Epoch [5/5], Batch [211/428], Loss: 1.3781
Epoch [5/5], Batch [212/428], Loss: 5.5497
Epoch [5/5], Batch [213/428], Loss: 5.8885
Epoch [5/5], Batch [214/428], Loss: 5.6336
Epoch [5/5], Batch [215/428], Loss: 2.9839
Epoch [5/5], Batch [216/428], Loss: 4.9999
Epoch [5/5], Batch [217/428], Loss: 4.5955
Epoch [5/5], Batch [218/428], Loss: 3.9443
Epoch [5/5], Batch [219/428], Loss: 1.8532
Epoch [5/5], Batch [220/428], Loss: 2.8502
Epoch [5/5], Batch [221/428], Loss: 3.1370
Epoch [5/5], Batch [222/428], Loss: 1.4483
Epoch [5/5], Batch [223/428], Loss: 2.1223
Epoch [5/5], Batch [224/428], Loss: 1.5939
Epoch [5/5], Batch [225/428], Loss: 1.5096
Epoch [5/5], Batch [226/428], Loss: 3.0876
Epoch [5/5], Batch [227/428], Loss: 3.1523
Epoch [5/5], Batch [228/428], Loss: 0.9709
Epoch [5/5], Batch [229/428], Loss: 2.9996
Epoch [5/5], Batch [230/428], Loss: 3.9002
Epoch [5/5], Batch [231/428], Loss: 1.6948
Epoch [5/5], Batch [232/428], Loss: 5.6703
Epoch [5/5], Batch [233/428], Loss: 5.3960
Epoch [5/5], Batch [234/428], Loss: 1.8908
Epoch [5/5], Batch [235/428], Loss: 2.5517
Epoch [5/5], Batch [236/428], Loss: 2.3996
Epoch [5/5], Batch [237/428], Loss: 2.0653
Epoch [5/5], Batch [238/428], Loss: 1.6211
Epoch [5/5], Batch [239/428], Loss: 1.1401
Epoch [5/5], Batch [240/428], Loss: 2.9345
Epoch [5/5], Batch [241/428], Loss: 3.7367
Epoch [5/5], Batch [242/428], Loss: 3.0329
Epoch [5/5], Batch [243/428], Loss: 0.5308
Epoch [5/5], Batch [244/428], Loss: 3.0776
Epoch [5/5], Batch [245/428], Loss: 0.4188
Epoch [5/5], Batch [246/428], Loss: 1.9970
Epoch [5/5], Batch [247/428], Loss: 2.2165
Epoch [5/5], Batch [248/428], Loss: 3.6738
Epoch [5/5], Batch [249/428], Loss: 3.5604
Epoch [5/5], Batch [250/428], Loss: 1.7633
Epoch [5/5], Batch [251/428], Loss: 3.1033
Epoch [5/5], Batch [252/428], Loss: 2.7734
Epoch [5/5], Batch [253/428], Loss: 1.8568
Epoch [5/5], Batch [254/428], Loss: 5.8156
Epoch [5/5], Batch [255/428], Loss: 5.5697
Epoch [5/5], Batch [256/428], Loss: 1.2442
Epoch [5/5], Batch [257/428], Loss: 1.1849
Epoch [5/5], Batch [258/428], Loss: 1.4609
Epoch [5/5], Batch [259/428], Loss: 0.9656
Epoch [5/5], Batch [260/428], Loss: 1.2759
Epoch [5/5], Batch [261/428], Loss: 4.1412
Epoch [5/5], Batch [262/428], Loss: 3.1018
Epoch [5/5], Batch [263/428], Loss: 3.0021
Epoch [5/5], Batch [264/428], Loss: 3.1863
Epoch [5/5], Batch [265/428], Loss: 3.0652
Epoch [5/5], Batch [266/428], Loss: 3.0060
Epoch [5/5], Batch [267/428], Loss: 1.8062
Epoch [5/5], Batch [268/428], Loss: 3.7312
Epoch [5/5], Batch [269/428], Loss: 1.6043
Epoch [5/5], Batch [270/428], Loss: 3.6464
Epoch [5/5], Batch [271/428], Loss: 0.7459
Epoch [5/5], Batch [272/428], Loss: 2.0713
Epoch [5/5], Batch [273/428], Loss: 7.1413
Epoch [5/5], Batch [274/428], Loss: 7.1013
Epoch [5/5], Batch [275/428], Loss: 6.7686
Epoch [5/5], Batch [276/428], Loss: 2.5021
Epoch [5/5], Batch [277/428], Loss: 1.7674
Epoch [5/5], Batch [278/428], Loss: 0.9989
Epoch [5/5], Batch [279/428], Loss: 1.4691
Epoch [5/5], Batch [280/428], Loss: 3.6680
Epoch [5/5], Batch [281/428], Loss: 4.4052
Epoch [5/5], Batch [282/428], Loss: 1.7371
Epoch [5/5], Batch [283/428], Loss: 1.3352
Epoch [5/5], Batch [284/428], Loss: 1.8211
Epoch [5/5], Batch [285/428], Loss: 1.1819
Epoch [5/5], Batch [286/428], Loss: 1.6563
Epoch [5/5], Batch [287/428], Loss: 1.5998
Epoch [5/5], Batch [288/428], Loss: 1.6638
Epoch [5/5], Batch [289/428], Loss: 1.0869
Epoch [5/5], Batch [290/428], Loss: 1.0082
Epoch [5/5], Batch [291/428], Loss: 1.5276
Epoch [5/5], Batch [292/428], Loss: 3.9760
Epoch [5/5], Batch [293/428], Loss: 3.6175
Epoch [5/5], Batch [294/428], Loss: 3.5725
Epoch [5/5], Batch [295/428], Loss: 4.7278
Epoch [5/5], Batch [296/428], Loss: 2.3353
Epoch [5/5], Batch [297/428], Loss: 1.0331
Epoch [5/5], Batch [298/428], Loss: 2.3873
Epoch [5/5], Batch [299/428], Loss: 4.0608
Epoch [5/5], Batch [300/428], Loss: 1.7774
Epoch [5/5], Batch [301/428], Loss: 1.6600
Epoch [5/5], Batch [302/428], Loss: 1.4716
Epoch [5/5], Batch [303/428], Loss: 1.9145
Epoch [5/5], Batch [304/428], Loss: 1.5299
Epoch [5/5], Batch [305/428], Loss: 2.1845
Epoch [5/5], Batch [306/428], Loss: 3.3884
Epoch [5/5], Batch [307/428], Loss: 3.4116
Epoch [5/5], Batch [308/428], Loss: 2.5171
Epoch [5/5], Batch [309/428], Loss: 3.2643
Epoch [5/5], Batch [310/428], Loss: 2.2678
Epoch [5/5], Batch [311/428], Loss: 2.6078
Epoch [5/5], Batch [312/428], Loss: 1.6547
Epoch [5/5], Batch [313/428], Loss: 2.1625
Epoch [5/5], Batch [314/428], Loss: 1.4890
Epoch [5/5], Batch [315/428], Loss: 1.9520
Epoch [5/5], Batch [316/428], Loss: 2.1018
Epoch [5/5], Batch [317/428], Loss: 1.8768
Epoch [5/5], Batch [318/428], Loss: 2.1392
Epoch [5/5], Batch [319/428], Loss: 1.7229
Epoch [5/5], Batch [320/428], Loss: 2.5625
Epoch [5/5], Batch [321/428], Loss: 3.3139
Epoch [5/5], Batch [322/428], Loss: 1.2270
Epoch [5/5], Batch [323/428], Loss: 2.3163
Epoch [5/5], Batch [324/428], Loss: 2.2445
Epoch [5/5], Batch [325/428], Loss: 2.1333
Epoch [5/5], Batch [326/428], Loss: 1.9515
Epoch [5/5], Batch [327/428], Loss: 1.8596
Epoch [5/5], Batch [328/428], Loss: 1.3299
Epoch [5/5], Batch [329/428], Loss: 1.0647
Epoch [5/5], Batch [330/428], Loss: 1.5992
Epoch [5/5], Batch [331/428], Loss: 0.5433
Epoch [5/5], Batch [332/428], Loss: 2.7150
Epoch [5/5], Batch [333/428], Loss: 4.0204
Epoch [5/5], Batch [334/428], Loss: 5.3708
Epoch [5/5], Batch [335/428], Loss: 5.1793
Epoch [5/5], Batch [336/428], Loss: 4.1549
Epoch [5/5], Batch [337/428], Loss: 0.2748
Epoch [5/5], Batch [338/428], Loss: 3.8069
Epoch [5/5], Batch [339/428], Loss: 0.2604
Epoch [5/5], Batch [340/428], Loss: 4.8459
Epoch [5/5], Batch [341/428], Loss: 4.6278
Epoch [5/5], Batch [342/428], Loss: 2.3081
Epoch [5/5], Batch [343/428], Loss: 3.8501
Epoch [5/5], Batch [344/428], Loss: 2.0444
Epoch [5/5], Batch [345/428], Loss: 1.7703
Epoch [5/5], Batch [346/428], Loss: 3.6266
Epoch [5/5], Batch [347/428], Loss: 3.4748
Epoch [5/5], Batch [348/428], Loss: 1.7877
Epoch [5/5], Batch [349/428], Loss: 1.0178
Epoch [5/5], Batch [350/428], Loss: 0.9180
Epoch [5/5], Batch [351/428], Loss: 2.9563
Epoch [5/5], Batch [352/428], Loss: 4.0262
Epoch [5/5], Batch [353/428], Loss: 2.6765
Epoch [5/5], Batch [354/428], Loss: 3.6753
Epoch [5/5], Batch [355/428], Loss: 3.6999
Epoch [5/5], Batch [356/428], Loss: 3.4305
Epoch [5/5], Batch [357/428], Loss: 4.1210
Epoch [5/5], Batch [358/428], Loss: 3.1531
Epoch [5/5], Batch [359/428], Loss: 2.2396
Epoch [5/5], Batch [360/428], Loss: 2.0973
Epoch [5/5], Batch [361/428], Loss: 2.4348
Epoch [5/5], Batch [362/428], Loss: 2.0144
Epoch [5/5], Batch [363/428], Loss: 2.2408
Epoch [5/5], Batch [364/428], Loss: 1.8049
Epoch [5/5], Batch [365/428], Loss: 1.6761
Epoch [5/5], Batch [366/428], Loss: 1.6761
Epoch [5/5], Batch [367/428], Loss: 3.3703
Epoch [5/5], Batch [368/428], Loss: 1.7440
Epoch [5/5], Batch [369/428], Loss: 1.3329
Epoch [5/5], Batch [370/428], Loss: 1.1672
Epoch [5/5], Batch [371/428], Loss: 2.4676
Epoch [5/5], Batch [372/428], Loss: 2.0749
Epoch [5/5], Batch [373/428], Loss: 2.0449
Epoch [5/5], Batch [374/428], Loss: 0.6526
Epoch [5/5], Batch [375/428], Loss: 4.3631
Epoch [5/5], Batch [376/428], Loss: 1.6575
Epoch [5/5], Batch [377/428], Loss: 1.3667
Epoch [5/5], Batch [378/428], Loss: 2.9184
Epoch [5/5], Batch [379/428], Loss: 4.2368
Epoch [5/5], Batch [380/428], Loss: 4.3082
Epoch [5/5], Batch [381/428], Loss: 1.4741
Epoch [5/5], Batch [382/428], Loss: 3.9847
Epoch [5/5], Batch [383/428], Loss: 2.9033
Epoch [5/5], Batch [384/428], Loss: 2.9491
Epoch [5/5], Batch [385/428], Loss: 0.7983
Epoch [5/5], Batch [386/428], Loss: 1.3396
Epoch [5/5], Batch [387/428], Loss: 2.6208
Epoch [5/5], Batch [388/428], Loss: 2.7582
Epoch [5/5], Batch [389/428], Loss: 2.5212
Epoch [5/5], Batch [390/428], Loss: 2.2234
Epoch [5/5], Batch [391/428], Loss: 2.0893
Epoch [5/5], Batch [392/428], Loss: 1.5681
Epoch [5/5], Batch [393/428], Loss: 1.6191
Epoch [5/5], Batch [394/428], Loss: 1.5159
Epoch [5/5], Batch [395/428], Loss: 1.7789
Epoch [5/5], Batch [396/428], Loss: 1.3855
Epoch [5/5], Batch [397/428], Loss: 1.2255
Epoch [5/5], Batch [398/428], Loss: 1.8757
Epoch [5/5], Batch [399/428], Loss: 4.4987
Epoch [5/5], Batch [400/428], Loss: 4.6796
Epoch [5/5], Batch [401/428], Loss: 1.3057
Epoch [5/5], Batch [402/428], Loss: 4.5803
Epoch [5/5], Batch [403/428], Loss: 2.7780
Epoch [5/5], Batch [404/428], Loss: 4.1673
Epoch [5/5], Batch [405/428], Loss: 1.7177
Epoch [5/5], Batch [406/428], Loss: 1.6147
Epoch [5/5], Batch [407/428], Loss: 2.3395
Epoch [5/5], Batch [408/428], Loss: 2.9373
Epoch [5/5], Batch [409/428], Loss: 2.5362
Epoch [5/5], Batch [410/428], Loss: 2.0131
Epoch [5/5], Batch [411/428], Loss: 1.8171
Epoch [5/5], Batch [412/428], Loss: 2.3469
Epoch [5/5], Batch [413/428], Loss: 3.5845
Epoch [5/5], Batch [414/428], Loss: 3.8094
Epoch [5/5], Batch [415/428], Loss: 1.7344
Epoch [5/5], Batch [416/428], Loss: 3.7219
Epoch [5/5], Batch [417/428], Loss: 1.4112
Epoch [5/5], Batch [418/428], Loss: 3.2174
Epoch [5/5], Batch [419/428], Loss: 3.7626
Epoch [5/5], Batch [420/428], Loss: 3.6021
Epoch [5/5], Batch [421/428], Loss: 2.8779
Epoch [5/5], Batch [422/428], Loss: 3.3954
Epoch [5/5], Batch [423/428], Loss: 0.6688
Epoch [5/5], Batch [424/428], Loss: 2.6227
Epoch [5/5], Batch [425/428], Loss: 2.1315
Epoch [5/5], Batch [426/428], Loss: 2.4805
Epoch [5/5], Batch [427/428], Loss: 2.6680
Epoch [5/5], Batch [428/428], Loss: 3.1678
Epoch [5] Training Time: 361.92 seconds
Epoch [5/5], Average Loss: 3.1101, Training Accuracy: 0.1519
Epoch [5], Validation Loss: 2.0080, Validation Accuracy: 0.1429
Epoch [5] Validation Time: 14.98 seconds
--------------------------------------------------

Running trial 6 with config: {'batch_size': 1, 'lr': 4.287158665344996e-05, 'num_epochs': 10, 'unfreeze_epoch': 2, 'max_length': 32000, 'device': device(type='cpu')}
Epoch [1/10], Batch [1/428], Loss: 2.3456
Epoch [1/10], Batch [2/428], Loss: 3.1216
Epoch [1/10], Batch [3/428], Loss: 2.3093
Epoch [1/10], Batch [4/428], Loss: 1.9417
Epoch [1/10], Batch [5/428], Loss: 1.8811
Epoch [1/10], Batch [6/428], Loss: 1.3883
Epoch [1/10], Batch [7/428], Loss: 2.8530
Epoch [1/10], Batch [8/428], Loss: 1.3037
Epoch [1/10], Batch [9/428], Loss: 1.4204
Epoch [1/10], Batch [10/428], Loss: 2.0085
Epoch [1/10], Batch [11/428], Loss: 2.6645
Epoch [1/10], Batch [12/428], Loss: 1.4922
Epoch [1/10], Batch [13/428], Loss: 2.4997
Epoch [1/10], Batch [14/428], Loss: 2.2066
Epoch [1/10], Batch [15/428], Loss: 3.9783
Epoch [1/10], Batch [16/428], Loss: 2.6878
Epoch [1/10], Batch [17/428], Loss: 2.8572
Epoch [1/10], Batch [18/428], Loss: 0.9088
Epoch [1/10], Batch [19/428], Loss: 1.8541
Epoch [1/10], Batch [20/428], Loss: 2.0715
Epoch [1/10], Batch [21/428], Loss: 2.3947
Epoch [1/10], Batch [22/428], Loss: 1.9862
Epoch [1/10], Batch [23/428], Loss: 2.4385
Epoch [1/10], Batch [24/428], Loss: 2.9865
Epoch [1/10], Batch [25/428], Loss: 3.0707
Epoch [1/10], Batch [26/428], Loss: 1.6474
Epoch [1/10], Batch [27/428], Loss: 1.2421
Epoch [1/10], Batch [28/428], Loss: 1.5296
Epoch [1/10], Batch [29/428], Loss: 1.1191
Epoch [1/10], Batch [30/428], Loss: 1.4571
Epoch [1/10], Batch [31/428], Loss: 2.1255
Epoch [1/10], Batch [32/428], Loss: 1.5281
Epoch [1/10], Batch [33/428], Loss: 1.6884
Epoch [1/10], Batch [34/428], Loss: 1.2138
Epoch [1/10], Batch [35/428], Loss: 1.0858
Epoch [1/10], Batch [36/428], Loss: 1.7003
Epoch [1/10], Batch [37/428], Loss: 3.0349
Epoch [1/10], Batch [38/428], Loss: 2.1687
Epoch [1/10], Batch [39/428], Loss: 0.7728
Epoch [1/10], Batch [40/428], Loss: 3.9796
Epoch [1/10], Batch [41/428], Loss: 1.7116
Epoch [1/10], Batch [42/428], Loss: 4.0956
Epoch [1/10], Batch [43/428], Loss: 1.7498
Epoch [1/10], Batch [44/428], Loss: 2.7953
Epoch [1/10], Batch [45/428], Loss: 4.4275
Epoch [1/10], Batch [46/428], Loss: 3.7337
Epoch [1/10], Batch [47/428], Loss: 2.6805
Epoch [1/10], Batch [48/428], Loss: 2.5586
Epoch [1/10], Batch [49/428], Loss: 2.3322
Epoch [1/10], Batch [50/428], Loss: 1.4372
Epoch [1/10], Batch [51/428], Loss: 1.3487
Epoch [1/10], Batch [52/428], Loss: 2.1856
Epoch [1/10], Batch [53/428], Loss: 3.5956
Epoch [1/10], Batch [54/428], Loss: 1.8040
Epoch [1/10], Batch [55/428], Loss: 1.5250
Epoch [1/10], Batch [56/428], Loss: 1.3982
Epoch [1/10], Batch [57/428], Loss: 1.2973
Epoch [1/10], Batch [58/428], Loss: 2.7592
Epoch [1/10], Batch [59/428], Loss: 1.9490
Epoch [1/10], Batch [60/428], Loss: 1.9518
Epoch [1/10], Batch [61/428], Loss: 3.6499
Epoch [1/10], Batch [62/428], Loss: 1.9038
Epoch [1/10], Batch [63/428], Loss: 2.2492
Epoch [1/10], Batch [64/428], Loss: 3.6341
Epoch [1/10], Batch [65/428], Loss: 1.8625
Epoch [1/10], Batch [66/428], Loss: 2.3514
Epoch [1/10], Batch [67/428], Loss: 1.6334
Epoch [1/10], Batch [68/428], Loss: 2.3941
Epoch [1/10], Batch [69/428], Loss: 2.0814
Epoch [1/10], Batch [70/428], Loss: 3.7503
Epoch [1/10], Batch [71/428], Loss: 2.3422
Epoch [1/10], Batch [72/428], Loss: 2.8762
Epoch [1/10], Batch [73/428], Loss: 3.4849
Epoch [1/10], Batch [74/428], Loss: 2.5863
Epoch [1/10], Batch [75/428], Loss: 1.0866
Epoch [1/10], Batch [76/428], Loss: 3.5023
Epoch [1/10], Batch [77/428], Loss: 1.3546
Epoch [1/10], Batch [78/428], Loss: 0.7824
Epoch [1/10], Batch [79/428], Loss: 1.7757
Epoch [1/10], Batch [80/428], Loss: 1.7244
Epoch [1/10], Batch [81/428], Loss: 3.5473
Epoch [1/10], Batch [82/428], Loss: 2.0053
Epoch [1/10], Batch [83/428], Loss: 2.5956
Epoch [1/10], Batch [84/428], Loss: 1.9430
Epoch [1/10], Batch [85/428], Loss: 2.5117
Epoch [1/10], Batch [86/428], Loss: 1.0997
Epoch [1/10], Batch [87/428], Loss: 1.9217
Epoch [1/10], Batch [88/428], Loss: 2.4623
Epoch [1/10], Batch [89/428], Loss: 1.8760
Epoch [1/10], Batch [90/428], Loss: 3.1848
Epoch [1/10], Batch [91/428], Loss: 1.5835
Epoch [1/10], Batch [92/428], Loss: 1.5693
Epoch [1/10], Batch [93/428], Loss: 2.6618
Epoch [1/10], Batch [94/428], Loss: 2.7494
Epoch [1/10], Batch [95/428], Loss: 0.7903
Epoch [1/10], Batch [96/428], Loss: 2.2048
Epoch [1/10], Batch [97/428], Loss: 1.9312
Epoch [1/10], Batch [98/428], Loss: 1.9536
Epoch [1/10], Batch [99/428], Loss: 3.2886
Epoch [1/10], Batch [100/428], Loss: 1.8097
Epoch [1/10], Batch [101/428], Loss: 3.4762
Epoch [1/10], Batch [102/428], Loss: 2.1193
Epoch [1/10], Batch [103/428], Loss: 2.4529
Epoch [1/10], Batch [104/428], Loss: 1.6700
Epoch [1/10], Batch [105/428], Loss: 2.4618
Epoch [1/10], Batch [106/428], Loss: 3.4572
Epoch [1/10], Batch [107/428], Loss: 3.4615
Epoch [1/10], Batch [108/428], Loss: 3.2391
Epoch [1/10], Batch [109/428], Loss: 1.3446
Epoch [1/10], Batch [110/428], Loss: 3.0717
Epoch [1/10], Batch [111/428], Loss: 0.8655
Epoch [1/10], Batch [112/428], Loss: 3.2854
Epoch [1/10], Batch [113/428], Loss: 2.2019
Epoch [1/10], Batch [114/428], Loss: 1.9958
Epoch [1/10], Batch [115/428], Loss: 1.4352
Epoch [1/10], Batch [116/428], Loss: 1.7818
Epoch [1/10], Batch [117/428], Loss: 1.8769
Epoch [1/10], Batch [118/428], Loss: 2.2259
Epoch [1/10], Batch [119/428], Loss: 1.7268
Epoch [1/10], Batch [120/428], Loss: 1.2799
Epoch [1/10], Batch [121/428], Loss: 2.9757
Epoch [1/10], Batch [122/428], Loss: 1.9367
Epoch [1/10], Batch [123/428], Loss: 1.7671
Epoch [1/10], Batch [124/428], Loss: 2.2129
Epoch [1/10], Batch [125/428], Loss: 0.9436
Epoch [1/10], Batch [126/428], Loss: 1.9607
Epoch [1/10], Batch [127/428], Loss: 1.5906
Epoch [1/10], Batch [128/428], Loss: 2.0189
Epoch [1/10], Batch [129/428], Loss: 2.7677
Epoch [1/10], Batch [130/428], Loss: 2.6314
Epoch [1/10], Batch [131/428], Loss: 0.6412
Epoch [1/10], Batch [132/428], Loss: 2.8201
Epoch [1/10], Batch [133/428], Loss: 2.0025
Epoch [1/10], Batch [134/428], Loss: 0.8212
Epoch [1/10], Batch [135/428], Loss: 1.8718
Epoch [1/10], Batch [136/428], Loss: 1.3538
Epoch [1/10], Batch [137/428], Loss: 1.6017
Epoch [1/10], Batch [138/428], Loss: 2.2759
Epoch [1/10], Batch [139/428], Loss: 2.0799
Epoch [1/10], Batch [140/428], Loss: 3.1051
Epoch [1/10], Batch [141/428], Loss: 2.4344
Epoch [1/10], Batch [142/428], Loss: 0.8120
Epoch [1/10], Batch [143/428], Loss: 1.7020
Epoch [1/10], Batch [144/428], Loss: 1.9600
Epoch [1/10], Batch [145/428], Loss: 1.2238
Epoch [1/10], Batch [146/428], Loss: 2.7477
Epoch [1/10], Batch [147/428], Loss: 0.6674
Epoch [1/10], Batch [148/428], Loss: 2.2772
Epoch [1/10], Batch [149/428], Loss: 1.3953
Epoch [1/10], Batch [150/428], Loss: 2.1366
Epoch [1/10], Batch [151/428], Loss: 1.3532
Epoch [1/10], Batch [152/428], Loss: 2.4343
Epoch [1/10], Batch [153/428], Loss: 1.6526
Epoch [1/10], Batch [154/428], Loss: 1.9438
Epoch [1/10], Batch [155/428], Loss: 2.0137
Epoch [1/10], Batch [156/428], Loss: 1.7247
Epoch [1/10], Batch [157/428], Loss: 3.7986
Epoch [1/10], Batch [158/428], Loss: 3.1863
Epoch [1/10], Batch [159/428], Loss: 2.4165
Epoch [1/10], Batch [160/428], Loss: 0.9498
Epoch [1/10], Batch [161/428], Loss: 0.5827
Epoch [1/10], Batch [162/428], Loss: 0.7048
Epoch [1/10], Batch [163/428], Loss: 2.0382
Epoch [1/10], Batch [164/428], Loss: 1.3949
Epoch [1/10], Batch [165/428], Loss: 1.4803
Epoch [1/10], Batch [166/428], Loss: 2.5545
Epoch [1/10], Batch [167/428], Loss: 1.4416
Epoch [1/10], Batch [168/428], Loss: 1.1984
Epoch [1/10], Batch [169/428], Loss: 1.3417
Epoch [1/10], Batch [170/428], Loss: 2.1697
Epoch [1/10], Batch [171/428], Loss: 1.6926
Epoch [1/10], Batch [172/428], Loss: 1.7457
Epoch [1/10], Batch [173/428], Loss: 0.8979
Epoch [1/10], Batch [174/428], Loss: 1.1552
Epoch [1/10], Batch [175/428], Loss: 1.6342
Epoch [1/10], Batch [176/428], Loss: 2.5688
Epoch [1/10], Batch [177/428], Loss: 1.5777
Epoch [1/10], Batch [178/428], Loss: 0.6381
Epoch [1/10], Batch [179/428], Loss: 2.3410
Epoch [1/10], Batch [180/428], Loss: 1.9600
Epoch [1/10], Batch [181/428], Loss: 2.4168
Epoch [1/10], Batch [182/428], Loss: 1.1167
Epoch [1/10], Batch [183/428], Loss: 2.4351
Epoch [1/10], Batch [184/428], Loss: 2.6208
Epoch [1/10], Batch [185/428], Loss: 2.1489
Epoch [1/10], Batch [186/428], Loss: 1.0733
Epoch [1/10], Batch [187/428], Loss: 1.0696
Epoch [1/10], Batch [188/428], Loss: 2.0569
Epoch [1/10], Batch [189/428], Loss: 1.4653
Epoch [1/10], Batch [190/428], Loss: 1.5819
Epoch [1/10], Batch [191/428], Loss: 0.4968
Epoch [1/10], Batch [192/428], Loss: 1.8681
Epoch [1/10], Batch [193/428], Loss: 2.1917
Epoch [1/10], Batch [194/428], Loss: 2.7437
Epoch [1/10], Batch [195/428], Loss: 2.2180
Epoch [1/10], Batch [196/428], Loss: 0.5778
Epoch [1/10], Batch [197/428], Loss: 0.7870
Epoch [1/10], Batch [198/428], Loss: 0.5539
Epoch [1/10], Batch [199/428], Loss: 0.6127
Epoch [1/10], Batch [200/428], Loss: 1.5311
Epoch [1/10], Batch [201/428], Loss: 3.3456
Epoch [1/10], Batch [202/428], Loss: 1.4864
Epoch [1/10], Batch [203/428], Loss: 1.5959
Epoch [1/10], Batch [204/428], Loss: 2.0728
Epoch [1/10], Batch [205/428], Loss: 1.9650
Epoch [1/10], Batch [206/428], Loss: 2.5247
Epoch [1/10], Batch [207/428], Loss: 0.9579
Epoch [1/10], Batch [208/428], Loss: 2.2706
Epoch [1/10], Batch [209/428], Loss: 2.7564
Epoch [1/10], Batch [210/428], Loss: 2.2342
Epoch [1/10], Batch [211/428], Loss: 0.6505
Epoch [1/10], Batch [212/428], Loss: 3.2206
Epoch [1/10], Batch [213/428], Loss: 1.5383
Epoch [1/10], Batch [214/428], Loss: 2.6134
Epoch [1/10], Batch [215/428], Loss: 3.0676
Epoch [1/10], Batch [216/428], Loss: 2.4985
Epoch [1/10], Batch [217/428], Loss: 2.0719
Epoch [1/10], Batch [218/428], Loss: 1.2193
Epoch [1/10], Batch [219/428], Loss: 1.5724
Epoch [1/10], Batch [220/428], Loss: 2.7649
Epoch [1/10], Batch [221/428], Loss: 2.2695
Epoch [1/10], Batch [222/428], Loss: 1.7085
Epoch [1/10], Batch [223/428], Loss: 2.4061
Epoch [1/10], Batch [224/428], Loss: 1.7087
Epoch [1/10], Batch [225/428], Loss: 1.9735
Epoch [1/10], Batch [226/428], Loss: 2.2164
Epoch [1/10], Batch [227/428], Loss: 1.9346
Epoch [1/10], Batch [228/428], Loss: 1.5800
Epoch [1/10], Batch [229/428], Loss: 2.2323
Epoch [1/10], Batch [230/428], Loss: 2.0482
Epoch [1/10], Batch [231/428], Loss: 1.8091
Epoch [1/10], Batch [232/428], Loss: 3.9004
Epoch [1/10], Batch [233/428], Loss: 2.0771
Epoch [1/10], Batch [234/428], Loss: 1.1958
Epoch [1/10], Batch [235/428], Loss: 1.8263
Epoch [1/10], Batch [236/428], Loss: 0.6084
Epoch [1/10], Batch [237/428], Loss: 2.1148
Epoch [1/10], Batch [238/428], Loss: 2.5935
Epoch [1/10], Batch [239/428], Loss: 3.4289
Epoch [1/10], Batch [240/428], Loss: 0.5357
Epoch [1/10], Batch [241/428], Loss: 2.3115
Epoch [1/10], Batch [242/428], Loss: 2.0956
Epoch [1/10], Batch [243/428], Loss: 2.5450
Epoch [1/10], Batch [244/428], Loss: 2.2416
Epoch [1/10], Batch [245/428], Loss: 1.6468
Epoch [1/10], Batch [246/428], Loss: 1.7109
Epoch [1/10], Batch [247/428], Loss: 1.8874
Epoch [1/10], Batch [248/428], Loss: 0.6015
Epoch [1/10], Batch [249/428], Loss: 2.1733
Epoch [1/10], Batch [250/428], Loss: 1.6997
Epoch [1/10], Batch [251/428], Loss: 1.9531
Epoch [1/10], Batch [252/428], Loss: 1.8031
Epoch [1/10], Batch [253/428], Loss: 1.5351
Epoch [1/10], Batch [254/428], Loss: 2.2343
Epoch [1/10], Batch [255/428], Loss: 2.1176
Epoch [1/10], Batch [256/428], Loss: 1.5450
Epoch [1/10], Batch [257/428], Loss: 2.5141
Epoch [1/10], Batch [258/428], Loss: 2.2331
Epoch [1/10], Batch [259/428], Loss: 1.5207
Epoch [1/10], Batch [260/428], Loss: 1.2017
Epoch [1/10], Batch [261/428], Loss: 1.3520
Epoch [1/10], Batch [262/428], Loss: 0.8201
Epoch [1/10], Batch [263/428], Loss: 1.4704
Epoch [1/10], Batch [264/428], Loss: 2.0274
Epoch [1/10], Batch [265/428], Loss: 0.4446
Epoch [1/10], Batch [266/428], Loss: 0.6954
Epoch [1/10], Batch [267/428], Loss: 1.7848
Epoch [1/10], Batch [268/428], Loss: 2.6087
Epoch [1/10], Batch [269/428], Loss: 0.8026
Epoch [1/10], Batch [270/428], Loss: 1.4204
Epoch [1/10], Batch [271/428], Loss: 1.6725
Epoch [1/10], Batch [272/428], Loss: 2.2910
Epoch [1/10], Batch [273/428], Loss: 1.9622
Epoch [1/10], Batch [274/428], Loss: 0.4668
Epoch [1/10], Batch [275/428], Loss: 2.3310
Epoch [1/10], Batch [276/428], Loss: 1.5245
Epoch [1/10], Batch [277/428], Loss: 1.7408
Epoch [1/10], Batch [278/428], Loss: 0.5054
Epoch [1/10], Batch [279/428], Loss: 1.9341
Epoch [1/10], Batch [280/428], Loss: 0.6570
Epoch [1/10], Batch [281/428], Loss: 1.8565
Epoch [1/10], Batch [282/428], Loss: 2.0289
Epoch [1/10], Batch [283/428], Loss: 2.4455
Epoch [1/10], Batch [284/428], Loss: 1.3055
Epoch [1/10], Batch [285/428], Loss: 1.4042
Epoch [1/10], Batch [286/428], Loss: 1.2869
Epoch [1/10], Batch [287/428], Loss: 1.2403
Epoch [1/10], Batch [288/428], Loss: 1.9248
Epoch [1/10], Batch [289/428], Loss: 1.1059
Epoch [1/10], Batch [290/428], Loss: 1.4178
Epoch [1/10], Batch [291/428], Loss: 1.8689
Epoch [1/10], Batch [292/428], Loss: 0.5087
Epoch [1/10], Batch [293/428], Loss: 1.3979
Epoch [1/10], Batch [294/428], Loss: 1.5241
Epoch [1/10], Batch [295/428], Loss: 1.9728
Epoch [1/10], Batch [296/428], Loss: 1.6846
Epoch [1/10], Batch [297/428], Loss: 1.3272
Epoch [1/10], Batch [298/428], Loss: 1.3308
Epoch [1/10], Batch [299/428], Loss: 1.5429
Epoch [1/10], Batch [300/428], Loss: 1.6815
Epoch [1/10], Batch [301/428], Loss: 2.0143
Epoch [1/10], Batch [302/428], Loss: 1.9872
Epoch [1/10], Batch [303/428], Loss: 2.1409
Epoch [1/10], Batch [304/428], Loss: 1.3203
Epoch [1/10], Batch [305/428], Loss: 2.7018
Epoch [1/10], Batch [306/428], Loss: 2.3093
Epoch [1/10], Batch [307/428], Loss: 1.3308
Epoch [1/10], Batch [308/428], Loss: 1.0740
Epoch [1/10], Batch [309/428], Loss: 1.6450
Epoch [1/10], Batch [310/428], Loss: 0.5068
Epoch [1/10], Batch [311/428], Loss: 1.0378
Epoch [1/10], Batch [312/428], Loss: 1.5730
Epoch [1/10], Batch [313/428], Loss: 1.2909
Epoch [1/10], Batch [314/428], Loss: 2.0388
Epoch [1/10], Batch [315/428], Loss: 1.1528
Epoch [1/10], Batch [316/428], Loss: 2.5353
Epoch [1/10], Batch [317/428], Loss: 1.5331
Epoch [1/10], Batch [318/428], Loss: 1.4323
Epoch [1/10], Batch [319/428], Loss: 0.4940
Epoch [1/10], Batch [320/428], Loss: 2.5239
Epoch [1/10], Batch [321/428], Loss: 1.3791
Epoch [1/10], Batch [322/428], Loss: 1.4485
Epoch [1/10], Batch [323/428], Loss: 1.4688
Epoch [1/10], Batch [324/428], Loss: 1.2255
Epoch [1/10], Batch [325/428], Loss: 3.6266
Epoch [1/10], Batch [326/428], Loss: 1.9879
Epoch [1/10], Batch [327/428], Loss: 1.1166
Epoch [1/10], Batch [328/428], Loss: 1.5058
Epoch [1/10], Batch [329/428], Loss: 1.7594
Epoch [1/10], Batch [330/428], Loss: 1.2434
Epoch [1/10], Batch [331/428], Loss: 1.8893
Epoch [1/10], Batch [332/428], Loss: 1.2539
Epoch [1/10], Batch [333/428], Loss: 1.1073
Epoch [1/10], Batch [334/428], Loss: 1.6917
Epoch [1/10], Batch [335/428], Loss: 1.6371
Epoch [1/10], Batch [336/428], Loss: 1.2316
Epoch [1/10], Batch [337/428], Loss: 1.0028
Epoch [1/10], Batch [338/428], Loss: 1.2380
Epoch [1/10], Batch [339/428], Loss: 1.2081
Epoch [1/10], Batch [340/428], Loss: 1.8081
Epoch [1/10], Batch [341/428], Loss: 1.0708
Epoch [1/10], Batch [342/428], Loss: 2.5817
Epoch [1/10], Batch [343/428], Loss: 0.5668
Epoch [1/10], Batch [344/428], Loss: 0.9639
Epoch [1/10], Batch [345/428], Loss: 1.8837
Epoch [1/10], Batch [346/428], Loss: 1.0557
Epoch [1/10], Batch [347/428], Loss: 1.2931
Epoch [1/10], Batch [348/428], Loss: 1.0861
Epoch [1/10], Batch [349/428], Loss: 1.6875
Epoch [1/10], Batch [350/428], Loss: 1.3854
Epoch [1/10], Batch [351/428], Loss: 2.2920
Epoch [1/10], Batch [352/428], Loss: 0.5390
Epoch [1/10], Batch [353/428], Loss: 1.6400
Epoch [1/10], Batch [354/428], Loss: 1.0979
Epoch [1/10], Batch [355/428], Loss: 1.6958
Epoch [1/10], Batch [356/428], Loss: 1.0527
Epoch [1/10], Batch [357/428], Loss: 2.1705
Epoch [1/10], Batch [358/428], Loss: 1.9386
Epoch [1/10], Batch [359/428], Loss: 2.6331
Epoch [1/10], Batch [360/428], Loss: 0.4451
Epoch [1/10], Batch [361/428], Loss: 2.1186
Epoch [1/10], Batch [362/428], Loss: 0.7076
Epoch [1/10], Batch [363/428], Loss: 1.3696
Epoch [1/10], Batch [364/428], Loss: 1.8199
Epoch [1/10], Batch [365/428], Loss: 0.7273
Epoch [1/10], Batch [366/428], Loss: 1.9763
Epoch [1/10], Batch [367/428], Loss: 1.9488
Epoch [1/10], Batch [368/428], Loss: 2.7438
Epoch [1/10], Batch [369/428], Loss: 1.0498
Epoch [1/10], Batch [370/428], Loss: 1.9280
Epoch [1/10], Batch [371/428], Loss: 1.8099
Epoch [1/10], Batch [372/428], Loss: 1.5821
Epoch [1/10], Batch [373/428], Loss: 1.3299
Epoch [1/10], Batch [374/428], Loss: 0.9422
Epoch [1/10], Batch [375/428], Loss: 2.9191
Epoch [1/10], Batch [376/428], Loss: 1.9114
Epoch [1/10], Batch [377/428], Loss: 2.4938
Epoch [1/10], Batch [378/428], Loss: 2.1797
Epoch [1/10], Batch [379/428], Loss: 2.6816
Epoch [1/10], Batch [380/428], Loss: 2.3317
Epoch [1/10], Batch [381/428], Loss: 1.9750
Epoch [1/10], Batch [382/428], Loss: 3.5871
Epoch [1/10], Batch [383/428], Loss: 1.9181
Epoch [1/10], Batch [384/428], Loss: 0.5830
Epoch [1/10], Batch [385/428], Loss: 1.9371
Epoch [1/10], Batch [386/428], Loss: 1.6708
Epoch [1/10], Batch [387/428], Loss: 3.1879
Epoch [1/10], Batch [388/428], Loss: 0.3879
Epoch [1/10], Batch [389/428], Loss: 2.6087
Epoch [1/10], Batch [390/428], Loss: 2.9491
Epoch [1/10], Batch [391/428], Loss: 0.8206
Epoch [1/10], Batch [392/428], Loss: 2.8296
Epoch [1/10], Batch [393/428], Loss: 0.7442
Epoch [1/10], Batch [394/428], Loss: 1.2192
Epoch [1/10], Batch [395/428], Loss: 2.1896
Epoch [1/10], Batch [396/428], Loss: 1.3312
Epoch [1/10], Batch [397/428], Loss: 1.1516
Epoch [1/10], Batch [398/428], Loss: 2.5748
Epoch [1/10], Batch [399/428], Loss: 1.6811
Epoch [1/10], Batch [400/428], Loss: 1.6768
Epoch [1/10], Batch [401/428], Loss: 0.8841
Epoch [1/10], Batch [402/428], Loss: 2.1243
Epoch [1/10], Batch [403/428], Loss: 1.7710
Epoch [1/10], Batch [404/428], Loss: 0.6558
Epoch [1/10], Batch [405/428], Loss: 2.3537
Epoch [1/10], Batch [406/428], Loss: 1.7834
Epoch [1/10], Batch [407/428], Loss: 1.3318
Epoch [1/10], Batch [408/428], Loss: 2.0739
Epoch [1/10], Batch [409/428], Loss: 1.0220
Epoch [1/10], Batch [410/428], Loss: 2.7346
Epoch [1/10], Batch [411/428], Loss: 1.5972
Epoch [1/10], Batch [412/428], Loss: 0.2660
Epoch [1/10], Batch [413/428], Loss: 2.7877
Epoch [1/10], Batch [414/428], Loss: 1.4065
Epoch [1/10], Batch [415/428], Loss: 0.7003
Epoch [1/10], Batch [416/428], Loss: 0.4767
Epoch [1/10], Batch [417/428], Loss: 1.3750
Epoch [1/10], Batch [418/428], Loss: 0.3810
Epoch [1/10], Batch [419/428], Loss: 1.6100
Epoch [1/10], Batch [420/428], Loss: 1.9723
Epoch [1/10], Batch [421/428], Loss: 2.2494
Epoch [1/10], Batch [422/428], Loss: 0.2217
Epoch [1/10], Batch [423/428], Loss: 1.3002
Epoch [1/10], Batch [424/428], Loss: 1.7314
Epoch [1/10], Batch [425/428], Loss: 0.7205
Epoch [1/10], Batch [426/428], Loss: 0.3141
Epoch [1/10], Batch [427/428], Loss: 1.4486
Epoch [1/10], Batch [428/428], Loss: 1.3272
Epoch [1] Training Time: 90.48 seconds
Epoch [1/10], Average Loss: 1.8496, Training Accuracy: 0.2874
Epoch [1], Validation Loss: 1.5899, Validation Accuracy: 0.3123
Epoch [1] Validation Time: 5.60 seconds
--------------------------------------------------
Epoch [2/10], Batch [1/428], Loss: 1.9020
Epoch [2/10], Batch [2/428], Loss: 1.2766
Epoch [2/10], Batch [3/428], Loss: 1.5505
Epoch [2/10], Batch [4/428], Loss: 2.1257
Epoch [2/10], Batch [5/428], Loss: 2.1240
Epoch [2/10], Batch [6/428], Loss: 1.6408
Epoch [2/10], Batch [7/428], Loss: 1.9879
Epoch [2/10], Batch [8/428], Loss: 0.7520
Epoch [2/10], Batch [9/428], Loss: 0.6213
Epoch [2/10], Batch [10/428], Loss: 0.9133
Epoch [2/10], Batch [11/428], Loss: 1.7892
Epoch [2/10], Batch [12/428], Loss: 0.7997
Epoch [2/10], Batch [13/428], Loss: 0.7700
Epoch [2/10], Batch [14/428], Loss: 0.5998
Epoch [2/10], Batch [15/428], Loss: 1.7681
Epoch [2/10], Batch [16/428], Loss: 1.5722
Epoch [2/10], Batch [17/428], Loss: 2.9447
Epoch [2/10], Batch [18/428], Loss: 1.6331
Epoch [2/10], Batch [19/428], Loss: 0.4264
Epoch [2/10], Batch [20/428], Loss: 1.7964
Epoch [2/10], Batch [21/428], Loss: 0.8187
Epoch [2/10], Batch [22/428], Loss: 1.0119
Epoch [2/10], Batch [23/428], Loss: 1.2033
Epoch [2/10], Batch [24/428], Loss: 0.5295
Epoch [2/10], Batch [25/428], Loss: 1.9680
Epoch [2/10], Batch [26/428], Loss: 1.5122
Epoch [2/10], Batch [27/428], Loss: 2.2774
Epoch [2/10], Batch [28/428], Loss: 1.4628
Epoch [2/10], Batch [29/428], Loss: 1.8222
Epoch [2/10], Batch [30/428], Loss: 1.1839
Epoch [2/10], Batch [31/428], Loss: 1.3844
Epoch [2/10], Batch [32/428], Loss: 1.8924
Epoch [2/10], Batch [33/428], Loss: 1.1786
Epoch [2/10], Batch [34/428], Loss: 1.0519
Epoch [2/10], Batch [35/428], Loss: 2.6333
Epoch [2/10], Batch [36/428], Loss: 1.7225
Epoch [2/10], Batch [37/428], Loss: 1.4159
Epoch [2/10], Batch [38/428], Loss: 2.7762
Epoch [2/10], Batch [39/428], Loss: 2.0193
Epoch [2/10], Batch [40/428], Loss: 0.5440
Epoch [2/10], Batch [41/428], Loss: 2.2251
Epoch [2/10], Batch [42/428], Loss: 1.8670
Epoch [2/10], Batch [43/428], Loss: 1.7831
Epoch [2/10], Batch [44/428], Loss: 1.9306
Epoch [2/10], Batch [45/428], Loss: 0.3602
Epoch [2/10], Batch [46/428], Loss: 0.4690
Epoch [2/10], Batch [47/428], Loss: 2.7496
Epoch [2/10], Batch [48/428], Loss: 1.9982
Epoch [2/10], Batch [49/428], Loss: 2.7910
Epoch [2/10], Batch [50/428], Loss: 0.4787
Epoch [2/10], Batch [51/428], Loss: 1.8247
Epoch [2/10], Batch [52/428], Loss: 1.3953
Epoch [2/10], Batch [53/428], Loss: 1.8104
Epoch [2/10], Batch [54/428], Loss: 0.5794
Epoch [2/10], Batch [55/428], Loss: 0.3591
Epoch [2/10], Batch [56/428], Loss: 1.7557
Epoch [2/10], Batch [57/428], Loss: 1.7752
Epoch [2/10], Batch [58/428], Loss: 1.8491
Epoch [2/10], Batch [59/428], Loss: 0.7962
Epoch [2/10], Batch [60/428], Loss: 0.4696
Epoch [2/10], Batch [61/428], Loss: 1.9956
Epoch [2/10], Batch [62/428], Loss: 0.4170
Epoch [2/10], Batch [63/428], Loss: 0.5595
Epoch [2/10], Batch [64/428], Loss: 1.0504
Epoch [2/10], Batch [65/428], Loss: 1.7287
Epoch [2/10], Batch [66/428], Loss: 2.1239
Epoch [2/10], Batch [67/428], Loss: 0.3790
Epoch [2/10], Batch [68/428], Loss: 1.3710
Epoch [2/10], Batch [69/428], Loss: 2.7525
Epoch [2/10], Batch [70/428], Loss: 1.5749
Epoch [2/10], Batch [71/428], Loss: 0.6120
Epoch [2/10], Batch [72/428], Loss: 0.4952
Epoch [2/10], Batch [73/428], Loss: 1.1862
Epoch [2/10], Batch [74/428], Loss: 2.0776
Epoch [2/10], Batch [75/428], Loss: 0.8718
Epoch [2/10], Batch [76/428], Loss: 0.9296
Epoch [2/10], Batch [77/428], Loss: 1.2256
Epoch [2/10], Batch [78/428], Loss: 2.3505
Epoch [2/10], Batch [79/428], Loss: 1.7820
Epoch [2/10], Batch [80/428], Loss: 1.3376
Epoch [2/10], Batch [81/428], Loss: 1.2036
Epoch [2/10], Batch [82/428], Loss: 0.5114
Epoch [2/10], Batch [83/428], Loss: 1.0779
Epoch [2/10], Batch [84/428], Loss: 2.3153
Epoch [2/10], Batch [85/428], Loss: 0.4026
Epoch [2/10], Batch [86/428], Loss: 2.0305
Epoch [2/10], Batch [87/428], Loss: 0.4805
Epoch [2/10], Batch [88/428], Loss: 0.8237
Epoch [2/10], Batch [89/428], Loss: 0.8561
Epoch [2/10], Batch [90/428], Loss: 0.2804
Epoch [2/10], Batch [91/428], Loss: 1.5763
Epoch [2/10], Batch [92/428], Loss: 0.7645
Epoch [2/10], Batch [93/428], Loss: 1.0990
Epoch [2/10], Batch [94/428], Loss: 2.4779
Epoch [2/10], Batch [95/428], Loss: 2.2883
Epoch [2/10], Batch [96/428], Loss: 1.7897
Epoch [2/10], Batch [97/428], Loss: 1.6814
Epoch [2/10], Batch [98/428], Loss: 0.9887
Epoch [2/10], Batch [99/428], Loss: 1.5490
Epoch [2/10], Batch [100/428], Loss: 1.7899
Epoch [2/10], Batch [101/428], Loss: 1.1662
Epoch [2/10], Batch [102/428], Loss: 1.8237
Epoch [2/10], Batch [103/428], Loss: 0.3310
Epoch [2/10], Batch [104/428], Loss: 0.4893
Epoch [2/10], Batch [105/428], Loss: 3.1807
Epoch [2/10], Batch [106/428], Loss: 0.3060
Epoch [2/10], Batch [107/428], Loss: 1.8973
Epoch [2/10], Batch [108/428], Loss: 0.4236
Epoch [2/10], Batch [109/428], Loss: 1.2222
Epoch [2/10], Batch [110/428], Loss: 0.6831
Epoch [2/10], Batch [111/428], Loss: 0.1848
Epoch [2/10], Batch [112/428], Loss: 0.2947
Epoch [2/10], Batch [113/428], Loss: 2.5563
Epoch [2/10], Batch [114/428], Loss: 1.3389
Epoch [2/10], Batch [115/428], Loss: 0.9796
Epoch [2/10], Batch [116/428], Loss: 2.2274
Epoch [2/10], Batch [117/428], Loss: 0.2279
Epoch [2/10], Batch [118/428], Loss: 1.2317
Epoch [2/10], Batch [119/428], Loss: 2.1553
Epoch [2/10], Batch [120/428], Loss: 1.9761
Epoch [2/10], Batch [121/428], Loss: 2.4720
Epoch [2/10], Batch [122/428], Loss: 0.2470
Epoch [2/10], Batch [123/428], Loss: 1.1777
Epoch [2/10], Batch [124/428], Loss: 0.7048
Epoch [2/10], Batch [125/428], Loss: 1.4307
Epoch [2/10], Batch [126/428], Loss: 1.6938
Epoch [2/10], Batch [127/428], Loss: 0.2284
Epoch [2/10], Batch [128/428], Loss: 0.2039
Epoch [2/10], Batch [129/428], Loss: 1.2991
Epoch [2/10], Batch [130/428], Loss: 2.1363
Epoch [2/10], Batch [131/428], Loss: 0.5789
Epoch [2/10], Batch [132/428], Loss: 2.2581
Epoch [2/10], Batch [133/428], Loss: 2.5006
Epoch [2/10], Batch [134/428], Loss: 0.6669
Epoch [2/10], Batch [135/428], Loss: 1.4223
Epoch [2/10], Batch [136/428], Loss: 1.4323
Epoch [2/10], Batch [137/428], Loss: 1.2549
Epoch [2/10], Batch [138/428], Loss: 0.1912
Epoch [2/10], Batch [139/428], Loss: 2.8928
Epoch [2/10], Batch [140/428], Loss: 1.7977
Epoch [2/10], Batch [141/428], Loss: 1.5134
Epoch [2/10], Batch [142/428], Loss: 2.2418
Epoch [2/10], Batch [143/428], Loss: 0.2411
Epoch [2/10], Batch [144/428], Loss: 3.8268
Epoch [2/10], Batch [145/428], Loss: 0.4901
Epoch [2/10], Batch [146/428], Loss: 2.4448
Epoch [2/10], Batch [147/428], Loss: 1.8470
Epoch [2/10], Batch [148/428], Loss: 3.0720
Epoch [2/10], Batch [149/428], Loss: 1.6636
Epoch [2/10], Batch [150/428], Loss: 2.2648
Epoch [2/10], Batch [151/428], Loss: 1.3513
Epoch [2/10], Batch [152/428], Loss: 1.3652
Epoch [2/10], Batch [153/428], Loss: 1.9861
Epoch [2/10], Batch [154/428], Loss: 0.4078
Epoch [2/10], Batch [155/428], Loss: 0.6565
Epoch [2/10], Batch [156/428], Loss: 1.6761
Epoch [2/10], Batch [157/428], Loss: 1.1501
Epoch [2/10], Batch [158/428], Loss: 0.7078
Epoch [2/10], Batch [159/428], Loss: 0.1654
Epoch [2/10], Batch [160/428], Loss: 1.6793
Epoch [2/10], Batch [161/428], Loss: 1.2841
Epoch [2/10], Batch [162/428], Loss: 1.1758
Epoch [2/10], Batch [163/428], Loss: 1.9862
Epoch [2/10], Batch [164/428], Loss: 0.2476
Epoch [2/10], Batch [165/428], Loss: 0.1927
Epoch [2/10], Batch [166/428], Loss: 1.9012
Epoch [2/10], Batch [167/428], Loss: 2.1283
Epoch [2/10], Batch [168/428], Loss: 2.1241
Epoch [2/10], Batch [169/428], Loss: 1.5847
Epoch [2/10], Batch [170/428], Loss: 2.4289
Epoch [2/10], Batch [171/428], Loss: 2.8071
Epoch [2/10], Batch [172/428], Loss: 1.4968
Epoch [2/10], Batch [173/428], Loss: 1.2640
Epoch [2/10], Batch [174/428], Loss: 4.1027
Epoch [2/10], Batch [175/428], Loss: 1.0551
Epoch [2/10], Batch [176/428], Loss: 0.1840
Epoch [2/10], Batch [177/428], Loss: 2.0168
Epoch [2/10], Batch [178/428], Loss: 0.1792
Epoch [2/10], Batch [179/428], Loss: 0.7156
Epoch [2/10], Batch [180/428], Loss: 0.2636
Epoch [2/10], Batch [181/428], Loss: 0.1390
Epoch [2/10], Batch [182/428], Loss: 2.0240
Epoch [2/10], Batch [183/428], Loss: 0.1781
Epoch [2/10], Batch [184/428], Loss: 2.2870
Epoch [2/10], Batch [185/428], Loss: 0.7673
Epoch [2/10], Batch [186/428], Loss: 1.7186
Epoch [2/10], Batch [187/428], Loss: 1.8158
Epoch [2/10], Batch [188/428], Loss: 1.3261
Epoch [2/10], Batch [189/428], Loss: 2.9250
Epoch [2/10], Batch [190/428], Loss: 1.8265
Epoch [2/10], Batch [191/428], Loss: 0.6849
Epoch [2/10], Batch [192/428], Loss: 2.1062
Epoch [2/10], Batch [193/428], Loss: 0.7910
Epoch [2/10], Batch [194/428], Loss: 1.4043
Epoch [2/10], Batch [195/428], Loss: 0.4936
Epoch [2/10], Batch [196/428], Loss: 1.2976
Epoch [2/10], Batch [197/428], Loss: 1.0376
Epoch [2/10], Batch [198/428], Loss: 0.3591
Epoch [2/10], Batch [199/428], Loss: 1.4354
Epoch [2/10], Batch [200/428], Loss: 0.1498
Epoch [2/10], Batch [201/428], Loss: 1.0543
Epoch [2/10], Batch [202/428], Loss: 2.5292
Epoch [2/10], Batch [203/428], Loss: 1.5564
Epoch [2/10], Batch [204/428], Loss: 1.1881
Epoch [2/10], Batch [205/428], Loss: 0.1528
Epoch [2/10], Batch [206/428], Loss: 0.1436
Epoch [2/10], Batch [207/428], Loss: 1.2145
Epoch [2/10], Batch [208/428], Loss: 3.5506
Epoch [2/10], Batch [209/428], Loss: 0.4589
Epoch [2/10], Batch [210/428], Loss: 1.7944
Epoch [2/10], Batch [211/428], Loss: 2.7241
Epoch [2/10], Batch [212/428], Loss: 2.2052
Epoch [2/10], Batch [213/428], Loss: 2.4855
Epoch [2/10], Batch [214/428], Loss: 1.1983
Epoch [2/10], Batch [215/428], Loss: 0.2058
Epoch [2/10], Batch [216/428], Loss: 1.2418
Epoch [2/10], Batch [217/428], Loss: 1.5464
Epoch [2/10], Batch [218/428], Loss: 2.0391
Epoch [2/10], Batch [219/428], Loss: 1.7627
Epoch [2/10], Batch [220/428], Loss: 1.5596
Epoch [2/10], Batch [221/428], Loss: 0.3056
Epoch [2/10], Batch [222/428], Loss: 1.7059
Epoch [2/10], Batch [223/428], Loss: 0.3037
Epoch [2/10], Batch [224/428], Loss: 1.7996
Epoch [2/10], Batch [225/428], Loss: 0.1116
Epoch [2/10], Batch [226/428], Loss: 0.8664
Epoch [2/10], Batch [227/428], Loss: 0.9295
Epoch [2/10], Batch [228/428], Loss: 0.5321
Epoch [2/10], Batch [229/428], Loss: 0.0986
Epoch [2/10], Batch [230/428], Loss: 0.1379
Epoch [2/10], Batch [231/428], Loss: 1.9158
Epoch [2/10], Batch [232/428], Loss: 1.8462
Epoch [2/10], Batch [233/428], Loss: 1.7180
Epoch [2/10], Batch [234/428], Loss: 1.3480
Epoch [2/10], Batch [235/428], Loss: 1.6061
Epoch [2/10], Batch [236/428], Loss: 1.1450
Epoch [2/10], Batch [237/428], Loss: 1.2449
Epoch [2/10], Batch [238/428], Loss: 1.7933
Epoch [2/10], Batch [239/428], Loss: 0.2435
Epoch [2/10], Batch [240/428], Loss: 0.2722
Epoch [2/10], Batch [241/428], Loss: 2.2516
Epoch [2/10], Batch [242/428], Loss: 1.2188
Epoch [2/10], Batch [243/428], Loss: 0.0834
Epoch [2/10], Batch [244/428], Loss: 0.1186
Epoch [2/10], Batch [245/428], Loss: 1.3152
Epoch [2/10], Batch [246/428], Loss: 1.2647
Epoch [2/10], Batch [247/428], Loss: 0.2115
Epoch [2/10], Batch [248/428], Loss: 1.7284
Epoch [2/10], Batch [249/428], Loss: 0.1021
Epoch [2/10], Batch [250/428], Loss: 1.1358
Epoch [2/10], Batch [251/428], Loss: 0.0936
Epoch [2/10], Batch [252/428], Loss: 1.6270
Epoch [2/10], Batch [253/428], Loss: 2.1303
Epoch [2/10], Batch [254/428], Loss: 1.5376
Epoch [2/10], Batch [255/428], Loss: 1.2598
Epoch [2/10], Batch [256/428], Loss: 2.7284
Epoch [2/10], Batch [257/428], Loss: 1.3669
Epoch [2/10], Batch [258/428], Loss: 1.4484
Epoch [2/10], Batch [259/428], Loss: 0.0679
Epoch [2/10], Batch [260/428], Loss: 2.1910
Epoch [2/10], Batch [261/428], Loss: 0.9990
Epoch [2/10], Batch [262/428], Loss: 1.6735
Epoch [2/10], Batch [263/428], Loss: 1.8110
Epoch [2/10], Batch [264/428], Loss: 2.4522
Epoch [2/10], Batch [265/428], Loss: 1.2111
Epoch [2/10], Batch [266/428], Loss: 3.0736
Epoch [2/10], Batch [267/428], Loss: 0.5592
Epoch [2/10], Batch [268/428], Loss: 1.0313
Epoch [2/10], Batch [269/428], Loss: 1.8697
Epoch [2/10], Batch [270/428], Loss: 2.5920
Epoch [2/10], Batch [271/428], Loss: 0.1095
Epoch [2/10], Batch [272/428], Loss: 1.9575
Epoch [2/10], Batch [273/428], Loss: 0.9641
Epoch [2/10], Batch [274/428], Loss: 2.6138
Epoch [2/10], Batch [275/428], Loss: 1.2344
Epoch [2/10], Batch [276/428], Loss: 1.4373
Epoch [2/10], Batch [277/428], Loss: 2.5354
Epoch [2/10], Batch [278/428], Loss: 4.2954
Epoch [2/10], Batch [279/428], Loss: 1.4329
Epoch [2/10], Batch [280/428], Loss: 2.2008
Epoch [2/10], Batch [281/428], Loss: 0.2076
Epoch [2/10], Batch [282/428], Loss: 1.8601
Epoch [2/10], Batch [283/428], Loss: 0.6927
Epoch [2/10], Batch [284/428], Loss: 1.6798
Epoch [2/10], Batch [285/428], Loss: 1.4165
Epoch [2/10], Batch [286/428], Loss: 1.5401
Epoch [2/10], Batch [287/428], Loss: 0.1318
Epoch [2/10], Batch [288/428], Loss: 1.3104
Epoch [2/10], Batch [289/428], Loss: 2.1231
Epoch [2/10], Batch [290/428], Loss: 1.9857
Epoch [2/10], Batch [291/428], Loss: 0.4580
Epoch [2/10], Batch [292/428], Loss: 0.7934
Epoch [2/10], Batch [293/428], Loss: 1.7318
Epoch [2/10], Batch [294/428], Loss: 0.2798
Epoch [2/10], Batch [295/428], Loss: 1.9041
Epoch [2/10], Batch [296/428], Loss: 0.9970
Epoch [2/10], Batch [297/428], Loss: 0.0755
Epoch [2/10], Batch [298/428], Loss: 1.8762
Epoch [2/10], Batch [299/428], Loss: 1.2966
Epoch [2/10], Batch [300/428], Loss: 1.2264
Epoch [2/10], Batch [301/428], Loss: 0.5609
Epoch [2/10], Batch [302/428], Loss: 0.0764
Epoch [2/10], Batch [303/428], Loss: 0.1715
Epoch [2/10], Batch [304/428], Loss: 3.1693
Epoch [2/10], Batch [305/428], Loss: 1.8351
Epoch [2/10], Batch [306/428], Loss: 1.7842
Epoch [2/10], Batch [307/428], Loss: 1.7929
Epoch [2/10], Batch [308/428], Loss: 0.1106
Epoch [2/10], Batch [309/428], Loss: 0.4928
Epoch [2/10], Batch [310/428], Loss: 1.9467
Epoch [2/10], Batch [311/428], Loss: 1.8496
Epoch [2/10], Batch [312/428], Loss: 1.7608
Epoch [2/10], Batch [313/428], Loss: 1.4699
Epoch [2/10], Batch [314/428], Loss: 4.3062
Epoch [2/10], Batch [315/428], Loss: 0.3188
Epoch [2/10], Batch [316/428], Loss: 1.8391
Epoch [2/10], Batch [317/428], Loss: 1.4795
Epoch [2/10], Batch [318/428], Loss: 0.1037
Epoch [2/10], Batch [319/428], Loss: 0.2908
Epoch [2/10], Batch [320/428], Loss: 2.2549
Epoch [2/10], Batch [321/428], Loss: 3.4086
Epoch [2/10], Batch [322/428], Loss: 0.0573
Epoch [2/10], Batch [323/428], Loss: 0.0487
Epoch [2/10], Batch [324/428], Loss: 0.2217
Epoch [2/10], Batch [325/428], Loss: 2.0251
Epoch [2/10], Batch [326/428], Loss: 3.0841
Epoch [2/10], Batch [327/428], Loss: 0.3705
Epoch [2/10], Batch [328/428], Loss: 2.7668
Epoch [2/10], Batch [329/428], Loss: 2.0105
Epoch [2/10], Batch [330/428], Loss: 0.6613
Epoch [2/10], Batch [331/428], Loss: 0.0350
Epoch [2/10], Batch [332/428], Loss: 0.0445
Epoch [2/10], Batch [333/428], Loss: 0.3223
Epoch [2/10], Batch [334/428], Loss: 0.1720
Epoch [2/10], Batch [335/428], Loss: 5.0930
Epoch [2/10], Batch [336/428], Loss: 2.3408
Epoch [2/10], Batch [337/428], Loss: 1.7722
Epoch [2/10], Batch [338/428], Loss: 2.4687
Epoch [2/10], Batch [339/428], Loss: 0.0480
Epoch [2/10], Batch [340/428], Loss: 1.9910
Epoch [2/10], Batch [341/428], Loss: 1.4758
Epoch [2/10], Batch [342/428], Loss: 1.7383
Epoch [2/10], Batch [343/428], Loss: 2.0417
Epoch [2/10], Batch [344/428], Loss: 1.5212
Epoch [2/10], Batch [345/428], Loss: 2.5404
Epoch [2/10], Batch [346/428], Loss: 1.1098
Epoch [2/10], Batch [347/428], Loss: 1.5257
Epoch [2/10], Batch [348/428], Loss: 3.2822
Epoch [2/10], Batch [349/428], Loss: 2.8619
Epoch [2/10], Batch [350/428], Loss: 4.3187
Epoch [2/10], Batch [351/428], Loss: 0.1945
Epoch [2/10], Batch [352/428], Loss: 0.0452
Epoch [2/10], Batch [353/428], Loss: 1.7426
Epoch [2/10], Batch [354/428], Loss: 0.1879
Epoch [2/10], Batch [355/428], Loss: 0.0319
Epoch [2/10], Batch [356/428], Loss: 1.3775
Epoch [2/10], Batch [357/428], Loss: 1.4156
Epoch [2/10], Batch [358/428], Loss: 2.0143
Epoch [2/10], Batch [359/428], Loss: 1.4231
Epoch [2/10], Batch [360/428], Loss: 0.0299
Epoch [2/10], Batch [361/428], Loss: 0.2099
Epoch [2/10], Batch [362/428], Loss: 2.0240
Epoch [2/10], Batch [363/428], Loss: 1.0246
Epoch [2/10], Batch [364/428], Loss: 1.6278
Epoch [2/10], Batch [365/428], Loss: 1.2732
Epoch [2/10], Batch [366/428], Loss: 0.0281
Epoch [2/10], Batch [367/428], Loss: 1.2936
Epoch [2/10], Batch [368/428], Loss: 0.4048
Epoch [2/10], Batch [369/428], Loss: 2.2656
Epoch [2/10], Batch [370/428], Loss: 0.8980
Epoch [2/10], Batch [371/428], Loss: 1.1921
Epoch [2/10], Batch [372/428], Loss: 0.7250
Epoch [2/10], Batch [373/428], Loss: 0.0310
Epoch [2/10], Batch [374/428], Loss: 1.9453
Epoch [2/10], Batch [375/428], Loss: 3.0374
Epoch [2/10], Batch [376/428], Loss: 0.1736
Epoch [2/10], Batch [377/428], Loss: 0.0266
Epoch [2/10], Batch [378/428], Loss: 0.1234
Epoch [2/10], Batch [379/428], Loss: 1.6848
Epoch [2/10], Batch [380/428], Loss: 1.2276
Epoch [2/10], Batch [381/428], Loss: 1.3863
Epoch [2/10], Batch [382/428], Loss: 0.6269
Epoch [2/10], Batch [383/428], Loss: 1.2930
Epoch [2/10], Batch [384/428], Loss: 0.2227
Epoch [2/10], Batch [385/428], Loss: 1.9306
Epoch [2/10], Batch [386/428], Loss: 0.4406
Epoch [2/10], Batch [387/428], Loss: 2.1733
Epoch [2/10], Batch [388/428], Loss: 0.4914
Epoch [2/10], Batch [389/428], Loss: 1.0202
Epoch [2/10], Batch [390/428], Loss: 1.1583
Epoch [2/10], Batch [391/428], Loss: 4.9529
Epoch [2/10], Batch [392/428], Loss: 2.7085
Epoch [2/10], Batch [393/428], Loss: 0.7607
Epoch [2/10], Batch [394/428], Loss: 2.9954
Epoch [2/10], Batch [395/428], Loss: 0.0841
Epoch [2/10], Batch [396/428], Loss: 0.3053
Epoch [2/10], Batch [397/428], Loss: 4.4527
Epoch [2/10], Batch [398/428], Loss: 1.3880
Epoch [2/10], Batch [399/428], Loss: 0.2049
Epoch [2/10], Batch [400/428], Loss: 0.3259
Epoch [2/10], Batch [401/428], Loss: 1.1574
Epoch [2/10], Batch [402/428], Loss: 0.0305
Epoch [2/10], Batch [403/428], Loss: 1.8816
Epoch [2/10], Batch [404/428], Loss: 3.1647
Epoch [2/10], Batch [405/428], Loss: 1.9715
Epoch [2/10], Batch [406/428], Loss: 1.7494
Epoch [2/10], Batch [407/428], Loss: 1.5734
Epoch [2/10], Batch [408/428], Loss: 2.7389
Epoch [2/10], Batch [409/428], Loss: 0.4885
Epoch [2/10], Batch [410/428], Loss: 1.5555
Epoch [2/10], Batch [411/428], Loss: 1.2897
Epoch [2/10], Batch [412/428], Loss: 0.2828
Epoch [2/10], Batch [413/428], Loss: 1.8001
Epoch [2/10], Batch [414/428], Loss: 2.3720
Epoch [2/10], Batch [415/428], Loss: 2.1606
Epoch [2/10], Batch [416/428], Loss: 1.8642
Epoch [2/10], Batch [417/428], Loss: 2.2999
Epoch [2/10], Batch [418/428], Loss: 0.0285
Epoch [2/10], Batch [419/428], Loss: 4.1140
Epoch [2/10], Batch [420/428], Loss: 0.1009
Epoch [2/10], Batch [421/428], Loss: 0.0258
Epoch [2/10], Batch [422/428], Loss: 2.4291
Epoch [2/10], Batch [423/428], Loss: 0.4298
Epoch [2/10], Batch [424/428], Loss: 2.2748
Epoch [2/10], Batch [425/428], Loss: 0.0239
Epoch [2/10], Batch [426/428], Loss: 3.5658
Epoch [2/10], Batch [427/428], Loss: 1.1919
Epoch [2/10], Batch [428/428], Loss: 0.0225
Epoch [2] Training Time: 90.82 seconds
Epoch [2/10], Average Loss: 1.3823, Training Accuracy: 0.4626
Epoch [2], Validation Loss: 1.6789, Validation Accuracy: 0.3123
Epoch [2] Validation Time: 5.58 seconds
--------------------------------------------------
Epoch 3: Unfreezing feature extractor layers...
Epoch [3/10], Batch [1/428], Loss: 1.7610
Epoch [3/10], Batch [2/428], Loss: 2.4703
Epoch [3/10], Batch [3/428], Loss: 2.3517
Epoch [3/10], Batch [4/428], Loss: 1.9405
Epoch [3/10], Batch [5/428], Loss: 0.9236
Epoch [3/10], Batch [6/428], Loss: 3.5685
Epoch [3/10], Batch [7/428], Loss: 2.0525
Epoch [3/10], Batch [8/428], Loss: 5.9073
Epoch [3/10], Batch [9/428], Loss: 1.1990
Epoch [3/10], Batch [10/428], Loss: 1.4404
Epoch [3/10], Batch [11/428], Loss: 3.9579
Epoch [3/10], Batch [12/428], Loss: 0.4446
Epoch [3/10], Batch [13/428], Loss: 0.3748
Epoch [3/10], Batch [14/428], Loss: 8.2631
Epoch [3/10], Batch [15/428], Loss: 7.7978
Epoch [3/10], Batch [16/428], Loss: 6.1321
Epoch [3/10], Batch [17/428], Loss: 0.1347
Epoch [3/10], Batch [18/428], Loss: 4.4265
Epoch [3/10], Batch [19/428], Loss: 1.8876
Epoch [3/10], Batch [20/428], Loss: 5.9714
Epoch [3/10], Batch [21/428], Loss: 5.6092
Epoch [3/10], Batch [22/428], Loss: 0.1228
Epoch [3/10], Batch [23/428], Loss: 0.1118
Epoch [3/10], Batch [24/428], Loss: 4.8479
Epoch [3/10], Batch [25/428], Loss: 5.5969
Epoch [3/10], Batch [26/428], Loss: 0.8975
Epoch [3/10], Batch [27/428], Loss: 2.4605
Epoch [3/10], Batch [28/428], Loss: 0.0387
Epoch [3/10], Batch [29/428], Loss: 7.3408
Epoch [3/10], Batch [30/428], Loss: 4.2975
Epoch [3/10], Batch [31/428], Loss: 7.5101
Epoch [3/10], Batch [32/428], Loss: 1.9512
Epoch [3/10], Batch [33/428], Loss: 2.2870
Epoch [3/10], Batch [34/428], Loss: 2.0762
Epoch [3/10], Batch [35/428], Loss: 2.6255
Epoch [3/10], Batch [36/428], Loss: 1.9818
Epoch [3/10], Batch [37/428], Loss: 0.6175
Epoch [3/10], Batch [38/428], Loss: 5.7673
Epoch [3/10], Batch [39/428], Loss: 5.1943
Epoch [3/10], Batch [40/428], Loss: 3.9940
Epoch [3/10], Batch [41/428], Loss: 3.6581
Epoch [3/10], Batch [42/428], Loss: 1.2329
Epoch [3/10], Batch [43/428], Loss: 1.5369
Epoch [3/10], Batch [44/428], Loss: 2.9918
Epoch [3/10], Batch [45/428], Loss: 2.7064
Epoch [3/10], Batch [46/428], Loss: 2.9425
Epoch [3/10], Batch [47/428], Loss: 3.6317
Epoch [3/10], Batch [48/428], Loss: 3.0625
Epoch [3/10], Batch [49/428], Loss: 1.6170
Epoch [3/10], Batch [50/428], Loss: 1.3595
Epoch [3/10], Batch [51/428], Loss: 1.1434
Epoch [3/10], Batch [52/428], Loss: 0.7293
Epoch [3/10], Batch [53/428], Loss: 2.8787
Epoch [3/10], Batch [54/428], Loss: 3.7169
Epoch [3/10], Batch [55/428], Loss: 5.7756
Epoch [3/10], Batch [56/428], Loss: 4.1922
Epoch [3/10], Batch [57/428], Loss: 3.9735
Epoch [3/10], Batch [58/428], Loss: 1.7741
Epoch [3/10], Batch [59/428], Loss: 1.8514
Epoch [3/10], Batch [60/428], Loss: 2.2530
Epoch [3/10], Batch [61/428], Loss: 2.4145
Epoch [3/10], Batch [62/428], Loss: 4.9555
Epoch [3/10], Batch [63/428], Loss: 1.2840
Epoch [3/10], Batch [64/428], Loss: 2.6108
Epoch [3/10], Batch [65/428], Loss: 1.8679
Epoch [3/10], Batch [66/428], Loss: 4.1297
Epoch [3/10], Batch [67/428], Loss: 0.9560
Epoch [3/10], Batch [68/428], Loss: 1.8747
Epoch [3/10], Batch [69/428], Loss: 1.9937
Epoch [3/10], Batch [70/428], Loss: 3.8895
Epoch [3/10], Batch [71/428], Loss: 1.7262
Epoch [3/10], Batch [72/428], Loss: 3.4813
Epoch [3/10], Batch [73/428], Loss: 3.1835
Epoch [3/10], Batch [74/428], Loss: 2.2578
Epoch [3/10], Batch [75/428], Loss: 2.5252
Epoch [3/10], Batch [76/428], Loss: 1.9894
Epoch [3/10], Batch [77/428], Loss: 1.5062
Epoch [3/10], Batch [78/428], Loss: 1.9924
Epoch [3/10], Batch [79/428], Loss: 3.9501
Epoch [3/10], Batch [80/428], Loss: 1.7447
Epoch [3/10], Batch [81/428], Loss: 1.8114
Epoch [3/10], Batch [82/428], Loss: 1.4770
Epoch [3/10], Batch [83/428], Loss: 1.4945
Epoch [3/10], Batch [84/428], Loss: 1.6672
Epoch [3/10], Batch [85/428], Loss: 0.9564
Epoch [3/10], Batch [86/428], Loss: 3.1573
Epoch [3/10], Batch [87/428], Loss: 2.4116
Epoch [3/10], Batch [88/428], Loss: 5.1611
Epoch [3/10], Batch [89/428], Loss: 4.7103
Epoch [3/10], Batch [90/428], Loss: 0.4976
Epoch [3/10], Batch [91/428], Loss: 2.2966
Epoch [3/10], Batch [92/428], Loss: 3.0638
Epoch [3/10], Batch [93/428], Loss: 3.6623
Epoch [3/10], Batch [94/428], Loss: 4.1797
Epoch [3/10], Batch [95/428], Loss: 1.3407
Epoch [3/10], Batch [96/428], Loss: 1.1575
Epoch [3/10], Batch [97/428], Loss: 3.2602
Epoch [3/10], Batch [98/428], Loss: 2.0038
Epoch [3/10], Batch [99/428], Loss: 2.4758
Epoch [3/10], Batch [100/428], Loss: 2.8688
Epoch [3/10], Batch [101/428], Loss: 0.6289
Epoch [3/10], Batch [102/428], Loss: 3.5403
Epoch [3/10], Batch [103/428], Loss: 3.5415
Epoch [3/10], Batch [104/428], Loss: 0.4321
Epoch [3/10], Batch [105/428], Loss: 0.3774
Epoch [3/10], Batch [106/428], Loss: 1.6825
Epoch [3/10], Batch [107/428], Loss: 3.7186
Epoch [3/10], Batch [108/428], Loss: 7.1407
Epoch [3/10], Batch [109/428], Loss: 4.3800
Epoch [3/10], Batch [110/428], Loss: 2.5929
Epoch [3/10], Batch [111/428], Loss: 0.2849
Epoch [3/10], Batch [112/428], Loss: 1.8286
Epoch [3/10], Batch [113/428], Loss: 2.0285
Epoch [3/10], Batch [114/428], Loss: 0.7079
Epoch [3/10], Batch [115/428], Loss: 3.1377
Epoch [3/10], Batch [116/428], Loss: 2.1284
Epoch [3/10], Batch [117/428], Loss: 1.5596
Epoch [3/10], Batch [118/428], Loss: 0.7767
Epoch [3/10], Batch [119/428], Loss: 1.1223
Epoch [3/10], Batch [120/428], Loss: 2.0054
Epoch [3/10], Batch [121/428], Loss: 1.7024
Epoch [3/10], Batch [122/428], Loss: 1.5569
Epoch [3/10], Batch [123/428], Loss: 2.4208
Epoch [3/10], Batch [124/428], Loss: 0.3556
Epoch [3/10], Batch [125/428], Loss: 3.9455
Epoch [3/10], Batch [126/428], Loss: 0.1103
Epoch [3/10], Batch [127/428], Loss: 3.0743
Epoch [3/10], Batch [128/428], Loss: 0.0221
Epoch [3/10], Batch [129/428], Loss: 3.8364
Epoch [3/10], Batch [130/428], Loss: 2.5750
Epoch [3/10], Batch [131/428], Loss: 2.4603
Epoch [3/10], Batch [132/428], Loss: 2.9591
Epoch [3/10], Batch [133/428], Loss: 0.0001
Epoch [3/10], Batch [134/428], Loss: 2.8619
Epoch [3/10], Batch [135/428], Loss: 1.7156
Epoch [3/10], Batch [136/428], Loss: 2.3625
Epoch [3/10], Batch [137/428], Loss: 2.1555
Epoch [3/10], Batch [138/428], Loss: 1.6711
Epoch [3/10], Batch [139/428], Loss: 11.6148
Epoch [3/10], Batch [140/428], Loss: 3.7838
Epoch [3/10], Batch [141/428], Loss: 3.9734
Epoch [3/10], Batch [142/428], Loss: 1.7662
Epoch [3/10], Batch [143/428], Loss: 3.2398
Epoch [3/10], Batch [144/428], Loss: 1.4890
Epoch [3/10], Batch [145/428], Loss: 0.0384
Epoch [3/10], Batch [146/428], Loss: 4.9097
Epoch [3/10], Batch [147/428], Loss: 2.9280
Epoch [3/10], Batch [148/428], Loss: 0.0257
Epoch [3/10], Batch [149/428], Loss: 0.0110
Epoch [3/10], Batch [150/428], Loss: 7.6218
Epoch [3/10], Batch [151/428], Loss: 0.5949
Epoch [3/10], Batch [152/428], Loss: 2.1127
Epoch [3/10], Batch [153/428], Loss: 1.7729
Epoch [3/10], Batch [154/428], Loss: 6.9317
Epoch [3/10], Batch [155/428], Loss: 1.3925
Epoch [3/10], Batch [156/428], Loss: 6.1180
Epoch [3/10], Batch [157/428], Loss: 0.1928
Epoch [3/10], Batch [158/428], Loss: 8.0460
Epoch [3/10], Batch [159/428], Loss: 2.9455
Epoch [3/10], Batch [160/428], Loss: 5.4401
Epoch [3/10], Batch [161/428], Loss: 6.8557
Epoch [3/10], Batch [162/428], Loss: 1.4778
Epoch [3/10], Batch [163/428], Loss: 1.1298
Epoch [3/10], Batch [164/428], Loss: 4.5293
Epoch [3/10], Batch [165/428], Loss: 3.8581
Epoch [3/10], Batch [166/428], Loss: 1.7737
Epoch [3/10], Batch [167/428], Loss: 4.2151
Epoch [3/10], Batch [168/428], Loss: 1.7570
Epoch [3/10], Batch [169/428], Loss: 3.6691
Epoch [3/10], Batch [170/428], Loss: 2.9007
Epoch [3/10], Batch [171/428], Loss: 0.9703
Epoch [3/10], Batch [172/428], Loss: 4.9463
Epoch [3/10], Batch [173/428], Loss: 3.0167
Epoch [3/10], Batch [174/428], Loss: 0.5626
Epoch [3/10], Batch [175/428], Loss: 3.6853
Epoch [3/10], Batch [176/428], Loss: 2.6665
Epoch [3/10], Batch [177/428], Loss: 3.1882
Epoch [3/10], Batch [178/428], Loss: 2.1082
Epoch [3/10], Batch [179/428], Loss: 2.5113
Epoch [3/10], Batch [180/428], Loss: 1.4406
Epoch [3/10], Batch [181/428], Loss: 3.3490
Epoch [3/10], Batch [182/428], Loss: 2.7977
Epoch [3/10], Batch [183/428], Loss: 0.7330
Epoch [3/10], Batch [184/428], Loss: 2.0629
Epoch [3/10], Batch [185/428], Loss: 2.2368
Epoch [3/10], Batch [186/428], Loss: 3.5804
Epoch [3/10], Batch [187/428], Loss: 3.3442
Epoch [3/10], Batch [188/428], Loss: 1.3409
Epoch [3/10], Batch [189/428], Loss: 0.6865
Epoch [3/10], Batch [190/428], Loss: 0.9114
Epoch [3/10], Batch [191/428], Loss: 2.9539
Epoch [3/10], Batch [192/428], Loss: 1.9686
Epoch [3/10], Batch [193/428], Loss: 3.1994
Epoch [3/10], Batch [194/428], Loss: 1.7167
Epoch [3/10], Batch [195/428], Loss: 3.8409
Epoch [3/10], Batch [196/428], Loss: 1.0128
Epoch [3/10], Batch [197/428], Loss: 1.4189
Epoch [3/10], Batch [198/428], Loss: 4.6853
Epoch [3/10], Batch [199/428], Loss: 0.2936
Epoch [3/10], Batch [200/428], Loss: 3.0462
Epoch [3/10], Batch [201/428], Loss: 0.0765
Epoch [3/10], Batch [202/428], Loss: 2.7672
Epoch [3/10], Batch [203/428], Loss: 0.0075
Epoch [3/10], Batch [204/428], Loss: 0.0032
Epoch [3/10], Batch [205/428], Loss: 6.8590
Epoch [3/10], Batch [206/428], Loss: 4.0954
Epoch [3/10], Batch [207/428], Loss: 5.6934
Epoch [3/10], Batch [208/428], Loss: 0.0147
Epoch [3/10], Batch [209/428], Loss: 1.9434
Epoch [3/10], Batch [210/428], Loss: 7.8562
Epoch [3/10], Batch [211/428], Loss: 0.0058
Epoch [3/10], Batch [212/428], Loss: 0.0136
Epoch [3/10], Batch [213/428], Loss: 3.9418
Epoch [3/10], Batch [214/428], Loss: 1.2755
Epoch [3/10], Batch [215/428], Loss: 5.4731
Epoch [3/10], Batch [216/428], Loss: 3.4115
Epoch [3/10], Batch [217/428], Loss: 2.2182
Epoch [3/10], Batch [218/428], Loss: 3.4936
Epoch [3/10], Batch [219/428], Loss: 1.6928
Epoch [3/10], Batch [220/428], Loss: 1.6099
Epoch [3/10], Batch [221/428], Loss: 2.1732
Epoch [3/10], Batch [222/428], Loss: 2.2916
Epoch [3/10], Batch [223/428], Loss: 3.1201
Epoch [3/10], Batch [224/428], Loss: 1.4220
Epoch [3/10], Batch [225/428], Loss: 2.8307
Epoch [3/10], Batch [226/428], Loss: 3.7778
Epoch [3/10], Batch [227/428], Loss: 2.8547
Epoch [3/10], Batch [228/428], Loss: 2.6000
Epoch [3/10], Batch [229/428], Loss: 2.4024
Epoch [3/10], Batch [230/428], Loss: 3.4525
Epoch [3/10], Batch [231/428], Loss: 1.6645
Epoch [3/10], Batch [232/428], Loss: 1.8434
Epoch [3/10], Batch [233/428], Loss: 3.1882
Epoch [3/10], Batch [234/428], Loss: 3.0654
Epoch [3/10], Batch [235/428], Loss: 2.9664
Epoch [3/10], Batch [236/428], Loss: 2.6449
Epoch [3/10], Batch [237/428], Loss: 2.6093
Epoch [3/10], Batch [238/428], Loss: 1.9112
Epoch [3/10], Batch [239/428], Loss: 2.4801
Epoch [3/10], Batch [240/428], Loss: 1.1659
Epoch [3/10], Batch [241/428], Loss: 0.5922
Epoch [3/10], Batch [242/428], Loss: 3.4484
Epoch [3/10], Batch [243/428], Loss: 6.9769
Epoch [3/10], Batch [244/428], Loss: 0.0811
Epoch [3/10], Batch [245/428], Loss: 5.8502
Epoch [3/10], Batch [246/428], Loss: 0.0969
Epoch [3/10], Batch [247/428], Loss: 4.0990
Epoch [3/10], Batch [248/428], Loss: 4.3864
Epoch [3/10], Batch [249/428], Loss: 3.7497
Epoch [3/10], Batch [250/428], Loss: 3.0986
Epoch [3/10], Batch [251/428], Loss: 0.3636
Epoch [3/10], Batch [252/428], Loss: 2.1035
Epoch [3/10], Batch [253/428], Loss: 3.9484
Epoch [3/10], Batch [254/428], Loss: 0.7312
Epoch [3/10], Batch [255/428], Loss: 0.7480
Epoch [3/10], Batch [256/428], Loss: 3.5732
Epoch [3/10], Batch [257/428], Loss: 3.6458
Epoch [3/10], Batch [258/428], Loss: 3.6364
Epoch [3/10], Batch [259/428], Loss: 0.7039
Epoch [3/10], Batch [260/428], Loss: 1.6542
Epoch [3/10], Batch [261/428], Loss: 0.7194
Epoch [3/10], Batch [262/428], Loss: 0.6124
Epoch [3/10], Batch [263/428], Loss: 2.2377
Epoch [3/10], Batch [264/428], Loss: 3.3743
Epoch [3/10], Batch [265/428], Loss: 0.4394
Epoch [3/10], Batch [266/428], Loss: 3.6462
Epoch [3/10], Batch [267/428], Loss: 3.1736
Epoch [3/10], Batch [268/428], Loss: 2.5867
Epoch [3/10], Batch [269/428], Loss: 2.6158
Epoch [3/10], Batch [270/428], Loss: 2.3694
Epoch [3/10], Batch [271/428], Loss: 2.3260
Epoch [3/10], Batch [272/428], Loss: 2.1358
Epoch [3/10], Batch [273/428], Loss: 1.7667
Epoch [3/10], Batch [274/428], Loss: 1.4071
Epoch [3/10], Batch [275/428], Loss: 1.0346
Epoch [3/10], Batch [276/428], Loss: 2.3832
Epoch [3/10], Batch [277/428], Loss: 2.8940
Epoch [3/10], Batch [278/428], Loss: 3.5605
Epoch [3/10], Batch [279/428], Loss: 3.5404
Epoch [3/10], Batch [280/428], Loss: 2.6402
Epoch [3/10], Batch [281/428], Loss: 3.3995
Epoch [3/10], Batch [282/428], Loss: 0.3638
Epoch [3/10], Batch [283/428], Loss: 0.3501
Epoch [3/10], Batch [284/428], Loss: 2.7457
Epoch [3/10], Batch [285/428], Loss: 2.8359
Epoch [3/10], Batch [286/428], Loss: 2.9563
Epoch [3/10], Batch [287/428], Loss: 4.4204
Epoch [3/10], Batch [288/428], Loss: 3.8736
Epoch [3/10], Batch [289/428], Loss: 2.2778
Epoch [3/10], Batch [290/428], Loss: 2.8169
Epoch [3/10], Batch [291/428], Loss: 3.2089
Epoch [3/10], Batch [292/428], Loss: 3.9891
Epoch [3/10], Batch [293/428], Loss: 1.9212
Epoch [3/10], Batch [294/428], Loss: 1.5762
Epoch [3/10], Batch [295/428], Loss: 3.4828
Epoch [3/10], Batch [296/428], Loss: 1.7759
Epoch [3/10], Batch [297/428], Loss: 2.1183
Epoch [3/10], Batch [298/428], Loss: 2.2273
Epoch [3/10], Batch [299/428], Loss: 2.0312
Epoch [3/10], Batch [300/428], Loss: 1.8440
Epoch [3/10], Batch [301/428], Loss: 1.9497
Epoch [3/10], Batch [302/428], Loss: 2.4163
Epoch [3/10], Batch [303/428], Loss: 2.2086
Epoch [3/10], Batch [304/428], Loss: 1.0218
Epoch [3/10], Batch [305/428], Loss: 0.8827
Epoch [3/10], Batch [306/428], Loss: 2.3889
Epoch [3/10], Batch [307/428], Loss: 2.6174
Epoch [3/10], Batch [308/428], Loss: 2.6840
Epoch [3/10], Batch [309/428], Loss: 0.4701
Epoch [3/10], Batch [310/428], Loss: 3.0453
Epoch [3/10], Batch [311/428], Loss: 2.8853
Epoch [3/10], Batch [312/428], Loss: 3.0030
Epoch [3/10], Batch [313/428], Loss: 2.2231
Epoch [3/10], Batch [314/428], Loss: 2.2378
Epoch [3/10], Batch [315/428], Loss: 1.9298
Epoch [3/10], Batch [316/428], Loss: 1.7765
Epoch [3/10], Batch [317/428], Loss: 2.7626
Epoch [3/10], Batch [318/428], Loss: 1.3821
Epoch [3/10], Batch [319/428], Loss: 2.5442
Epoch [3/10], Batch [320/428], Loss: 1.0648
Epoch [3/10], Batch [321/428], Loss: 2.4856
Epoch [3/10], Batch [322/428], Loss: 2.5325
Epoch [3/10], Batch [323/428], Loss: 2.5217
Epoch [3/10], Batch [324/428], Loss: 2.1297
Epoch [3/10], Batch [325/428], Loss: 0.7171
Epoch [3/10], Batch [326/428], Loss: 1.9042
Epoch [3/10], Batch [327/428], Loss: 3.4003
Epoch [3/10], Batch [328/428], Loss: 2.0013
Epoch [3/10], Batch [329/428], Loss: 3.5219
Epoch [3/10], Batch [330/428], Loss: 1.3101
Epoch [3/10], Batch [331/428], Loss: 1.0893
Epoch [3/10], Batch [332/428], Loss: 2.6683
Epoch [3/10], Batch [333/428], Loss: 1.3251
Epoch [3/10], Batch [334/428], Loss: 0.8558
Epoch [3/10], Batch [335/428], Loss: 1.7313
Epoch [3/10], Batch [336/428], Loss: 1.4016
Epoch [3/10], Batch [337/428], Loss: 1.4161
Epoch [3/10], Batch [338/428], Loss: 0.9699
Epoch [3/10], Batch [339/428], Loss: 1.2181
Epoch [3/10], Batch [340/428], Loss: 3.6108
Epoch [3/10], Batch [341/428], Loss: 0.9519
Epoch [3/10], Batch [342/428], Loss: 0.7887
Epoch [3/10], Batch [343/428], Loss: 1.4051
Epoch [3/10], Batch [344/428], Loss: 5.5554
Epoch [3/10], Batch [345/428], Loss: 5.0689
Epoch [3/10], Batch [346/428], Loss: 3.6054
Epoch [3/10], Batch [347/428], Loss: 3.4084
Epoch [3/10], Batch [348/428], Loss: 1.6845
Epoch [3/10], Batch [349/428], Loss: 3.1709
Epoch [3/10], Batch [350/428], Loss: 0.6501
Epoch [3/10], Batch [351/428], Loss: 2.7083
Epoch [3/10], Batch [352/428], Loss: 0.7030
Epoch [3/10], Batch [353/428], Loss: 0.7097
Epoch [3/10], Batch [354/428], Loss: 1.6889
Epoch [3/10], Batch [355/428], Loss: 0.6496
Epoch [3/10], Batch [356/428], Loss: 2.4826
Epoch [3/10], Batch [357/428], Loss: 1.8935
Epoch [3/10], Batch [358/428], Loss: 2.3506
Epoch [3/10], Batch [359/428], Loss: 2.1014
Epoch [3/10], Batch [360/428], Loss: 1.8934
Epoch [3/10], Batch [361/428], Loss: 1.4792
Epoch [3/10], Batch [362/428], Loss: 1.8127
Epoch [3/10], Batch [363/428], Loss: 4.0575
Epoch [3/10], Batch [364/428], Loss: 2.3840
Epoch [3/10], Batch [365/428], Loss: 1.9197
Epoch [3/10], Batch [366/428], Loss: 3.9339
Epoch [3/10], Batch [367/428], Loss: 2.2235
Epoch [3/10], Batch [368/428], Loss: 0.5527
Epoch [3/10], Batch [369/428], Loss: 0.5486
Epoch [3/10], Batch [370/428], Loss: 4.3380
Epoch [3/10], Batch [371/428], Loss: 3.5830
Epoch [3/10], Batch [372/428], Loss: 1.8758
Epoch [3/10], Batch [373/428], Loss: 0.4660
Epoch [3/10], Batch [374/428], Loss: 2.9069
Epoch [3/10], Batch [375/428], Loss: 4.2680
Epoch [3/10], Batch [376/428], Loss: 2.7934
Epoch [3/10], Batch [377/428], Loss: 3.9512
Epoch [3/10], Batch [378/428], Loss: 2.6238
Epoch [3/10], Batch [379/428], Loss: 1.8247
Epoch [3/10], Batch [380/428], Loss: 2.3726
Epoch [3/10], Batch [381/428], Loss: 0.9920
Epoch [3/10], Batch [382/428], Loss: 2.1314
Epoch [3/10], Batch [383/428], Loss: 2.0801
Epoch [3/10], Batch [384/428], Loss: 3.4389
Epoch [3/10], Batch [385/428], Loss: 2.6456
Epoch [3/10], Batch [386/428], Loss: 3.1499
Epoch [3/10], Batch [387/428], Loss: 1.3657
Epoch [3/10], Batch [388/428], Loss: 1.2129
Epoch [3/10], Batch [389/428], Loss: 1.0560
Epoch [3/10], Batch [390/428], Loss: 0.7692
Epoch [3/10], Batch [391/428], Loss: 2.7058
Epoch [3/10], Batch [392/428], Loss: 2.6707
Epoch [3/10], Batch [393/428], Loss: 2.6326
Epoch [3/10], Batch [394/428], Loss: 0.3591
Epoch [3/10], Batch [395/428], Loss: 3.0599
Epoch [3/10], Batch [396/428], Loss: 0.2834
Epoch [3/10], Batch [397/428], Loss: 3.8218
Epoch [3/10], Batch [398/428], Loss: 3.6231
Epoch [3/10], Batch [399/428], Loss: 0.2138
Epoch [3/10], Batch [400/428], Loss: 2.4531
Epoch [3/10], Batch [401/428], Loss: 3.8037
Epoch [3/10], Batch [402/428], Loss: 4.2898
Epoch [3/10], Batch [403/428], Loss: 0.2477
Epoch [3/10], Batch [404/428], Loss: 2.2500
Epoch [3/10], Batch [405/428], Loss: 0.2699
Epoch [3/10], Batch [406/428], Loss: 3.8370
Epoch [3/10], Batch [407/428], Loss: 4.2320
Epoch [3/10], Batch [408/428], Loss: 2.0757
Epoch [3/10], Batch [409/428], Loss: 1.8898
Epoch [3/10], Batch [410/428], Loss: 3.0922
Epoch [3/10], Batch [411/428], Loss: 5.0057
Epoch [3/10], Batch [412/428], Loss: 0.6198
Epoch [3/10], Batch [413/428], Loss: 2.5231
Epoch [3/10], Batch [414/428], Loss: 2.4225
Epoch [3/10], Batch [415/428], Loss: 3.0307
Epoch [3/10], Batch [416/428], Loss: 1.8627
Epoch [3/10], Batch [417/428], Loss: 1.2150
Epoch [3/10], Batch [418/428], Loss: 1.2913
Epoch [3/10], Batch [419/428], Loss: 2.4848
Epoch [3/10], Batch [420/428], Loss: 2.4057
Epoch [3/10], Batch [421/428], Loss: 1.1260
Epoch [3/10], Batch [422/428], Loss: 1.9214
Epoch [3/10], Batch [423/428], Loss: 4.3219
Epoch [3/10], Batch [424/428], Loss: 4.2703
Epoch [3/10], Batch [425/428], Loss: 2.1272
Epoch [3/10], Batch [426/428], Loss: 1.9051
Epoch [3/10], Batch [427/428], Loss: 2.0828
Epoch [3/10], Batch [428/428], Loss: 1.9738
Epoch [3] Training Time: 165.20 seconds
Epoch [3/10], Average Loss: 2.5120, Training Accuracy: 0.2103
Epoch [3], Validation Loss: 2.2551, Validation Accuracy: 0.1429
Epoch [3] Validation Time: 5.54 seconds
--------------------------------------------------
Epoch [4/10], Batch [1/428], Loss: 1.7301
Epoch [4/10], Batch [2/428], Loss: 3.2491
Epoch [4/10], Batch [3/428], Loss: 2.7542
Epoch [4/10], Batch [4/428], Loss: 1.6104
Epoch [4/10], Batch [5/428], Loss: 2.0529
Epoch [4/10], Batch [6/428], Loss: 1.3644
Epoch [4/10], Batch [7/428], Loss: 1.2826
Epoch [4/10], Batch [8/428], Loss: 1.1129
Epoch [4/10], Batch [9/428], Loss: 3.2432
Epoch [4/10], Batch [10/428], Loss: 3.1960
Epoch [4/10], Batch [11/428], Loss: 1.7674
Epoch [4/10], Batch [12/428], Loss: 2.5103
Epoch [4/10], Batch [13/428], Loss: 2.4799
Epoch [4/10], Batch [14/428], Loss: 0.7391
Epoch [4/10], Batch [15/428], Loss: 0.7403
Epoch [4/10], Batch [16/428], Loss: 0.6420
Epoch [4/10], Batch [17/428], Loss: 2.3992
Epoch [4/10], Batch [18/428], Loss: 3.1574
Epoch [4/10], Batch [19/428], Loss: 0.4725
Epoch [4/10], Batch [20/428], Loss: 4.1343
Epoch [4/10], Batch [21/428], Loss: 2.8321
Epoch [4/10], Batch [22/428], Loss: 2.7717
Epoch [4/10], Batch [23/428], Loss: 4.2796
Epoch [4/10], Batch [24/428], Loss: 0.4348
Epoch [4/10], Batch [25/428], Loss: 2.4579
Epoch [4/10], Batch [26/428], Loss: 4.0007
Epoch [4/10], Batch [27/428], Loss: 0.4166
Epoch [4/10], Batch [28/428], Loss: 0.4511
Epoch [4/10], Batch [29/428], Loss: 0.3990
Epoch [4/10], Batch [30/428], Loss: 3.7434
Epoch [4/10], Batch [31/428], Loss: 2.8371
Epoch [4/10], Batch [32/428], Loss: 0.3171
Epoch [4/10], Batch [33/428], Loss: 3.5624
Epoch [4/10], Batch [34/428], Loss: 0.2729
Epoch [4/10], Batch [35/428], Loss: 3.7107
Epoch [4/10], Batch [36/428], Loss: 3.9541
Epoch [4/10], Batch [37/428], Loss: 0.2145
Epoch [4/10], Batch [38/428], Loss: 3.1796
Epoch [4/10], Batch [39/428], Loss: 0.2205
Epoch [4/10], Batch [40/428], Loss: 0.2100
Epoch [4/10], Batch [41/428], Loss: 3.1045
Epoch [4/10], Batch [42/428], Loss: 3.2175
Epoch [4/10], Batch [43/428], Loss: 3.6810
Epoch [4/10], Batch [44/428], Loss: 4.5906
Epoch [4/10], Batch [45/428], Loss: 0.2090
Epoch [4/10], Batch [46/428], Loss: 4.4389
Epoch [4/10], Batch [47/428], Loss: 2.4367
Epoch [4/10], Batch [48/428], Loss: 3.9569
Epoch [4/10], Batch [49/428], Loss: 0.3139
Epoch [4/10], Batch [50/428], Loss: 3.6426
Epoch [4/10], Batch [51/428], Loss: 3.2943
Epoch [4/10], Batch [52/428], Loss: 3.3985
Epoch [4/10], Batch [53/428], Loss: 3.1488
Epoch [4/10], Batch [54/428], Loss: 3.0191
Epoch [4/10], Batch [55/428], Loss: 2.7255
Epoch [4/10], Batch [56/428], Loss: 1.5188
Epoch [4/10], Batch [57/428], Loss: 2.4501
Epoch [4/10], Batch [58/428], Loss: 2.0397
Epoch [4/10], Batch [59/428], Loss: 1.2651
Epoch [4/10], Batch [60/428], Loss: 1.3795
Epoch [4/10], Batch [61/428], Loss: 1.3601
Epoch [4/10], Batch [62/428], Loss: 1.5779
Epoch [4/10], Batch [63/428], Loss: 1.8462
Epoch [4/10], Batch [64/428], Loss: 1.3139
Epoch [4/10], Batch [65/428], Loss: 3.4773
Epoch [4/10], Batch [66/428], Loss: 2.1807
Epoch [4/10], Batch [67/428], Loss: 1.7851
Epoch [4/10], Batch [68/428], Loss: 1.6667
Epoch [4/10], Batch [69/428], Loss: 1.4064
Epoch [4/10], Batch [70/428], Loss: 3.0217
Epoch [4/10], Batch [71/428], Loss: 0.6836
Epoch [4/10], Batch [72/428], Loss: 3.2560
Epoch [4/10], Batch [73/428], Loss: 3.5109
Epoch [4/10], Batch [74/428], Loss: 3.1061
Epoch [4/10], Batch [75/428], Loss: 0.4314
Epoch [4/10], Batch [76/428], Loss: 2.2268
Epoch [4/10], Batch [77/428], Loss: 0.5491
Epoch [4/10], Batch [78/428], Loss: 3.3419
Epoch [4/10], Batch [79/428], Loss: 2.7697
Epoch [4/10], Batch [80/428], Loss: 0.5871
Epoch [4/10], Batch [81/428], Loss: 3.0078
Epoch [4/10], Batch [82/428], Loss: 1.5930
Epoch [4/10], Batch [83/428], Loss: 0.6603
Epoch [4/10], Batch [84/428], Loss: 4.4243
Epoch [4/10], Batch [85/428], Loss: 0.6132
Epoch [4/10], Batch [86/428], Loss: 3.0824
Epoch [4/10], Batch [87/428], Loss: 3.0264
Epoch [4/10], Batch [88/428], Loss: 0.5967
Epoch [4/10], Batch [89/428], Loss: 3.1897
Epoch [4/10], Batch [90/428], Loss: 1.9065
Epoch [4/10], Batch [91/428], Loss: 2.8806
Epoch [4/10], Batch [92/428], Loss: 2.9790
Epoch [4/10], Batch [93/428], Loss: 2.7264
Epoch [4/10], Batch [94/428], Loss: 2.2611
Epoch [4/10], Batch [95/428], Loss: 0.8970
Epoch [4/10], Batch [96/428], Loss: 0.9516
Epoch [4/10], Batch [97/428], Loss: 2.4658
Epoch [4/10], Batch [98/428], Loss: 1.9055
Epoch [4/10], Batch [99/428], Loss: 2.7410
Epoch [4/10], Batch [100/428], Loss: 2.2673
Epoch [4/10], Batch [101/428], Loss: 2.5990
Epoch [4/10], Batch [102/428], Loss: 3.4327
Epoch [4/10], Batch [103/428], Loss: 1.5372
Epoch [4/10], Batch [104/428], Loss: 1.7374
Epoch [4/10], Batch [105/428], Loss: 1.6697
Epoch [4/10], Batch [106/428], Loss: 1.8857
Epoch [4/10], Batch [107/428], Loss: 2.8573
Epoch [4/10], Batch [108/428], Loss: 1.9808
Epoch [4/10], Batch [109/428], Loss: 1.4762
Epoch [4/10], Batch [110/428], Loss: 1.7698
Epoch [4/10], Batch [111/428], Loss: 2.9005
Epoch [4/10], Batch [112/428], Loss: 2.3744
Epoch [4/10], Batch [113/428], Loss: 1.3546
Epoch [4/10], Batch [114/428], Loss: 2.3992
Epoch [4/10], Batch [115/428], Loss: 2.3077
Epoch [4/10], Batch [116/428], Loss: 2.1826
Epoch [4/10], Batch [117/428], Loss: 1.8202
Epoch [4/10], Batch [118/428], Loss: 1.0621
Epoch [4/10], Batch [119/428], Loss: 1.0436
Epoch [4/10], Batch [120/428], Loss: 2.7254
Epoch [4/10], Batch [121/428], Loss: 0.8626
Epoch [4/10], Batch [122/428], Loss: 2.6604
Epoch [4/10], Batch [123/428], Loss: 3.4938
Epoch [4/10], Batch [124/428], Loss: 1.7250
Epoch [4/10], Batch [125/428], Loss: 3.4580
Epoch [4/10], Batch [126/428], Loss: 2.4510
Epoch [4/10], Batch [127/428], Loss: 2.1225
Epoch [4/10], Batch [128/428], Loss: 3.5913
Epoch [4/10], Batch [129/428], Loss: 1.8294
Epoch [4/10], Batch [130/428], Loss: 3.4504
Epoch [4/10], Batch [131/428], Loss: 1.3740
Epoch [4/10], Batch [132/428], Loss: 1.2985
Epoch [4/10], Batch [133/428], Loss: 2.2519
Epoch [4/10], Batch [134/428], Loss: 1.7152
Epoch [4/10], Batch [135/428], Loss: 3.4827
Epoch [4/10], Batch [136/428], Loss: 2.1991
Epoch [4/10], Batch [137/428], Loss: 2.1055
Epoch [4/10], Batch [138/428], Loss: 1.6436
Epoch [4/10], Batch [139/428], Loss: 2.0099
Epoch [4/10], Batch [140/428], Loss: 2.0636
Epoch [4/10], Batch [141/428], Loss: 1.6006
Epoch [4/10], Batch [142/428], Loss: 1.5790
Epoch [4/10], Batch [143/428], Loss: 1.5369
Epoch [4/10], Batch [144/428], Loss: 2.0249
Epoch [4/10], Batch [145/428], Loss: 1.3720
Epoch [4/10], Batch [146/428], Loss: 2.7695
Epoch [4/10], Batch [147/428], Loss: 1.1463
Epoch [4/10], Batch [148/428], Loss: 3.0469
Epoch [4/10], Batch [149/428], Loss: 2.6423
Epoch [4/10], Batch [150/428], Loss: 3.0848
Epoch [4/10], Batch [151/428], Loss: 2.7932
Epoch [4/10], Batch [152/428], Loss: 3.5082
Epoch [4/10], Batch [153/428], Loss: 2.2945
Epoch [4/10], Batch [154/428], Loss: 0.8230
Epoch [4/10], Batch [155/428], Loss: 2.6816
Epoch [4/10], Batch [156/428], Loss: 2.9377
Epoch [4/10], Batch [157/428], Loss: 2.4844
Epoch [4/10], Batch [158/428], Loss: 2.1518
Epoch [4/10], Batch [159/428], Loss: 2.3841
Epoch [4/10], Batch [160/428], Loss: 1.0265
Epoch [4/10], Batch [161/428], Loss: 1.7723
Epoch [4/10], Batch [162/428], Loss: 3.0354
Epoch [4/10], Batch [163/428], Loss: 1.6909
Epoch [4/10], Batch [164/428], Loss: 1.5465
Epoch [4/10], Batch [165/428], Loss: 2.3449
Epoch [4/10], Batch [166/428], Loss: 1.4852
Epoch [4/10], Batch [167/428], Loss: 1.1944
Epoch [4/10], Batch [168/428], Loss: 1.6180
Epoch [4/10], Batch [169/428], Loss: 2.5229
Epoch [4/10], Batch [170/428], Loss: 1.5423
Epoch [4/10], Batch [171/428], Loss: 2.7995
Epoch [4/10], Batch [172/428], Loss: 3.0537
Epoch [4/10], Batch [173/428], Loss: 1.4625
Epoch [4/10], Batch [174/428], Loss: 2.3177
Epoch [4/10], Batch [175/428], Loss: 1.0770
Epoch [4/10], Batch [176/428], Loss: 2.9265
Epoch [4/10], Batch [177/428], Loss: 2.9222
Epoch [4/10], Batch [178/428], Loss: 2.6354
Epoch [4/10], Batch [179/428], Loss: 2.6578
Epoch [4/10], Batch [180/428], Loss: 2.4379
Epoch [4/10], Batch [181/428], Loss: 1.2709
Epoch [4/10], Batch [182/428], Loss: 2.7767
Epoch [4/10], Batch [183/428], Loss: 1.9307
Epoch [4/10], Batch [184/428], Loss: 1.3583
Epoch [4/10], Batch [185/428], Loss: 2.7680
Epoch [4/10], Batch [186/428], Loss: 1.3000
Epoch [4/10], Batch [187/428], Loss: 1.2698
Epoch [4/10], Batch [188/428], Loss: 2.2127
Epoch [4/10], Batch [189/428], Loss: 2.2510
Epoch [4/10], Batch [190/428], Loss: 1.3960
Epoch [4/10], Batch [191/428], Loss: 1.0492
Epoch [4/10], Batch [192/428], Loss: 2.7037
Epoch [4/10], Batch [193/428], Loss: 0.9209
Epoch [4/10], Batch [194/428], Loss: 2.7184
Epoch [4/10], Batch [195/428], Loss: 2.6282
Epoch [4/10], Batch [196/428], Loss: 3.4164
Epoch [4/10], Batch [197/428], Loss: 3.3313
Epoch [4/10], Batch [198/428], Loss: 2.8213
Epoch [4/10], Batch [199/428], Loss: 2.5221
Epoch [4/10], Batch [200/428], Loss: 1.7296
Epoch [4/10], Batch [201/428], Loss: 2.6422
Epoch [4/10], Batch [202/428], Loss: 2.4951
Epoch [4/10], Batch [203/428], Loss: 1.0852
Epoch [4/10], Batch [204/428], Loss: 2.6315
Epoch [4/10], Batch [205/428], Loss: 2.0246
Epoch [4/10], Batch [206/428], Loss: 1.8922
Epoch [4/10], Batch [207/428], Loss: 2.2316
Epoch [4/10], Batch [208/428], Loss: 1.9645
Epoch [4/10], Batch [209/428], Loss: 1.2914
Epoch [4/10], Batch [210/428], Loss: 3.0870
Epoch [4/10], Batch [211/428], Loss: 2.3454
Epoch [4/10], Batch [212/428], Loss: 2.6694
Epoch [4/10], Batch [213/428], Loss: 2.6383
Epoch [4/10], Batch [214/428], Loss: 2.0428
Epoch [4/10], Batch [215/428], Loss: 2.3071
Epoch [4/10], Batch [216/428], Loss: 2.6187
Epoch [4/10], Batch [217/428], Loss: 1.0194
Epoch [4/10], Batch [218/428], Loss: 1.9641
Epoch [4/10], Batch [219/428], Loss: 1.8950
Epoch [4/10], Batch [220/428], Loss: 3.0798
Epoch [4/10], Batch [221/428], Loss: 2.0926
Epoch [4/10], Batch [222/428], Loss: 1.5483
Epoch [4/10], Batch [223/428], Loss: 1.5974
Epoch [4/10], Batch [224/428], Loss: 2.9048
Epoch [4/10], Batch [225/428], Loss: 1.2493
Epoch [4/10], Batch [226/428], Loss: 3.0684
Epoch [4/10], Batch [227/428], Loss: 1.3002
Epoch [4/10], Batch [228/428], Loss: 1.8957
Epoch [4/10], Batch [229/428], Loss: 2.6776
Epoch [4/10], Batch [230/428], Loss: 1.7195
Epoch [4/10], Batch [231/428], Loss: 1.7796
Epoch [4/10], Batch [232/428], Loss: 1.6589
Epoch [4/10], Batch [233/428], Loss: 2.2923
Epoch [4/10], Batch [234/428], Loss: 1.6927
Epoch [4/10], Batch [235/428], Loss: 2.0075
Epoch [4/10], Batch [236/428], Loss: 1.6161
Epoch [4/10], Batch [237/428], Loss: 1.4789
Epoch [4/10], Batch [238/428], Loss: 1.4592
Epoch [4/10], Batch [239/428], Loss: 1.5139
Epoch [4/10], Batch [240/428], Loss: 3.1521
Epoch [4/10], Batch [241/428], Loss: 2.2134
Epoch [4/10], Batch [242/428], Loss: 2.5141
Epoch [4/10], Batch [243/428], Loss: 1.0669
Epoch [4/10], Batch [244/428], Loss: 3.2755
Epoch [4/10], Batch [245/428], Loss: 3.2857
Epoch [4/10], Batch [246/428], Loss: 0.6696
Epoch [4/10], Batch [247/428], Loss: 0.9772
Epoch [4/10], Batch [248/428], Loss: 2.1022
Epoch [4/10], Batch [249/428], Loss: 0.6141
Epoch [4/10], Batch [250/428], Loss: 2.8412
Epoch [4/10], Batch [251/428], Loss: 3.2469
Epoch [4/10], Batch [252/428], Loss: 1.7340
Epoch [4/10], Batch [253/428], Loss: 0.9503
Epoch [4/10], Batch [254/428], Loss: 2.5029
Epoch [4/10], Batch [255/428], Loss: 0.4015
Epoch [4/10], Batch [256/428], Loss: 2.4631
Epoch [4/10], Batch [257/428], Loss: 0.9897
Epoch [4/10], Batch [258/428], Loss: 2.0843
Epoch [4/10], Batch [259/428], Loss: 1.4103
Epoch [4/10], Batch [260/428], Loss: 3.0678
Epoch [4/10], Batch [261/428], Loss: 0.2360
Epoch [4/10], Batch [262/428], Loss: 3.0591
Epoch [4/10], Batch [263/428], Loss: 1.6480
Epoch [4/10], Batch [264/428], Loss: 1.5816
Epoch [4/10], Batch [265/428], Loss: 1.3639
Epoch [4/10], Batch [266/428], Loss: 0.0181
Epoch [4/10], Batch [267/428], Loss: 0.0020
Epoch [4/10], Batch [268/428], Loss: 7.4618
Epoch [4/10], Batch [269/428], Loss: 0.0004
Epoch [4/10], Batch [270/428], Loss: 9.2165
Epoch [4/10], Batch [271/428], Loss: 2.9116
Epoch [4/10], Batch [272/428], Loss: 6.8154
Epoch [4/10], Batch [273/428], Loss: 2.3703
Epoch [4/10], Batch [274/428], Loss: 2.5342
Epoch [4/10], Batch [275/428], Loss: 3.5736
Epoch [4/10], Batch [276/428], Loss: 0.8858
Epoch [4/10], Batch [277/428], Loss: 0.8547
Epoch [4/10], Batch [278/428], Loss: 2.2898
Epoch [4/10], Batch [279/428], Loss: 3.2473
Epoch [4/10], Batch [280/428], Loss: 3.2312
Epoch [4/10], Batch [281/428], Loss: 2.8946
Epoch [4/10], Batch [282/428], Loss: 1.3549
Epoch [4/10], Batch [283/428], Loss: 0.9324
Epoch [4/10], Batch [284/428], Loss: 0.9487
Epoch [4/10], Batch [285/428], Loss: 2.8833
Epoch [4/10], Batch [286/428], Loss: 1.7552
Epoch [4/10], Batch [287/428], Loss: 2.3327
Epoch [4/10], Batch [288/428], Loss: 2.0147
Epoch [4/10], Batch [289/428], Loss: 1.8343
Epoch [4/10], Batch [290/428], Loss: 1.9950
Epoch [4/10], Batch [291/428], Loss: 1.0458
Epoch [4/10], Batch [292/428], Loss: 1.0625
Epoch [4/10], Batch [293/428], Loss: 1.7325
Epoch [4/10], Batch [294/428], Loss: 1.9266
Epoch [4/10], Batch [295/428], Loss: 1.6873
Epoch [4/10], Batch [296/428], Loss: 3.1391
Epoch [4/10], Batch [297/428], Loss: 1.4747
Epoch [4/10], Batch [298/428], Loss: 4.5489
Epoch [4/10], Batch [299/428], Loss: 1.8071
Epoch [4/10], Batch [300/428], Loss: 0.3678
Epoch [4/10], Batch [301/428], Loss: 4.1987
Epoch [4/10], Batch [302/428], Loss: 1.7473
Epoch [4/10], Batch [303/428], Loss: 0.1674
Epoch [4/10], Batch [304/428], Loss: 2.1729
Epoch [4/10], Batch [305/428], Loss: 3.0128
Epoch [4/10], Batch [306/428], Loss: 0.0336
Epoch [4/10], Batch [307/428], Loss: 3.1891
Epoch [4/10], Batch [308/428], Loss: 2.1354
Epoch [4/10], Batch [309/428], Loss: 0.0012
Epoch [4/10], Batch [310/428], Loss: 1.8916
Epoch [4/10], Batch [311/428], Loss: 2.5692
Epoch [4/10], Batch [312/428], Loss: 1.6164
Epoch [4/10], Batch [313/428], Loss: 2.5535
Epoch [4/10], Batch [314/428], Loss: 1.6720
Epoch [4/10], Batch [315/428], Loss: 0.0018
Epoch [4/10], Batch [316/428], Loss: 0.0000
Epoch [4/10], Batch [317/428], Loss: 0.0000
Epoch [4/10], Batch [318/428], Loss: 0.0000
Epoch [4/10], Batch [319/428], Loss: 8.2042
Epoch [4/10], Batch [320/428], Loss: 1.9424
Epoch [4/10], Batch [321/428], Loss: 0.0000
Epoch [4/10], Batch [322/428], Loss: 1.9462
Epoch [4/10], Batch [323/428], Loss: 1.9367
Epoch [4/10], Batch [324/428], Loss: 1.9241
Epoch [4/10], Batch [325/428], Loss: 1.3818
Epoch [4/10], Batch [326/428], Loss: 1.4065
Epoch [4/10], Batch [327/428], Loss: 1.7526
Epoch [4/10], Batch [328/428], Loss: 2.8770
Epoch [4/10], Batch [329/428], Loss: 1.5879
Epoch [4/10], Batch [330/428], Loss: 1.5050
Epoch [4/10], Batch [331/428], Loss: 3.6195
Epoch [4/10], Batch [332/428], Loss: 2.6440
Epoch [4/10], Batch [333/428], Loss: 3.4454
Epoch [4/10], Batch [334/428], Loss: 1.4237
Epoch [4/10], Batch [335/428], Loss: 2.8601
Epoch [4/10], Batch [336/428], Loss: 1.6972
Epoch [4/10], Batch [337/428], Loss: 1.1075
Epoch [4/10], Batch [338/428], Loss: 3.0096
Epoch [4/10], Batch [339/428], Loss: 2.5817
Epoch [4/10], Batch [340/428], Loss: 1.7911
Epoch [4/10], Batch [341/428], Loss: 1.1149
Epoch [4/10], Batch [342/428], Loss: 15.1311
Epoch [4/10], Batch [343/428], Loss: 1.8780
Epoch [4/10], Batch [344/428], Loss: 1.6662
Epoch [4/10], Batch [345/428], Loss: 2.8482
Epoch [4/10], Batch [346/428], Loss: 1.3371
Epoch [4/10], Batch [347/428], Loss: 1.8802
Epoch [4/10], Batch [348/428], Loss: 2.1493
Epoch [4/10], Batch [349/428], Loss: 1.4047
Epoch [4/10], Batch [350/428], Loss: 1.8448
Epoch [4/10], Batch [351/428], Loss: 0.0010
Epoch [4/10], Batch [352/428], Loss: 7.5780
Epoch [4/10], Batch [353/428], Loss: 1.7093
Epoch [4/10], Batch [354/428], Loss: 0.0136
Epoch [4/10], Batch [355/428], Loss: 1.4798
Epoch [4/10], Batch [356/428], Loss: 1.7992
Epoch [4/10], Batch [357/428], Loss: 1.8224
Epoch [4/10], Batch [358/428], Loss: 1.9072
Epoch [4/10], Batch [359/428], Loss: 1.1016
Epoch [4/10], Batch [360/428], Loss: 3.8134
Epoch [4/10], Batch [361/428], Loss: 2.3920
Epoch [4/10], Batch [362/428], Loss: 2.0247
Epoch [4/10], Batch [363/428], Loss: 2.4199
Epoch [4/10], Batch [364/428], Loss: 0.9045
Epoch [4/10], Batch [365/428], Loss: 3.6972
Epoch [4/10], Batch [366/428], Loss: 0.0183
Epoch [4/10], Batch [367/428], Loss: 1.9240
Epoch [4/10], Batch [368/428], Loss: 1.8744
Epoch [4/10], Batch [369/428], Loss: 2.6407
Epoch [4/10], Batch [370/428], Loss: 2.1690
Epoch [4/10], Batch [371/428], Loss: 2.7113
Epoch [4/10], Batch [372/428], Loss: 2.0745
Epoch [4/10], Batch [373/428], Loss: 1.2794
Epoch [4/10], Batch [374/428], Loss: 1.2496
Epoch [4/10], Batch [375/428], Loss: 2.0294
Epoch [4/10], Batch [376/428], Loss: 1.9588
Epoch [4/10], Batch [377/428], Loss: 1.7921
Epoch [4/10], Batch [378/428], Loss: 2.6166
Epoch [4/10], Batch [379/428], Loss: 0.5111
Epoch [4/10], Batch [380/428], Loss: 1.9326
Epoch [4/10], Batch [381/428], Loss: 0.0014
Epoch [4/10], Batch [382/428], Loss: 2.4410
Epoch [4/10], Batch [383/428], Loss: 0.0006
Epoch [4/10], Batch [384/428], Loss: 7.9021
Epoch [4/10], Batch [385/428], Loss: 0.0007
Epoch [4/10], Batch [386/428], Loss: 2.0437
Epoch [4/10], Batch [387/428], Loss: 0.0015
Epoch [4/10], Batch [388/428], Loss: 2.0740
Epoch [4/10], Batch [389/428], Loss: 0.0025
Epoch [4/10], Batch [390/428], Loss: 3.1627
Epoch [4/10], Batch [391/428], Loss: 2.0666
Epoch [4/10], Batch [392/428], Loss: 10.1062
Epoch [4/10], Batch [393/428], Loss: 1.0735
Epoch [4/10], Batch [394/428], Loss: 0.0083
Epoch [4/10], Batch [395/428], Loss: 2.1567
Epoch [4/10], Batch [396/428], Loss: 6.6989
Epoch [4/10], Batch [397/428], Loss: 4.3201
Epoch [4/10], Batch [398/428], Loss: 3.8693
Epoch [4/10], Batch [399/428], Loss: 1.1237
Epoch [4/10], Batch [400/428], Loss: 0.1892
Epoch [4/10], Batch [401/428], Loss: 3.6041
Epoch [4/10], Batch [402/428], Loss: 3.2359
Epoch [4/10], Batch [403/428], Loss: 1.7233
Epoch [4/10], Batch [404/428], Loss: 0.8848
Epoch [4/10], Batch [405/428], Loss: 2.1714
Epoch [4/10], Batch [406/428], Loss: 1.4279
Epoch [4/10], Batch [407/428], Loss: 2.9152
Epoch [4/10], Batch [408/428], Loss: 1.7065
Epoch [4/10], Batch [409/428], Loss: 2.2449
Epoch [4/10], Batch [410/428], Loss: 1.9594
Epoch [4/10], Batch [411/428], Loss: 0.7033
Epoch [4/10], Batch [412/428], Loss: 1.7628
Epoch [4/10], Batch [413/428], Loss: 2.7433
Epoch [4/10], Batch [414/428], Loss: 2.9820
Epoch [4/10], Batch [415/428], Loss: 1.8224
Epoch [4/10], Batch [416/428], Loss: 1.7739
Epoch [4/10], Batch [417/428], Loss: 1.6691
Epoch [4/10], Batch [418/428], Loss: 0.9791
Epoch [4/10], Batch [419/428], Loss: 2.8954
Epoch [4/10], Batch [420/428], Loss: 2.7555
Epoch [4/10], Batch [421/428], Loss: 1.0727
Epoch [4/10], Batch [422/428], Loss: 2.5347
Epoch [4/10], Batch [423/428], Loss: 1.2100
Epoch [4/10], Batch [424/428], Loss: 2.1636
Epoch [4/10], Batch [425/428], Loss: 2.4592
Epoch [4/10], Batch [426/428], Loss: 2.8306
Epoch [4/10], Batch [427/428], Loss: 2.6550
Epoch [4/10], Batch [428/428], Loss: 3.3969
Epoch [4] Training Time: 159.38 seconds
Epoch [4/10], Average Loss: 2.1615, Training Accuracy: 0.2523
Epoch [4], Validation Loss: 2.1267, Validation Accuracy: 0.1714
Epoch [4] Validation Time: 5.60 seconds
--------------------------------------------------
Epoch [5/10], Batch [1/428], Loss: 2.5076
Epoch [5/10], Batch [2/428], Loss: 1.7014
Epoch [5/10], Batch [3/428], Loss: 2.0071
Epoch [5/10], Batch [4/428], Loss: 1.8188
Epoch [5/10], Batch [5/428], Loss: 1.3755
Epoch [5/10], Batch [6/428], Loss: 1.3780
Epoch [5/10], Batch [7/428], Loss: 2.1104
Epoch [5/10], Batch [8/428], Loss: 1.4980
Epoch [5/10], Batch [9/428], Loss: 1.3861
Epoch [5/10], Batch [10/428], Loss: 1.4227
Epoch [5/10], Batch [11/428], Loss: 1.1809
Epoch [5/10], Batch [12/428], Loss: 2.1578
Epoch [5/10], Batch [13/428], Loss: 2.8112
Epoch [5/10], Batch [14/428], Loss: 2.1760
Epoch [5/10], Batch [15/428], Loss: 2.0818
Epoch [5/10], Batch [16/428], Loss: 1.2615
Epoch [5/10], Batch [17/428], Loss: 1.2456
Epoch [5/10], Batch [18/428], Loss: 1.7059
Epoch [5/10], Batch [19/428], Loss: 2.1458
Epoch [5/10], Batch [20/428], Loss: 1.0032
Epoch [5/10], Batch [21/428], Loss: 2.0096
Epoch [5/10], Batch [22/428], Loss: 0.7246
Epoch [5/10], Batch [23/428], Loss: 2.7776
Epoch [5/10], Batch [24/428], Loss: 1.0510
Epoch [5/10], Batch [25/428], Loss: 0.4146
Epoch [5/10], Batch [26/428], Loss: 1.9353
Epoch [5/10], Batch [27/428], Loss: 0.2911
Epoch [5/10], Batch [28/428], Loss: 1.6636
Epoch [5/10], Batch [29/428], Loss: 0.9531
Epoch [5/10], Batch [30/428], Loss: 0.9320
Epoch [5/10], Batch [31/428], Loss: 2.2800
Epoch [5/10], Batch [32/428], Loss: 3.5240
Epoch [5/10], Batch [33/428], Loss: 2.7776
Epoch [5/10], Batch [34/428], Loss: 2.2335
Epoch [5/10], Batch [35/428], Loss: 1.6235
Epoch [5/10], Batch [36/428], Loss: 0.0388
Epoch [5/10], Batch [37/428], Loss: 1.5760
Epoch [5/10], Batch [38/428], Loss: 2.5616
Epoch [5/10], Batch [39/428], Loss: 1.0089
Epoch [5/10], Batch [40/428], Loss: 2.8066
Epoch [5/10], Batch [41/428], Loss: 1.9896
Epoch [5/10], Batch [42/428], Loss: 1.3719
Epoch [5/10], Batch [43/428], Loss: 1.2060
Epoch [5/10], Batch [44/428], Loss: 1.1930
Epoch [5/10], Batch [45/428], Loss: 4.4005
Epoch [5/10], Batch [46/428], Loss: 1.0933
Epoch [5/10], Batch [47/428], Loss: 2.9871
Epoch [5/10], Batch [48/428], Loss: 0.0063
Epoch [5/10], Batch [49/428], Loss: 0.2319
Epoch [5/10], Batch [50/428], Loss: 3.1001
Epoch [5/10], Batch [51/428], Loss: 0.0052
Epoch [5/10], Batch [52/428], Loss: 7.8701
Epoch [5/10], Batch [53/428], Loss: 2.7239
Epoch [5/10], Batch [54/428], Loss: 5.6614
Epoch [5/10], Batch [55/428], Loss: 1.6609
Epoch [5/10], Batch [56/428], Loss: 0.0091
Epoch [5/10], Batch [57/428], Loss: 0.9305
Epoch [5/10], Batch [58/428], Loss: 4.8884
Epoch [5/10], Batch [59/428], Loss: 8.4889
Epoch [5/10], Batch [60/428], Loss: 1.6325
Epoch [5/10], Batch [61/428], Loss: 0.9435
Epoch [5/10], Batch [62/428], Loss: 0.0439
Epoch [5/10], Batch [63/428], Loss: 2.2940
Epoch [5/10], Batch [64/428], Loss: 1.5367
Epoch [5/10], Batch [65/428], Loss: 0.3530
Epoch [5/10], Batch [66/428], Loss: 0.0647
Epoch [5/10], Batch [67/428], Loss: 5.0684
Epoch [5/10], Batch [68/428], Loss: 3.3730
Epoch [5/10], Batch [69/428], Loss: 0.0501
Epoch [5/10], Batch [70/428], Loss: 1.2912
Epoch [5/10], Batch [71/428], Loss: 2.7690
Epoch [5/10], Batch [72/428], Loss: 5.8281
Epoch [5/10], Batch [73/428], Loss: 1.0982
Epoch [5/10], Batch [74/428], Loss: 4.2543
Epoch [5/10], Batch [75/428], Loss: 4.4765
Epoch [5/10], Batch [76/428], Loss: 0.0530
Epoch [5/10], Batch [77/428], Loss: 2.5329
Epoch [5/10], Batch [78/428], Loss: 0.7250
Epoch [5/10], Batch [79/428], Loss: 1.7183
Epoch [5/10], Batch [80/428], Loss: 4.4252
Epoch [5/10], Batch [81/428], Loss: 2.3157
Epoch [5/10], Batch [82/428], Loss: 0.5978
Epoch [5/10], Batch [83/428], Loss: 0.5765
Epoch [5/10], Batch [84/428], Loss: 0.5353
Epoch [5/10], Batch [85/428], Loss: 0.0710
Epoch [5/10], Batch [86/428], Loss: 0.0670
Epoch [5/10], Batch [87/428], Loss: 3.4759
Epoch [5/10], Batch [88/428], Loss: 0.0421
Epoch [5/10], Batch [89/428], Loss: 0.6999
Epoch [5/10], Batch [90/428], Loss: 0.2867
Epoch [5/10], Batch [91/428], Loss: 5.3828
Epoch [5/10], Batch [92/428], Loss: 5.5357
Epoch [5/10], Batch [93/428], Loss: 0.1966
Epoch [5/10], Batch [94/428], Loss: 0.0085
Epoch [5/10], Batch [95/428], Loss: 3.3946
Epoch [5/10], Batch [96/428], Loss: 0.0089
Epoch [5/10], Batch [97/428], Loss: 0.0065
Epoch [5/10], Batch [98/428], Loss: 0.0930
Epoch [5/10], Batch [99/428], Loss: 3.9119
Epoch [5/10], Batch [100/428], Loss: 0.1090
Epoch [5/10], Batch [101/428], Loss: 4.2527
Epoch [5/10], Batch [102/428], Loss: 3.9831
Epoch [5/10], Batch [103/428], Loss: 0.0028
Epoch [5/10], Batch [104/428], Loss: 0.0023
Epoch [5/10], Batch [105/428], Loss: 5.2784
Epoch [5/10], Batch [106/428], Loss: 3.3928
Epoch [5/10], Batch [107/428], Loss: 3.2851
Epoch [5/10], Batch [108/428], Loss: 0.0016
Epoch [5/10], Batch [109/428], Loss: 0.3223
Epoch [5/10], Batch [110/428], Loss: 3.0037
Epoch [5/10], Batch [111/428], Loss: 0.4057
Epoch [5/10], Batch [112/428], Loss: 3.1590
Epoch [5/10], Batch [113/428], Loss: 3.0463
Epoch [5/10], Batch [114/428], Loss: 2.9526
Epoch [5/10], Batch [115/428], Loss: 2.3561
Epoch [5/10], Batch [116/428], Loss: 2.2340
Epoch [5/10], Batch [117/428], Loss: 2.1393
Epoch [5/10], Batch [118/428], Loss: 0.0010
Epoch [5/10], Batch [119/428], Loss: 1.8873
Epoch [5/10], Batch [120/428], Loss: 1.9269
Epoch [5/10], Batch [121/428], Loss: 2.9023
Epoch [5/10], Batch [122/428], Loss: 0.0030
Epoch [5/10], Batch [123/428], Loss: 0.0008
Epoch [5/10], Batch [124/428], Loss: 1.6849
Epoch [5/10], Batch [125/428], Loss: 1.5639
Epoch [5/10], Batch [126/428], Loss: 6.3711
Epoch [5/10], Batch [127/428], Loss: 6.1906
Epoch [5/10], Batch [128/428], Loss: 2.3839
Epoch [5/10], Batch [129/428], Loss: 1.0437
Epoch [5/10], Batch [130/428], Loss: 1.6999
Epoch [5/10], Batch [131/428], Loss: 0.0029
Epoch [5/10], Batch [132/428], Loss: 0.0124
Epoch [5/10], Batch [133/428], Loss: 2.8422
Epoch [5/10], Batch [134/428], Loss: 3.9307
Epoch [5/10], Batch [135/428], Loss: 3.4087
Epoch [5/10], Batch [136/428], Loss: 3.6777
Epoch [5/10], Batch [137/428], Loss: 2.7126
Epoch [5/10], Batch [138/428], Loss: 0.0176
Epoch [5/10], Batch [139/428], Loss: 2.8758
Epoch [5/10], Batch [140/428], Loss: 0.9987
Epoch [5/10], Batch [141/428], Loss: 0.0046
Epoch [5/10], Batch [142/428], Loss: 2.2750
Epoch [5/10], Batch [143/428], Loss: 2.7379
Epoch [5/10], Batch [144/428], Loss: 0.0040
Epoch [5/10], Batch [145/428], Loss: 5.5640
Epoch [5/10], Batch [146/428], Loss: 0.0045
Epoch [5/10], Batch [147/428], Loss: 2.3736
Epoch [5/10], Batch [148/428], Loss: 2.6068
Epoch [5/10], Batch [149/428], Loss: 2.3349
Epoch [5/10], Batch [150/428], Loss: 1.4661
Epoch [5/10], Batch [151/428], Loss: 2.1523
Epoch [5/10], Batch [152/428], Loss: 2.0785
Epoch [5/10], Batch [153/428], Loss: 1.5856
Epoch [5/10], Batch [154/428], Loss: 1.5634
Epoch [5/10], Batch [155/428], Loss: 2.0258
Epoch [5/10], Batch [156/428], Loss: 1.8832
Epoch [5/10], Batch [157/428], Loss: 0.0243
Epoch [5/10], Batch [158/428], Loss: 0.0096
Epoch [5/10], Batch [159/428], Loss: 2.6495
Epoch [5/10], Batch [160/428], Loss: 2.5494
Epoch [5/10], Batch [161/428], Loss: 1.9484
Epoch [5/10], Batch [162/428], Loss: 0.0057
Epoch [5/10], Batch [163/428], Loss: 1.9622
Epoch [5/10], Batch [164/428], Loss: 1.4970
Epoch [5/10], Batch [165/428], Loss: 1.5712
Epoch [5/10], Batch [166/428], Loss: 1.5040
Epoch [5/10], Batch [167/428], Loss: 2.9160
Epoch [5/10], Batch [168/428], Loss: 0.0030
Epoch [5/10], Batch [169/428], Loss: 1.3371
Epoch [5/10], Batch [170/428], Loss: 2.9179
Epoch [5/10], Batch [171/428], Loss: 0.0020
Epoch [5/10], Batch [172/428], Loss: 6.4476
Epoch [5/10], Batch [173/428], Loss: 1.1020
Epoch [5/10], Batch [174/428], Loss: 6.0493
Epoch [5/10], Batch [175/428], Loss: 0.0037
Epoch [5/10], Batch [176/428], Loss: 2.0894
Epoch [5/10], Batch [177/428], Loss: 3.0188
Epoch [5/10], Batch [178/428], Loss: 2.5428
Epoch [5/10], Batch [179/428], Loss: 1.9764
Epoch [5/10], Batch [180/428], Loss: 0.0122
Epoch [5/10], Batch [181/428], Loss: 2.4612
Epoch [5/10], Batch [182/428], Loss: 0.9063
Epoch [5/10], Batch [183/428], Loss: 0.0152
Epoch [5/10], Batch [184/428], Loss: 3.3260
Epoch [5/10], Batch [185/428], Loss: 2.2471
Epoch [5/10], Batch [186/428], Loss: 3.0587
Epoch [5/10], Batch [187/428], Loss: 0.0091
Epoch [5/10], Batch [188/428], Loss: 2.3270
Epoch [5/10], Batch [189/428], Loss: 4.4693
Epoch [5/10], Batch [190/428], Loss: 4.4258
Epoch [5/10], Batch [191/428], Loss: 1.1340
Epoch [5/10], Batch [192/428], Loss: 1.1747
Epoch [5/10], Batch [193/428], Loss: 2.3763
Epoch [5/10], Batch [194/428], Loss: 1.8134
Epoch [5/10], Batch [195/428], Loss: 2.8850
Epoch [5/10], Batch [196/428], Loss: 2.1844
Epoch [5/10], Batch [197/428], Loss: 1.9575
Epoch [5/10], Batch [198/428], Loss: 0.0117
Epoch [5/10], Batch [199/428], Loss: 2.6957
Epoch [5/10], Batch [200/428], Loss: 1.2340
Epoch [5/10], Batch [201/428], Loss: 2.6288
Epoch [5/10], Batch [202/428], Loss: 2.4259
Epoch [5/10], Batch [203/428], Loss: 1.9420
Epoch [5/10], Batch [204/428], Loss: 2.6387
Epoch [5/10], Batch [205/428], Loss: 4.8190
Epoch [5/10], Batch [206/428], Loss: 1.8640
Epoch [5/10], Batch [207/428], Loss: 2.5819
Epoch [5/10], Batch [208/428], Loss: 0.0167
Epoch [5/10], Batch [209/428], Loss: 1.8315
Epoch [5/10], Batch [210/428], Loss: 0.0332
Epoch [5/10], Batch [211/428], Loss: 1.7100
Epoch [5/10], Batch [212/428], Loss: 1.5396
Epoch [5/10], Batch [213/428], Loss: 1.9225
Epoch [5/10], Batch [214/428], Loss: 1.6514
Epoch [5/10], Batch [215/428], Loss: 1.9118
Epoch [5/10], Batch [216/428], Loss: 2.5223
Epoch [5/10], Batch [217/428], Loss: 3.2510
Epoch [5/10], Batch [218/428], Loss: 2.3373
Epoch [5/10], Batch [219/428], Loss: 0.0190
Epoch [5/10], Batch [220/428], Loss: 1.9640
Epoch [5/10], Batch [221/428], Loss: 1.8457
Epoch [5/10], Batch [222/428], Loss: 0.0119
Epoch [5/10], Batch [223/428], Loss: 0.0085
Epoch [5/10], Batch [224/428], Loss: 2.0100
Epoch [5/10], Batch [225/428], Loss: 0.0041
Epoch [5/10], Batch [226/428], Loss: 2.8821
Epoch [5/10], Batch [227/428], Loss: 0.0022
Epoch [5/10], Batch [228/428], Loss: 1.5872
Epoch [5/10], Batch [229/428], Loss: 0.0012
Epoch [5/10], Batch [230/428], Loss: 1.5083
Epoch [5/10], Batch [231/428], Loss: 1.3801
Epoch [5/10], Batch [232/428], Loss: 0.0005
Epoch [5/10], Batch [233/428], Loss: 2.2359
Epoch [5/10], Batch [234/428], Loss: 2.1979
Epoch [5/10], Batch [235/428], Loss: 1.8452
Epoch [5/10], Batch [236/428], Loss: 2.4297
Epoch [5/10], Batch [237/428], Loss: 0.0003
Epoch [5/10], Batch [238/428], Loss: 2.0244
Epoch [5/10], Batch [239/428], Loss: 8.8697
Epoch [5/10], Batch [240/428], Loss: 1.8883
Epoch [5/10], Batch [241/428], Loss: 3.0219
Epoch [5/10], Batch [242/428], Loss: 1.8042
Epoch [5/10], Batch [243/428], Loss: 0.0005
Epoch [5/10], Batch [244/428], Loss: 2.6466
Epoch [5/10], Batch [245/428], Loss: 1.2429
Epoch [5/10], Batch [246/428], Loss: 1.3000
Epoch [5/10], Batch [247/428], Loss: 2.7059
Epoch [5/10], Batch [248/428], Loss: 0.0010
Epoch [5/10], Batch [249/428], Loss: 1.2437
Epoch [5/10], Batch [250/428], Loss: 2.4767
Epoch [5/10], Batch [251/428], Loss: 1.1603
Epoch [5/10], Batch [252/428], Loss: 1.5043
Epoch [5/10], Batch [253/428], Loss: 0.0014
Epoch [5/10], Batch [254/428], Loss: 2.0159
Epoch [5/10], Batch [255/428], Loss: 6.7677
Epoch [5/10], Batch [256/428], Loss: 2.1251
Epoch [5/10], Batch [257/428], Loss: 2.0126
Epoch [5/10], Batch [258/428], Loss: 0.0030
Epoch [5/10], Batch [259/428], Loss: 5.7768
Epoch [5/10], Batch [260/428], Loss: 5.3087
Epoch [5/10], Batch [261/428], Loss: 1.7839
Epoch [5/10], Batch [262/428], Loss: 2.7790
Epoch [5/10], Batch [263/428], Loss: 1.7126
Epoch [5/10], Batch [264/428], Loss: 1.2978
Epoch [5/10], Batch [265/428], Loss: 1.9657
Epoch [5/10], Batch [266/428], Loss: 0.1277
Epoch [5/10], Batch [267/428], Loss: 1.4642
Epoch [5/10], Batch [268/428], Loss: 2.4420
Epoch [5/10], Batch [269/428], Loss: 1.9421
Epoch [5/10], Batch [270/428], Loss: 1.2434
Epoch [5/10], Batch [271/428], Loss: 1.5514
Epoch [5/10], Batch [272/428], Loss: 0.2053
Epoch [5/10], Batch [273/428], Loss: 2.4630
Epoch [5/10], Batch [274/428], Loss: 1.6326
Epoch [5/10], Batch [275/428], Loss: 1.7358
Epoch [5/10], Batch [276/428], Loss: 0.1559
Epoch [5/10], Batch [277/428], Loss: 1.1631
Epoch [5/10], Batch [278/428], Loss: 2.2106
Epoch [5/10], Batch [279/428], Loss: 1.9583
Epoch [5/10], Batch [280/428], Loss: 3.2379
Epoch [5/10], Batch [281/428], Loss: 2.4089
Epoch [5/10], Batch [282/428], Loss: 3.2425
Epoch [5/10], Batch [283/428], Loss: 1.5348
Epoch [5/10], Batch [284/428], Loss: 2.9455
Epoch [5/10], Batch [285/428], Loss: 1.8567
Epoch [5/10], Batch [286/428], Loss: 2.7410
Epoch [5/10], Batch [287/428], Loss: 1.3980
Epoch [5/10], Batch [288/428], Loss: 1.8842
Epoch [5/10], Batch [289/428], Loss: 1.3989
Epoch [5/10], Batch [290/428], Loss: 1.3305
Epoch [5/10], Batch [291/428], Loss: 0.2382
Epoch [5/10], Batch [292/428], Loss: 1.1877
Epoch [5/10], Batch [293/428], Loss: 1.9775
Epoch [5/10], Batch [294/428], Loss: 0.2092
Epoch [5/10], Batch [295/428], Loss: 2.4549
Epoch [5/10], Batch [296/428], Loss: 2.0173
Epoch [5/10], Batch [297/428], Loss: 0.1368
Epoch [5/10], Batch [298/428], Loss: 0.8684
Epoch [5/10], Batch [299/428], Loss: 0.0769
Epoch [5/10], Batch [300/428], Loss: 0.8063
Epoch [5/10], Batch [301/428], Loss: 0.6670
Epoch [5/10], Batch [302/428], Loss: 0.0272
Epoch [5/10], Batch [303/428], Loss: 1.8549
Epoch [5/10], Batch [304/428], Loss: 4.5324
Epoch [5/10], Batch [305/428], Loss: 0.0094
Epoch [5/10], Batch [306/428], Loss: 0.3814
Epoch [5/10], Batch [307/428], Loss: 2.0297
Epoch [5/10], Batch [308/428], Loss: 3.5398
Epoch [5/10], Batch [309/428], Loss: 4.1985
Epoch [5/10], Batch [310/428], Loss: 0.3183
Epoch [5/10], Batch [311/428], Loss: 0.0029
Epoch [5/10], Batch [312/428], Loss: 3.5482
Epoch [5/10], Batch [313/428], Loss: 0.0024
Epoch [5/10], Batch [314/428], Loss: 6.5619
Epoch [5/10], Batch [315/428], Loss: 6.4580
Epoch [5/10], Batch [316/428], Loss: 0.0025
Epoch [5/10], Batch [317/428], Loss: 2.0152
Epoch [5/10], Batch [318/428], Loss: 0.0033
Epoch [5/10], Batch [319/428], Loss: 0.2968
Epoch [5/10], Batch [320/428], Loss: 0.2779
Epoch [5/10], Batch [321/428], Loss: 0.0045
Epoch [5/10], Batch [322/428], Loss: 0.0051
Epoch [5/10], Batch [323/428], Loss: 3.4185
Epoch [5/10], Batch [324/428], Loss: 6.9832
Epoch [5/10], Batch [325/428], Loss: 5.3456
Epoch [5/10], Batch [326/428], Loss: 0.2913
Epoch [5/10], Batch [327/428], Loss: 0.0094
Epoch [5/10], Batch [328/428], Loss: 0.2465
Epoch [5/10], Batch [329/428], Loss: 0.0120
Epoch [5/10], Batch [330/428], Loss: 0.0119
Epoch [5/10], Batch [331/428], Loss: 4.7461
Epoch [5/10], Batch [332/428], Loss: 0.1745
Epoch [5/10], Batch [333/428], Loss: 0.1485
Epoch [5/10], Batch [334/428], Loss: 0.0142
Epoch [5/10], Batch [335/428], Loss: 0.0140
Epoch [5/10], Batch [336/428], Loss: 4.6354
Epoch [5/10], Batch [337/428], Loss: 4.0899
Epoch [5/10], Batch [338/428], Loss: 3.4380
Epoch [5/10], Batch [339/428], Loss: 0.0090
Epoch [5/10], Batch [340/428], Loss: 0.0758
Epoch [5/10], Batch [341/428], Loss: 4.7128
Epoch [5/10], Batch [342/428], Loss: 5.3776
Epoch [5/10], Batch [343/428], Loss: 4.3986
Epoch [5/10], Batch [344/428], Loss: 3.4855
Epoch [5/10], Batch [345/428], Loss: 3.3997
Epoch [5/10], Batch [346/428], Loss: 3.2617
Epoch [5/10], Batch [347/428], Loss: 5.0723
Epoch [5/10], Batch [348/428], Loss: 3.3589
Epoch [5/10], Batch [349/428], Loss: 3.0502
Epoch [5/10], Batch [350/428], Loss: 0.0130
Epoch [5/10], Batch [351/428], Loss: 0.0138
Epoch [5/10], Batch [352/428], Loss: 2.4503
Epoch [5/10], Batch [353/428], Loss: 4.4162
Epoch [5/10], Batch [354/428], Loss: 1.7705
Epoch [5/10], Batch [355/428], Loss: 1.8838
Epoch [5/10], Batch [356/428], Loss: 1.5498
Epoch [5/10], Batch [357/428], Loss: 0.9833
Epoch [5/10], Batch [358/428], Loss: 1.3753
Epoch [5/10], Batch [359/428], Loss: 0.0218
Epoch [5/10], Batch [360/428], Loss: 0.0186
Epoch [5/10], Batch [361/428], Loss: 1.0007
Epoch [5/10], Batch [362/428], Loss: 0.9268
Epoch [5/10], Batch [363/428], Loss: 4.4482
Epoch [5/10], Batch [364/428], Loss: 0.7129
Epoch [5/10], Batch [365/428], Loss: 2.8747
Epoch [5/10], Batch [366/428], Loss: 1.6752
Epoch [5/10], Batch [367/428], Loss: 2.3812
Epoch [5/10], Batch [368/428], Loss: 2.4767
Epoch [5/10], Batch [369/428], Loss: 0.4130
Epoch [5/10], Batch [370/428], Loss: 3.5199
Epoch [5/10], Batch [371/428], Loss: 0.0118
Epoch [5/10], Batch [372/428], Loss: 2.4945
Epoch [5/10], Batch [373/428], Loss: 2.3543
Epoch [5/10], Batch [374/428], Loss: 2.0235
Epoch [5/10], Batch [375/428], Loss: 3.0234
Epoch [5/10], Batch [376/428], Loss: 0.0085
Epoch [5/10], Batch [377/428], Loss: 1.8807
Epoch [5/10], Batch [378/428], Loss: 0.0073
Epoch [5/10], Batch [379/428], Loss: 0.0059
Epoch [5/10], Batch [380/428], Loss: 0.0047
Epoch [5/10], Batch [381/428], Loss: 1.7990
Epoch [5/10], Batch [382/428], Loss: 0.0032
Epoch [5/10], Batch [383/428], Loss: 8.7872
Epoch [5/10], Batch [384/428], Loss: 0.0026
Epoch [5/10], Batch [385/428], Loss: 1.3859
Epoch [5/10], Batch [386/428], Loss: 0.0025
Epoch [5/10], Batch [387/428], Loss: 1.4831
Epoch [5/10], Batch [388/428], Loss: 1.4062
Epoch [5/10], Batch [389/428], Loss: 0.0022
Epoch [5/10], Batch [390/428], Loss: 1.1749
Epoch [5/10], Batch [391/428], Loss: 0.0021
Epoch [5/10], Batch [392/428], Loss: 1.7289
Epoch [5/10], Batch [393/428], Loss: 1.3757
Epoch [5/10], Batch [394/428], Loss: 1.8449
Epoch [5/10], Batch [395/428], Loss: 0.7990
Epoch [5/10], Batch [396/428], Loss: 1.8307
Epoch [5/10], Batch [397/428], Loss: 6.8996
Epoch [5/10], Batch [398/428], Loss: 1.7935
Epoch [5/10], Batch [399/428], Loss: 1.6842
Epoch [5/10], Batch [400/428], Loss: 1.6996
Epoch [5/10], Batch [401/428], Loss: 0.8396
Epoch [5/10], Batch [402/428], Loss: 2.8047
Epoch [5/10], Batch [403/428], Loss: 1.6171
Epoch [5/10], Batch [404/428], Loss: 0.0038
Epoch [5/10], Batch [405/428], Loss: 1.5282
Epoch [5/10], Batch [406/428], Loss: 6.0378
Epoch [5/10], Batch [407/428], Loss: 3.5259
Epoch [5/10], Batch [408/428], Loss: 4.6452
Epoch [5/10], Batch [409/428], Loss: 0.0070
Epoch [5/10], Batch [410/428], Loss: 1.2842
Epoch [5/10], Batch [411/428], Loss: 5.4495
Epoch [5/10], Batch [412/428], Loss: 1.2882
Epoch [5/10], Batch [413/428], Loss: 7.8629
Epoch [5/10], Batch [414/428], Loss: 0.9952
Epoch [5/10], Batch [415/428], Loss: 0.0208
Epoch [5/10], Batch [416/428], Loss: 2.8099
Epoch [5/10], Batch [417/428], Loss: 1.6991
Epoch [5/10], Batch [418/428], Loss: 4.0880
Epoch [5/10], Batch [419/428], Loss: 1.5779
Epoch [5/10], Batch [420/428], Loss: 2.6248
Epoch [5/10], Batch [421/428], Loss: 4.8176
Epoch [5/10], Batch [422/428], Loss: 4.8926
Epoch [5/10], Batch [423/428], Loss: 0.0438
Epoch [5/10], Batch [424/428], Loss: 0.8249
Epoch [5/10], Batch [425/428], Loss: 0.8468
Epoch [5/10], Batch [426/428], Loss: 4.4204
Epoch [5/10], Batch [427/428], Loss: 0.7755
Epoch [5/10], Batch [428/428], Loss: 0.7199
Epoch [5] Training Time: 158.94 seconds
Epoch [5/10], Average Loss: 1.9382, Training Accuracy: 0.3972
Epoch [5], Validation Loss: 2.2797, Validation Accuracy: 0.2768
Epoch [5] Validation Time: 5.65 seconds
--------------------------------------------------
Epoch [6/10], Batch [1/428], Loss: 0.0694
Epoch [6/10], Batch [2/428], Loss: 3.7606
Epoch [6/10], Batch [3/428], Loss: 3.5042
Epoch [6/10], Batch [4/428], Loss: 0.0904
Epoch [6/10], Batch [5/428], Loss: 2.3049
Epoch [6/10], Batch [6/428], Loss: 4.1981
Epoch [6/10], Batch [7/428], Loss: 2.0609
Epoch [6/10], Batch [8/428], Loss: 2.9231
Epoch [6/10], Batch [9/428], Loss: 2.6027
Epoch [6/10], Batch [10/428], Loss: 0.5087
Epoch [6/10], Batch [11/428], Loss: 0.2660
Epoch [6/10], Batch [12/428], Loss: 2.7325
Epoch [6/10], Batch [13/428], Loss: 0.3475
Epoch [6/10], Batch [14/428], Loss: 1.7542
Epoch [6/10], Batch [15/428], Loss: 1.8237
Epoch [6/10], Batch [16/428], Loss: 2.5118
Epoch [6/10], Batch [17/428], Loss: 3.4055
Epoch [6/10], Batch [18/428], Loss: 0.5903
Epoch [6/10], Batch [19/428], Loss: 0.3723
Epoch [6/10], Batch [20/428], Loss: 3.5752
Epoch [6/10], Batch [21/428], Loss: 0.3284
Epoch [6/10], Batch [22/428], Loss: 2.2814
Epoch [6/10], Batch [23/428], Loss: 2.1637
Epoch [6/10], Batch [24/428], Loss: 1.5731
Epoch [6/10], Batch [25/428], Loss: 1.8508
Epoch [6/10], Batch [26/428], Loss: 1.7363
Epoch [6/10], Batch [27/428], Loss: 3.2454
Epoch [6/10], Batch [28/428], Loss: 0.3393
Epoch [6/10], Batch [29/428], Loss: 4.3930
Epoch [6/10], Batch [30/428], Loss: 1.3127
Epoch [6/10], Batch [31/428], Loss: 0.4292
Epoch [6/10], Batch [32/428], Loss: 4.5576
Epoch [6/10], Batch [33/428], Loss: 3.5303
Epoch [6/10], Batch [34/428], Loss: 0.4453
Epoch [6/10], Batch [35/428], Loss: 2.6782
Epoch [6/10], Batch [36/428], Loss: 3.2720
Epoch [6/10], Batch [37/428], Loss: 2.6024
Epoch [6/10], Batch [38/428], Loss: 0.4085
Epoch [6/10], Batch [39/428], Loss: 0.3974
Epoch [6/10], Batch [40/428], Loss: 2.5947
Epoch [6/10], Batch [41/428], Loss: 0.2594
Epoch [6/10], Batch [42/428], Loss: 2.1623
Epoch [6/10], Batch [43/428], Loss: 2.0393
Epoch [6/10], Batch [44/428], Loss: 0.1404
Epoch [6/10], Batch [45/428], Loss: 1.7182
Epoch [6/10], Batch [46/428], Loss: 0.0818
Epoch [6/10], Batch [47/428], Loss: 3.6625
Epoch [6/10], Batch [48/428], Loss: 3.6213
Epoch [6/10], Batch [49/428], Loss: 5.9474
Epoch [6/10], Batch [50/428], Loss: 3.4799
Epoch [6/10], Batch [51/428], Loss: 1.4735
Epoch [6/10], Batch [52/428], Loss: 2.7986
Epoch [6/10], Batch [53/428], Loss: 1.0944
Epoch [6/10], Batch [54/428], Loss: 1.6223
Epoch [6/10], Batch [55/428], Loss: 0.0879
Epoch [6/10], Batch [56/428], Loss: 1.6702
Epoch [6/10], Batch [57/428], Loss: 1.6257
Epoch [6/10], Batch [58/428], Loss: 0.0827
Epoch [6/10], Batch [59/428], Loss: 5.2714
Epoch [6/10], Batch [60/428], Loss: 2.9213
Epoch [6/10], Batch [61/428], Loss: 0.9750
Epoch [6/10], Batch [62/428], Loss: 1.4214
Epoch [6/10], Batch [63/428], Loss: 0.0849
Epoch [6/10], Batch [64/428], Loss: 1.3266
Epoch [6/10], Batch [65/428], Loss: 2.4976
Epoch [6/10], Batch [66/428], Loss: 1.1305
Epoch [6/10], Batch [67/428], Loss: 2.9124
Epoch [6/10], Batch [68/428], Loss: 0.0822
Epoch [6/10], Batch [69/428], Loss: 1.1388
Epoch [6/10], Batch [70/428], Loss: 5.3410
Epoch [6/10], Batch [71/428], Loss: 0.0808
Epoch [6/10], Batch [72/428], Loss: 1.0936
Epoch [6/10], Batch [73/428], Loss: 0.0677
Epoch [6/10], Batch [74/428], Loss: 3.3822
Epoch [6/10], Batch [75/428], Loss: 0.0525
Epoch [6/10], Batch [76/428], Loss: 0.0423
Epoch [6/10], Batch [77/428], Loss: 2.1420
Epoch [6/10], Batch [78/428], Loss: 0.0216
Epoch [6/10], Batch [79/428], Loss: 3.6571
Epoch [6/10], Batch [80/428], Loss: 2.0427
Epoch [6/10], Batch [81/428], Loss: 7.4938
Epoch [6/10], Batch [82/428], Loss: 1.8326
Epoch [6/10], Batch [83/428], Loss: 1.7863
Epoch [6/10], Batch [84/428], Loss: 1.6703
Epoch [6/10], Batch [85/428], Loss: 2.8852
Epoch [6/10], Batch [86/428], Loss: 1.1592
Epoch [6/10], Batch [87/428], Loss: 0.0044
Epoch [6/10], Batch [88/428], Loss: 0.0040
Epoch [6/10], Batch [89/428], Loss: 2.7556
Epoch [6/10], Batch [90/428], Loss: 0.9863
Epoch [6/10], Batch [91/428], Loss: 1.2811
Epoch [6/10], Batch [92/428], Loss: 1.3154
Epoch [6/10], Batch [93/428], Loss: 1.9270
Epoch [6/10], Batch [94/428], Loss: 1.8856
Epoch [6/10], Batch [95/428], Loss: 7.2914
Epoch [6/10], Batch [96/428], Loss: 0.8274
Epoch [6/10], Batch [97/428], Loss: 3.3830
Epoch [6/10], Batch [98/428], Loss: 0.0033
Epoch [6/10], Batch [99/428], Loss: 0.0033
Epoch [6/10], Batch [100/428], Loss: 0.0039
Epoch [6/10], Batch [101/428], Loss: 6.8857
Epoch [6/10], Batch [102/428], Loss: 1.9809
Epoch [6/10], Batch [103/428], Loss: 1.9518
Epoch [6/10], Batch [104/428], Loss: 1.3837
Epoch [6/10], Batch [105/428], Loss: 3.1022
Epoch [6/10], Batch [106/428], Loss: 0.0054
Epoch [6/10], Batch [107/428], Loss: 1.7223
Epoch [6/10], Batch [108/428], Loss: 6.3118
Epoch [6/10], Batch [109/428], Loss: 0.0066
Epoch [6/10], Batch [110/428], Loss: 1.3676
Epoch [6/10], Batch [111/428], Loss: 6.0551
Epoch [6/10], Batch [112/428], Loss: 0.0090
Epoch [6/10], Batch [113/428], Loss: 1.3748
Epoch [6/10], Batch [114/428], Loss: 1.2421
Epoch [6/10], Batch [115/428], Loss: 1.4899
Epoch [6/10], Batch [116/428], Loss: 0.0126
Epoch [6/10], Batch [117/428], Loss: 1.1907
Epoch [6/10], Batch [118/428], Loss: 5.3042
Epoch [6/10], Batch [119/428], Loss: 2.5485
Epoch [6/10], Batch [120/428], Loss: 2.7255
Epoch [6/10], Batch [121/428], Loss: 2.5347
Epoch [6/10], Batch [122/428], Loss: 1.7466
Epoch [6/10], Batch [123/428], Loss: 2.4551
Epoch [6/10], Batch [124/428], Loss: 0.0202
Epoch [6/10], Batch [125/428], Loss: 0.0187
Epoch [6/10], Batch [126/428], Loss: 2.0836
Epoch [6/10], Batch [127/428], Loss: 1.4811
Epoch [6/10], Batch [128/428], Loss: 0.0138
Epoch [6/10], Batch [129/428], Loss: 5.8448
Epoch [6/10], Batch [130/428], Loss: 2.4207
Epoch [6/10], Batch [131/428], Loss: 7.5667
Epoch [6/10], Batch [132/428], Loss: 2.2620
Epoch [6/10], Batch [133/428], Loss: 0.0140
Epoch [6/10], Batch [134/428], Loss: 1.3014
Epoch [6/10], Batch [135/428], Loss: 1.7137
Epoch [6/10], Batch [136/428], Loss: 1.3452
Epoch [6/10], Batch [137/428], Loss: 1.5899
Epoch [6/10], Batch [138/428], Loss: 1.6058
Epoch [6/10], Batch [139/428], Loss: 5.0497
Epoch [6/10], Batch [140/428], Loss: 4.9742
Epoch [6/10], Batch [141/428], Loss: 4.8339
Epoch [6/10], Batch [142/428], Loss: 2.1680
Epoch [6/10], Batch [143/428], Loss: 1.3634
Epoch [6/10], Batch [144/428], Loss: 2.2330
Epoch [6/10], Batch [145/428], Loss: 1.7529
Epoch [6/10], Batch [146/428], Loss: 4.5275
Epoch [6/10], Batch [147/428], Loss: 1.2831
Epoch [6/10], Batch [148/428], Loss: 2.0636
Epoch [6/10], Batch [149/428], Loss: 1.6750
Epoch [6/10], Batch [150/428], Loss: 1.6406
Epoch [6/10], Batch [151/428], Loss: 3.8350
Epoch [6/10], Batch [152/428], Loss: 1.5214
Epoch [6/10], Batch [153/428], Loss: 1.3231
Epoch [6/10], Batch [154/428], Loss: 1.3163
Epoch [6/10], Batch [155/428], Loss: 1.3245
Epoch [6/10], Batch [156/428], Loss: 1.2956
Epoch [6/10], Batch [157/428], Loss: 1.3303
Epoch [6/10], Batch [158/428], Loss: 0.1180
Epoch [6/10], Batch [159/428], Loss: 1.9876
Epoch [6/10], Batch [160/428], Loss: 1.9432
Epoch [6/10], Batch [161/428], Loss: 1.9313
Epoch [6/10], Batch [162/428], Loss: 0.0981
Epoch [6/10], Batch [163/428], Loss: 0.0928
Epoch [6/10], Batch [164/428], Loss: 0.0742
Epoch [6/10], Batch [165/428], Loss: 0.0524
Epoch [6/10], Batch [166/428], Loss: 0.9818
Epoch [6/10], Batch [167/428], Loss: 2.7736
Epoch [6/10], Batch [168/428], Loss: 4.2765
Epoch [6/10], Batch [169/428], Loss: 0.0169
Epoch [6/10], Batch [170/428], Loss: 3.1346
Epoch [6/10], Batch [171/428], Loss: 0.0112
Epoch [6/10], Batch [172/428], Loss: 0.0090
Epoch [6/10], Batch [173/428], Loss: 0.0068
Epoch [6/10], Batch [174/428], Loss: 2.7230
Epoch [6/10], Batch [175/428], Loss: 1.3985
Epoch [6/10], Batch [176/428], Loss: 1.0775
Epoch [6/10], Batch [177/428], Loss: 0.0030
Epoch [6/10], Batch [178/428], Loss: 0.0028
Epoch [6/10], Batch [179/428], Loss: 1.4647
Epoch [6/10], Batch [180/428], Loss: 7.9537
Epoch [6/10], Batch [181/428], Loss: 1.4726
Epoch [6/10], Batch [182/428], Loss: 0.0018
Epoch [6/10], Batch [183/428], Loss: 0.0018
Epoch [6/10], Batch [184/428], Loss: 1.2731
Epoch [6/10], Batch [185/428], Loss: 0.0017
Epoch [6/10], Batch [186/428], Loss: 9.6754
Epoch [6/10], Batch [187/428], Loss: 7.4845
Epoch [6/10], Batch [188/428], Loss: 7.1867
Epoch [6/10], Batch [189/428], Loss: 2.2301
Epoch [6/10], Batch [190/428], Loss: 8.3998
Epoch [6/10], Batch [191/428], Loss: 0.0055
Epoch [6/10], Batch [192/428], Loss: 1.0967
Epoch [6/10], Batch [193/428], Loss: 1.5334
Epoch [6/10], Batch [194/428], Loss: 0.0131
Epoch [6/10], Batch [195/428], Loss: 0.0148
Epoch [6/10], Batch [196/428], Loss: 6.7336
Epoch [6/10], Batch [197/428], Loss: 0.9460
Epoch [6/10], Batch [198/428], Loss: 1.5553
Epoch [6/10], Batch [199/428], Loss: 1.9819
Epoch [6/10], Batch [200/428], Loss: 1.4678
Epoch [6/10], Batch [201/428], Loss: 0.9624
Epoch [6/10], Batch [202/428], Loss: 1.4767
Epoch [6/10], Batch [203/428], Loss: 0.0353
Epoch [6/10], Batch [204/428], Loss: 1.3612
Epoch [6/10], Batch [205/428], Loss: 1.9409
Epoch [6/10], Batch [206/428], Loss: 5.6455
Epoch [6/10], Batch [207/428], Loss: 3.9670
Epoch [6/10], Batch [208/428], Loss: 1.0754
Epoch [6/10], Batch [209/428], Loss: 3.7015
Epoch [6/10], Batch [210/428], Loss: 0.0589
Epoch [6/10], Batch [211/428], Loss: 1.0857
Epoch [6/10], Batch [212/428], Loss: 5.3827
Epoch [6/10], Batch [213/428], Loss: 1.0333
Epoch [6/10], Batch [214/428], Loss: 0.0925
Epoch [6/10], Batch [215/428], Loss: 0.0899
Epoch [6/10], Batch [216/428], Loss: 2.6858
Epoch [6/10], Batch [217/428], Loss: 0.0709
Epoch [6/10], Batch [218/428], Loss: 5.3217
Epoch [6/10], Batch [219/428], Loss: 3.3462
Epoch [6/10], Batch [220/428], Loss: 5.3949
Epoch [6/10], Batch [221/428], Loss: 2.1181
Epoch [6/10], Batch [222/428], Loss: 1.0354
Epoch [6/10], Batch [223/428], Loss: 0.9760
Epoch [6/10], Batch [224/428], Loss: 1.0024
Epoch [6/10], Batch [225/428], Loss: 5.0274
Epoch [6/10], Batch [226/428], Loss: 0.9694
Epoch [6/10], Batch [227/428], Loss: 0.0397
Epoch [6/10], Batch [228/428], Loss: 2.5822
Epoch [6/10], Batch [229/428], Loss: 2.1000
Epoch [6/10], Batch [230/428], Loss: 3.1683
Epoch [6/10], Batch [231/428], Loss: 0.0332
Epoch [6/10], Batch [232/428], Loss: 0.0287
Epoch [6/10], Batch [233/428], Loss: 1.4131
Epoch [6/10], Batch [234/428], Loss: 4.8038
Epoch [6/10], Batch [235/428], Loss: 2.3880
Epoch [6/10], Batch [236/428], Loss: 2.0600
Epoch [6/10], Batch [237/428], Loss: 4.8079
Epoch [6/10], Batch [238/428], Loss: 1.4048
Epoch [6/10], Batch [239/428], Loss: 1.9499
Epoch [6/10], Batch [240/428], Loss: 0.0177
Epoch [6/10], Batch [241/428], Loss: 1.3918
Epoch [6/10], Batch [242/428], Loss: 0.0148
Epoch [6/10], Batch [243/428], Loss: 2.7071
Epoch [6/10], Batch [244/428], Loss: 2.0967
Epoch [6/10], Batch [245/428], Loss: 4.7715
Epoch [6/10], Batch [246/428], Loss: 3.0546
Epoch [6/10], Batch [247/428], Loss: 0.0134
Epoch [6/10], Batch [248/428], Loss: 4.5855
Epoch [6/10], Batch [249/428], Loss: 2.4741
Epoch [6/10], Batch [250/428], Loss: 0.0150
Epoch [6/10], Batch [251/428], Loss: 2.3427
Epoch [6/10], Batch [252/428], Loss: 1.1390
Epoch [6/10], Batch [253/428], Loss: 0.0153
Epoch [6/10], Batch [254/428], Loss: 1.0932
Epoch [6/10], Batch [255/428], Loss: 1.9031
Epoch [6/10], Batch [256/428], Loss: 1.0316
Epoch [6/10], Batch [257/428], Loss: 0.0134
Epoch [6/10], Batch [258/428], Loss: 4.5553
Epoch [6/10], Batch [259/428], Loss: 0.8893
Epoch [6/10], Batch [260/428], Loss: 0.8412
Epoch [6/10], Batch [261/428], Loss: 0.7293
Epoch [6/10], Batch [262/428], Loss: 2.2591
Epoch [6/10], Batch [263/428], Loss: 2.3226
Epoch [6/10], Batch [264/428], Loss: 0.0129
Epoch [6/10], Batch [265/428], Loss: 0.4701
Epoch [6/10], Batch [266/428], Loss: 4.5871
Epoch [6/10], Batch [267/428], Loss: 0.0125
Epoch [6/10], Batch [268/428], Loss: 2.7132
Epoch [6/10], Batch [269/428], Loss: 2.7205
Epoch [6/10], Batch [270/428], Loss: 0.0129
Epoch [6/10], Batch [271/428], Loss: 2.8254
Epoch [6/10], Batch [272/428], Loss: 2.7511
Epoch [6/10], Batch [273/428], Loss: 0.0106
Epoch [6/10], Batch [274/428], Loss: 4.7259
Epoch [6/10], Batch [275/428], Loss: 0.3554
Epoch [6/10], Batch [276/428], Loss: 4.6546
Epoch [6/10], Batch [277/428], Loss: 2.6234
Epoch [6/10], Batch [278/428], Loss: 0.3624
Epoch [6/10], Batch [279/428], Loss: 0.0152
Epoch [6/10], Batch [280/428], Loss: 2.4830
Epoch [6/10], Batch [281/428], Loss: 2.7493
Epoch [6/10], Batch [282/428], Loss: 2.6759
Epoch [6/10], Batch [283/428], Loss: 2.5374
Epoch [6/10], Batch [284/428], Loss: 2.4376
Epoch [6/10], Batch [285/428], Loss: 2.5531
Epoch [6/10], Batch [286/428], Loss: 2.1813
Epoch [6/10], Batch [287/428], Loss: 0.5638
Epoch [6/10], Batch [288/428], Loss: 2.3491
Epoch [6/10], Batch [289/428], Loss: 2.7176
Epoch [6/10], Batch [290/428], Loss: 2.1222
Epoch [6/10], Batch [291/428], Loss: 0.0265
Epoch [6/10], Batch [292/428], Loss: 3.7248
Epoch [6/10], Batch [293/428], Loss: 1.7982
Epoch [6/10], Batch [294/428], Loss: 1.4723
Epoch [6/10], Batch [295/428], Loss: 4.6037
Epoch [6/10], Batch [296/428], Loss: 2.4262
Epoch [6/10], Batch [297/428], Loss: 1.3513
Epoch [6/10], Batch [298/428], Loss: 0.0281
Epoch [6/10], Batch [299/428], Loss: 2.8515
Epoch [6/10], Batch [300/428], Loss: 1.1587
Epoch [6/10], Batch [301/428], Loss: 1.3743
Epoch [6/10], Batch [302/428], Loss: 2.2250
Epoch [6/10], Batch [303/428], Loss: 1.3083
Epoch [6/10], Batch [304/428], Loss: 1.2800
Epoch [6/10], Batch [305/428], Loss: 2.2271
Epoch [6/10], Batch [306/428], Loss: 2.3386
Epoch [6/10], Batch [307/428], Loss: 2.0753
Epoch [6/10], Batch [308/428], Loss: 0.0159
Epoch [6/10], Batch [309/428], Loss: 0.0136
Epoch [6/10], Batch [310/428], Loss: 2.4801
Epoch [6/10], Batch [311/428], Loss: 4.0739
Epoch [6/10], Batch [312/428], Loss: 1.2856
Epoch [6/10], Batch [313/428], Loss: 3.9552
Epoch [6/10], Batch [314/428], Loss: 2.3973
Epoch [6/10], Batch [315/428], Loss: 1.1460
Epoch [6/10], Batch [316/428], Loss: 0.0062
Epoch [6/10], Batch [317/428], Loss: 1.4162
Epoch [6/10], Batch [318/428], Loss: 2.4133
Epoch [6/10], Batch [319/428], Loss: 0.0056
Epoch [6/10], Batch [320/428], Loss: 1.7076
Epoch [6/10], Batch [321/428], Loss: 1.6044
Epoch [6/10], Batch [322/428], Loss: 0.0046
Epoch [6/10], Batch [323/428], Loss: 2.2310
Epoch [6/10], Batch [324/428], Loss: 2.8083
Epoch [6/10], Batch [325/428], Loss: 1.4139
Epoch [6/10], Batch [326/428], Loss: 0.0037
Epoch [6/10], Batch [327/428], Loss: 0.0034
Epoch [6/10], Batch [328/428], Loss: 1.4115
Epoch [6/10], Batch [329/428], Loss: 5.9152
Epoch [6/10], Batch [330/428], Loss: 1.3109
Epoch [6/10], Batch [331/428], Loss: 1.3440
Epoch [6/10], Batch [332/428], Loss: 0.0035
Epoch [6/10], Batch [333/428], Loss: 1.1959
Epoch [6/10], Batch [334/428], Loss: 1.0961
Epoch [6/10], Batch [335/428], Loss: 5.6612
Epoch [6/10], Batch [336/428], Loss: 0.9073
Epoch [6/10], Batch [337/428], Loss: 0.8075
Epoch [6/10], Batch [338/428], Loss: 2.3691
Epoch [6/10], Batch [339/428], Loss: 0.0054
Epoch [6/10], Batch [340/428], Loss: 1.6825
Epoch [6/10], Batch [341/428], Loss: 0.5327
Epoch [6/10], Batch [342/428], Loss: 0.4693
Epoch [6/10], Batch [343/428], Loss: 0.0077
Epoch [6/10], Batch [344/428], Loss: 0.0073
Epoch [6/10], Batch [345/428], Loss: 0.3398
Epoch [6/10], Batch [346/428], Loss: 3.0576
Epoch [6/10], Batch [347/428], Loss: 3.1641
Epoch [6/10], Batch [348/428], Loss: 3.0887
Epoch [6/10], Batch [349/428], Loss: 4.3680
Epoch [6/10], Batch [350/428], Loss: 0.0064
Epoch [6/10], Batch [351/428], Loss: 5.2825
Epoch [6/10], Batch [352/428], Loss: 0.0064
Epoch [6/10], Batch [353/428], Loss: 8.8341
Epoch [6/10], Batch [354/428], Loss: 2.8903
Epoch [6/10], Batch [355/428], Loss: 0.2623
Epoch [6/10], Batch [356/428], Loss: 4.9492
Epoch [6/10], Batch [357/428], Loss: 4.0795
Epoch [6/10], Batch [358/428], Loss: 2.6672
Epoch [6/10], Batch [359/428], Loss: 0.0115
Epoch [6/10], Batch [360/428], Loss: 0.3221
Epoch [6/10], Batch [361/428], Loss: 3.6101
Epoch [6/10], Batch [362/428], Loss: 4.5809
Epoch [6/10], Batch [363/428], Loss: 3.4735
Epoch [6/10], Batch [364/428], Loss: 2.4521
Epoch [6/10], Batch [365/428], Loss: 3.7853
Epoch [6/10], Batch [366/428], Loss: 7.1905
Epoch [6/10], Batch [367/428], Loss: 2.3381
Epoch [6/10], Batch [368/428], Loss: 0.0231
Epoch [6/10], Batch [369/428], Loss: 0.0228
Epoch [6/10], Batch [370/428], Loss: 1.3676
Epoch [6/10], Batch [371/428], Loss: 2.2356
Epoch [6/10], Batch [372/428], Loss: 0.0209
Epoch [6/10], Batch [373/428], Loss: 0.6804
Epoch [6/10], Batch [374/428], Loss: 3.3416
Epoch [6/10], Batch [375/428], Loss: 2.0478
Epoch [6/10], Batch [376/428], Loss: 2.3591
Epoch [6/10], Batch [377/428], Loss: 2.6516
Epoch [6/10], Batch [378/428], Loss: 0.0121
Epoch [6/10], Batch [379/428], Loss: 1.9124
Epoch [6/10], Batch [380/428], Loss: 0.0099
Epoch [6/10], Batch [381/428], Loss: 0.0085
Epoch [6/10], Batch [382/428], Loss: 0.0072
Epoch [6/10], Batch [383/428], Loss: 0.0058
Epoch [6/10], Batch [384/428], Loss: 5.5345
Epoch [6/10], Batch [385/428], Loss: 1.6523
Epoch [6/10], Batch [386/428], Loss: 1.9185
Epoch [6/10], Batch [387/428], Loss: 2.4392
Epoch [6/10], Batch [388/428], Loss: 2.0611
Epoch [6/10], Batch [389/428], Loss: 1.8511
Epoch [6/10], Batch [390/428], Loss: 1.7639
Epoch [6/10], Batch [391/428], Loss: 2.0760
Epoch [6/10], Batch [392/428], Loss: 2.8823
Epoch [6/10], Batch [393/428], Loss: 1.9441
Epoch [6/10], Batch [394/428], Loss: 1.6581
Epoch [6/10], Batch [395/428], Loss: 2.2788
Epoch [6/10], Batch [396/428], Loss: 1.5860
Epoch [6/10], Batch [397/428], Loss: 1.5519
Epoch [6/10], Batch [398/428], Loss: 1.4808
Epoch [6/10], Batch [399/428], Loss: 2.0169
Epoch [6/10], Batch [400/428], Loss: 1.7146
Epoch [6/10], Batch [401/428], Loss: 1.6914
Epoch [6/10], Batch [402/428], Loss: 2.2700
Epoch [6/10], Batch [403/428], Loss: 1.9883
Epoch [6/10], Batch [404/428], Loss: 1.6099
Epoch [6/10], Batch [405/428], Loss: 1.6961
Epoch [6/10], Batch [406/428], Loss: 1.6720
Epoch [6/10], Batch [407/428], Loss: 1.4119
Epoch [6/10], Batch [408/428], Loss: 1.0207
Epoch [6/10], Batch [409/428], Loss: 0.0059
Epoch [6/10], Batch [410/428], Loss: 1.5137
Epoch [6/10], Batch [411/428], Loss: 1.6659
Epoch [6/10], Batch [412/428], Loss: 1.8458
Epoch [6/10], Batch [413/428], Loss: 2.5024
Epoch [6/10], Batch [414/428], Loss: 1.4574
Epoch [6/10], Batch [415/428], Loss: 3.0875
Epoch [6/10], Batch [416/428], Loss: 0.6541
Epoch [6/10], Batch [417/428], Loss: 1.4544
Epoch [6/10], Batch [418/428], Loss: 0.3463
Epoch [6/10], Batch [419/428], Loss: 2.0914
Epoch [6/10], Batch [420/428], Loss: 2.9706
Epoch [6/10], Batch [421/428], Loss: 2.8651
Epoch [6/10], Batch [422/428], Loss: 0.0841
Epoch [6/10], Batch [423/428], Loss: 0.0624
Epoch [6/10], Batch [424/428], Loss: 2.0765
Epoch [6/10], Batch [425/428], Loss: 2.4070
Epoch [6/10], Batch [426/428], Loss: 0.0152
Epoch [6/10], Batch [427/428], Loss: 0.0111
Epoch [6/10], Batch [428/428], Loss: 2.3911
Epoch [6] Training Time: 167.85 seconds
Epoch [6/10], Average Loss: 1.9452, Training Accuracy: 0.3575
Epoch [6], Validation Loss: 2.1932, Validation Accuracy: 0.2460
Epoch [6] Validation Time: 5.57 seconds
--------------------------------------------------
Epoch [7/10], Batch [1/428], Loss: 1.9309
Epoch [7/10], Batch [2/428], Loss: 5.8908
Epoch [7/10], Batch [3/428], Loss: 1.8338
Epoch [7/10], Batch [4/428], Loss: 1.5565
Epoch [7/10], Batch [5/428], Loss: 1.4165
Epoch [7/10], Batch [6/428], Loss: 1.4070
Epoch [7/10], Batch [7/428], Loss: 2.5467
Epoch [7/10], Batch [8/428], Loss: 2.4758
Epoch [7/10], Batch [9/428], Loss: 1.3419
Epoch [7/10], Batch [10/428], Loss: 2.2530
Epoch [7/10], Batch [11/428], Loss: 1.6632
Epoch [7/10], Batch [12/428], Loss: 0.0020
Epoch [7/10], Batch [13/428], Loss: 0.0023
Epoch [7/10], Batch [14/428], Loss: 1.7313
Epoch [7/10], Batch [15/428], Loss: 2.8005
Epoch [7/10], Batch [16/428], Loss: 0.0018
Epoch [7/10], Batch [17/428], Loss: 2.7361
Epoch [7/10], Batch [18/428], Loss: 0.0019
Epoch [7/10], Batch [19/428], Loss: 1.5266
Epoch [7/10], Batch [20/428], Loss: 0.0017
Epoch [7/10], Batch [21/428], Loss: 0.0015
Epoch [7/10], Batch [22/428], Loss: 1.7022
Epoch [7/10], Batch [23/428], Loss: 0.0015
Epoch [7/10], Batch [24/428], Loss: 0.0014
Epoch [7/10], Batch [25/428], Loss: 1.6833
Epoch [7/10], Batch [26/428], Loss: 0.0014
Epoch [7/10], Batch [27/428], Loss: 1.4020
Epoch [7/10], Batch [28/428], Loss: 1.5944
Epoch [7/10], Batch [29/428], Loss: 3.2950
Epoch [7/10], Batch [30/428], Loss: 2.3426
Epoch [7/10], Batch [31/428], Loss: 2.2705
Epoch [7/10], Batch [32/428], Loss: 1.4836
Epoch [7/10], Batch [33/428], Loss: 1.3629
Epoch [7/10], Batch [34/428], Loss: 0.0010
Epoch [7/10], Batch [35/428], Loss: 1.3903
Epoch [7/10], Batch [36/428], Loss: 0.0009
Epoch [7/10], Batch [37/428], Loss: 1.3255
Epoch [7/10], Batch [38/428], Loss: 1.9020
Epoch [7/10], Batch [39/428], Loss: 0.0008
Epoch [7/10], Batch [40/428], Loss: 0.0008
Epoch [7/10], Batch [41/428], Loss: 1.9408
Epoch [7/10], Batch [42/428], Loss: 0.0008
Epoch [7/10], Batch [43/428], Loss: 7.4320
Epoch [7/10], Batch [44/428], Loss: 1.2134
Epoch [7/10], Batch [45/428], Loss: 1.2752
Epoch [7/10], Batch [46/428], Loss: 1.2215
Epoch [7/10], Batch [47/428], Loss: 2.4591
Epoch [7/10], Batch [48/428], Loss: 0.0012
Epoch [7/10], Batch [49/428], Loss: 2.3949
Epoch [7/10], Batch [50/428], Loss: 0.0013
Epoch [7/10], Batch [51/428], Loss: 2.2718
Epoch [7/10], Batch [52/428], Loss: 3.5422
Epoch [7/10], Batch [53/428], Loss: 1.0651
Epoch [7/10], Batch [54/428], Loss: 1.3770
Epoch [7/10], Batch [55/428], Loss: 0.0014
Epoch [7/10], Batch [56/428], Loss: 6.7495
Epoch [7/10], Batch [57/428], Loss: 0.0015
Epoch [7/10], Batch [58/428], Loss: 0.0016
Epoch [7/10], Batch [59/428], Loss: 1.4174
Epoch [7/10], Batch [60/428], Loss: 0.0017
Epoch [7/10], Batch [61/428], Loss: 3.0450
Epoch [7/10], Batch [62/428], Loss: 2.9585
Epoch [7/10], Batch [63/428], Loss: 3.1623
Epoch [7/10], Batch [64/428], Loss: 1.9092
Epoch [7/10], Batch [65/428], Loss: 0.0022
Epoch [7/10], Batch [66/428], Loss: 8.9807
Epoch [7/10], Batch [67/428], Loss: 2.6306
Epoch [7/10], Batch [68/428], Loss: 0.0023
Epoch [7/10], Batch [69/428], Loss: 2.3373
Epoch [7/10], Batch [70/428], Loss: 2.3169
Epoch [7/10], Batch [71/428], Loss: 1.8395
Epoch [7/10], Batch [72/428], Loss: 1.8337
Epoch [7/10], Batch [73/428], Loss: 5.2619
Epoch [7/10], Batch [74/428], Loss: 2.2886
Epoch [7/10], Batch [75/428], Loss: 0.0038
Epoch [7/10], Batch [76/428], Loss: 1.6857
Epoch [7/10], Batch [77/428], Loss: 0.0037
Epoch [7/10], Batch [78/428], Loss: 0.0040
Epoch [7/10], Batch [79/428], Loss: 2.0804
Epoch [7/10], Batch [80/428], Loss: 0.0040
Epoch [7/10], Batch [81/428], Loss: 1.4988
Epoch [7/10], Batch [82/428], Loss: 1.6889
Epoch [7/10], Batch [83/428], Loss: 1.4521
Epoch [7/10], Batch [84/428], Loss: 1.6482
Epoch [7/10], Batch [85/428], Loss: 0.0034
Epoch [7/10], Batch [86/428], Loss: 2.0074
Epoch [7/10], Batch [87/428], Loss: 1.2523
Epoch [7/10], Batch [88/428], Loss: 1.9382
Epoch [7/10], Batch [89/428], Loss: 1.9591
Epoch [7/10], Batch [90/428], Loss: 3.0269
Epoch [7/10], Batch [91/428], Loss: 1.5388
Epoch [7/10], Batch [92/428], Loss: 0.0029
Epoch [7/10], Batch [93/428], Loss: 3.0087
Epoch [7/10], Batch [94/428], Loss: 1.4993
Epoch [7/10], Batch [95/428], Loss: 1.5104
Epoch [7/10], Batch [96/428], Loss: 2.2284
Epoch [7/10], Batch [97/428], Loss: 0.0024
Epoch [7/10], Batch [98/428], Loss: 2.9535
Epoch [7/10], Batch [99/428], Loss: 1.3613
Epoch [7/10], Batch [100/428], Loss: 1.8233
Epoch [7/10], Batch [101/428], Loss: 2.2260
Epoch [7/10], Batch [102/428], Loss: 2.2020
Epoch [7/10], Batch [103/428], Loss: 1.3114
Epoch [7/10], Batch [104/428], Loss: 2.3305
Epoch [7/10], Batch [105/428], Loss: 1.8631
Epoch [7/10], Batch [106/428], Loss: 1.3088
Epoch [7/10], Batch [107/428], Loss: 2.8786
Epoch [7/10], Batch [108/428], Loss: 0.0025
Epoch [7/10], Batch [109/428], Loss: 2.0122
Epoch [7/10], Batch [110/428], Loss: 1.2262
Epoch [7/10], Batch [111/428], Loss: 0.0020
Epoch [7/10], Batch [112/428], Loss: 0.0022
Epoch [7/10], Batch [113/428], Loss: 1.7867
Epoch [7/10], Batch [114/428], Loss: 1.2134
Epoch [7/10], Batch [115/428], Loss: 2.4258
Epoch [7/10], Batch [116/428], Loss: 0.0018
Epoch [7/10], Batch [117/428], Loss: 1.7276
Epoch [7/10], Batch [118/428], Loss: 1.0832
Epoch [7/10], Batch [119/428], Loss: 0.0017
Epoch [7/10], Batch [120/428], Loss: 2.2351
Epoch [7/10], Batch [121/428], Loss: 1.0259
Epoch [7/10], Batch [122/428], Loss: 2.2832
Epoch [7/10], Batch [123/428], Loss: 0.0015
Epoch [7/10], Batch [124/428], Loss: 1.6969
Epoch [7/10], Batch [125/428], Loss: 2.4209
Epoch [7/10], Batch [126/428], Loss: 2.2172
Epoch [7/10], Batch [127/428], Loss: 2.1765
Epoch [7/10], Batch [128/428], Loss: 2.3872
Epoch [7/10], Batch [129/428], Loss: 2.2860
Epoch [7/10], Batch [130/428], Loss: 1.6294
Epoch [7/10], Batch [131/428], Loss: 2.2049
Epoch [7/10], Batch [132/428], Loss: 2.0858
Epoch [7/10], Batch [133/428], Loss: 3.2458
Epoch [7/10], Batch [134/428], Loss: 0.0013
Epoch [7/10], Batch [135/428], Loss: 1.5490
Epoch [7/10], Batch [136/428], Loss: 0.0012
Epoch [7/10], Batch [137/428], Loss: 1.5501
Epoch [7/10], Batch [138/428], Loss: 0.0013
Epoch [7/10], Batch [139/428], Loss: 7.0613
Epoch [7/10], Batch [140/428], Loss: 0.0013
Epoch [7/10], Batch [141/428], Loss: 0.0016
Epoch [7/10], Batch [142/428], Loss: 1.3075
Epoch [7/10], Batch [143/428], Loss: 1.4789
Epoch [7/10], Batch [144/428], Loss: 1.9020
Epoch [7/10], Batch [145/428], Loss: 6.5577
Epoch [7/10], Batch [146/428], Loss: 2.7060
Epoch [7/10], Batch [147/428], Loss: 2.6511
Epoch [7/10], Batch [148/428], Loss: 1.3837
Epoch [7/10], Batch [149/428], Loss: 1.3578
Epoch [7/10], Batch [150/428], Loss: 0.0036
Epoch [7/10], Batch [151/428], Loss: 0.0037
Epoch [7/10], Batch [152/428], Loss: 1.2460
Epoch [7/10], Batch [153/428], Loss: 3.1398
Epoch [7/10], Batch [154/428], Loss: 2.4627
Epoch [7/10], Batch [155/428], Loss: 3.8012
Epoch [7/10], Batch [156/428], Loss: 2.9717
Epoch [7/10], Batch [157/428], Loss: 0.0048
Epoch [7/10], Batch [158/428], Loss: 2.3914
Epoch [7/10], Batch [159/428], Loss: 5.4294
Epoch [7/10], Batch [160/428], Loss: 0.0056
Epoch [7/10], Batch [161/428], Loss: 2.3186
Epoch [7/10], Batch [162/428], Loss: 2.2246
Epoch [7/10], Batch [163/428], Loss: 0.0063
Epoch [7/10], Batch [164/428], Loss: 0.0066
Epoch [7/10], Batch [165/428], Loss: 1.0883
Epoch [7/10], Batch [166/428], Loss: 2.2607
Epoch [7/10], Batch [167/428], Loss: 2.1702
Epoch [7/10], Batch [168/428], Loss: 1.0577
Epoch [7/10], Batch [169/428], Loss: 1.0755
Epoch [7/10], Batch [170/428], Loss: 1.8728
Epoch [7/10], Batch [171/428], Loss: 2.1739
Epoch [7/10], Batch [172/428], Loss: 2.1372
Epoch [7/10], Batch [173/428], Loss: 0.0061
Epoch [7/10], Batch [174/428], Loss: 2.5853
Epoch [7/10], Batch [175/428], Loss: 1.9706
Epoch [7/10], Batch [176/428], Loss: 2.5892
Epoch [7/10], Batch [177/428], Loss: 2.1684
Epoch [7/10], Batch [178/428], Loss: 5.2382
Epoch [7/10], Batch [179/428], Loss: 8.5315
Epoch [7/10], Batch [180/428], Loss: 1.0869
Epoch [7/10], Batch [181/428], Loss: 0.0088
Epoch [7/10], Batch [182/428], Loss: 1.9577
Epoch [7/10], Batch [183/428], Loss: 0.0107
Epoch [7/10], Batch [184/428], Loss: 1.9460
Epoch [7/10], Batch [185/428], Loss: 0.0107
Epoch [7/10], Batch [186/428], Loss: 0.0102
Epoch [7/10], Batch [187/428], Loss: 1.8265
Epoch [7/10], Batch [188/428], Loss: 1.8172
Epoch [7/10], Batch [189/428], Loss: 2.1636
Epoch [7/10], Batch [190/428], Loss: 2.3503
Epoch [7/10], Batch [191/428], Loss: 7.0381
Epoch [7/10], Batch [192/428], Loss: 1.9674
Epoch [7/10], Batch [193/428], Loss: 1.3314
Epoch [7/10], Batch [194/428], Loss: 0.0103
Epoch [7/10], Batch [195/428], Loss: 0.0098
Epoch [7/10], Batch [196/428], Loss: 1.8987
Epoch [7/10], Batch [197/428], Loss: 2.2334
Epoch [7/10], Batch [198/428], Loss: 0.0084
Epoch [7/10], Batch [199/428], Loss: 2.1936
Epoch [7/10], Batch [200/428], Loss: 1.3863
Epoch [7/10], Batch [201/428], Loss: 5.2268
Epoch [7/10], Batch [202/428], Loss: 2.4103
Epoch [7/10], Batch [203/428], Loss: 1.2036
Epoch [7/10], Batch [204/428], Loss: 0.0076
Epoch [7/10], Batch [205/428], Loss: 1.1507
Epoch [7/10], Batch [206/428], Loss: 5.0753
Epoch [7/10], Batch [207/428], Loss: 5.0095
Epoch [7/10], Batch [208/428], Loss: 1.8204
Epoch [7/10], Batch [209/428], Loss: 0.0124
Epoch [7/10], Batch [210/428], Loss: 2.1789
Epoch [7/10], Batch [211/428], Loss: 2.2346
Epoch [7/10], Batch [212/428], Loss: 4.3238
Epoch [7/10], Batch [213/428], Loss: 1.9680
Epoch [7/10], Batch [214/428], Loss: 4.0109
Epoch [7/10], Batch [215/428], Loss: 2.0486
Epoch [7/10], Batch [216/428], Loss: 1.9826
Epoch [7/10], Batch [217/428], Loss: 3.2983
Epoch [7/10], Batch [218/428], Loss: 2.0001
Epoch [7/10], Batch [219/428], Loss: 1.1571
Epoch [7/10], Batch [220/428], Loss: 1.8627
Epoch [7/10], Batch [221/428], Loss: 0.1003
Epoch [7/10], Batch [222/428], Loss: 1.9312
Epoch [7/10], Batch [223/428], Loss: 1.8221
Epoch [7/10], Batch [224/428], Loss: 2.2506
Epoch [7/10], Batch [225/428], Loss: 2.7098
Epoch [7/10], Batch [226/428], Loss: 1.9057
Epoch [7/10], Batch [227/428], Loss: 1.3106
Epoch [7/10], Batch [228/428], Loss: 1.6293
Epoch [7/10], Batch [229/428], Loss: 1.9829
Epoch [7/10], Batch [230/428], Loss: 4.8016
Epoch [7/10], Batch [231/428], Loss: 0.2401
Epoch [7/10], Batch [232/428], Loss: 1.8143
Epoch [7/10], Batch [233/428], Loss: 0.2361
Epoch [7/10], Batch [234/428], Loss: 2.7309
Epoch [7/10], Batch [235/428], Loss: 0.2339
Epoch [7/10], Batch [236/428], Loss: 1.4838
Epoch [7/10], Batch [237/428], Loss: 2.6621
Epoch [7/10], Batch [238/428], Loss: 1.7765
Epoch [7/10], Batch [239/428], Loss: 1.4019
Epoch [7/10], Batch [240/428], Loss: 2.0343
Epoch [7/10], Batch [241/428], Loss: 1.5284
Epoch [7/10], Batch [242/428], Loss: 2.2994
Epoch [7/10], Batch [243/428], Loss: 1.9942
Epoch [7/10], Batch [244/428], Loss: 1.5047
Epoch [7/10], Batch [245/428], Loss: 4.4823
Epoch [7/10], Batch [246/428], Loss: 0.0951
Epoch [7/10], Batch [247/428], Loss: 1.5027
Epoch [7/10], Batch [248/428], Loss: 0.0720
Epoch [7/10], Batch [249/428], Loss: 3.0477
Epoch [7/10], Batch [250/428], Loss: 1.8187
Epoch [7/10], Batch [251/428], Loss: 0.0506
Epoch [7/10], Batch [252/428], Loss: 1.6093
Epoch [7/10], Batch [253/428], Loss: 2.3543
Epoch [7/10], Batch [254/428], Loss: 1.7100
Epoch [7/10], Batch [255/428], Loss: 1.2553
Epoch [7/10], Batch [256/428], Loss: 0.0250
Epoch [7/10], Batch [257/428], Loss: 1.8317
Epoch [7/10], Batch [258/428], Loss: 1.5519
Epoch [7/10], Batch [259/428], Loss: 1.8146
Epoch [7/10], Batch [260/428], Loss: 0.0133
Epoch [7/10], Batch [261/428], Loss: 4.8592
Epoch [7/10], Batch [262/428], Loss: 7.0032
Epoch [7/10], Batch [263/428], Loss: 1.6668
Epoch [7/10], Batch [264/428], Loss: 1.5328
Epoch [7/10], Batch [265/428], Loss: 1.5655
Epoch [7/10], Batch [266/428], Loss: 1.4395
Epoch [7/10], Batch [267/428], Loss: 1.4149
Epoch [7/10], Batch [268/428], Loss: 0.0104
Epoch [7/10], Batch [269/428], Loss: 1.4683
Epoch [7/10], Batch [270/428], Loss: 0.0107
Epoch [7/10], Batch [271/428], Loss: 0.0089
Epoch [7/10], Batch [272/428], Loss: 3.0213
Epoch [7/10], Batch [273/428], Loss: 2.9928
Epoch [7/10], Batch [274/428], Loss: 5.2595
Epoch [7/10], Batch [275/428], Loss: 5.2537
Epoch [7/10], Batch [276/428], Loss: 2.5359
Epoch [7/10], Batch [277/428], Loss: 1.3476
Epoch [7/10], Batch [278/428], Loss: 2.4652
Epoch [7/10], Batch [279/428], Loss: 2.4257
Epoch [7/10], Batch [280/428], Loss: 2.3583
Epoch [7/10], Batch [281/428], Loss: 0.3707
Epoch [7/10], Batch [282/428], Loss: 1.4644
Epoch [7/10], Batch [283/428], Loss: 1.5437
Epoch [7/10], Batch [284/428], Loss: 2.0490
Epoch [7/10], Batch [285/428], Loss: 1.4793
Epoch [7/10], Batch [286/428], Loss: 1.4829
Epoch [7/10], Batch [287/428], Loss: 4.3713
Epoch [7/10], Batch [288/428], Loss: 1.5171
Epoch [7/10], Batch [289/428], Loss: 1.8368
Epoch [7/10], Batch [290/428], Loss: 3.9488
Epoch [7/10], Batch [291/428], Loss: 3.9396
Epoch [7/10], Batch [292/428], Loss: 1.6347
Epoch [7/10], Batch [293/428], Loss: 2.9281
Epoch [7/10], Batch [294/428], Loss: 3.2793
Epoch [7/10], Batch [295/428], Loss: 3.0403
Epoch [7/10], Batch [296/428], Loss: 2.7981
Epoch [7/10], Batch [297/428], Loss: 5.5205
Epoch [7/10], Batch [298/428], Loss: 1.4202
Epoch [7/10], Batch [299/428], Loss: 0.1864
Epoch [7/10], Batch [300/428], Loss: 4.7877
Epoch [7/10], Batch [301/428], Loss: 5.9350
Epoch [7/10], Batch [302/428], Loss: 2.7456
Epoch [7/10], Batch [303/428], Loss: 1.9369
Epoch [7/10], Batch [304/428], Loss: 0.4223
Epoch [7/10], Batch [305/428], Loss: 1.3421
Epoch [7/10], Batch [306/428], Loss: 1.8918
Epoch [7/10], Batch [307/428], Loss: 1.8599
Epoch [7/10], Batch [308/428], Loss: 1.3556
Epoch [7/10], Batch [309/428], Loss: 0.6366
Epoch [7/10], Batch [310/428], Loss: 1.1332
Epoch [7/10], Batch [311/428], Loss: 1.6289
Epoch [7/10], Batch [312/428], Loss: 0.6655
Epoch [7/10], Batch [313/428], Loss: 0.6690
Epoch [7/10], Batch [314/428], Loss: 1.3850
Epoch [7/10], Batch [315/428], Loss: 2.0459
Epoch [7/10], Batch [316/428], Loss: 2.4684
Epoch [7/10], Batch [317/428], Loss: 0.4935
Epoch [7/10], Batch [318/428], Loss: 1.4353
Epoch [7/10], Batch [319/428], Loss: 1.3009
Epoch [7/10], Batch [320/428], Loss: 1.3454
Epoch [7/10], Batch [321/428], Loss: 2.4427
Epoch [7/10], Batch [322/428], Loss: 1.2765
Epoch [7/10], Batch [323/428], Loss: 2.1681
Epoch [7/10], Batch [324/428], Loss: 1.2095
Epoch [7/10], Batch [325/428], Loss: 2.0771
Epoch [7/10], Batch [326/428], Loss: 1.2906
Epoch [7/10], Batch [327/428], Loss: 2.0720
Epoch [7/10], Batch [328/428], Loss: 1.2062
Epoch [7/10], Batch [329/428], Loss: 0.2285
Epoch [7/10], Batch [330/428], Loss: 1.9433
Epoch [7/10], Batch [331/428], Loss: 3.5411
Epoch [7/10], Batch [332/428], Loss: 1.2380
Epoch [7/10], Batch [333/428], Loss: 1.1229
Epoch [7/10], Batch [334/428], Loss: 1.1270
Epoch [7/10], Batch [335/428], Loss: 4.8604
Epoch [7/10], Batch [336/428], Loss: 0.9730
Epoch [7/10], Batch [337/428], Loss: 2.3827
Epoch [7/10], Batch [338/428], Loss: 2.7449
Epoch [7/10], Batch [339/428], Loss: 2.5256
Epoch [7/10], Batch [340/428], Loss: 0.2148
Epoch [7/10], Batch [341/428], Loss: 2.2813
Epoch [7/10], Batch [342/428], Loss: 2.7294
Epoch [7/10], Batch [343/428], Loss: 1.7767
Epoch [7/10], Batch [344/428], Loss: 2.1966
Epoch [7/10], Batch [345/428], Loss: 1.7881
Epoch [7/10], Batch [346/428], Loss: 0.8746
Epoch [7/10], Batch [347/428], Loss: 0.8184
Epoch [7/10], Batch [348/428], Loss: 2.6512
Epoch [7/10], Batch [349/428], Loss: 2.5768
Epoch [7/10], Batch [350/428], Loss: 0.7723
Epoch [7/10], Batch [351/428], Loss: 3.7840
Epoch [7/10], Batch [352/428], Loss: 0.7446
Epoch [7/10], Batch [353/428], Loss: 1.8881
Epoch [7/10], Batch [354/428], Loss: 1.7079
Epoch [7/10], Batch [355/428], Loss: 0.5190
Epoch [7/10], Batch [356/428], Loss: 3.1401
Epoch [7/10], Batch [357/428], Loss: 0.5853
Epoch [7/10], Batch [358/428], Loss: 3.2245
Epoch [7/10], Batch [359/428], Loss: 1.5633
Epoch [7/10], Batch [360/428], Loss: 2.0702
Epoch [7/10], Batch [361/428], Loss: 1.5350
Epoch [7/10], Batch [362/428], Loss: 2.4803
Epoch [7/10], Batch [363/428], Loss: 3.5534
Epoch [7/10], Batch [364/428], Loss: 0.8884
Epoch [7/10], Batch [365/428], Loss: 0.9144
Epoch [7/10], Batch [366/428], Loss: 1.0705
Epoch [7/10], Batch [367/428], Loss: 0.9209
Epoch [7/10], Batch [368/428], Loss: 0.8573
Epoch [7/10], Batch [369/428], Loss: 2.0557
Epoch [7/10], Batch [370/428], Loss: 0.7358
Epoch [7/10], Batch [371/428], Loss: 0.5788
Epoch [7/10], Batch [372/428], Loss: 2.9999
Epoch [7/10], Batch [373/428], Loss: 0.4634
Epoch [7/10], Batch [374/428], Loss: 3.3926
Epoch [7/10], Batch [375/428], Loss: 2.7025
Epoch [7/10], Batch [376/428], Loss: 1.8287
Epoch [7/10], Batch [377/428], Loss: 0.5032
Epoch [7/10], Batch [378/428], Loss: 2.6755
Epoch [7/10], Batch [379/428], Loss: 1.7778
Epoch [7/10], Batch [380/428], Loss: 0.2654
Epoch [7/10], Batch [381/428], Loss: 0.2301
Epoch [7/10], Batch [382/428], Loss: 2.4186
Epoch [7/10], Batch [383/428], Loss: 1.5832
Epoch [7/10], Batch [384/428], Loss: 2.4494
Epoch [7/10], Batch [385/428], Loss: 0.1350
Epoch [7/10], Batch [386/428], Loss: 0.1196
Epoch [7/10], Batch [387/428], Loss: 3.0520
Epoch [7/10], Batch [388/428], Loss: 0.0791
Epoch [7/10], Batch [389/428], Loss: 4.8137
Epoch [7/10], Batch [390/428], Loss: 2.0471
Epoch [7/10], Batch [391/428], Loss: 0.8812
Epoch [7/10], Batch [392/428], Loss: 6.3227
Epoch [7/10], Batch [393/428], Loss: 1.9273
Epoch [7/10], Batch [394/428], Loss: 0.0431
Epoch [7/10], Batch [395/428], Loss: 4.0077
Epoch [7/10], Batch [396/428], Loss: 1.0103
Epoch [7/10], Batch [397/428], Loss: 1.2203
Epoch [7/10], Batch [398/428], Loss: 0.0343
Epoch [7/10], Batch [399/428], Loss: 1.5835
Epoch [7/10], Batch [400/428], Loss: 0.0290
Epoch [7/10], Batch [401/428], Loss: 0.0242
Epoch [7/10], Batch [402/428], Loss: 0.0218
Epoch [7/10], Batch [403/428], Loss: 2.2996
Epoch [7/10], Batch [404/428], Loss: 2.2225
Epoch [7/10], Batch [405/428], Loss: 0.0110
Epoch [7/10], Batch [406/428], Loss: 0.0100
Epoch [7/10], Batch [407/428], Loss: 1.2284
Epoch [7/10], Batch [408/428], Loss: 3.4084
Epoch [7/10], Batch [409/428], Loss: 5.7274
Epoch [7/10], Batch [410/428], Loss: 3.3033
Epoch [7/10], Batch [411/428], Loss: 0.0043
Epoch [7/10], Batch [412/428], Loss: 1.4234
Epoch [7/10], Batch [413/428], Loss: 0.0039
Epoch [7/10], Batch [414/428], Loss: 0.0035
Epoch [7/10], Batch [415/428], Loss: 1.2272
Epoch [7/10], Batch [416/428], Loss: 1.4189
Epoch [7/10], Batch [417/428], Loss: 1.1995
Epoch [7/10], Batch [418/428], Loss: 1.9559
Epoch [7/10], Batch [419/428], Loss: 0.0025
Epoch [7/10], Batch [420/428], Loss: 1.9066
Epoch [7/10], Batch [421/428], Loss: 1.9002
Epoch [7/10], Batch [422/428], Loss: 1.4575
Epoch [7/10], Batch [423/428], Loss: 4.4817
Epoch [7/10], Batch [424/428], Loss: 1.4341
Epoch [7/10], Batch [425/428], Loss: 0.0022
Epoch [7/10], Batch [426/428], Loss: 1.5884
Epoch [7/10], Batch [427/428], Loss: 6.7258
Epoch [7/10], Batch [428/428], Loss: 1.9181
Epoch [7] Training Time: 167.14 seconds
Epoch [7/10], Average Loss: 1.8089, Training Accuracy: 0.3621
Epoch [7], Validation Loss: 2.8130, Validation Accuracy: 0.2698
Epoch [7] Validation Time: 5.54 seconds
--------------------------------------------------
Epoch [8/10], Batch [1/428], Loss: 1.3089
Epoch [8/10], Batch [2/428], Loss: 1.9298
Epoch [8/10], Batch [3/428], Loss: 0.0023
Epoch [8/10], Batch [4/428], Loss: 0.0023
Epoch [8/10], Batch [5/428], Loss: 9.4906
Epoch [8/10], Batch [6/428], Loss: 0.0024
Epoch [8/10], Batch [7/428], Loss: 0.0026
Epoch [8/10], Batch [8/428], Loss: 1.5594
Epoch [8/10], Batch [9/428], Loss: 1.2459
Epoch [8/10], Batch [10/428], Loss: 8.2438
Epoch [8/10], Batch [11/428], Loss: 6.2777
Epoch [8/10], Batch [12/428], Loss: 1.6090
Epoch [8/10], Batch [13/428], Loss: 0.0030
Epoch [8/10], Batch [14/428], Loss: 2.9025
Epoch [8/10], Batch [15/428], Loss: 8.6357
Epoch [8/10], Batch [16/428], Loss: 2.8884
Epoch [8/10], Batch [17/428], Loss: 1.9521
Epoch [8/10], Batch [18/428], Loss: 5.7247
Epoch [8/10], Batch [19/428], Loss: 1.8386
Epoch [8/10], Batch [20/428], Loss: 5.5371
Epoch [8/10], Batch [21/428], Loss: 4.0823
Epoch [8/10], Batch [22/428], Loss: 0.0076
Epoch [8/10], Batch [23/428], Loss: 0.0086
Epoch [8/10], Batch [24/428], Loss: 0.0089
Epoch [8/10], Batch [25/428], Loss: 1.6425
Epoch [8/10], Batch [26/428], Loss: 6.5524
Epoch [8/10], Batch [27/428], Loss: 1.6331
Epoch [8/10], Batch [28/428], Loss: 0.0112
Epoch [8/10], Batch [29/428], Loss: 0.0112
Epoch [8/10], Batch [30/428], Loss: 1.3141
Epoch [8/10], Batch [31/428], Loss: 1.5792
Epoch [8/10], Batch [32/428], Loss: 6.0006
Epoch [8/10], Batch [33/428], Loss: 0.0114
Epoch [8/10], Batch [34/428], Loss: 1.5335
Epoch [8/10], Batch [35/428], Loss: 0.0116
Epoch [8/10], Batch [36/428], Loss: 1.5417
Epoch [8/10], Batch [37/428], Loss: 0.0109
Epoch [8/10], Batch [38/428], Loss: 1.3702
Epoch [8/10], Batch [39/428], Loss: 1.3093
Epoch [8/10], Batch [40/428], Loss: 6.4644
Epoch [8/10], Batch [41/428], Loss: 2.5592
Epoch [8/10], Batch [42/428], Loss: 5.0662
Epoch [8/10], Batch [43/428], Loss: 4.9168
Epoch [8/10], Batch [44/428], Loss: 0.0121
Epoch [8/10], Batch [45/428], Loss: 1.2376
Epoch [8/10], Batch [46/428], Loss: 1.8201
Epoch [8/10], Batch [47/428], Loss: 1.5390
Epoch [8/10], Batch [48/428], Loss: 1.7454
Epoch [8/10], Batch [49/428], Loss: 1.6212
Epoch [8/10], Batch [50/428], Loss: 1.6041
Epoch [8/10], Batch [51/428], Loss: 5.9903
Epoch [8/10], Batch [52/428], Loss: 1.1897
Epoch [8/10], Batch [53/428], Loss: 0.0149
Epoch [8/10], Batch [54/428], Loss: 0.0168
Epoch [8/10], Batch [55/428], Loss: 1.6711
Epoch [8/10], Batch [56/428], Loss: 1.5611
Epoch [8/10], Batch [57/428], Loss: 1.5280
Epoch [8/10], Batch [58/428], Loss: 3.9305
Epoch [8/10], Batch [59/428], Loss: 2.5914
Epoch [8/10], Batch [60/428], Loss: 2.6350
Epoch [8/10], Batch [61/428], Loss: 1.4855
Epoch [8/10], Batch [62/428], Loss: 1.5129
Epoch [8/10], Batch [63/428], Loss: 5.9935
Epoch [8/10], Batch [64/428], Loss: 0.0157
Epoch [8/10], Batch [65/428], Loss: 0.0142
Epoch [8/10], Batch [66/428], Loss: 4.9038
Epoch [8/10], Batch [67/428], Loss: 1.3432
Epoch [8/10], Batch [68/428], Loss: 1.4843
Epoch [8/10], Batch [69/428], Loss: 1.5074
Epoch [8/10], Batch [70/428], Loss: 4.5357
Epoch [8/10], Batch [71/428], Loss: 1.4660
Epoch [8/10], Batch [72/428], Loss: 1.7616
Epoch [8/10], Batch [73/428], Loss: 1.7232
Epoch [8/10], Batch [74/428], Loss: 1.2648
Epoch [8/10], Batch [75/428], Loss: 1.3169
Epoch [8/10], Batch [76/428], Loss: 2.4246
Epoch [8/10], Batch [77/428], Loss: 0.0260
Epoch [8/10], Batch [78/428], Loss: 1.7917
Epoch [8/10], Batch [79/428], Loss: 1.3550
Epoch [8/10], Batch [80/428], Loss: 1.8048
Epoch [8/10], Batch [81/428], Loss: 1.4043
Epoch [8/10], Batch [82/428], Loss: 1.3569
Epoch [8/10], Batch [83/428], Loss: 1.9303
Epoch [8/10], Batch [84/428], Loss: 1.8715
Epoch [8/10], Batch [85/428], Loss: 4.3391
Epoch [8/10], Batch [86/428], Loss: 1.3745
Epoch [8/10], Batch [87/428], Loss: 1.4155
Epoch [8/10], Batch [88/428], Loss: 1.8527
Epoch [8/10], Batch [89/428], Loss: 1.7689
Epoch [8/10], Batch [90/428], Loss: 3.4099
Epoch [8/10], Batch [91/428], Loss: 0.0216
Epoch [8/10], Batch [92/428], Loss: 1.2696
Epoch [8/10], Batch [93/428], Loss: 1.4421
Epoch [8/10], Batch [94/428], Loss: 1.4402
Epoch [8/10], Batch [95/428], Loss: 1.2028
Epoch [8/10], Batch [96/428], Loss: 1.7154
Epoch [8/10], Batch [97/428], Loss: 0.0192
Epoch [8/10], Batch [98/428], Loss: 1.7702
Epoch [8/10], Batch [99/428], Loss: 1.6697
Epoch [8/10], Batch [100/428], Loss: 0.0216
Epoch [8/10], Batch [101/428], Loss: 1.6381
Epoch [8/10], Batch [102/428], Loss: 1.7865
Epoch [8/10], Batch [103/428], Loss: 1.2227
Epoch [8/10], Batch [104/428], Loss: 0.0116
Epoch [8/10], Batch [105/428], Loss: 1.7606
Epoch [8/10], Batch [106/428], Loss: 1.3694
Epoch [8/10], Batch [107/428], Loss: 0.0124
Epoch [8/10], Batch [108/428], Loss: 1.2399
Epoch [8/10], Batch [109/428], Loss: 0.0068
Epoch [8/10], Batch [110/428], Loss: 1.4108
Epoch [8/10], Batch [111/428], Loss: 1.6612
Epoch [8/10], Batch [112/428], Loss: 0.0040
Epoch [8/10], Batch [113/428], Loss: 4.0434
Epoch [8/10], Batch [114/428], Loss: 1.3272
Epoch [8/10], Batch [115/428], Loss: 0.0098
Epoch [8/10], Batch [116/428], Loss: 1.6444
Epoch [8/10], Batch [117/428], Loss: 0.0030
Epoch [8/10], Batch [118/428], Loss: 6.8639
Epoch [8/10], Batch [119/428], Loss: 2.8459
Epoch [8/10], Batch [120/428], Loss: 1.6263
Epoch [8/10], Batch [121/428], Loss: 0.0072
Epoch [8/10], Batch [122/428], Loss: 1.2967
Epoch [8/10], Batch [123/428], Loss: 1.5892
Epoch [8/10], Batch [124/428], Loss: 1.5322
Epoch [8/10], Batch [125/428], Loss: 0.0023
Epoch [8/10], Batch [126/428], Loss: 1.5371
Epoch [8/10], Batch [127/428], Loss: 3.9802
Epoch [8/10], Batch [128/428], Loss: 0.0026
Epoch [8/10], Batch [129/428], Loss: 1.5271
Epoch [8/10], Batch [130/428], Loss: 1.4983
Epoch [8/10], Batch [131/428], Loss: 1.4898
Epoch [8/10], Batch [132/428], Loss: 1.4743
Epoch [8/10], Batch [133/428], Loss: 0.0020
Epoch [8/10], Batch [134/428], Loss: 1.4599
Epoch [8/10], Batch [135/428], Loss: 1.6583
Epoch [8/10], Batch [136/428], Loss: 1.6655
Epoch [8/10], Batch [137/428], Loss: 0.0021
Epoch [8/10], Batch [138/428], Loss: 2.8627
Epoch [8/10], Batch [139/428], Loss: 1.3059
Epoch [8/10], Batch [140/428], Loss: 5.4735
Epoch [8/10], Batch [141/428], Loss: 0.0020
Epoch [8/10], Batch [142/428], Loss: 1.2397
Epoch [8/10], Batch [143/428], Loss: 6.6218
Epoch [8/10], Batch [144/428], Loss: 1.6849
Epoch [8/10], Batch [145/428], Loss: 6.5094
Epoch [8/10], Batch [146/428], Loss: 0.0023
Epoch [8/10], Batch [147/428], Loss: 6.3316
Epoch [8/10], Batch [148/428], Loss: 1.5983
Epoch [8/10], Batch [149/428], Loss: 1.1058
Epoch [8/10], Batch [150/428], Loss: 2.7541
Epoch [8/10], Batch [151/428], Loss: 1.6244
Epoch [8/10], Batch [152/428], Loss: 1.6522
Epoch [8/10], Batch [153/428], Loss: 1.0958
Epoch [8/10], Batch [154/428], Loss: 1.0429
Epoch [8/10], Batch [155/428], Loss: 0.0047
Epoch [8/10], Batch [156/428], Loss: 1.5405
Epoch [8/10], Batch [157/428], Loss: 1.5229
Epoch [8/10], Batch [158/428], Loss: 0.9750
Epoch [8/10], Batch [159/428], Loss: 0.0152
Epoch [8/10], Batch [160/428], Loss: 0.9601
Epoch [8/10], Batch [161/428], Loss: 5.3283
Epoch [8/10], Batch [162/428], Loss: 1.3966
Epoch [8/10], Batch [163/428], Loss: 5.5853
Epoch [8/10], Batch [164/428], Loss: 0.8792
Epoch [8/10], Batch [165/428], Loss: 2.1379
Epoch [8/10], Batch [166/428], Loss: 2.1981
Epoch [8/10], Batch [167/428], Loss: 5.4519
Epoch [8/10], Batch [168/428], Loss: 2.1542
Epoch [8/10], Batch [169/428], Loss: 3.9995
Epoch [8/10], Batch [170/428], Loss: 2.1149
Epoch [8/10], Batch [171/428], Loss: 2.1899
Epoch [8/10], Batch [172/428], Loss: 1.3429
Epoch [8/10], Batch [173/428], Loss: 1.3152
Epoch [8/10], Batch [174/428], Loss: 2.0685
Epoch [8/10], Batch [175/428], Loss: 2.0736
Epoch [8/10], Batch [176/428], Loss: 0.0096
Epoch [8/10], Batch [177/428], Loss: 1.9887
Epoch [8/10], Batch [178/428], Loss: 1.0162
Epoch [8/10], Batch [179/428], Loss: 1.2537
Epoch [8/10], Batch [180/428], Loss: 1.9252
Epoch [8/10], Batch [181/428], Loss: 4.8159
Epoch [8/10], Batch [182/428], Loss: 1.2834
Epoch [8/10], Batch [183/428], Loss: 0.0117
Epoch [8/10], Batch [184/428], Loss: 1.1854
Epoch [8/10], Batch [185/428], Loss: 1.8556
Epoch [8/10], Batch [186/428], Loss: 1.9082
Epoch [8/10], Batch [187/428], Loss: 4.8364
Epoch [8/10], Batch [188/428], Loss: 0.0126
Epoch [8/10], Batch [189/428], Loss: 4.6954
Epoch [8/10], Batch [190/428], Loss: 0.0114
Epoch [8/10], Batch [191/428], Loss: 5.6413
Epoch [8/10], Batch [192/428], Loss: 2.9923
Epoch [8/10], Batch [193/428], Loss: 1.4314
Epoch [8/10], Batch [194/428], Loss: 1.7976
Epoch [8/10], Batch [195/428], Loss: 0.0279
Epoch [8/10], Batch [196/428], Loss: 2.8737
Epoch [8/10], Batch [197/428], Loss: 1.1672
Epoch [8/10], Batch [198/428], Loss: 1.5116
Epoch [8/10], Batch [199/428], Loss: 2.8571
Epoch [8/10], Batch [200/428], Loss: 0.0140
Epoch [8/10], Batch [201/428], Loss: 2.6999
Epoch [8/10], Batch [202/428], Loss: 1.6367
Epoch [8/10], Batch [203/428], Loss: 1.5098
Epoch [8/10], Batch [204/428], Loss: 1.1721
Epoch [8/10], Batch [205/428], Loss: 3.4614
Epoch [8/10], Batch [206/428], Loss: 1.1945
Epoch [8/10], Batch [207/428], Loss: 2.4560
Epoch [8/10], Batch [208/428], Loss: 0.0113
Epoch [8/10], Batch [209/428], Loss: 1.5206
Epoch [8/10], Batch [210/428], Loss: 1.5260
Epoch [8/10], Batch [211/428], Loss: 0.0107
Epoch [8/10], Batch [212/428], Loss: 1.6976
Epoch [8/10], Batch [213/428], Loss: 1.4507
Epoch [8/10], Batch [214/428], Loss: 4.9057
Epoch [8/10], Batch [215/428], Loss: 0.0103
Epoch [8/10], Batch [216/428], Loss: 1.2079
Epoch [8/10], Batch [217/428], Loss: 2.2847
Epoch [8/10], Batch [218/428], Loss: 1.6051
Epoch [8/10], Batch [219/428], Loss: 0.0094
Epoch [8/10], Batch [220/428], Loss: 0.0084
Epoch [8/10], Batch [221/428], Loss: 2.1763
Epoch [8/10], Batch [222/428], Loss: 0.0081
Epoch [8/10], Batch [223/428], Loss: 0.0083
Epoch [8/10], Batch [224/428], Loss: 2.2120
Epoch [8/10], Batch [225/428], Loss: 3.4494
Epoch [8/10], Batch [226/428], Loss: 1.3463
Epoch [8/10], Batch [227/428], Loss: 1.6279
Epoch [8/10], Batch [228/428], Loss: 0.0071
Epoch [8/10], Batch [229/428], Loss: 0.0063
Epoch [8/10], Batch [230/428], Loss: 1.3771
Epoch [8/10], Batch [231/428], Loss: 1.3320
Epoch [8/10], Batch [232/428], Loss: 1.3030
Epoch [8/10], Batch [233/428], Loss: 0.0058
Epoch [8/10], Batch [234/428], Loss: 1.6018
Epoch [8/10], Batch [235/428], Loss: 3.3809
Epoch [8/10], Batch [236/428], Loss: 0.0049
Epoch [8/10], Batch [237/428], Loss: 1.5123
Epoch [8/10], Batch [238/428], Loss: 2.0792
Epoch [8/10], Batch [239/428], Loss: 0.0044
Epoch [8/10], Batch [240/428], Loss: 5.7185
Epoch [8/10], Batch [241/428], Loss: 1.6255
Epoch [8/10], Batch [242/428], Loss: 0.0105
Epoch [8/10], Batch [243/428], Loss: 3.2961
Epoch [8/10], Batch [244/428], Loss: 0.0045
Epoch [8/10], Batch [245/428], Loss: 0.0044
Epoch [8/10], Batch [246/428], Loss: 3.9767
Epoch [8/10], Batch [247/428], Loss: 1.1671
Epoch [8/10], Batch [248/428], Loss: 1.5395
Epoch [8/10], Batch [249/428], Loss: 1.6103
Epoch [8/10], Batch [250/428], Loss: 2.4000
Epoch [8/10], Batch [251/428], Loss: 2.4059
Epoch [8/10], Batch [252/428], Loss: 2.3238
Epoch [8/10], Batch [253/428], Loss: 0.0045
Epoch [8/10], Batch [254/428], Loss: 1.7001
Epoch [8/10], Batch [255/428], Loss: 5.6178
Epoch [8/10], Batch [256/428], Loss: 2.1811
Epoch [8/10], Batch [257/428], Loss: 2.1791
Epoch [8/10], Batch [258/428], Loss: 1.2490
Epoch [8/10], Batch [259/428], Loss: 1.5462
Epoch [8/10], Batch [260/428], Loss: 0.0083
Epoch [8/10], Batch [261/428], Loss: 1.3298
Epoch [8/10], Batch [262/428], Loss: 1.6290
Epoch [8/10], Batch [263/428], Loss: 1.3020
Epoch [8/10], Batch [264/428], Loss: 1.9353
Epoch [8/10], Batch [265/428], Loss: 1.3256
Epoch [8/10], Batch [266/428], Loss: 0.0047
Epoch [8/10], Batch [267/428], Loss: 0.0055
Epoch [8/10], Batch [268/428], Loss: 0.0052
Epoch [8/10], Batch [269/428], Loss: 1.1628
Epoch [8/10], Batch [270/428], Loss: 0.0046
Epoch [8/10], Batch [271/428], Loss: 1.6469
Epoch [8/10], Batch [272/428], Loss: 8.1548
Epoch [8/10], Batch [273/428], Loss: 3.1571
Epoch [8/10], Batch [274/428], Loss: 1.1663
Epoch [8/10], Batch [275/428], Loss: 1.8857
Epoch [8/10], Batch [276/428], Loss: 1.8942
Epoch [8/10], Batch [277/428], Loss: 1.6404
Epoch [8/10], Batch [278/428], Loss: 1.7197
Epoch [8/10], Batch [279/428], Loss: 3.2161
Epoch [8/10], Batch [280/428], Loss: 1.6507
Epoch [8/10], Batch [281/428], Loss: 1.9266
Epoch [8/10], Batch [282/428], Loss: 0.0055
Epoch [8/10], Batch [283/428], Loss: 1.1062
Epoch [8/10], Batch [284/428], Loss: 1.8229
Epoch [8/10], Batch [285/428], Loss: 1.0974
Epoch [8/10], Batch [286/428], Loss: 1.1081
Epoch [8/10], Batch [287/428], Loss: 2.6241
Epoch [8/10], Batch [288/428], Loss: 0.0054
Epoch [8/10], Batch [289/428], Loss: 7.8150
Epoch [8/10], Batch [290/428], Loss: 1.0694
Epoch [8/10], Batch [291/428], Loss: 1.5164
Epoch [8/10], Batch [292/428], Loss: 5.4191
Epoch [8/10], Batch [293/428], Loss: 3.1897
Epoch [8/10], Batch [294/428], Loss: 0.0061
Epoch [8/10], Batch [295/428], Loss: 0.0067
Epoch [8/10], Batch [296/428], Loss: 1.5510
Epoch [8/10], Batch [297/428], Loss: 2.0756
Epoch [8/10], Batch [298/428], Loss: 1.8299
Epoch [8/10], Batch [299/428], Loss: 2.0177
Epoch [8/10], Batch [300/428], Loss: 5.1570
Epoch [8/10], Batch [301/428], Loss: 5.0755
Epoch [8/10], Batch [302/428], Loss: 0.0087
Epoch [8/10], Batch [303/428], Loss: 0.0099
Epoch [8/10], Batch [304/428], Loss: 0.0105
Epoch [8/10], Batch [305/428], Loss: 2.1315
Epoch [8/10], Batch [306/428], Loss: 2.0911
Epoch [8/10], Batch [307/428], Loss: 1.7997
Epoch [8/10], Batch [308/428], Loss: 2.6161
Epoch [8/10], Batch [309/428], Loss: 0.0114
Epoch [8/10], Batch [310/428], Loss: 0.0104
Epoch [8/10], Batch [311/428], Loss: 0.0104
Epoch [8/10], Batch [312/428], Loss: 4.8596
Epoch [8/10], Batch [313/428], Loss: 0.0101
Epoch [8/10], Batch [314/428], Loss: 4.8539
Epoch [8/10], Batch [315/428], Loss: 2.8094
Epoch [8/10], Batch [316/428], Loss: 1.4735
Epoch [8/10], Batch [317/428], Loss: 9.3045
Epoch [8/10], Batch [318/428], Loss: 1.2733
Epoch [8/10], Batch [319/428], Loss: 0.0122
Epoch [8/10], Batch [320/428], Loss: 4.6212
Epoch [8/10], Batch [321/428], Loss: 0.0149
Epoch [8/10], Batch [322/428], Loss: 1.7477
Epoch [8/10], Batch [323/428], Loss: 6.5433
Epoch [8/10], Batch [324/428], Loss: 1.7516
Epoch [8/10], Batch [325/428], Loss: 1.4781
Epoch [8/10], Batch [326/428], Loss: 1.6845
Epoch [8/10], Batch [327/428], Loss: 2.6415
Epoch [8/10], Batch [328/428], Loss: 1.3349
Epoch [8/10], Batch [329/428], Loss: 0.0139
Epoch [8/10], Batch [330/428], Loss: 1.8548
Epoch [8/10], Batch [331/428], Loss: 0.0138
Epoch [8/10], Batch [332/428], Loss: 1.8261
Epoch [8/10], Batch [333/428], Loss: 1.5732
Epoch [8/10], Batch [334/428], Loss: 1.8781
Epoch [8/10], Batch [335/428], Loss: 1.8510
Epoch [8/10], Batch [336/428], Loss: 1.4987
Epoch [8/10], Batch [337/428], Loss: 2.6401
Epoch [8/10], Batch [338/428], Loss: 1.6136
Epoch [8/10], Batch [339/428], Loss: 1.6890
Epoch [8/10], Batch [340/428], Loss: 1.6165
Epoch [8/10], Batch [341/428], Loss: 0.0113
Epoch [8/10], Batch [342/428], Loss: 1.5209
Epoch [8/10], Batch [343/428], Loss: 1.5121
Epoch [8/10], Batch [344/428], Loss: 4.7439
Epoch [8/10], Batch [345/428], Loss: 4.7493
Epoch [8/10], Batch [346/428], Loss: 2.2479
Epoch [8/10], Batch [347/428], Loss: 1.6727
Epoch [8/10], Batch [348/428], Loss: 2.7662
Epoch [8/10], Batch [349/428], Loss: 4.1345
Epoch [8/10], Batch [350/428], Loss: 1.6369
Epoch [8/10], Batch [351/428], Loss: 0.0136
Epoch [8/10], Batch [352/428], Loss: 1.6335
Epoch [8/10], Batch [353/428], Loss: 2.7073
Epoch [8/10], Batch [354/428], Loss: 1.8993
Epoch [8/10], Batch [355/428], Loss: 2.4617
Epoch [8/10], Batch [356/428], Loss: 2.6459
Epoch [8/10], Batch [357/428], Loss: 1.5392
Epoch [8/10], Batch [358/428], Loss: 3.2208
Epoch [8/10], Batch [359/428], Loss: 1.3128
Epoch [8/10], Batch [360/428], Loss: 1.5850
Epoch [8/10], Batch [361/428], Loss: 4.1967
Epoch [8/10], Batch [362/428], Loss: 0.0150
Epoch [8/10], Batch [363/428], Loss: 1.3436
Epoch [8/10], Batch [364/428], Loss: 0.0132
Epoch [8/10], Batch [365/428], Loss: 1.9293
Epoch [8/10], Batch [366/428], Loss: 1.2540
Epoch [8/10], Batch [367/428], Loss: 0.0120
Epoch [8/10], Batch [368/428], Loss: 2.0149
Epoch [8/10], Batch [369/428], Loss: 1.9096
Epoch [8/10], Batch [370/428], Loss: 1.9015
Epoch [8/10], Batch [371/428], Loss: 2.2154
Epoch [8/10], Batch [372/428], Loss: 3.3035
Epoch [8/10], Batch [373/428], Loss: 0.0098
Epoch [8/10], Batch [374/428], Loss: 1.7934
Epoch [8/10], Batch [375/428], Loss: 2.1276
Epoch [8/10], Batch [376/428], Loss: 4.9834
Epoch [8/10], Batch [377/428], Loss: 1.6526
Epoch [8/10], Batch [378/428], Loss: 1.6308
Epoch [8/10], Batch [379/428], Loss: 0.0081
Epoch [8/10], Batch [380/428], Loss: 1.5938
Epoch [8/10], Batch [381/428], Loss: 2.0528
Epoch [8/10], Batch [382/428], Loss: 1.5169
Epoch [8/10], Batch [383/428], Loss: 0.0072
Epoch [8/10], Batch [384/428], Loss: 1.9836
Epoch [8/10], Batch [385/428], Loss: 1.9329
Epoch [8/10], Batch [386/428], Loss: 2.6498
Epoch [8/10], Batch [387/428], Loss: 5.1629
Epoch [8/10], Batch [388/428], Loss: 0.0064
Epoch [8/10], Batch [389/428], Loss: 1.6959
Epoch [8/10], Batch [390/428], Loss: 1.7334
Epoch [8/10], Batch [391/428], Loss: 0.0069
Epoch [8/10], Batch [392/428], Loss: 1.4352
Epoch [8/10], Batch [393/428], Loss: 1.4713
Epoch [8/10], Batch [394/428], Loss: 2.5881
Epoch [8/10], Batch [395/428], Loss: 4.2540
Epoch [8/10], Batch [396/428], Loss: 0.0069
Epoch [8/10], Batch [397/428], Loss: 6.0356
Epoch [8/10], Batch [398/428], Loss: 1.6531
Epoch [8/10], Batch [399/428], Loss: 2.4964
Epoch [8/10], Batch [400/428], Loss: 5.0287
Epoch [8/10], Batch [401/428], Loss: 1.3998
Epoch [8/10], Batch [402/428], Loss: 0.0094
Epoch [8/10], Batch [403/428], Loss: 0.0242
Epoch [8/10], Batch [404/428], Loss: 2.9450
Epoch [8/10], Batch [405/428], Loss: 0.0111
Epoch [8/10], Batch [406/428], Loss: 1.6996
Epoch [8/10], Batch [407/428], Loss: 0.0100
Epoch [8/10], Batch [408/428], Loss: 1.6624
Epoch [8/10], Batch [409/428], Loss: 0.0310
Epoch [8/10], Batch [410/428], Loss: 0.0093
Epoch [8/10], Batch [411/428], Loss: 4.8893
Epoch [8/10], Batch [412/428], Loss: 1.6551
Epoch [8/10], Batch [413/428], Loss: 0.0093
Epoch [8/10], Batch [414/428], Loss: 0.0083
Epoch [8/10], Batch [415/428], Loss: 0.0081
Epoch [8/10], Batch [416/428], Loss: 5.0953
Epoch [8/10], Batch [417/428], Loss: 0.0076
Epoch [8/10], Batch [418/428], Loss: 1.6256
Epoch [8/10], Batch [419/428], Loss: 0.0072
Epoch [8/10], Batch [420/428], Loss: 2.3509
Epoch [8/10], Batch [421/428], Loss: 1.6116
Epoch [8/10], Batch [422/428], Loss: 0.0074
Epoch [8/10], Batch [423/428], Loss: 0.0061
Epoch [8/10], Batch [424/428], Loss: 2.3550
Epoch [8/10], Batch [425/428], Loss: 0.0066
Epoch [8/10], Batch [426/428], Loss: 1.4839
Epoch [8/10], Batch [427/428], Loss: 5.3187
Epoch [8/10], Batch [428/428], Loss: 2.1705
Epoch [8] Training Time: 166.63 seconds
Epoch [8/10], Average Loss: 1.8737, Training Accuracy: 0.3645
Epoch [8], Validation Loss: 2.7237, Validation Accuracy: 0.2786
Epoch [8] Validation Time: 5.54 seconds
--------------------------------------------------
Epoch [9/10], Batch [1/428], Loss: 1.5414
Epoch [9/10], Batch [2/428], Loss: 5.7717
Epoch [9/10], Batch [3/428], Loss: 7.9002
Epoch [9/10], Batch [4/428], Loss: 1.8120
Epoch [9/10], Batch [5/428], Loss: 1.4289
Epoch [9/10], Batch [6/428], Loss: 1.4862
Epoch [9/10], Batch [7/428], Loss: 2.3731
Epoch [9/10], Batch [8/428], Loss: 1.8535
Epoch [9/10], Batch [9/428], Loss: 1.7391
Epoch [9/10], Batch [10/428], Loss: 0.0064
Epoch [9/10], Batch [11/428], Loss: 1.8139
Epoch [9/10], Batch [12/428], Loss: 1.4364
Epoch [9/10], Batch [13/428], Loss: 1.7171
Epoch [9/10], Batch [14/428], Loss: 1.8493
Epoch [9/10], Batch [15/428], Loss: 5.2727
Epoch [9/10], Batch [16/428], Loss: 0.0069
Epoch [9/10], Batch [17/428], Loss: 4.3215
Epoch [9/10], Batch [18/428], Loss: 1.4930
Epoch [9/10], Batch [19/428], Loss: 3.9692
Epoch [9/10], Batch [20/428], Loss: 1.4109
Epoch [9/10], Batch [21/428], Loss: 1.6404
Epoch [9/10], Batch [22/428], Loss: 0.0070
Epoch [9/10], Batch [23/428], Loss: 1.6863
Epoch [9/10], Batch [24/428], Loss: 1.5906
Epoch [9/10], Batch [25/428], Loss: 0.0066
Epoch [9/10], Batch [26/428], Loss: 1.6349
Epoch [9/10], Batch [27/428], Loss: 0.0067
Epoch [9/10], Batch [28/428], Loss: 5.1273
Epoch [9/10], Batch [29/428], Loss: 0.0071
Epoch [9/10], Batch [30/428], Loss: 1.7064
Epoch [9/10], Batch [31/428], Loss: 1.5372
Epoch [9/10], Batch [32/428], Loss: 0.0200
Epoch [9/10], Batch [33/428], Loss: 1.6359
Epoch [9/10], Batch [34/428], Loss: 1.4867
Epoch [9/10], Batch [35/428], Loss: 1.5090
Epoch [9/10], Batch [36/428], Loss: 1.4318
Epoch [9/10], Batch [37/428], Loss: 1.7351
Epoch [9/10], Batch [38/428], Loss: 0.0070
Epoch [9/10], Batch [39/428], Loss: 5.2379
Epoch [9/10], Batch [40/428], Loss: 1.7046
Epoch [9/10], Batch [41/428], Loss: 0.0072
Epoch [9/10], Batch [42/428], Loss: 0.0073
Epoch [9/10], Batch [43/428], Loss: 2.3176
Epoch [9/10], Batch [44/428], Loss: 1.6867
Epoch [9/10], Batch [45/428], Loss: 5.1464
Epoch [9/10], Batch [46/428], Loss: 1.6613
Epoch [9/10], Batch [47/428], Loss: 1.6323
Epoch [9/10], Batch [48/428], Loss: 5.1687
Epoch [9/10], Batch [49/428], Loss: 0.0076
Epoch [9/10], Batch [50/428], Loss: 0.0078
Epoch [9/10], Batch [51/428], Loss: 9.1466
Epoch [9/10], Batch [52/428], Loss: 3.8868
Epoch [9/10], Batch [53/428], Loss: 0.0082
Epoch [9/10], Batch [54/428], Loss: 1.5280
Epoch [9/10], Batch [55/428], Loss: 4.8745
Epoch [9/10], Batch [56/428], Loss: 1.5457
Epoch [9/10], Batch [57/428], Loss: 0.0092
Epoch [9/10], Batch [58/428], Loss: 0.0101
Epoch [9/10], Batch [59/428], Loss: 4.7917
Epoch [9/10], Batch [60/428], Loss: 1.5179
Epoch [9/10], Batch [61/428], Loss: 1.6565
Epoch [9/10], Batch [62/428], Loss: 0.0106
Epoch [9/10], Batch [63/428], Loss: 1.5812
Epoch [9/10], Batch [64/428], Loss: 1.4445
Epoch [9/10], Batch [65/428], Loss: 0.0112
Epoch [9/10], Batch [66/428], Loss: 2.3664
Epoch [9/10], Batch [67/428], Loss: 1.5919
Epoch [9/10], Batch [68/428], Loss: 7.1921
Epoch [9/10], Batch [69/428], Loss: 2.3969
Epoch [9/10], Batch [70/428], Loss: 0.0111
Epoch [9/10], Batch [71/428], Loss: 1.4582
Epoch [9/10], Batch [72/428], Loss: 0.0114
Epoch [9/10], Batch [73/428], Loss: 1.7169
Epoch [9/10], Batch [74/428], Loss: 0.0108
Epoch [9/10], Batch [75/428], Loss: 0.0116
Epoch [9/10], Batch [76/428], Loss: 0.0121
Epoch [9/10], Batch [77/428], Loss: 0.0103
Epoch [9/10], Batch [78/428], Loss: 1.4872
Epoch [9/10], Batch [79/428], Loss: 1.4270
Epoch [9/10], Batch [80/428], Loss: 0.0093
Epoch [9/10], Batch [81/428], Loss: 0.0094
Epoch [9/10], Batch [82/428], Loss: 4.9845
Epoch [9/10], Batch [83/428], Loss: 0.0083
Epoch [9/10], Batch [84/428], Loss: 0.0087
Epoch [9/10], Batch [85/428], Loss: 1.5189
Epoch [9/10], Batch [86/428], Loss: 1.8105
Epoch [9/10], Batch [87/428], Loss: 1.5938
Epoch [9/10], Batch [88/428], Loss: 0.0069
Epoch [9/10], Batch [89/428], Loss: 1.5399
Epoch [9/10], Batch [90/428], Loss: 0.0069
Epoch [9/10], Batch [91/428], Loss: 7.4157
Epoch [9/10], Batch [92/428], Loss: 0.0068
Epoch [9/10], Batch [93/428], Loss: 0.0067
Epoch [9/10], Batch [94/428], Loss: 0.0066
Epoch [9/10], Batch [95/428], Loss: 1.4437
Epoch [9/10], Batch [96/428], Loss: 0.0061
Epoch [9/10], Batch [97/428], Loss: 5.3513
Epoch [9/10], Batch [98/428], Loss: 2.4088
Epoch [9/10], Batch [99/428], Loss: 7.5104
Epoch [9/10], Batch [100/428], Loss: 5.3731
Epoch [9/10], Batch [101/428], Loss: 0.0066
Epoch [9/10], Batch [102/428], Loss: 0.0063
Epoch [9/10], Batch [103/428], Loss: 1.4336
Epoch [9/10], Batch [104/428], Loss: 0.0066
Epoch [9/10], Batch [105/428], Loss: 0.0069
Epoch [9/10], Batch [106/428], Loss: 1.5250
Epoch [9/10], Batch [107/428], Loss: 1.5097
Epoch [9/10], Batch [108/428], Loss: 1.7865
Epoch [9/10], Batch [109/428], Loss: 1.3475
Epoch [9/10], Batch [110/428], Loss: 0.0073
Epoch [9/10], Batch [111/428], Loss: 1.5348
Epoch [9/10], Batch [112/428], Loss: 1.4451
Epoch [9/10], Batch [113/428], Loss: 3.3382
Epoch [9/10], Batch [114/428], Loss: 0.0066
Epoch [9/10], Batch [115/428], Loss: 1.3378
Epoch [9/10], Batch [116/428], Loss: 1.3918
Epoch [9/10], Batch [117/428], Loss: 1.7644
Epoch [9/10], Batch [118/428], Loss: 0.0070
Epoch [9/10], Batch [119/428], Loss: 4.9481
Epoch [9/10], Batch [120/428], Loss: 1.6226
Epoch [9/10], Batch [121/428], Loss: 1.6014
Epoch [9/10], Batch [122/428], Loss: 0.0064
Epoch [9/10], Batch [123/428], Loss: 0.0068
Epoch [9/10], Batch [124/428], Loss: 1.6073
Epoch [9/10], Batch [125/428], Loss: 1.6313
Epoch [9/10], Batch [126/428], Loss: 5.3454
Epoch [9/10], Batch [127/428], Loss: 1.3442
Epoch [9/10], Batch [128/428], Loss: 1.3794
Epoch [9/10], Batch [129/428], Loss: 0.0069
Epoch [9/10], Batch [130/428], Loss: 1.2618
Epoch [9/10], Batch [131/428], Loss: 1.8027
Epoch [9/10], Batch [132/428], Loss: 0.0074
Epoch [9/10], Batch [133/428], Loss: 1.8683
Epoch [9/10], Batch [134/428], Loss: 1.5756
Epoch [9/10], Batch [135/428], Loss: 0.0065
Epoch [9/10], Batch [136/428], Loss: 0.0063
Epoch [9/10], Batch [137/428], Loss: 1.2699
Epoch [9/10], Batch [138/428], Loss: 1.5798
Epoch [9/10], Batch [139/428], Loss: 1.6368
Epoch [9/10], Batch [140/428], Loss: 6.7848
Epoch [9/10], Batch [141/428], Loss: 5.3328
Epoch [9/10], Batch [142/428], Loss: 0.0061
Epoch [9/10], Batch [143/428], Loss: 0.0066
Epoch [9/10], Batch [144/428], Loss: 0.0058
Epoch [9/10], Batch [145/428], Loss: 0.0071
Epoch [9/10], Batch [146/428], Loss: 1.4245
Epoch [9/10], Batch [147/428], Loss: 3.4845
Epoch [9/10], Batch [148/428], Loss: 1.2022
Epoch [9/10], Batch [149/428], Loss: 1.4172
Epoch [9/10], Batch [150/428], Loss: 7.2150
Epoch [9/10], Batch [151/428], Loss: 5.3100
Epoch [9/10], Batch [152/428], Loss: 1.3321
Epoch [9/10], Batch [153/428], Loss: 1.2081
Epoch [9/10], Batch [154/428], Loss: 1.2127
Epoch [9/10], Batch [155/428], Loss: 0.0083
Epoch [9/10], Batch [156/428], Loss: 1.1484
Epoch [9/10], Batch [157/428], Loss: 3.3945
Epoch [9/10], Batch [158/428], Loss: 2.6704
Epoch [9/10], Batch [159/428], Loss: 1.1554
Epoch [9/10], Batch [160/428], Loss: 2.6392
Epoch [9/10], Batch [161/428], Loss: 1.1098
Epoch [9/10], Batch [162/428], Loss: 0.0113
Epoch [9/10], Batch [163/428], Loss: 1.0804
Epoch [9/10], Batch [164/428], Loss: 2.6305
Epoch [9/10], Batch [165/428], Loss: 0.0081
Epoch [9/10], Batch [166/428], Loss: 2.0238
Epoch [9/10], Batch [167/428], Loss: 1.9301
Epoch [9/10], Batch [168/428], Loss: 0.9915
Epoch [9/10], Batch [169/428], Loss: 0.0080
Epoch [9/10], Batch [170/428], Loss: 0.0075
Epoch [9/10], Batch [171/428], Loss: 3.2302
Epoch [9/10], Batch [172/428], Loss: 1.9601
Epoch [9/10], Batch [173/428], Loss: 1.5744
Epoch [9/10], Batch [174/428], Loss: 1.8894
Epoch [9/10], Batch [175/428], Loss: 0.0068
Epoch [9/10], Batch [176/428], Loss: 0.9266
Epoch [9/10], Batch [177/428], Loss: 3.4475
Epoch [9/10], Batch [178/428], Loss: 5.1887
Epoch [9/10], Batch [179/428], Loss: 4.7582
Epoch [9/10], Batch [180/428], Loss: 2.0847
Epoch [9/10], Batch [181/428], Loss: 0.0069
Epoch [9/10], Batch [182/428], Loss: 0.9547
Epoch [9/10], Batch [183/428], Loss: 1.9835
Epoch [9/10], Batch [184/428], Loss: 5.1455
Epoch [9/10], Batch [185/428], Loss: 5.0819
Epoch [9/10], Batch [186/428], Loss: 2.0939
Epoch [9/10], Batch [187/428], Loss: 1.8517
Epoch [9/10], Batch [188/428], Loss: 1.7325
Epoch [9/10], Batch [189/428], Loss: 0.0145
Epoch [9/10], Batch [190/428], Loss: 2.5114
Epoch [9/10], Batch [191/428], Loss: 4.8959
Epoch [9/10], Batch [192/428], Loss: 0.0091
Epoch [9/10], Batch [193/428], Loss: 0.0088
Epoch [9/10], Batch [194/428], Loss: 1.6278
Epoch [9/10], Batch [195/428], Loss: 1.7721
Epoch [9/10], Batch [196/428], Loss: 3.0541
Epoch [9/10], Batch [197/428], Loss: 2.4800
Epoch [9/10], Batch [198/428], Loss: 0.0091
Epoch [9/10], Batch [199/428], Loss: 5.6283
Epoch [9/10], Batch [200/428], Loss: 1.7265
Epoch [9/10], Batch [201/428], Loss: 2.4122
Epoch [9/10], Batch [202/428], Loss: 1.9192
Epoch [9/10], Batch [203/428], Loss: 1.0941
Epoch [9/10], Batch [204/428], Loss: 2.2118
Epoch [9/10], Batch [205/428], Loss: 4.4608
Epoch [9/10], Batch [206/428], Loss: 1.8467
Epoch [9/10], Batch [207/428], Loss: 0.0103
Epoch [9/10], Batch [208/428], Loss: 4.8556
Epoch [9/10], Batch [209/428], Loss: 2.3578
Epoch [9/10], Batch [210/428], Loss: 1.1044
Epoch [9/10], Batch [211/428], Loss: 1.0975
Epoch [9/10], Batch [212/428], Loss: 2.3664
Epoch [9/10], Batch [213/428], Loss: 1.8226
Epoch [9/10], Batch [214/428], Loss: 1.7565
Epoch [9/10], Batch [215/428], Loss: 1.8617
Epoch [9/10], Batch [216/428], Loss: 2.2506
Epoch [9/10], Batch [217/428], Loss: 0.0118
Epoch [9/10], Batch [218/428], Loss: 1.8665
Epoch [9/10], Batch [219/428], Loss: 4.4589
Epoch [9/10], Batch [220/428], Loss: 0.0120
Epoch [9/10], Batch [221/428], Loss: 0.0120
Epoch [9/10], Batch [222/428], Loss: 1.7555
Epoch [9/10], Batch [223/428], Loss: 1.8327
Epoch [9/10], Batch [224/428], Loss: 1.1784
Epoch [9/10], Batch [225/428], Loss: 1.8395
Epoch [9/10], Batch [226/428], Loss: 1.8063
Epoch [9/10], Batch [227/428], Loss: 1.8103
Epoch [9/10], Batch [228/428], Loss: 1.1902
Epoch [9/10], Batch [229/428], Loss: 1.7721
Epoch [9/10], Batch [230/428], Loss: 1.7998
Epoch [9/10], Batch [231/428], Loss: 0.0109
Epoch [9/10], Batch [232/428], Loss: 0.0106
Epoch [9/10], Batch [233/428], Loss: 1.7519
Epoch [9/10], Batch [234/428], Loss: 1.7499
Epoch [9/10], Batch [235/428], Loss: 1.2079
Epoch [9/10], Batch [236/428], Loss: 1.2056
Epoch [9/10], Batch [237/428], Loss: 0.0097
Epoch [9/10], Batch [238/428], Loss: 1.6306
Epoch [9/10], Batch [239/428], Loss: 1.7707
Epoch [9/10], Batch [240/428], Loss: 2.1954
Epoch [9/10], Batch [241/428], Loss: 1.7300
Epoch [9/10], Batch [242/428], Loss: 2.2089
Epoch [9/10], Batch [243/428], Loss: 1.7701
Epoch [9/10], Batch [244/428], Loss: 2.3935
Epoch [9/10], Batch [245/428], Loss: 1.5774
Epoch [9/10], Batch [246/428], Loss: 2.0376
Epoch [9/10], Batch [247/428], Loss: 1.7348
Epoch [9/10], Batch [248/428], Loss: 0.0075
Epoch [9/10], Batch [249/428], Loss: 2.0964
Epoch [9/10], Batch [250/428], Loss: 0.0200
Epoch [9/10], Batch [251/428], Loss: 1.3368
Epoch [9/10], Batch [252/428], Loss: 2.1100
Epoch [9/10], Batch [253/428], Loss: 0.0074
Epoch [9/10], Batch [254/428], Loss: 1.8450
Epoch [9/10], Batch [255/428], Loss: 1.7236
Epoch [9/10], Batch [256/428], Loss: 4.9234
Epoch [9/10], Batch [257/428], Loss: 1.5026
Epoch [9/10], Batch [258/428], Loss: 1.7345
Epoch [9/10], Batch [259/428], Loss: 1.5254
Epoch [9/10], Batch [260/428], Loss: 1.6868
Epoch [9/10], Batch [261/428], Loss: 0.0072
Epoch [9/10], Batch [262/428], Loss: 1.4145
Epoch [9/10], Batch [263/428], Loss: 1.3940
Epoch [9/10], Batch [264/428], Loss: 1.9757
Epoch [9/10], Batch [265/428], Loss: 0.0129
Epoch [9/10], Batch [266/428], Loss: 4.4862
Epoch [9/10], Batch [267/428], Loss: 1.5908
Epoch [9/10], Batch [268/428], Loss: 1.5450
Epoch [9/10], Batch [269/428], Loss: 2.8122
Epoch [9/10], Batch [270/428], Loss: 0.0086
Epoch [9/10], Batch [271/428], Loss: 1.9641
Epoch [9/10], Batch [272/428], Loss: 1.4086
Epoch [9/10], Batch [273/428], Loss: 1.5096
Epoch [9/10], Batch [274/428], Loss: 0.0062
Epoch [9/10], Batch [275/428], Loss: 1.9635
Epoch [9/10], Batch [276/428], Loss: 0.0067
Epoch [9/10], Batch [277/428], Loss: 3.2422
Epoch [9/10], Batch [278/428], Loss: 0.0060
Epoch [9/10], Batch [279/428], Loss: 3.9547
Epoch [9/10], Batch [280/428], Loss: 1.5227
Epoch [9/10], Batch [281/428], Loss: 1.5527
Epoch [9/10], Batch [282/428], Loss: 1.5469
Epoch [9/10], Batch [283/428], Loss: 0.0067
Epoch [9/10], Batch [284/428], Loss: 5.4680
Epoch [9/10], Batch [285/428], Loss: 5.2927
Epoch [9/10], Batch [286/428], Loss: 1.4212
Epoch [9/10], Batch [287/428], Loss: 1.8157
Epoch [9/10], Batch [288/428], Loss: 1.3343
Epoch [9/10], Batch [289/428], Loss: 1.5617
Epoch [9/10], Batch [290/428], Loss: 0.0059
Epoch [9/10], Batch [291/428], Loss: 1.3815
Epoch [9/10], Batch [292/428], Loss: 1.5527
Epoch [9/10], Batch [293/428], Loss: 0.0070
Epoch [9/10], Batch [294/428], Loss: 1.3178
Epoch [9/10], Batch [295/428], Loss: 5.3799
Epoch [9/10], Batch [296/428], Loss: 1.5734
Epoch [9/10], Batch [297/428], Loss: 2.0559
Epoch [9/10], Batch [298/428], Loss: 1.2739
Epoch [9/10], Batch [299/428], Loss: 0.0065
Epoch [9/10], Batch [300/428], Loss: 1.2296
Epoch [9/10], Batch [301/428], Loss: 1.2253
Epoch [9/10], Batch [302/428], Loss: 0.0098
Epoch [9/10], Batch [303/428], Loss: 5.2184
Epoch [9/10], Batch [304/428], Loss: 1.5563
Epoch [9/10], Batch [305/428], Loss: 2.1572
Epoch [9/10], Batch [306/428], Loss: 1.5640
Epoch [9/10], Batch [307/428], Loss: 5.0444
Epoch [9/10], Batch [308/428], Loss: 1.0777
Epoch [9/10], Batch [309/428], Loss: 2.2018
Epoch [9/10], Batch [310/428], Loss: 1.7462
Epoch [9/10], Batch [311/428], Loss: 1.5612
Epoch [9/10], Batch [312/428], Loss: 1.5259
Epoch [9/10], Batch [313/428], Loss: 2.2775
Epoch [9/10], Batch [314/428], Loss: 0.0093
Epoch [9/10], Batch [315/428], Loss: 2.3626
Epoch [9/10], Batch [316/428], Loss: 0.0089
Epoch [9/10], Batch [317/428], Loss: 1.7866
Epoch [9/10], Batch [318/428], Loss: 2.2774
Epoch [9/10], Batch [319/428], Loss: 1.7837
Epoch [9/10], Batch [320/428], Loss: 4.8911
Epoch [9/10], Batch [321/428], Loss: 1.0934
Epoch [9/10], Batch [322/428], Loss: 2.7857
Epoch [9/10], Batch [323/428], Loss: 2.1567
Epoch [9/10], Batch [324/428], Loss: 1.7125
Epoch [9/10], Batch [325/428], Loss: 3.2822
Epoch [9/10], Batch [326/428], Loss: 1.1242
Epoch [9/10], Batch [327/428], Loss: 2.3324
Epoch [9/10], Batch [328/428], Loss: 1.9985
Epoch [9/10], Batch [329/428], Loss: 4.4586
Epoch [9/10], Batch [330/428], Loss: 1.5812
Epoch [9/10], Batch [331/428], Loss: 1.8669
Epoch [9/10], Batch [332/428], Loss: 2.2666
Epoch [9/10], Batch [333/428], Loss: 0.0119
Epoch [9/10], Batch [334/428], Loss: 1.7160
Epoch [9/10], Batch [335/428], Loss: 0.0109
Epoch [9/10], Batch [336/428], Loss: 1.6071
Epoch [9/10], Batch [337/428], Loss: 0.0102
Epoch [9/10], Batch [338/428], Loss: 1.5380
Epoch [9/10], Batch [339/428], Loss: 1.7333
Epoch [9/10], Batch [340/428], Loss: 0.0096
Epoch [9/10], Batch [341/428], Loss: 1.2575
Epoch [9/10], Batch [342/428], Loss: 0.0092
Epoch [9/10], Batch [343/428], Loss: 4.8838
Epoch [9/10], Batch [344/428], Loss: 1.5178
Epoch [9/10], Batch [345/428], Loss: 1.2756
Epoch [9/10], Batch [346/428], Loss: 1.7512
Epoch [9/10], Batch [347/428], Loss: 0.0087
Epoch [9/10], Batch [348/428], Loss: 1.7163
Epoch [9/10], Batch [349/428], Loss: 0.0084
Epoch [9/10], Batch [350/428], Loss: 1.7143
Epoch [9/10], Batch [351/428], Loss: 6.3063
Epoch [9/10], Batch [352/428], Loss: 1.6851
Epoch [9/10], Batch [353/428], Loss: 0.0079
Epoch [9/10], Batch [354/428], Loss: 5.9179
Epoch [9/10], Batch [355/428], Loss: 1.5525
Epoch [9/10], Batch [356/428], Loss: 1.5941
Epoch [9/10], Batch [357/428], Loss: 1.3405
Epoch [9/10], Batch [358/428], Loss: 2.1112
Epoch [9/10], Batch [359/428], Loss: 1.5015
Epoch [9/10], Batch [360/428], Loss: 1.3042
Epoch [9/10], Batch [361/428], Loss: 3.0303
Epoch [9/10], Batch [362/428], Loss: 0.0082
Epoch [9/10], Batch [363/428], Loss: 4.9834
Epoch [9/10], Batch [364/428], Loss: 2.0644
Epoch [9/10], Batch [365/428], Loss: 0.0079
Epoch [9/10], Batch [366/428], Loss: 1.5201
Epoch [9/10], Batch [367/428], Loss: 1.5239
Epoch [9/10], Batch [368/428], Loss: 0.0087
Epoch [9/10], Batch [369/428], Loss: 2.0483
Epoch [9/10], Batch [370/428], Loss: 1.9587
Epoch [9/10], Batch [371/428], Loss: 1.4579
Epoch [9/10], Batch [372/428], Loss: 1.3882
Epoch [9/10], Batch [373/428], Loss: 0.0081
Epoch [9/10], Batch [374/428], Loss: 2.7521
Epoch [9/10], Batch [375/428], Loss: 1.4616
Epoch [9/10], Batch [376/428], Loss: 1.3668
Epoch [9/10], Batch [377/428], Loss: 1.3324
Epoch [9/10], Batch [378/428], Loss: 0.0074
Epoch [9/10], Batch [379/428], Loss: 1.9718[INFO 06-13 19:35:30] ax.service.ax_client: Completed trial 6 with data: {'objective': (np.float64(-0.418226), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.
  warn("Encountered exception in computing model fit quality: " + str(e))
[INFO 06-13 19:35:30] ax.service.ax_client: Generated new trial 7 with parameters {'lr': 1.4e-05, 'num_epochs': 2, 'unfreeze_epoch': 4, 'max_length': 112000} using model Sobol.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [9/10], Batch [380/428], Loss: 3.1238
Epoch [9/10], Batch [381/428], Loss: 1.8646
Epoch [9/10], Batch [382/428], Loss: 0.5990
Epoch [9/10], Batch [383/428], Loss: 1.9740
Epoch [9/10], Batch [384/428], Loss: 3.4169
Epoch [9/10], Batch [385/428], Loss: 0.0069
Epoch [9/10], Batch [386/428], Loss: 0.3649
Epoch [9/10], Batch [387/428], Loss: 1.4993
Epoch [9/10], Batch [388/428], Loss: 1.3423
Epoch [9/10], Batch [389/428], Loss: 1.5153
Epoch [9/10], Batch [390/428], Loss: 2.7791
Epoch [9/10], Batch [391/428], Loss: 2.5697
Epoch [9/10], Batch [392/428], Loss: 1.7310
Epoch [9/10], Batch [393/428], Loss: 1.6154
Epoch [9/10], Batch [394/428], Loss: 1.5844
Epoch [9/10], Batch [395/428], Loss: 1.3768
Epoch [9/10], Batch [396/428], Loss: 0.0065
Epoch [9/10], Batch [397/428], Loss: 1.5238
Epoch [9/10], Batch [398/428], Loss: 0.0067
Epoch [9/10], Batch [399/428], Loss: 1.6113
Epoch [9/10], Batch [400/428], Loss: 5.2504
Epoch [9/10], Batch [401/428], Loss: 2.5169
Epoch [9/10], Batch [402/428], Loss: 0.0062
Epoch [9/10], Batch [403/428], Loss: 2.6207
Epoch [9/10], Batch [404/428], Loss: 0.0069
Epoch [9/10], Batch [405/428], Loss: 1.6109
Epoch [9/10], Batch [406/428], Loss: 1.7156
Epoch [9/10], Batch [407/428], Loss: 5.2339
Epoch [9/10], Batch [408/428], Loss: 1.5594
Epoch [9/10], Batch [409/428], Loss: 1.7051
Epoch [9/10], Batch [410/428], Loss: 7.5678
Epoch [9/10], Batch [411/428], Loss: 1.4501
Epoch [9/10], Batch [412/428], Loss: 1.4532
Epoch [9/10], Batch [413/428], Loss: 1.4457
Epoch [9/10], Batch [414/428], Loss: 1.5938
Epoch [9/10], Batch [415/428], Loss: 5.1038
Epoch [9/10], Batch [416/428], Loss: 4.1652
Epoch [9/10], Batch [417/428], Loss: 1.4228
Epoch [9/10], Batch [418/428], Loss: 0.0096
Epoch [9/10], Batch [419/428], Loss: 5.7532
Epoch [9/10], Batch [420/428], Loss: 1.6354
Epoch [9/10], Batch [421/428], Loss: 3.7295
Epoch [9/10], Batch [422/428], Loss: 1.4911
Epoch [9/10], Batch [423/428], Loss: 1.3102
Epoch [9/10], Batch [424/428], Loss: 2.5677
Epoch [9/10], Batch [425/428], Loss: 1.5052
Epoch [9/10], Batch [426/428], Loss: 0.0128
Epoch [9/10], Batch [427/428], Loss: 4.4728
Epoch [9/10], Batch [428/428], Loss: 1.2671
Epoch [9] Training Time: 165.18 seconds
Epoch [9/10], Average Loss: 1.7997, Training Accuracy: 0.3925
Epoch [9], Validation Loss: 1.8855, Validation Accuracy: 0.2831
Epoch [9] Validation Time: 5.48 seconds
--------------------------------------------------
Epoch [10/10], Batch [1/428], Loss: 0.0212
Epoch [10/10], Batch [2/428], Loss: 1.4712
Epoch [10/10], Batch [3/428], Loss: 1.6218
Epoch [10/10], Batch [4/428], Loss: 3.5018
Epoch [10/10], Batch [5/428], Loss: 4.5466
Epoch [10/10], Batch [6/428], Loss: 1.2886
Epoch [10/10], Batch [7/428], Loss: 1.6232
Epoch [10/10], Batch [8/428], Loss: 0.0138
Epoch [10/10], Batch [9/428], Loss: 0.0135
Epoch [10/10], Batch [10/428], Loss: 1.2333
Epoch [10/10], Batch [11/428], Loss: 1.6290
Epoch [10/10], Batch [12/428], Loss: 0.0128
Epoch [10/10], Batch [13/428], Loss: 1.4739
Epoch [10/10], Batch [14/428], Loss: 1.2840
Epoch [10/10], Batch [15/428], Loss: 1.2395
Epoch [10/10], Batch [16/428], Loss: 0.0126
Epoch [10/10], Batch [17/428], Loss: 1.4429
Epoch [10/10], Batch [18/428], Loss: 1.2253
Epoch [10/10], Batch [19/428], Loss: 0.0124
Epoch [10/10], Batch [20/428], Loss: 3.0739
Epoch [10/10], Batch [21/428], Loss: 0.0124
Epoch [10/10], Batch [22/428], Loss: 1.5605
Epoch [10/10], Batch [23/428], Loss: 1.4831
Epoch [10/10], Batch [24/428], Loss: 0.0120
Epoch [10/10], Batch [25/428], Loss: 1.6724
Epoch [10/10], Batch [26/428], Loss: 0.0115
Epoch [10/10], Batch [27/428], Loss: 4.6362
Epoch [10/10], Batch [28/428], Loss: 1.4973
Epoch [10/10], Batch [29/428], Loss: 0.0110
Epoch [10/10], Batch [30/428], Loss: 0.0110
Epoch [10/10], Batch [31/428], Loss: 2.3363
Epoch [10/10], Batch [32/428], Loss: 0.0115
Epoch [10/10], Batch [33/428], Loss: 0.0112
Epoch [10/10], Batch [34/428], Loss: 0.0132
Epoch [10/10], Batch [35/428], Loss: 2.2166
Epoch [10/10], Batch [36/428], Loss: 2.5267
Epoch [10/10], Batch [37/428], Loss: 1.2672
Epoch [10/10], Batch [38/428], Loss: 3.8530
Epoch [10/10], Batch [39/428], Loss: 1.1995
Epoch [10/10], Batch [40/428], Loss: 1.5841
Epoch [10/10], Batch [41/428], Loss: 1.5533
Epoch [10/10], Batch [42/428], Loss: 4.7194
Epoch [10/10], Batch [43/428], Loss: 1.5951
Epoch [10/10], Batch [44/428], Loss: 1.4513
Epoch [10/10], Batch [45/428], Loss: 2.6109
Epoch [10/10], Batch [46/428], Loss: 2.5498
Epoch [10/10], Batch [47/428], Loss: 3.5157
Epoch [10/10], Batch [48/428], Loss: 2.6053
Epoch [10/10], Batch [49/428], Loss: 0.0106
Epoch [10/10], Batch [50/428], Loss: 1.6187
Epoch [10/10], Batch [51/428], Loss: 1.4500
Epoch [10/10], Batch [52/428], Loss: 1.8186
Epoch [10/10], Batch [53/428], Loss: 0.0108
Epoch [10/10], Batch [54/428], Loss: 4.7352
Epoch [10/10], Batch [55/428], Loss: 1.2350
Epoch [10/10], Batch [56/428], Loss: 1.5924
Epoch [10/10], Batch [57/428], Loss: 0.0108
Epoch [10/10], Batch [58/428], Loss: 1.2505
Epoch [10/10], Batch [59/428], Loss: 1.2304
Epoch [10/10], Batch [60/428], Loss: 0.0105
Epoch [10/10], Batch [61/428], Loss: 1.1297
Epoch [10/10], Batch [62/428], Loss: 1.4604
Epoch [10/10], Batch [63/428], Loss: 1.6604
Epoch [10/10], Batch [64/428], Loss: 0.0103
Epoch [10/10], Batch [65/428], Loss: 1.4745
Epoch [10/10], Batch [66/428], Loss: 1.4486
Epoch [10/10], Batch [67/428], Loss: 2.5132
Epoch [10/10], Batch [68/428], Loss: 0.0098
Epoch [10/10], Batch [69/428], Loss: 2.1769
Epoch [10/10], Batch [70/428], Loss: 4.8826
Epoch [10/10], Batch [71/428], Loss: 1.4767
Epoch [10/10], Batch [72/428], Loss: 0.0336
Epoch [10/10], Batch [73/428], Loss: 1.4340
Epoch [10/10], Batch [74/428], Loss: 0.0103
Epoch [10/10], Batch [75/428], Loss: 1.6096
Epoch [10/10], Batch [76/428], Loss: 1.3945
Epoch [10/10], Batch [77/428], Loss: 1.9525
Epoch [10/10], Batch [78/428], Loss: 1.5899
Epoch [10/10], Batch [79/428], Loss: 1.5332
Epoch [10/10], Batch [80/428], Loss: 1.2971
Epoch [10/10], Batch [81/428], Loss: 2.5162
Epoch [10/10], Batch [82/428], Loss: 1.2708
Epoch [10/10], Batch [83/428], Loss: 1.2907
Epoch [10/10], Batch [84/428], Loss: 0.0096
Epoch [10/10], Batch [85/428], Loss: 1.6728
Epoch [10/10], Batch [86/428], Loss: 1.9666
Epoch [10/10], Batch [87/428], Loss: 1.6882
Epoch [10/10], Batch [88/428], Loss: 0.0096
Epoch [10/10], Batch [89/428], Loss: 0.0090
Epoch [10/10], Batch [90/428], Loss: 2.5751
Epoch [10/10], Batch [91/428], Loss: 2.1943
Epoch [10/10], Batch [92/428], Loss: 0.0097
Epoch [10/10], Batch [93/428], Loss: 1.1959
Epoch [10/10], Batch [94/428], Loss: 1.2668
Epoch [10/10], Batch [95/428], Loss: 0.0097
Epoch [10/10], Batch [96/428], Loss: 3.6067
Epoch [10/10], Batch [97/428], Loss: 1.4217
Epoch [10/10], Batch [98/428], Loss: 1.2023
Epoch [10/10], Batch [99/428], Loss: 1.2284
Epoch [10/10], Batch [100/428], Loss: 2.1847
Epoch [10/10], Batch [101/428], Loss: 1.2458
Epoch [10/10], Batch [102/428], Loss: 1.1889
Epoch [10/10], Batch [103/428], Loss: 0.0085
Epoch [10/10], Batch [104/428], Loss: 0.0086
Epoch [10/10], Batch [105/428], Loss: 1.6894
Epoch [10/10], Batch [106/428], Loss: 0.0092
Epoch [10/10], Batch [107/428], Loss: 0.0085
Epoch [10/10], Batch [108/428], Loss: 1.2633
Epoch [10/10], Batch [109/428], Loss: 1.1136
Epoch [10/10], Batch [110/428], Loss: 2.0683
Epoch [10/10], Batch [111/428], Loss: 1.1359
Epoch [10/10], Batch [112/428], Loss: 4.9939
Epoch [10/10], Batch [113/428], Loss: 1.1744
Epoch [10/10], Batch [114/428], Loss: 1.8197
Epoch [10/10], Batch [115/428], Loss: 1.3421
Epoch [10/10], Batch [116/428], Loss: 0.0085
Epoch [10/10], Batch [117/428], Loss: 1.5808
Epoch [10/10], Batch [118/428], Loss: 1.6382
Epoch [10/10], Batch [119/428], Loss: 1.1035
Epoch [10/10], Batch [120/428], Loss: 2.5443
Epoch [10/10], Batch [121/428], Loss: 0.0082
Epoch [10/10], Batch [122/428], Loss: 0.0084
Epoch [10/10], Batch [123/428], Loss: 1.7012
Epoch [10/10], Batch [124/428], Loss: 1.6392
Epoch [10/10], Batch [125/428], Loss: 0.0083
Epoch [10/10], Batch [126/428], Loss: 1.5631
Epoch [10/10], Batch [127/428], Loss: 1.9432
Epoch [10/10], Batch [128/428], Loss: 0.0085
Epoch [10/10], Batch [129/428], Loss: 0.0081
Epoch [10/10], Batch [130/428], Loss: 1.6737
Epoch [10/10], Batch [131/428], Loss: 5.0977
Epoch [10/10], Batch [132/428], Loss: 3.7354
Epoch [10/10], Batch [133/428], Loss: 2.8263
Epoch [10/10], Batch [134/428], Loss: 0.0079
Epoch [10/10], Batch [135/428], Loss: 2.6321
Epoch [10/10], Batch [136/428], Loss: 2.5360
Epoch [10/10], Batch [137/428], Loss: 1.6887
Epoch [10/10], Batch [138/428], Loss: 1.8948
Epoch [10/10], Batch [139/428], Loss: 1.0806
Epoch [10/10], Batch [140/428], Loss: 2.5784
Epoch [10/10], Batch [141/428], Loss: 0.0071
Epoch [10/10], Batch [142/428], Loss: 1.7241
Epoch [10/10], Batch [143/428], Loss: 0.0075
Epoch [10/10], Batch [144/428], Loss: 1.0589
Epoch [10/10], Batch [145/428], Loss: 1.7068
Epoch [10/10], Batch [146/428], Loss: 0.0077
Epoch [10/10], Batch [147/428], Loss: 0.0072
Epoch [10/10], Batch [148/428], Loss: 1.6171
Epoch [10/10], Batch [149/428], Loss: 1.5677
Epoch [10/10], Batch [150/428], Loss: 2.2412
Epoch [10/10], Batch [151/428], Loss: 1.6190
Epoch [10/10], Batch [152/428], Loss: 1.5474
Epoch [10/10], Batch [153/428], Loss: 1.6644
Epoch [10/10], Batch [154/428], Loss: 1.5827
Epoch [10/10], Batch [155/428], Loss: 5.1151
Epoch [10/10], Batch [156/428], Loss: 1.9410
Epoch [10/10], Batch [157/428], Loss: 1.8015
Epoch [10/10], Batch [158/428], Loss: 1.1792
Epoch [10/10], Batch [159/428], Loss: 2.2826
Epoch [10/10], Batch [160/428], Loss: 2.5729
Epoch [10/10], Batch [161/428], Loss: 0.0071
Epoch [10/10], Batch [162/428], Loss: 1.5706
Epoch [10/10], Batch [163/428], Loss: 4.5655
Epoch [10/10], Batch [164/428], Loss: 0.0077
Epoch [10/10], Batch [165/428], Loss: 0.0082
Epoch [10/10], Batch [166/428], Loss: 1.5519
Epoch [10/10], Batch [167/428], Loss: 0.0072
Epoch [10/10], Batch [168/428], Loss: 1.1407
Epoch [10/10], Batch [169/428], Loss: 1.1404
Epoch [10/10], Batch [170/428], Loss: 1.9355
Epoch [10/10], Batch [171/428], Loss: 1.8851
Epoch [10/10], Batch [172/428], Loss: 0.0078
Epoch [10/10], Batch [173/428], Loss: 1.1087
Epoch [10/10], Batch [174/428], Loss: 0.0303
Epoch [10/10], Batch [175/428], Loss: 1.4426
Epoch [10/10], Batch [176/428], Loss: 0.0075
Epoch [10/10], Batch [177/428], Loss: 1.1518
Epoch [10/10], Batch [178/428], Loss: 1.5799
Epoch [10/10], Batch [179/428], Loss: 1.8924
Epoch [10/10], Batch [180/428], Loss: 3.1087
Epoch [10/10], Batch [181/428], Loss: 0.0074
Epoch [10/10], Batch [182/428], Loss: 1.0596
Epoch [10/10], Batch [183/428], Loss: 1.8407
Epoch [10/10], Batch [184/428], Loss: 1.5700
Epoch [10/10], Batch [185/428], Loss: 0.0071
Epoch [10/10], Batch [186/428], Loss: 5.1783
Epoch [10/10], Batch [187/428], Loss: 0.0074
Epoch [10/10], Batch [188/428], Loss: 1.6410
Epoch [10/10], Batch [189/428], Loss: 0.0067
Epoch [10/10], Batch [190/428], Loss: 2.5903
Epoch [10/10], Batch [191/428], Loss: 1.5909
Epoch [10/10], Batch [192/428], Loss: 2.1826
Epoch [10/10], Batch [193/428], Loss: 1.5988
Epoch [10/10], Batch [194/428], Loss: 0.0064
Epoch [10/10], Batch [195/428], Loss: 1.6206
Epoch [10/10], Batch [196/428], Loss: 1.6444
Epoch [10/10], Batch [197/428], Loss: 0.0069
Epoch [10/10], Batch [198/428], Loss: 0.0069
Epoch [10/10], Batch [199/428], Loss: 2.5542
Epoch [10/10], Batch [200/428], Loss: 1.5740
Epoch [10/10], Batch [201/428], Loss: 1.1202
Epoch [10/10], Batch [202/428], Loss: 1.5969
Epoch [10/10], Batch [203/428], Loss: 0.0075
Epoch [10/10], Batch [204/428], Loss: 1.6536
Epoch [10/10], Batch [205/428], Loss: 0.0068
Epoch [10/10], Batch [206/428], Loss: 1.5332
Epoch [10/10], Batch [207/428], Loss: 1.5965
Epoch [10/10], Batch [208/428], Loss: 2.6038
Epoch [10/10], Batch [209/428], Loss: 1.6086
Epoch [10/10], Batch [210/428], Loss: 1.6284
Epoch [10/10], Batch [211/428], Loss: 1.4910
Epoch [10/10], Batch [212/428], Loss: 1.5595
Epoch [10/10], Batch [213/428], Loss: 2.2416
Epoch [10/10], Batch [214/428], Loss: 1.6117
Epoch [10/10], Batch [215/428], Loss: 1.5055
Epoch [10/10], Batch [216/428], Loss: 1.7072
Epoch [10/10], Batch [217/428], Loss: 0.0065
Epoch [10/10], Batch [218/428], Loss: 1.5244
Epoch [10/10], Batch [219/428], Loss: 1.4900
Epoch [10/10], Batch [220/428], Loss: 5.2452
Epoch [10/10], Batch [221/428], Loss: 1.4238
Epoch [10/10], Batch [222/428], Loss: 2.5614
Epoch [10/10], Batch [223/428], Loss: 1.1450
Epoch [10/10], Batch [224/428], Loss: 2.2834
Epoch [10/10], Batch [225/428], Loss: 7.3929
Epoch [10/10], Batch [226/428], Loss: 1.5415
Epoch [10/10], Batch [227/428], Loss: 5.1361
Epoch [10/10], Batch [228/428], Loss: 0.0066
Epoch [10/10], Batch [229/428], Loss: 1.5350
Epoch [10/10], Batch [230/428], Loss: 1.4611
Epoch [10/10], Batch [231/428], Loss: 1.4617
Epoch [10/10], Batch [232/428], Loss: 1.6825
Epoch [10/10], Batch [233/428], Loss: 2.2313
Epoch [10/10], Batch [234/428], Loss: 0.0075
Epoch [10/10], Batch [235/428], Loss: 1.6090
Epoch [10/10], Batch [236/428], Loss: 1.6727
Epoch [10/10], Batch [237/428], Loss: 1.6023
Epoch [10/10], Batch [238/428], Loss: 1.4090
Epoch [10/10], Batch [239/428], Loss: 2.1920
Epoch [10/10], Batch [240/428], Loss: 1.1787
Epoch [10/10], Batch [241/428], Loss: 1.2052
Epoch [10/10], Batch [242/428], Loss: 1.9088
Epoch [10/10], Batch [243/428], Loss: 0.0078
Epoch [10/10], Batch [244/428], Loss: 0.0074
Epoch [10/10], Batch [245/428], Loss: 1.9051
Epoch [10/10], Batch [246/428], Loss: 0.0072
Epoch [10/10], Batch [247/428], Loss: 2.1909
Epoch [10/10], Batch [248/428], Loss: 1.5523
Epoch [10/10], Batch [249/428], Loss: 0.0076
Epoch [10/10], Batch [250/428], Loss: 1.5146
Epoch [10/10], Batch [251/428], Loss: 1.5580
Epoch [10/10], Batch [252/428], Loss: 0.0079
Epoch [10/10], Batch [253/428], Loss: 1.4985
Epoch [10/10], Batch [254/428], Loss: 1.5843
Epoch [10/10], Batch [255/428], Loss: 1.6247
Epoch [10/10], Batch [256/428], Loss: 1.4937
Epoch [10/10], Batch [257/428], Loss: 0.0073
Epoch [10/10], Batch [258/428], Loss: 1.3931
Epoch [10/10], Batch [259/428], Loss: 2.3279
Epoch [10/10], Batch [260/428], Loss: 1.5470
Epoch [10/10], Batch [261/428], Loss: 0.0075
Epoch [10/10], Batch [262/428], Loss: 2.0767
Epoch [10/10], Batch [263/428], Loss: 2.1929
Epoch [10/10], Batch [264/428], Loss: 1.8683
Epoch [10/10], Batch [265/428], Loss: 1.2630
Epoch [10/10], Batch [266/428], Loss: 1.3003
Epoch [10/10], Batch [267/428], Loss: 2.1158
Epoch [10/10], Batch [268/428], Loss: 1.3229
Epoch [10/10], Batch [269/428], Loss: 1.2572
Epoch [10/10], Batch [270/428], Loss: 0.8445
Epoch [10/10], Batch [271/428], Loss: 0.5457
Epoch [10/10], Batch [272/428], Loss: 1.8010
Epoch [10/10], Batch [273/428], Loss: 2.4502
Epoch [10/10], Batch [274/428], Loss: 5.1207
Epoch [10/10], Batch [275/428], Loss: 0.0566
Epoch [10/10], Batch [276/428], Loss: 0.0074
Epoch [10/10], Batch [277/428], Loss: 1.2504
Epoch [10/10], Batch [278/428], Loss: 0.0072
Epoch [10/10], Batch [279/428], Loss: 1.8577
Epoch [10/10], Batch [280/428], Loss: 1.4969
Epoch [10/10], Batch [281/428], Loss: 1.4364
Epoch [10/10], Batch [282/428], Loss: 1.4508
Epoch [10/10], Batch [283/428], Loss: 2.0904
Epoch [10/10], Batch [284/428], Loss: 1.4875
Epoch [10/10], Batch [285/428], Loss: 7.7171
Epoch [10/10], Batch [286/428], Loss: 1.6385
Epoch [10/10], Batch [287/428], Loss: 1.2190
Epoch [10/10], Batch [288/428], Loss: 1.4640
Epoch [10/10], Batch [289/428], Loss: 1.4428
Epoch [10/10], Batch [290/428], Loss: 0.7734
Epoch [10/10], Batch [291/428], Loss: 1.4959
Epoch [10/10], Batch [292/428], Loss: 0.0075
Epoch [10/10], Batch [293/428], Loss: 1.4090
Epoch [10/10], Batch [294/428], Loss: 1.5994
Epoch [10/10], Batch [295/428], Loss: 0.0079
Epoch [10/10], Batch [296/428], Loss: 2.0472
Epoch [10/10], Batch [297/428], Loss: 0.0085
Epoch [10/10], Batch [298/428], Loss: 0.5044
Epoch [10/10], Batch [299/428], Loss: 0.0078
Epoch [10/10], Batch [300/428], Loss: 1.4637
Epoch [10/10], Batch [301/428], Loss: 0.0076
Epoch [10/10], Batch [302/428], Loss: 1.7184
Epoch [10/10], Batch [303/428], Loss: 1.4303
Epoch [10/10], Batch [304/428], Loss: 2.7023
Epoch [10/10], Batch [305/428], Loss: 1.4691
Epoch [10/10], Batch [306/428], Loss: 1.3722
Epoch [10/10], Batch [307/428], Loss: 2.7460
Epoch [10/10], Batch [308/428], Loss: 2.4204
Epoch [10/10], Batch [309/428], Loss: 1.3819
Epoch [10/10], Batch [310/428], Loss: 1.4047
Epoch [10/10], Batch [311/428], Loss: 0.0074
Epoch [10/10], Batch [312/428], Loss: 1.9305
Epoch [10/10], Batch [313/428], Loss: 1.3470
Epoch [10/10], Batch [314/428], Loss: 2.2251
Epoch [10/10], Batch [315/428], Loss: 1.7827
Epoch [10/10], Batch [316/428], Loss: 1.4871
Epoch [10/10], Batch [317/428], Loss: 0.0069
Epoch [10/10], Batch [318/428], Loss: 1.4652
Epoch [10/10], Batch [319/428], Loss: 1.3430
Epoch [10/10], Batch [320/428], Loss: 1.3779
Epoch [10/10], Batch [321/428], Loss: 1.3363
Epoch [10/10], Batch [322/428], Loss: 1.2839
Epoch [10/10], Batch [323/428], Loss: 3.3268
Epoch [10/10], Batch [324/428], Loss: 0.0069
Epoch [10/10], Batch [325/428], Loss: 1.4278
Epoch [10/10], Batch [326/428], Loss: 2.2317
Epoch [10/10], Batch [327/428], Loss: 0.0069
Epoch [10/10], Batch [328/428], Loss: 0.0070
Epoch [10/10], Batch [329/428], Loss: 2.8234
Epoch [10/10], Batch [330/428], Loss: 1.3726
Epoch [10/10], Batch [331/428], Loss: 2.3180
Epoch [10/10], Batch [332/428], Loss: 5.1953
Epoch [10/10], Batch [333/428], Loss: 1.4228
Epoch [10/10], Batch [334/428], Loss: 2.5867
Epoch [10/10], Batch [335/428], Loss: 1.7995
Epoch [10/10], Batch [336/428], Loss: 0.0067
Epoch [10/10], Batch [337/428], Loss: 1.4400
Epoch [10/10], Batch [338/428], Loss: 1.4617
Epoch [10/10], Batch [339/428], Loss: 1.4102
Epoch [10/10], Batch [340/428], Loss: 0.0068
Epoch [10/10], Batch [341/428], Loss: 2.3828
Epoch [10/10], Batch [342/428], Loss: 2.2237
Epoch [10/10], Batch [343/428], Loss: 1.4334
Epoch [10/10], Batch [344/428], Loss: 0.8111
Epoch [10/10], Batch [345/428], Loss: 5.2116
Epoch [10/10], Batch [346/428], Loss: 1.3572
Epoch [10/10], Batch [347/428], Loss: 1.7743
Epoch [10/10], Batch [348/428], Loss: 2.1171
Epoch [10/10], Batch [349/428], Loss: 2.3416
Epoch [10/10], Batch [350/428], Loss: 5.1515
Epoch [10/10], Batch [351/428], Loss: 1.4114
Epoch [10/10], Batch [352/428], Loss: 1.6815
Epoch [10/10], Batch [353/428], Loss: 0.0073
Epoch [10/10], Batch [354/428], Loss: 1.4773
Epoch [10/10], Batch [355/428], Loss: 1.4257
Epoch [10/10], Batch [356/428], Loss: 1.4879
Epoch [10/10], Batch [357/428], Loss: 1.4383
Epoch [10/10], Batch [358/428], Loss: 1.4149
Epoch [10/10], Batch [359/428], Loss: 0.0073
Epoch [10/10], Batch [360/428], Loss: 1.4261
Epoch [10/10], Batch [361/428], Loss: 1.4301
Epoch [10/10], Batch [362/428], Loss: 1.3001
Epoch [10/10], Batch [363/428], Loss: 0.0078
Epoch [10/10], Batch [364/428], Loss: 1.5181
Epoch [10/10], Batch [365/428], Loss: 0.0078
Epoch [10/10], Batch [366/428], Loss: 2.1830
Epoch [10/10], Batch [367/428], Loss: 2.6182
Epoch [10/10], Batch [368/428], Loss: 1.3769
Epoch [10/10], Batch [369/428], Loss: 5.0577
Epoch [10/10], Batch [370/428], Loss: 1.3687
Epoch [10/10], Batch [371/428], Loss: 1.3682
Epoch [10/10], Batch [372/428], Loss: 5.1577
Epoch [10/10], Batch [373/428], Loss: 2.1225
Epoch [10/10], Batch [374/428], Loss: 0.0077
Epoch [10/10], Batch [375/428], Loss: 2.0019
Epoch [10/10], Batch [376/428], Loss: 2.5732
Epoch [10/10], Batch [377/428], Loss: 0.0078
Epoch [10/10], Batch [378/428], Loss: 2.0582
Epoch [10/10], Batch [379/428], Loss: 0.0084
Epoch [10/10], Batch [380/428], Loss: 1.4316
Epoch [10/10], Batch [381/428], Loss: 3.5486
Epoch [10/10], Batch [382/428], Loss: 1.3944
Epoch [10/10], Batch [383/428], Loss: 2.0458
Epoch [10/10], Batch [384/428], Loss: 2.2811
Epoch [10/10], Batch [385/428], Loss: 1.6167
Epoch [10/10], Batch [386/428], Loss: 1.5719
Epoch [10/10], Batch [387/428], Loss: 1.4172
Epoch [10/10], Batch [388/428], Loss: 0.0085
Epoch [10/10], Batch [389/428], Loss: 1.2912
Epoch [10/10], Batch [390/428], Loss: 1.4586
Epoch [10/10], Batch [391/428], Loss: 1.4815
Epoch [10/10], Batch [392/428], Loss: 1.3502
Epoch [10/10], Batch [393/428], Loss: 2.2972
Epoch [10/10], Batch [394/428], Loss: 1.3825
Epoch [10/10], Batch [395/428], Loss: 0.0084
Epoch [10/10], Batch [396/428], Loss: 1.4088
Epoch [10/10], Batch [397/428], Loss: 1.4101
Epoch [10/10], Batch [398/428], Loss: 0.0080
Epoch [10/10], Batch [399/428], Loss: 2.3072
Epoch [10/10], Batch [400/428], Loss: 1.6057
Epoch [10/10], Batch [401/428], Loss: 2.1959
Epoch [10/10], Batch [402/428], Loss: 1.3892
Epoch [10/10], Batch [403/428], Loss: 2.1843
Epoch [10/10], Batch [404/428], Loss: 2.1239
Epoch [10/10], Batch [405/428], Loss: 1.9318
Epoch [10/10], Batch [406/428], Loss: 1.9188
Epoch [10/10], Batch [407/428], Loss: 1.5832
Epoch [10/10], Batch [408/428], Loss: 0.0088
Epoch [10/10], Batch [409/428], Loss: 1.5138
Epoch [10/10], Batch [410/428], Loss: 1.4938
Epoch [10/10], Batch [411/428], Loss: 1.0091
Epoch [10/10], Batch [412/428], Loss: 1.5453
Epoch [10/10], Batch [413/428], Loss: 1.9714
Epoch [10/10], Batch [414/428], Loss: 1.2534
Epoch [10/10], Batch [415/428], Loss: 0.1212
Epoch [10/10], Batch [416/428], Loss: 1.3882
Epoch [10/10], Batch [417/428], Loss: 1.5186
Epoch [10/10], Batch [418/428], Loss: 0.0077
Epoch [10/10], Batch [419/428], Loss: 2.2359
Epoch [10/10], Batch [420/428], Loss: 0.0078
Epoch [10/10], Batch [421/428], Loss: 0.0081
Epoch [10/10], Batch [422/428], Loss: 1.9033
Epoch [10/10], Batch [423/428], Loss: 0.0074
Epoch [10/10], Batch [424/428], Loss: 1.4114
Epoch [10/10], Batch [425/428], Loss: 0.1055
Epoch [10/10], Batch [426/428], Loss: 5.1369
Epoch [10/10], Batch [427/428], Loss: 0.0073
Epoch [10/10], Batch [428/428], Loss: 1.3870
Epoch [10] Training Time: 160.93 seconds
Epoch [10/10], Average Loss: 1.4875, Training Accuracy: 0.4019
Epoch [10], Validation Loss: 1.7300, Validation Accuracy: 0.4182
Epoch [10] Validation Time: 5.63 seconds
--------------------------------------------------

Running trial 7 with config: {'batch_size': 1, 'lr': 1.4332693750513623e-05, 'num_epochs': 2, 'unfreeze_epoch': 4, 'max_length': 112000, 'device': device(type='cpu')}
Epoch [1/2], Batch [1/428], Loss: 4.7861
Epoch [1/2], Batch [2/428], Loss: 4.9334
Epoch [1/2], Batch [3/428], Loss: 2.4627
Epoch [1/2], Batch [4/428], Loss: 3.4131
Epoch [1/2], Batch [5/428], Loss: 3.1078
Epoch [1/2], Batch [6/428], Loss: 2.7271
Epoch [1/2], Batch [7/428], Loss: 2.5270
Epoch [1/2], Batch [8/428], Loss: 2.3395
Epoch [1/2], Batch [9/428], Loss: 3.1362
Epoch [1/2], Batch [10/428], Loss: 3.8481
Epoch [1/2], Batch [11/428], Loss: 1.4429
Epoch [1/2], Batch [12/428], Loss: 4.5654
Epoch [1/2], Batch [13/428], Loss: 4.3954
Epoch [1/2], Batch [14/428], Loss: 4.1079
Epoch [1/2], Batch [15/428], Loss: 2.1743
Epoch [1/2], Batch [16/428], Loss: 1.4782
Epoch [1/2], Batch [17/428], Loss: 4.7155
Epoch [1/2], Batch [18/428], Loss: 1.9565
Epoch [1/2], Batch [19/428], Loss: 2.5477
Epoch [1/2], Batch [20/428], Loss: 1.1316
Epoch [1/2], Batch [21/428], Loss: 0.7672
Epoch [1/2], Batch [22/428], Loss: 3.6814
Epoch [1/2], Batch [23/428], Loss: 2.2112
Epoch [1/2], Batch [24/428], Loss: 3.0367
Epoch [1/2], Batch [25/428], Loss: 3.0859
Epoch [1/2], Batch [26/428], Loss: 0.9458
Epoch [1/2], Batch [27/428], Loss: 2.7366
Epoch [1/2], Batch [28/428], Loss: 2.9489
Epoch [1/2], Batch [29/428], Loss: 2.9755
Epoch [1/2], Batch [30/428], Loss: 3.9136
Epoch [1/2], Batch [31/428], Loss: 1.9709
Epoch [1/2], Batch [32/428], Loss: 3.1798
Epoch [1/2], Batch [33/428], Loss: 3.8889
Epoch [1/2], Batch [34/428], Loss: 2.0136
Epoch [1/2], Batch [35/428], Loss: 4.2823
Epoch [1/2], Batch [36/428], Loss: 2.0760
Epoch [1/2], Batch [37/428], Loss: 1.8726
Epoch [1/2], Batch [38/428], Loss: 2.8173
Epoch [1/2], Batch [39/428], Loss: 2.0098
Epoch [1/2], Batch [40/428], Loss: 2.8690
Epoch [1/2], Batch [41/428], Loss: 0.9972
Epoch [1/2], Batch [42/428], Loss: 2.4906
Epoch [1/2], Batch [43/428], Loss: 3.0312
Epoch [1/2], Batch [44/428], Loss: 2.7420
Epoch [1/2], Batch [45/428], Loss: 3.3344
Epoch [1/2], Batch [46/428], Loss: 2.1447
Epoch [1/2], Batch [47/428], Loss: 2.2586
Epoch [1/2], Batch [48/428], Loss: 3.9836
Epoch [1/2], Batch [49/428], Loss: 2.4175
Epoch [1/2], Batch [50/428], Loss: 3.9532
Epoch [1/2], Batch [51/428], Loss: 3.0066
Epoch [1/2], Batch [52/428], Loss: 2.0250
Epoch [1/2], Batch [53/428], Loss: 0.7540
Epoch [1/2], Batch [54/428], Loss: 0.8556
Epoch [1/2], Batch [55/428], Loss: 3.9647
Epoch [1/2], Batch [56/428], Loss: 3.5646
Epoch [1/2], Batch [57/428], Loss: 0.8917
Epoch [1/2], Batch [58/428], Loss: 2.7331
Epoch [1/2], Batch [59/428], Loss: 3.6896
Epoch [1/2], Batch [60/428], Loss: 2.3277
Epoch [1/2], Batch [61/428], Loss: 1.0278
Epoch [1/2], Batch [62/428], Loss: 3.0304
Epoch [1/2], Batch [63/428], Loss: 4.7307
Epoch [1/2], Batch [64/428], Loss: 3.4264
Epoch [1/2], Batch [65/428], Loss: 0.6071
Epoch [1/2], Batch [66/428], Loss: 3.2019
Epoch [1/2], Batch [67/428], Loss: 3.6106
Epoch [1/2], Batch [68/428], Loss: 3.1270
Epoch [1/2], Batch [69/428], Loss: 2.0824
Epoch [1/2], Batch [70/428], Loss: 4.4719
Epoch [1/2], Batch [71/428], Loss: 2.3161
Epoch [1/2], Batch [72/428], Loss: 3.4522
Epoch [1/2], Batch [73/428], Loss: 2.4829
Epoch [1/2], Batch [74/428], Loss: 4.9669
Epoch [1/2], Batch [75/428], Loss: 1.4606
Epoch [1/2], Batch [76/428], Loss: 1.9063
Epoch [1/2], Batch [77/428], Loss: 2.9986
Epoch [1/2], Batch [78/428], Loss: 4.0526
Epoch [1/2], Batch [79/428], Loss: 2.3085
Epoch [1/2], Batch [80/428], Loss: 1.9701
Epoch [1/2], Batch [81/428], Loss: 4.1492
Epoch [1/2], Batch [82/428], Loss: 2.4932
Epoch [1/2], Batch [83/428], Loss: 0.7722
Epoch [1/2], Batch [84/428], Loss: 2.6109
Epoch [1/2], Batch [85/428], Loss: 3.6083
Epoch [1/2], Batch [86/428], Loss: 1.0313
Epoch [1/2], Batch [87/428], Loss: 1.2222
Epoch [1/2], Batch [88/428], Loss: 0.8184
Epoch [1/2], Batch [89/428], Loss: 2.2401
Epoch [1/2], Batch [90/428], Loss: 2.5087
Epoch [1/2], Batch [91/428], Loss: 1.3632
Epoch [1/2], Batch [92/428], Loss: 3.1005
Epoch [1/2], Batch [93/428], Loss: 0.7302
Epoch [1/2], Batch [94/428], Loss: 0.8613
Epoch [1/2], Batch [95/428], Loss: 1.7224
Epoch [1/2], Batch [96/428], Loss: 1.1980
Epoch [1/2], Batch [97/428], Loss: 2.2762
Epoch [1/2], Batch [98/428], Loss: 1.7700
Epoch [1/2], Batch [99/428], Loss: 2.1015
Epoch [1/2], Batch [100/428], Loss: 2.5112
Epoch [1/2], Batch [101/428], Loss: 0.5270
Epoch [1/2], Batch [102/428], Loss: 1.6819
Epoch [1/2], Batch [103/428], Loss: 1.9248
Epoch [1/2], Batch [104/428], Loss: 0.9483
Epoch [1/2], Batch [105/428], Loss: 2.3849
Epoch [1/2], Batch [106/428], Loss: 2.0340
Epoch [1/2], Batch [107/428], Loss: 4.4743
Epoch [1/2], Batch [108/428], Loss: 3.7170
Epoch [1/2], Batch [109/428], Loss: 3.1319
Epoch [1/2], Batch [110/428], Loss: 2.2838
Epoch [1/2], Batch [111/428], Loss: 3.6542
Epoch [1/2], Batch [112/428], Loss: 3.5858
Epoch [1/2], Batch [113/428], Loss: 1.8740
Epoch [1/2], Batch [114/428], Loss: 1.9518
Epoch [1/2], Batch [115/428], Loss: 2.0170
Epoch [1/2], Batch [116/428], Loss: 0.6490
Epoch [1/2], Batch [117/428], Loss: 2.5537
Epoch [1/2], Batch [118/428], Loss: 0.7981
Epoch [1/2], Batch [119/428], Loss: 0.7903
Epoch [1/2], Batch [120/428], Loss: 2.2500
Epoch [1/2], Batch [121/428], Loss: 2.3265
Epoch [1/2], Batch [122/428], Loss: 4.0182
Epoch [1/2], Batch [123/428], Loss: 1.0461
Epoch [1/2], Batch [124/428], Loss: 0.7498
Epoch [1/2], Batch [125/428], Loss: 3.8699
Epoch [1/2], Batch [126/428], Loss: 2.9700
Epoch [1/2], Batch [127/428], Loss: 1.1064
Epoch [1/2], Batch [128/428], Loss: 3.0671
Epoch [1/2], Batch [129/428], Loss: 2.7402
Epoch [1/2], Batch [130/428], Loss: 4.3271
Epoch [1/2], Batch [131/428], Loss: 4.3106
Epoch [1/2], Batch [132/428], Loss: 1.9286
Epoch [1/2], Batch [133/428], Loss: 2.3887
Epoch [1/2], Batch [134/428], Loss: 2.4511
Epoch [1/2], Batch [135/428], Loss: 1.0174
Epoch [1/2], Batch [136/428], Loss: 0.9380
Epoch [1/2], Batch [137/428], Loss: 1.2338
Epoch [1/2], Batch [138/428], Loss: 3.3913
Epoch [1/2], Batch [139/428], Loss: 4.1431
Epoch [1/2], Batch [140/428], Loss: 2.2325
Epoch [1/2], Batch [141/428], Loss: 2.9392
Epoch [1/2], Batch [142/428], Loss: 2.9306
Epoch [1/2], Batch [143/428], Loss: 3.4001
Epoch [1/2], Batch [144/428], Loss: 4.2882
Epoch [1/2], Batch [145/428], Loss: 3.9182
Epoch [1/2], Batch [146/428], Loss: 3.3978
Epoch [1/2], Batch [147/428], Loss: 1.7647
Epoch [1/2], Batch [148/428], Loss: 3.0901
Epoch [1/2], Batch [149/428], Loss: 3.1103
Epoch [1/2], Batch [150/428], Loss: 2.3958
Epoch [1/2], Batch [151/428], Loss: 3.7156
Epoch [1/2], Batch [152/428], Loss: 0.6811
Epoch [1/2], Batch [153/428], Loss: 3.9879
Epoch [1/2], Batch [154/428], Loss: 1.9294
Epoch [1/2], Batch [155/428], Loss: 2.1591
Epoch [1/2], Batch [156/428], Loss: 3.9825
Epoch [1/2], Batch [157/428], Loss: 4.2030
Epoch [1/2], Batch [158/428], Loss: 2.0659
Epoch [1/2], Batch [159/428], Loss: 3.3309
Epoch [1/2], Batch [160/428], Loss: 1.2798
Epoch [1/2], Batch [161/428], Loss: 3.4895
Epoch [1/2], Batch [162/428], Loss: 0.8155
Epoch [1/2], Batch [163/428], Loss: 2.4365
Epoch [1/2], Batch [164/428], Loss: 3.8863
Epoch [1/2], Batch [165/428], Loss: 3.2702
Epoch [1/2], Batch [166/428], Loss: 1.9165
Epoch [1/2], Batch [167/428], Loss: 2.5207
Epoch [1/2], Batch [168/428], Loss: 1.8834
Epoch [1/2], Batch [169/428], Loss: 0.6854
Epoch [1/2], Batch [170/428], Loss: 1.6385
Epoch [1/2], Batch [171/428], Loss: 2.2726
Epoch [1/2], Batch [172/428], Loss: 1.4352
Epoch [1/2], Batch [173/428], Loss: 0.8780
Epoch [1/2], Batch [174/428], Loss: 3.8729
Epoch [1/2], Batch [175/428], Loss: 1.9560
Epoch [1/2], Batch [176/428], Loss: 2.8175
Epoch [1/2], Batch [177/428], Loss: 2.0537
Epoch [1/2], Batch [178/428], Loss: 3.8124
Epoch [1/2], Batch [179/428], Loss: 1.7683
Epoch [1/2], Batch [180/428], Loss: 1.9269
Epoch [1/2], Batch [181/428], Loss: 0.5076
Epoch [1/2], Batch [182/428], Loss: 1.0137
Epoch [1/2], Batch [183/428], Loss: 3.9323
Epoch [1/2], Batch [184/428], Loss: 2.7855
Epoch [1/2], Batch [185/428], Loss: 3.0034
Epoch [1/2], Batch [186/428], Loss: 2.0742
Epoch [1/2], Batch [187/428], Loss: 0.5026
Epoch [1/2], Batch [188/428], Loss: 3.7416
Epoch [1/2], Batch [189/428], Loss: 0.9783
Epoch [1/2], Batch [190/428], Loss: 2.4617
Epoch [1/2], Batch [191/428], Loss: 3.6103
Epoch [1/2], Batch [192/428], Loss: 2.3915
Epoch [1/2], Batch [193/428], Loss: 2.2167
Epoch [1/2], Batch [194/428], Loss: 3.2258
Epoch [1/2], Batch [195/428], Loss: 1.7550
Epoch [1/2], Batch [196/428], Loss: 3.7278
Epoch [1/2], Batch [197/428], Loss: 3.3328
Epoch [1/2], Batch [198/428], Loss: 2.0922
Epoch [1/2], Batch [199/428], Loss: 3.9896
Epoch [1/2], Batch [200/428], Loss: 1.0412
Epoch [1/2], Batch [201/428], Loss: 1.1382
Epoch [1/2], Batch [202/428], Loss: 1.6977
Epoch [1/2], Batch [203/428], Loss: 1.2430
Epoch [1/2], Batch [204/428], Loss: 2.4606
Epoch [1/2], Batch [205/428], Loss: 3.0156
Epoch [1/2], Batch [206/428], Loss: 1.5413
Epoch [1/2], Batch [207/428], Loss: 2.0684
Epoch [1/2], Batch [208/428], Loss: 1.6513
Epoch [1/2], Batch [209/428], Loss: 1.2230
Epoch [1/2], Batch [210/428], Loss: 3.2022
Epoch [1/2], Batch [211/428], Loss: 2.2034
Epoch [1/2], Batch [212/428], Loss: 1.6476
Epoch [1/2], Batch [213/428], Loss: 0.4847
Epoch [1/2], Batch [214/428], Loss: 2.6837
Epoch [1/2], Batch [215/428], Loss: 2.6998
Epoch [1/2], Batch [216/428], Loss: 3.3496
Epoch [1/2], Batch [217/428], Loss: 2.1964
Epoch [1/2], Batch [218/428], Loss: 2.4732
Epoch [1/2], Batch [219/428], Loss: 2.5716
Epoch [1/2], Batch [220/428], Loss: 2.4173
Epoch [1/2], Batch [221/428], Loss: 2.1460
Epoch [1/2], Batch [222/428], Loss: 2.7279
Epoch [1/2], Batch [223/428], Loss: 2.2268
Epoch [1/2], Batch [224/428], Loss: 3.2774
Epoch [1/2], Batch [225/428], Loss: 2.8688
Epoch [1/2], Batch [226/428], Loss: 2.3372
Epoch [1/2], Batch [227/428], Loss: 2.1928
Epoch [1/2], Batch [228/428], Loss: 0.8898
Epoch [1/2], Batch [229/428], Loss: 3.5537
Epoch [1/2], Batch [230/428], Loss: 2.9759
Epoch [1/2], Batch [231/428], Loss: 4.6832
Epoch [1/2], Batch [232/428], Loss: 2.3165
Epoch [1/2], Batch [233/428], Loss: 3.7216
Epoch [1/2], Batch [234/428], Loss: 3.7641
Epoch [1/2], Batch [235/428], Loss: 2.0283
Epoch [1/2], Batch [236/428], Loss: 2.3075
Epoch [1/2], Batch [237/428], Loss: 1.8090
Epoch [1/2], Batch [238/428], Loss: 2.2873
Epoch [1/2], Batch [239/428], Loss: 1.5146
Epoch [1/2], Batch [240/428], Loss: 3.2480
Epoch [1/2], Batch [241/428], Loss: 3.1301
Epoch [1/2], Batch [242/428], Loss: 3.8403
Epoch [1/2], Batch [243/428], Loss: 2.9734
Epoch [1/2], Batch [244/428], Loss: 1.9630
Epoch [1/2], Batch [245/428], Loss: 4.1135
Epoch [1/2], Batch [246/428], Loss: 2.5848
Epoch [1/2], Batch [247/428], Loss: 4.0303
Epoch [1/2], Batch [248/428], Loss: 1.2853
Epoch [1/2], Batch [249/428], Loss: 0.9434
Epoch [1/2], Batch [250/428], Loss: 2.2436
Epoch [1/2], Batch [251/428], Loss: 2.1494
Epoch [1/2], Batch [252/428], Loss: 0.8933
Epoch [1/2], Batch [253/428], Loss: 2.8542
Epoch [1/2], Batch [254/428], Loss: 3.3664
Epoch [1/2], Batch [255/428], Loss: 0.5277
Epoch [1/2], Batch [256/428], Loss: 0.5008
Epoch [1/2], Batch [257/428], Loss: 2.5258
Epoch [1/2], Batch [258/428], Loss: 2.3732
Epoch [1/2], Batch [259/428], Loss: 1.0472
Epoch [1/2], Batch [260/428], Loss: 2.1113
Epoch [1/2], Batch [261/428], Loss: 2.2305
Epoch [1/2], Batch [262/428], Loss: 1.0799
Epoch [1/2], Batch [263/428], Loss: 3.5819
Epoch [1/2], Batch [264/428], Loss: 2.1740
Epoch [1/2], Batch [265/428], Loss: 3.4781
Epoch [1/2], Batch [266/428], Loss: 1.0941
Epoch [1/2], Batch [267/428], Loss: 4.1220
Epoch [1/2], Batch [268/428], Loss: 2.1230
Epoch [1/2], Batch [269/428], Loss: 2.2047
Epoch [1/2], Batch [270/428], Loss: 2.7919
Epoch [1/2], Batch [271/428], Loss: 2.8707
Epoch [1/2], Batch [272/428], Loss: 1.6841
Epoch [1/2], Batch [273/428], Loss: 0.9391
Epoch [1/2], Batch [274/428], Loss: 2.6871
Epoch [1/2], Batch [275/428], Loss: 1.9348
Epoch [1/2], Batch [276/428], Loss: 0.6162
Epoch [1/2], Batch [277/428], Loss: 1.8420
Epoch [1/2], Batch [278/428], Loss: 1.9762
Epoch [1/2], Batch [279/428], Loss: 0.8743
Epoch [1/2], Batch [280/428], Loss: 2.3631
Epoch [1/2], Batch [281/428], Loss: 1.5778
Epoch [1/2], Batch [282/428], Loss: 2.0599
Epoch [1/2], Batch [283/428], Loss: 2.1567
Epoch [1/2], Batch [284/428], Loss: 2.2137
Epoch [1/2], Batch [285/428], Loss: 2.8341
Epoch [1/2], Batch [286/428], Loss: 3.8062
Epoch [1/2], Batch [287/428], Loss: 3.0680
Epoch [1/2], Batch [288/428], Loss: 2.5135
Epoch [1/2], Batch [289/428], Loss: 3.3387
Epoch [1/2], Batch [290/428], Loss: 1.8374
Epoch [1/2], Batch [291/428], Loss: 0.7167
Epoch [1/2], Batch [292/428], Loss: 1.9986
Epoch [1/2], Batch [293/428], Loss: 0.9569
Epoch [1/2], Batch [294/428], Loss: 2.0501
Epoch [1/2], Batch [295/428], Loss: 1.1263
Epoch [1/2], Batch [296/428], Loss: 0.4012
Epoch [1/2], Batch [297/428], Loss: 2.0830
Epoch [1/2], Batch [298/428], Loss: 3.3188
Epoch [1/2], Batch [299/428], Loss: 0.7220
Epoch [1/2], Batch [300/428], Loss: 1.3241
Epoch [1/2], Batch [301/428], Loss: 2.7721
Epoch [1/2], Batch [302/428], Loss: 1.4481
Epoch [1/2], Batch [303/428], Loss: 2.6528
Epoch [1/2], Batch [304/428], Loss: 2.8108
Epoch [1/2], Batch [305/428], Loss: 0.8981
Epoch [1/2], Batch [306/428], Loss: 3.4076
Epoch [1/2], Batch [307/428], Loss: 2.1669
Epoch [1/2], Batch [308/428], Loss: 2.0387
Epoch [1/2], Batch [309/428], Loss: 0.8090
Epoch [1/2], Batch [310/428], Loss: 2.2676
Epoch [1/2], Batch [311/428], Loss: 1.8261
Epoch [1/2], Batch [312/428], Loss: 2.9698
Epoch [1/2], Batch [313/428], Loss: 1.2562
Epoch [1/2], Batch [314/428], Loss: 1.8129
Epoch [1/2], Batch [315/428], Loss: 1.4900
Epoch [1/2], Batch [316/428], Loss: 0.9886
Epoch [1/2], Batch [317/428], Loss: 2.9019
Epoch [1/2], Batch [318/428], Loss: 1.0442
Epoch [1/2], Batch [319/428], Loss: 1.8558
Epoch [1/2], Batch [320/428], Loss: 1.3274
Epoch [1/2], Batch [321/428], Loss: 2.2865
Epoch [1/2], Batch [322/428], Loss: 3.0971
Epoch [1/2], Batch [323/428], Loss: 3.8309
Epoch [1/2], Batch [324/428], Loss: 1.9430
Epoch [1/2], Batch [325/428], Loss: 1.0604
Epoch [1/2], Batch [326/428], Loss: 3.2980
Epoch [1/2], Batch [327/428], Loss: 0.8161
Epoch [1/2], Batch [328/428], Loss: 2.5280
Epoch [1/2], Batch [329/428], Loss: 1.8587
Epoch [1/2], Batch [330/428], Loss: 3.9915
Epoch [1/2], Batch [331/428], Loss: 1.3982
Epoch [1/2], Batch [332/428], Loss: 2.2582
Epoch [1/2], Batch [333/428], Loss: 3.8989
Epoch [1/2], Batch [334/428], Loss: 2.8221
Epoch [1/2], Batch [335/428], Loss: 3.5454
Epoch [1/2], Batch [336/428], Loss: 2.0391
Epoch [1/2], Batch [337/428], Loss: 1.7437
Epoch [1/2], Batch [338/428], Loss: 3.4275
Epoch [1/2], Batch [339/428], Loss: 1.1709
Epoch [1/2], Batch [340/428], Loss: 3.2219
Epoch [1/2], Batch [341/428], Loss: 2.5929
Epoch [1/2], Batch [342/428], Loss: 1.7872
Epoch [1/2], Batch [343/428], Loss: 1.1287
Epoch [1/2], Batch [344/428], Loss: 2.4612
Epoch [1/2], Batch [345/428], Loss: 0.8555
Epoch [1/2], Batch [346/428], Loss: 1.8011
Epoch [1/2], Batch [347/428], Loss: 3.9731
Epoch [1/2], Batch [348/428], Loss: 1.0665
Epoch [1/2], Batch [349/428], Loss: 1.8073
Epoch [1/2], Batch [350/428], Loss: 1.7951
Epoch [1/2], Batch [351/428], Loss: 3.1320
Epoch [1/2], Batch [352/428], Loss: 0.8588
Epoch [1/2], Batch [353/428], Loss: 2.4730
Epoch [1/2], Batch [354/428], Loss: 3.0810
Epoch [1/2], Batch [355/428], Loss: 1.6235
Epoch [1/2], Batch [356/428], Loss: 3.9086
Epoch [1/2], Batch [357/428], Loss: 3.2909
Epoch [1/2], Batch [358/428], Loss: 3.0466
Epoch [1/2], Batch [359/428], Loss: 2.5495
Epoch [1/2], Batch [360/428], Loss: 1.3718
Epoch [1/2], Batch [361/428], Loss: 1.8923
Epoch [1/2], Batch [362/428], Loss: 0.9527
Epoch [1/2], Batch [363/428], Loss: 3.3200
Epoch [1/2], Batch [364/428], Loss: 2.0738
Epoch [1/2], Batch [365/428], Loss: 1.7554
Epoch [1/2], Batch [366/428], Loss: 3.9482
Epoch [1/2], Batch [367/428], Loss: 3.2582
Epoch [1/2], Batch [368/428], Loss: 1.8225
Epoch [1/2], Batch [369/428], Loss: 1.4172
Epoch [1/2], Batch [370/428], Loss: 2.9991
Epoch [1/2], Batch [371/428], Loss: 2.3952
Epoch [1/2], Batch [372/428], Loss: 1.2162
Epoch [1/2], Batch [373/428], Loss: 3.8426
Epoch [1/2], Batch [374/428], Loss: 4.2668
Epoch [1/2], Batch [375/428], Loss: 3.0860
Epoch [1/2], Batch [376/428], Loss: 2.1000
Epoch [1/2], Batch [377/428], Loss: 3.7568
Epoch [1/2], Batch [378/428], Loss: 1.8207
Epoch [1/2], Batch [379/428], Loss: 2.0856
Epoch [1/2], Batch [380/428], Loss: 1.3026
Epoch [1/2], Batch [381/428], Loss: 1.9202
Epoch [1/2], Batch [382/428], Loss: 1.0981
Epoch [1/2], Batch [383/428], Loss: 3.5517
Epoch [1/2], Batch [384/428], Loss: 3.8534
Epoch [1/2], Batch [385/428], Loss: 2.6085
Epoch [1/2], Batch [386/428], Loss: 0.8441
Epoch [1/2], Batch [387/428], Loss: 2.7755
Epoch [1/2], Batch [388/428], Loss: 2.6466
Epoch [1/2], Batch [389/428], Loss: 2.8136
Epoch [1/2], Batch [390/428], Loss: 3.1611
Epoch [1/2], Batch [391/428], Loss: 2.7194
Epoch [1/2], Batch [392/428], Loss: 1.6265
Epoch [1/2], Batch [393/428], Loss: 2.2334
Epoch [1/2], Batch [394/428], Loss: 2.6273
Epoch [1/2], Batch [395/428], Loss: 2.5196
Epoch [1/2], Batch [396/428], Loss: 2.4063
Epoch [1/2], Batch [397/428], Loss: 2.4987
Epoch [1/2], Batch [398/428], Loss: 3.1092
Epoch [1/2], Batch [399/428], Loss: 1.4935
Epoch [1/2], Batch [400/428], Loss: 2.7412
Epoch [1/2], Batch [401/428], Loss: 0.9286
Epoch [1/2], Batch [402/428], Loss: 2.3182
Epoch [1/2], Batch [403/428], Loss: 0.8708
Epoch [1/2], Batch [404/428], Loss: 0.9403
Epoch [1/2], Batch [405/428], Loss: 1.7042
Epoch [1/2], Batch [406/428], Loss: 1.3729
Epoch [1/2], Batch [407/428], Loss: 1.1545
Epoch [1/2], Batch [408/428], Loss: 2.2870
Epoch [1/2], Batch [409/428], Loss: 0.7415
Epoch [1/2], Batch [410/428], Loss: 3.0023
Epoch [1/2], Batch [411/428], Loss: 0.6274
Epoch [1/2], Batch [412/428], Loss: 3.8929
Epoch [1/2], Batch [413/428], Loss: 3.7972
Epoch [1/2], Batch [414/428], Loss: 2.3506
Epoch [1/2], Batch [415/428], Loss: 0.6390
Epoch [1/2], Batch [416/428], Loss: 2.5724
Epoch [1/2], Batch [417/428], Loss: 1.6612
Epoch [1/2], Batch [418/428], Loss: 1.0615
Epoch [1/2], Batch [419/428], Loss: 0.7701
Epoch [1/2], Batch [420/428], Loss: 1.3827
Epoch [1/2], Batch [421/428], Loss: 1.1061
Epoch [1/2], Batch [422/428], Loss: 1.0365
Epoch [1/2], Batch [423/428], Loss: 2.7915
Epoch [1/2], Batch [424/428], Loss: 3.4324
Epoch [1/2], Batch [425/428], Loss: 3.6779
Epoch [1/2], Batch [426/428], Loss: 1.9039
Epoch [1/2], Batch [427/428], Loss: 3.5942
Epoch [1/2], Batch [428/428], Loss: 1.3366
Epoch [1] Training Time: 237.00 seconds
Epoch [1/2], Average Loss: 2.3750, Training Accuracy: 0.1986
Epoch [1], Validation Loss: 2.2038, Validation Accuracy: 0.2234
Epoch [1] Validation Time: 14.42 seconds
--------------------------------------------------
Epoch [2/2], Batch [1/428], Loss: 2.1236
Epoch [2/2], Batch [2/428], Loss: 1.3014
Epoch [2/2], Batch [3/428], Loss: 3.2502
Epoch [2/2], Batch [4/428], Loss: 1.5587
Epoch [2/2], Batch [5/428], Loss: 1.8149
Epoch [2/2], Batch [6/428], Loss: 2.2627
Epoch [2/2], Batch [7/428], Loss: 2.3187
Epoch [2/2], Batch [8/428], Loss: 2.2248
Epoch [2/2], Batch [9/428], Loss: 3.4214
Epoch [2/2], Batch [10/428], Loss: 3.5387
Epoch [2/2], Batch [11/428], Loss: 3.3742
Epoch [2/2], Batch [12/428], Loss: 3.2118
Epoch [2/2], Batch [13/428], Loss: 0.6261
Epoch [2/2], Batch [14/428], Loss: 2.4283
Epoch [2/2], Batch [15/428], Loss: 2.8475
Epoch [2/2], Batch [16/428], Loss: 2.5899
Epoch [2/2], Batch [17/428], Loss: 2.6462
Epoch [2/2], Batch [18/428], Loss: 2.4006
Epoch [2/2], Batch [19/428], Loss: 1.4726
Epoch [2/2], Batch [20/428], Loss: 0.4961
Epoch [2/2], Batch [21/428], Loss: 0.7709
Epoch [2/2], Batch [22/428], Loss: 2.1919
Epoch [2/2], Batch [23/428], Loss: 0.8956
Epoch [2/2], Batch [24/428], Loss: 2.3604
Epoch [2/2], Batch [25/428], Loss: 0.9996
Epoch [2/2], Batch [26/428], Loss: 2.2005
Epoch [2/2], Batch [27/428], Loss: 3.0014
Epoch [2/2], Batch [28/428], Loss: 1.1857
Epoch [2/2], Batch [29/428], Loss: 3.6671
Epoch [2/2], Batch [30/428], Loss: 1.2849
Epoch [2/2], Batch [31/428], Loss: 0.7705
Epoch [2/2], Batch [32/428], Loss: 1.2379
Epoch [2/2], Batch [33/428], Loss: 2.9079
Epoch [2/2], Batch [34/428], Loss: 0.9825
Epoch [2/2], Batch [35/428], Loss: 2.9256
Epoch [2/2], Batch [36/428], Loss: 1.3788
Epoch [2/2], Batch [37/428], Loss: 2.2328
Epoch [2/2], Batch [38/428], Loss: 2.6371
Epoch [2/2], Batch [39/428], Loss: 1.6543
Epoch [2/2], Batch [40/428], Loss: 1.7290
Epoch [2/2], Batch [41/428], Loss: 1.7086
Epoch [2/2], Batch [42/428], Loss: 0.7205
Epoch [2/2], Batch [43/428], Loss: 0.8202
Epoch [2/2], Batch [44/428], Loss: 2.2273
Epoch [2/2], Batch [45/428], Loss: 2.1085
Epoch [2/2], Batch [46/428], Loss: 1.2191
Epoch [2/2], Batch [47/428], Loss: 1.6092
Epoch [2/2], Batch [48/428], Loss: 2.6853
Epoch [2/2], Batch [49/428], Loss: 1.2655
Epoch [2/2], Batch [50/428], Loss: 3.4515
Epoch [2/2], Batch [51/428], Loss: 3.3626
Epoch [2/2], Batch [52/428], Loss: 3.5484
Epoch [2/2], Batch [53/428], Loss: 2.3181
Epoch [2/2], Batch [54/428], Loss: 2.1465
Epoch [2/2], Batch [55/428], Loss: 1.9237
Epoch [2/2], Batch [56/428], Loss: 0.9711
Epoch [2/2], Batch [57/428], Loss: 0.6941
Epoch [2/2], Batch [58/428], Loss: 2.0133
Epoch [2/2], Batch [59/428], Loss: 3.6637
Epoch [2/2], Batch [60/428], Loss: 1.3142
Epoch [2/2], Batch [61/428], Loss: 1.7717
Epoch [2/2], Batch [62/428], Loss: 0.9490
Epoch [2/2], Batch [63/428], Loss: 0.6477
Epoch [2/2], Batch [64/428], Loss: 1.0690
Epoch [2/2], Batch [65/428], Loss: 2.8709
Epoch [2/2], Batch [66/428], Loss: 2.7950
Epoch [2/2], Batch [67/428], Loss: 0.9206
Epoch [2/2], Batch [68/428], Loss: 3.0720
Epoch [2/2], Batch [69/428], Loss: 1.3576
Epoch [2/2], Batch [70/428], Loss: 2.3380
Epoch [2/2], Batch [71/428], Loss: 3.4303
Epoch [2/2], Batch [72/428], Loss: 2.3907
Epoch [2/2], Batch [73/428], Loss: 2.3868
Epoch [2/2], Batch [74/428], Loss: 2.9053
Epoch [2/2], Batch [75/428], Loss: 2.3450
Epoch [2/2], Batch [76/428], Loss: 2.5647
Epoch [2/2], Batch [77/428], Loss: 2.1669
Epoch [2/2], Batch [78/428], Loss: 0.7596
Epoch [2/2], Batch [79/428], Loss: 3.4204
Epoch [2/2], Batch [80/428], Loss: 2.4004
Epoch [2/2], Batch [81/428], Loss: 0.5492
Epoch [2/2], Batch [82/428], Loss: 2.4728
Epoch [2/2], Batch [83/428], Loss: 0.6977
Epoch [2/2], Batch [84/428], Loss: 2.8840
Epoch [2/2], Batch [85/428], Loss: 3.9309
Epoch [2/2], Batch [86/428], Loss: 2.8740
Epoch [2/2], Batch [87/428], Loss: 1.9991
Epoch [2/2], Batch [88/428], Loss: 2.7944
Epoch [2/2], Batch [89/428], Loss: 2.3621
Epoch [2/2], Batch [90/428], Loss: 2.1220
Epoch [2/2], Batch [91/428], Loss: 3.5703
Epoch [2/2], Batch [92/428], Loss: 1.2539
Epoch [2/2], Batch [93/428], Loss: 0.6369
Epoch [2/2], Batch [94/428], Loss: 0.5728
Epoch [2/2], Batch [95/428], Loss: 1.0907
Epoch [2/2], Batch [96/428], Loss: 1.8727
Epoch [2/2], Batch [97/428], Loss: 2.4911
Epoch [2/2], Batch [98/428], Loss: 1.4326
Epoch [2/2], Batch [99/428], Loss: 0.4657
Epoch [2/2], Batch [100/428], Loss: 0.7602
Epoch [2/2], Batch [101/428], Loss: 3.0363
Epoch [2/2], Batch [102/428], Loss: 0.8127
Epoch [2/2], Batch [103/428], Loss: 1.2476
Epoch [2/2], Batch [104/428], Loss: 2.0794
Epoch [2/2], Batch [105/428], Loss: 2.6700
Epoch [2/2], Batch [106/428], Loss: 1.7734
Epoch [2/2], Batch [107/428], Loss: 3.4758
Epoch [2/2], Batch [108/428], Loss: 2.2134
Epoch [2/2], Batch [109/428], Loss: 1.0802
Epoch [2/2], Batch [110/428], Loss: 2.1979
Epoch [2/2], Batch [111/428], Loss: 2.1292
Epoch [2/2], Batch [112/428], Loss: 1.3535
Epoch [2/2], Batch [113/428], Loss: 3.0132
Epoch [2/2], Batch [114/428], Loss: 2.6149
Epoch [2/2], Batch [115/428], Loss: 0.9190
Epoch [2/2], Batch [116/428], Loss: 1.9630
Epoch [2/2], Batch [117/428], Loss: 1.3047
Epoch [2/2], Batch [118/428], Loss: 1.7794
Epoch [2/2], Batch [119/428], Loss: 0.3875
Epoch [2/2], Batch [120/428], Loss: 2.4235
Epoch [2/2], Batch [121/428], Loss: 1.1676
Epoch [2/2], Batch [122/428], Loss: 1.9719
Epoch [2/2], Batch [123/428], Loss: 1.4461
Epoch [2/2], Batch [124/428], Loss: 2.0509
Epoch [2/2], Batch [125/428], Loss: 1.2338
Epoch [2/2], Batch [126/428], Loss: 3.2373
Epoch [2/2], Batch [127/428], Loss: 0.7984
Epoch [2/2], Batch [128/428], Loss: 2.4982
Epoch [2/2], Batch [129/428], Loss: 1.6214
Epoch [2/2], Batch [130/428], Loss: 1.4405
Epoch [2/2], Batch [131/428], Loss: 2.3553
Epoch [2/2], Batch [132/428], Loss: 0.6612
Epoch [2/2], Batch [133/428], Loss: 3.4296
Epoch [2/2], Batch [134/428], Loss: 0.7846
Epoch [2/2], Batch [135/428], Loss: 2.7782
Epoch [2/2], Batch [136/428], Loss: 3.2666
Epoch [2/2], Batch [137/428], Loss: 1.5456
Epoch [2/2], Batch [138/428], Loss: 2.6886
Epoch [2/2], Batch [139/428], Loss: 1.9377
Epoch [2/2], Batch [140/428], Loss: 1.4464
Epoch [2/2], Batch [141/428], Loss: 1.5659
Epoch [2/2], Batch [142/428], Loss: 1.8713
Epoch [2/2], Batch [143/428], Loss: 3.4721
Epoch [2/2], Batch [144/428], Loss: 3.5629
Epoch [2/2], Batch [145/428], Loss: 2.7721
Epoch [2/2], Batch [146/428], Loss: 1.7034
Epoch [2/2], Batch [147/428], Loss: 1.6117
Epoch [2/2], Batch [148/428], Loss: 0.9252
Epoch [2/2], Batch [149/428], Loss: 1.7445
Epoch [2/2], Batch [150/428], Loss: 2.2626
Epoch [2/2], Batch [151/428], Loss: 2.2197
Epoch [2/2], Batch [152/428], Loss: 1.1827
Epoch [2/2], Batch [153/428], Loss: 2.5931
Epoch [2/2], Batch [154/428], Loss: 3.3413
Epoch [2/2], Batch [155/428], Loss: 1.6949
Epoch [2/2], Batch [156/428], Loss: 1.9531
Epoch [2/2], Batch [157/428], Loss: 3.8804
Epoch [2/2], Batch [158/428], Loss: 1.9446
Epoch [2/2], Batch [159/428], Loss: 0.5705
Epoch [2/2], Batch [160/428], Loss: 1.6706
Epoch [2/2], Batch [161/428], Loss: 1.7127
Epoch [2/2], Batch [162/428], Loss: 0.4625
Epoch [2/2], Batch [163/428], Loss: 2.4377
Epoch [2/2], Batch [164/428], Loss: 3.3073
Epoch [2/2], Batch [165/428], Loss: 1.6086
Epoch [2/2], Batch [166/428], Loss: 1.0493
Epoch [2/2], Batch [167/428], Loss: 2.6639
Epoch [2/2], Batch [168/428], Loss: 2.3221
Epoch [2/2], Batch [169/428], Loss: 1.0874
Epoch [2/2], Batch [170/428], Loss: 1.8549
Epoch [2/2], Batch [171/428], Loss: 2.0860
Epoch [2/2], Batch [172/428], Loss: 3.0979
Epoch [2/2], Batch [173/428], Loss: 1.7355
Epoch [2/2], Batch [174/428], Loss: 2.6107
Epoch [2/2], Batch [175/428], Loss: 0.7704
Epoch [2/2], Batch [176/428], Loss: 2.4686
Epoch [2/2], Batch [177/428], Loss: 1.3698
Epoch [2/2], Batch [178/428], Loss: 0.6321
Epoch [2/2], Batch [179/428], Loss: 3.2582
Epoch [2/2], Batch [180/428], Loss: 1.7300
Epoch [2/2], Batch [181/428], Loss: 1.8762
Epoch [2/2], Batch [182/428], Loss: 0.6259
Epoch [2/2], Batch [183/428], Loss: 1.3740
Epoch [2/2], Batch [184/428], Loss: 1.2399
Epoch [2/2], Batch [185/428], Loss: 0.8747
Epoch [2/2], Batch [186/428], Loss: 1.1061
Epoch [2/2], Batch [187/428], Loss: 1.4725
Epoch [2/2], Batch [188/428], Loss: 2.3602
Epoch [2/2], Batch [189/428], Loss: 1.2775
Epoch [2/2], Batch [190/428], Loss: 2.0324
Epoch [2/2], Batch [191/428], Loss: 0.9820
Epoch [2/2], Batch [192/428], Loss: 2.3831
Epoch [2/2], Batch [193/428], Loss: 3.5615
Epoch [2/2], Batch [194/428], Loss: 2.6157
Epoch [2/2], Batch [195/428], Loss: 2.9935
Epoch [2/2], Batch [196/428], Loss: 1.5902
Epoch [2/2], Batch [197/428], Loss: 3.1991
Epoch [2/2], Batch [198/428], Loss: 0.6393
Epoch [2/2], Batch [199/428], Loss: 3.3611
Epoch [2/2], Batch [200/428], Loss: 1.0473
Epoch [2/2], Batch [201/428], Loss: 2.3950
Epoch [2/2], Batch [202/428], Loss: 2.0965
Epoch [2/2], Batch [203/428], Loss: 1.5553
Epoch [2/2], Batch [204/428], Loss: 1.4202
Epoch [2/2], Batch [205/428], Loss: 2.0623[INFO 06-13 19:43:55] ax.service.ax_client: Completed trial 7 with data: {'objective': (np.float64(-0.240221), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 4
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 19:43:59] ax.service.ax_client: Generated new trial 8 with parameters {'lr': 8.4e-05, 'num_epochs': 1, 'unfreeze_epoch': 4, 'max_length': 160000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder
[INFO 06-13 19:49:58] ax.service.ax_client: Completed trial 8 with data: {'objective': (np.float64(-0.419388), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 1
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 19:50:01] ax.service.ax_client: Generated new trial 9 with parameters {'lr': 0.0003, 'num_epochs': 3, 'unfreeze_epoch': 3, 'max_length': 48000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [2/2], Batch [206/428], Loss: 1.7459
Epoch [2/2], Batch [207/428], Loss: 1.2547
Epoch [2/2], Batch [208/428], Loss: 1.9542
Epoch [2/2], Batch [209/428], Loss: 1.0843
Epoch [2/2], Batch [210/428], Loss: 2.3042
Epoch [2/2], Batch [211/428], Loss: 1.6792
Epoch [2/2], Batch [212/428], Loss: 0.6508
Epoch [2/2], Batch [213/428], Loss: 2.0540
Epoch [2/2], Batch [214/428], Loss: 3.2305
Epoch [2/2], Batch [215/428], Loss: 1.6001
Epoch [2/2], Batch [216/428], Loss: 0.8947
Epoch [2/2], Batch [217/428], Loss: 3.2547
Epoch [2/2], Batch [218/428], Loss: 2.8493
Epoch [2/2], Batch [219/428], Loss: 1.1535
Epoch [2/2], Batch [220/428], Loss: 3.5450
Epoch [2/2], Batch [221/428], Loss: 0.6651
Epoch [2/2], Batch [222/428], Loss: 3.5603
Epoch [2/2], Batch [223/428], Loss: 3.0730
Epoch [2/2], Batch [224/428], Loss: 2.9550
Epoch [2/2], Batch [225/428], Loss: 2.1212
Epoch [2/2], Batch [226/428], Loss: 2.6178
Epoch [2/2], Batch [227/428], Loss: 0.9890
Epoch [2/2], Batch [228/428], Loss: 3.6406
Epoch [2/2], Batch [229/428], Loss: 1.3174
Epoch [2/2], Batch [230/428], Loss: 0.8566
Epoch [2/2], Batch [231/428], Loss: 2.4573
Epoch [2/2], Batch [232/428], Loss: 2.5509
Epoch [2/2], Batch [233/428], Loss: 1.5689
Epoch [2/2], Batch [234/428], Loss: 0.6316
Epoch [2/2], Batch [235/428], Loss: 1.8906
Epoch [2/2], Batch [236/428], Loss: 2.2262
Epoch [2/2], Batch [237/428], Loss: 2.1064
Epoch [2/2], Batch [238/428], Loss: 2.8833
Epoch [2/2], Batch [239/428], Loss: 2.2654
Epoch [2/2], Batch [240/428], Loss: 0.8280
Epoch [2/2], Batch [241/428], Loss: 2.5639
Epoch [2/2], Batch [242/428], Loss: 1.9932
Epoch [2/2], Batch [243/428], Loss: 2.2270
Epoch [2/2], Batch [244/428], Loss: 1.1929
Epoch [2/2], Batch [245/428], Loss: 1.4789
Epoch [2/2], Batch [246/428], Loss: 1.7921
Epoch [2/2], Batch [247/428], Loss: 2.0147
Epoch [2/2], Batch [248/428], Loss: 0.9241
Epoch [2/2], Batch [249/428], Loss: 0.8963
Epoch [2/2], Batch [250/428], Loss: 2.4560
Epoch [2/2], Batch [251/428], Loss: 1.5339
Epoch [2/2], Batch [252/428], Loss: 1.8856
Epoch [2/2], Batch [253/428], Loss: 1.7511
Epoch [2/2], Batch [254/428], Loss: 2.0252
Epoch [2/2], Batch [255/428], Loss: 0.9929
Epoch [2/2], Batch [256/428], Loss: 1.7919
Epoch [2/2], Batch [257/428], Loss: 2.3718
Epoch [2/2], Batch [258/428], Loss: 1.8724
Epoch [2/2], Batch [259/428], Loss: 0.7306
Epoch [2/2], Batch [260/428], Loss: 1.4450
Epoch [2/2], Batch [261/428], Loss: 1.1882
Epoch [2/2], Batch [262/428], Loss: 0.4407
Epoch [2/2], Batch [263/428], Loss: 3.2750
Epoch [2/2], Batch [264/428], Loss: 1.7066
Epoch [2/2], Batch [265/428], Loss: 1.7036
Epoch [2/2], Batch [266/428], Loss: 2.0757
Epoch [2/2], Batch [267/428], Loss: 2.4469
Epoch [2/2], Batch [268/428], Loss: 1.3310
Epoch [2/2], Batch [269/428], Loss: 2.0587
Epoch [2/2], Batch [270/428], Loss: 1.8631
Epoch [2/2], Batch [271/428], Loss: 2.9707
Epoch [2/2], Batch [272/428], Loss: 2.3313
Epoch [2/2], Batch [273/428], Loss: 2.1279
Epoch [2/2], Batch [274/428], Loss: 0.8499
Epoch [2/2], Batch [275/428], Loss: 0.9229
Epoch [2/2], Batch [276/428], Loss: 1.6840
Epoch [2/2], Batch [277/428], Loss: 1.6546
Epoch [2/2], Batch [278/428], Loss: 2.2087
Epoch [2/2], Batch [279/428], Loss: 2.3421
Epoch [2/2], Batch [280/428], Loss: 1.8386
Epoch [2/2], Batch [281/428], Loss: 1.3441
Epoch [2/2], Batch [282/428], Loss: 2.2113
Epoch [2/2], Batch [283/428], Loss: 0.9694
Epoch [2/2], Batch [284/428], Loss: 1.7084
Epoch [2/2], Batch [285/428], Loss: 0.9853
Epoch [2/2], Batch [286/428], Loss: 2.0991
Epoch [2/2], Batch [287/428], Loss: 3.7394
Epoch [2/2], Batch [288/428], Loss: 2.9545
Epoch [2/2], Batch [289/428], Loss: 2.0392
Epoch [2/2], Batch [290/428], Loss: 1.9638
Epoch [2/2], Batch [291/428], Loss: 2.8539
Epoch [2/2], Batch [292/428], Loss: 4.2351
Epoch [2/2], Batch [293/428], Loss: 1.4973
Epoch [2/2], Batch [294/428], Loss: 2.4803
Epoch [2/2], Batch [295/428], Loss: 2.1826
Epoch [2/2], Batch [296/428], Loss: 2.2346
Epoch [2/2], Batch [297/428], Loss: 1.5729
Epoch [2/2], Batch [298/428], Loss: 2.5798
Epoch [2/2], Batch [299/428], Loss: 1.9634
Epoch [2/2], Batch [300/428], Loss: 1.0885
Epoch [2/2], Batch [301/428], Loss: 1.5573
Epoch [2/2], Batch [302/428], Loss: 1.5925
Epoch [2/2], Batch [303/428], Loss: 2.2588
Epoch [2/2], Batch [304/428], Loss: 1.6707
Epoch [2/2], Batch [305/428], Loss: 1.7458
Epoch [2/2], Batch [306/428], Loss: 1.6634
Epoch [2/2], Batch [307/428], Loss: 2.4128
Epoch [2/2], Batch [308/428], Loss: 2.3962
Epoch [2/2], Batch [309/428], Loss: 1.4245
Epoch [2/2], Batch [310/428], Loss: 2.2048
Epoch [2/2], Batch [311/428], Loss: 2.2698
Epoch [2/2], Batch [312/428], Loss: 1.7982
Epoch [2/2], Batch [313/428], Loss: 1.4509
Epoch [2/2], Batch [314/428], Loss: 3.1851
Epoch [2/2], Batch [315/428], Loss: 1.7824
Epoch [2/2], Batch [316/428], Loss: 1.5252
Epoch [2/2], Batch [317/428], Loss: 2.7830
Epoch [2/2], Batch [318/428], Loss: 1.2913
Epoch [2/2], Batch [319/428], Loss: 2.2210
Epoch [2/2], Batch [320/428], Loss: 2.1401
Epoch [2/2], Batch [321/428], Loss: 2.4965
Epoch [2/2], Batch [322/428], Loss: 2.5531
Epoch [2/2], Batch [323/428], Loss: 4.2656
Epoch [2/2], Batch [324/428], Loss: 3.4514
Epoch [2/2], Batch [325/428], Loss: 2.3820
Epoch [2/2], Batch [326/428], Loss: 1.5050
Epoch [2/2], Batch [327/428], Loss: 1.3070
Epoch [2/2], Batch [328/428], Loss: 1.1291
Epoch [2/2], Batch [329/428], Loss: 0.5566
Epoch [2/2], Batch [330/428], Loss: 2.7185
Epoch [2/2], Batch [331/428], Loss: 0.8735
Epoch [2/2], Batch [332/428], Loss: 2.0329
Epoch [2/2], Batch [333/428], Loss: 1.8673
Epoch [2/2], Batch [334/428], Loss: 0.3917
Epoch [2/2], Batch [335/428], Loss: 1.0742
Epoch [2/2], Batch [336/428], Loss: 1.9537
Epoch [2/2], Batch [337/428], Loss: 2.0591
Epoch [2/2], Batch [338/428], Loss: 1.6688
Epoch [2/2], Batch [339/428], Loss: 1.6153
Epoch [2/2], Batch [340/428], Loss: 0.4033
Epoch [2/2], Batch [341/428], Loss: 1.1758
Epoch [2/2], Batch [342/428], Loss: 1.6773
Epoch [2/2], Batch [343/428], Loss: 2.8121
Epoch [2/2], Batch [344/428], Loss: 0.3940
Epoch [2/2], Batch [345/428], Loss: 1.1015
Epoch [2/2], Batch [346/428], Loss: 3.4547
Epoch [2/2], Batch [347/428], Loss: 2.5635
Epoch [2/2], Batch [348/428], Loss: 1.1537
Epoch [2/2], Batch [349/428], Loss: 1.7466
Epoch [2/2], Batch [350/428], Loss: 1.6688
Epoch [2/2], Batch [351/428], Loss: 1.5411
Epoch [2/2], Batch [352/428], Loss: 3.3144
Epoch [2/2], Batch [353/428], Loss: 2.9038
Epoch [2/2], Batch [354/428], Loss: 0.8137
Epoch [2/2], Batch [355/428], Loss: 0.5706
Epoch [2/2], Batch [356/428], Loss: 1.8819
Epoch [2/2], Batch [357/428], Loss: 2.1072
Epoch [2/2], Batch [358/428], Loss: 3.5345
Epoch [2/2], Batch [359/428], Loss: 3.7415
Epoch [2/2], Batch [360/428], Loss: 1.2840
Epoch [2/2], Batch [361/428], Loss: 0.4347
Epoch [2/2], Batch [362/428], Loss: 1.8420
Epoch [2/2], Batch [363/428], Loss: 3.3404
Epoch [2/2], Batch [364/428], Loss: 1.2105
Epoch [2/2], Batch [365/428], Loss: 0.6341
Epoch [2/2], Batch [366/428], Loss: 1.2906
Epoch [2/2], Batch [367/428], Loss: 2.1539
Epoch [2/2], Batch [368/428], Loss: 1.5725
Epoch [2/2], Batch [369/428], Loss: 1.3931
Epoch [2/2], Batch [370/428], Loss: 1.4006
Epoch [2/2], Batch [371/428], Loss: 1.3910
Epoch [2/2], Batch [372/428], Loss: 1.3855
Epoch [2/2], Batch [373/428], Loss: 3.1725
Epoch [2/2], Batch [374/428], Loss: 1.7788
Epoch [2/2], Batch [375/428], Loss: 1.2914
Epoch [2/2], Batch [376/428], Loss: 0.7983
Epoch [2/2], Batch [377/428], Loss: 2.4212
Epoch [2/2], Batch [378/428], Loss: 1.8050
Epoch [2/2], Batch [379/428], Loss: 1.7040
Epoch [2/2], Batch [380/428], Loss: 2.8490
Epoch [2/2], Batch [381/428], Loss: 1.7677
Epoch [2/2], Batch [382/428], Loss: 0.8588
Epoch [2/2], Batch [383/428], Loss: 2.3235
Epoch [2/2], Batch [384/428], Loss: 1.9339
Epoch [2/2], Batch [385/428], Loss: 1.4937
Epoch [2/2], Batch [386/428], Loss: 0.6320
Epoch [2/2], Batch [387/428], Loss: 1.3175
Epoch [2/2], Batch [388/428], Loss: 1.6209
Epoch [2/2], Batch [389/428], Loss: 2.5981
Epoch [2/2], Batch [390/428], Loss: 2.0533
Epoch [2/2], Batch [391/428], Loss: 1.3970
Epoch [2/2], Batch [392/428], Loss: 2.9267
Epoch [2/2], Batch [393/428], Loss: 2.1177
Epoch [2/2], Batch [394/428], Loss: 1.0149
Epoch [2/2], Batch [395/428], Loss: 1.3677
Epoch [2/2], Batch [396/428], Loss: 2.5584
Epoch [2/2], Batch [397/428], Loss: 0.9786
Epoch [2/2], Batch [398/428], Loss: 2.2734
Epoch [2/2], Batch [399/428], Loss: 1.7743
Epoch [2/2], Batch [400/428], Loss: 3.2660
Epoch [2/2], Batch [401/428], Loss: 1.8098
Epoch [2/2], Batch [402/428], Loss: 2.1544
Epoch [2/2], Batch [403/428], Loss: 2.1643
Epoch [2/2], Batch [404/428], Loss: 1.8237
Epoch [2/2], Batch [405/428], Loss: 2.1699
Epoch [2/2], Batch [406/428], Loss: 3.1290
Epoch [2/2], Batch [407/428], Loss: 0.7477
Epoch [2/2], Batch [408/428], Loss: 0.9397
Epoch [2/2], Batch [409/428], Loss: 2.2836
Epoch [2/2], Batch [410/428], Loss: 1.4809
Epoch [2/2], Batch [411/428], Loss: 2.0347
Epoch [2/2], Batch [412/428], Loss: 1.3198
Epoch [2/2], Batch [413/428], Loss: 1.9597
Epoch [2/2], Batch [414/428], Loss: 2.5602
Epoch [2/2], Batch [415/428], Loss: 0.9933
Epoch [2/2], Batch [416/428], Loss: 2.5187
Epoch [2/2], Batch [417/428], Loss: 0.6323
Epoch [2/2], Batch [418/428], Loss: 2.1627
Epoch [2/2], Batch [419/428], Loss: 2.1862
Epoch [2/2], Batch [420/428], Loss: 2.6257
Epoch [2/2], Batch [421/428], Loss: 2.1655
Epoch [2/2], Batch [422/428], Loss: 0.7638
Epoch [2/2], Batch [423/428], Loss: 3.4376
Epoch [2/2], Batch [424/428], Loss: 1.1681
Epoch [2/2], Batch [425/428], Loss: 3.4882
Epoch [2/2], Batch [426/428], Loss: 0.8087
Epoch [2/2], Batch [427/428], Loss: 1.2812
Epoch [2/2], Batch [428/428], Loss: 2.6699
Epoch [2] Training Time: 238.05 seconds
Epoch [2/2], Average Loss: 1.9363, Training Accuracy: 0.2547
Epoch [2], Validation Loss: 1.9833, Validation Accuracy: 0.2402
Epoch [2] Validation Time: 14.28 seconds
--------------------------------------------------

Running trial 8 with config: {'batch_size': 1, 'lr': 8.372782025796683e-05, 'num_epochs': 1, 'unfreeze_epoch': 4, 'max_length': 160000, 'device': device(type='cpu')}
Epoch [1/1], Batch [1/428], Loss: 1.4887
Epoch [1/1], Batch [2/428], Loss: 1.4878
Epoch [1/1], Batch [3/428], Loss: 2.0956
Epoch [1/1], Batch [4/428], Loss: 0.9339
Epoch [1/1], Batch [5/428], Loss: 1.0111
Epoch [1/1], Batch [6/428], Loss: 3.2856
Epoch [1/1], Batch [7/428], Loss: 3.4601
Epoch [1/1], Batch [8/428], Loss: 2.8331
Epoch [1/1], Batch [9/428], Loss: 0.9804
Epoch [1/1], Batch [10/428], Loss: 2.1682
Epoch [1/1], Batch [11/428], Loss: 1.0238
Epoch [1/1], Batch [12/428], Loss: 1.6744
Epoch [1/1], Batch [13/428], Loss: 3.6248
Epoch [1/1], Batch [14/428], Loss: 2.1356
Epoch [1/1], Batch [15/428], Loss: 2.5847
Epoch [1/1], Batch [16/428], Loss: 0.8379
Epoch [1/1], Batch [17/428], Loss: 2.9112
Epoch [1/1], Batch [18/428], Loss: 1.3269
Epoch [1/1], Batch [19/428], Loss: 2.6541
Epoch [1/1], Batch [20/428], Loss: 0.5192
Epoch [1/1], Batch [21/428], Loss: 2.5068
Epoch [1/1], Batch [22/428], Loss: 1.4838
Epoch [1/1], Batch [23/428], Loss: 0.5950
Epoch [1/1], Batch [24/428], Loss: 2.1900
Epoch [1/1], Batch [25/428], Loss: 1.5267
Epoch [1/1], Batch [26/428], Loss: 0.9181
Epoch [1/1], Batch [27/428], Loss: 3.7363
Epoch [1/1], Batch [28/428], Loss: 3.0521
Epoch [1/1], Batch [29/428], Loss: 0.7706
Epoch [1/1], Batch [30/428], Loss: 3.5082
Epoch [1/1], Batch [31/428], Loss: 2.7430
Epoch [1/1], Batch [32/428], Loss: 3.4468
Epoch [1/1], Batch [33/428], Loss: 2.6338
Epoch [1/1], Batch [34/428], Loss: 1.7983
Epoch [1/1], Batch [35/428], Loss: 1.9306
Epoch [1/1], Batch [36/428], Loss: 2.3999
Epoch [1/1], Batch [37/428], Loss: 1.0501
Epoch [1/1], Batch [38/428], Loss: 3.1168
Epoch [1/1], Batch [39/428], Loss: 3.5325
Epoch [1/1], Batch [40/428], Loss: 2.4234
Epoch [1/1], Batch [41/428], Loss: 1.8535
Epoch [1/1], Batch [42/428], Loss: 1.5774
Epoch [1/1], Batch [43/428], Loss: 0.7326
Epoch [1/1], Batch [44/428], Loss: 1.6653
Epoch [1/1], Batch [45/428], Loss: 2.7443
Epoch [1/1], Batch [46/428], Loss: 2.5744
Epoch [1/1], Batch [47/428], Loss: 1.1899
Epoch [1/1], Batch [48/428], Loss: 1.2693
Epoch [1/1], Batch [49/428], Loss: 0.8163
Epoch [1/1], Batch [50/428], Loss: 0.8243
Epoch [1/1], Batch [51/428], Loss: 2.7739
Epoch [1/1], Batch [52/428], Loss: 0.6368
Epoch [1/1], Batch [53/428], Loss: 1.9820
Epoch [1/1], Batch [54/428], Loss: 2.8391
Epoch [1/1], Batch [55/428], Loss: 0.9632
Epoch [1/1], Batch [56/428], Loss: 2.3019
Epoch [1/1], Batch [57/428], Loss: 3.7062
Epoch [1/1], Batch [58/428], Loss: 2.0584
Epoch [1/1], Batch [59/428], Loss: 3.5961
Epoch [1/1], Batch [60/428], Loss: 1.3562
Epoch [1/1], Batch [61/428], Loss: 2.9404
Epoch [1/1], Batch [62/428], Loss: 0.7714
Epoch [1/1], Batch [63/428], Loss: 1.1493
Epoch [1/1], Batch [64/428], Loss: 1.8061
Epoch [1/1], Batch [65/428], Loss: 2.9449
Epoch [1/1], Batch [66/428], Loss: 2.5612
Epoch [1/1], Batch [67/428], Loss: 3.5153
Epoch [1/1], Batch [68/428], Loss: 3.0088
Epoch [1/1], Batch [69/428], Loss: 0.6836
Epoch [1/1], Batch [70/428], Loss: 3.1332
Epoch [1/1], Batch [71/428], Loss: 3.5068
Epoch [1/1], Batch [72/428], Loss: 3.1072
Epoch [1/1], Batch [73/428], Loss: 0.6525
Epoch [1/1], Batch [74/428], Loss: 2.8653
Epoch [1/1], Batch [75/428], Loss: 2.9411
Epoch [1/1], Batch [76/428], Loss: 2.8995
Epoch [1/1], Batch [77/428], Loss: 0.6187
Epoch [1/1], Batch [78/428], Loss: 3.0315
Epoch [1/1], Batch [79/428], Loss: 0.6297
Epoch [1/1], Batch [80/428], Loss: 1.7589
Epoch [1/1], Batch [81/428], Loss: 0.6286
Epoch [1/1], Batch [82/428], Loss: 2.6674
Epoch [1/1], Batch [83/428], Loss: 0.5444
Epoch [1/1], Batch [84/428], Loss: 2.9857
Epoch [1/1], Batch [85/428], Loss: 0.5471
Epoch [1/1], Batch [86/428], Loss: 0.8636
Epoch [1/1], Batch [87/428], Loss: 1.2123
Epoch [1/1], Batch [88/428], Loss: 2.5306
Epoch [1/1], Batch [89/428], Loss: 3.1756
Epoch [1/1], Batch [90/428], Loss: 2.0559
Epoch [1/1], Batch [91/428], Loss: 1.1061
Epoch [1/1], Batch [92/428], Loss: 1.2339
Epoch [1/1], Batch [93/428], Loss: 1.8402
Epoch [1/1], Batch [94/428], Loss: 2.4706
Epoch [1/1], Batch [95/428], Loss: 2.8679
Epoch [1/1], Batch [96/428], Loss: 0.3239
Epoch [1/1], Batch [97/428], Loss: 0.5650
Epoch [1/1], Batch [98/428], Loss: 2.9046
Epoch [1/1], Batch [99/428], Loss: 2.0194
Epoch [1/1], Batch [100/428], Loss: 0.3970
Epoch [1/1], Batch [101/428], Loss: 1.4406
Epoch [1/1], Batch [102/428], Loss: 0.4049
Epoch [1/1], Batch [103/428], Loss: 1.8120
Epoch [1/1], Batch [104/428], Loss: 2.2724
Epoch [1/1], Batch [105/428], Loss: 1.7712
Epoch [1/1], Batch [106/428], Loss: 2.8069
Epoch [1/1], Batch [107/428], Loss: 2.2471
Epoch [1/1], Batch [108/428], Loss: 2.7678
Epoch [1/1], Batch [109/428], Loss: 2.0270
Epoch [1/1], Batch [110/428], Loss: 2.1966
Epoch [1/1], Batch [111/428], Loss: 2.5835
Epoch [1/1], Batch [112/428], Loss: 0.6212
Epoch [1/1], Batch [113/428], Loss: 0.3371
Epoch [1/1], Batch [114/428], Loss: 1.0964
Epoch [1/1], Batch [115/428], Loss: 0.7947
Epoch [1/1], Batch [116/428], Loss: 0.8372
Epoch [1/1], Batch [117/428], Loss: 0.9890
Epoch [1/1], Batch [118/428], Loss: 2.5145
Epoch [1/1], Batch [119/428], Loss: 2.0884
Epoch [1/1], Batch [120/428], Loss: 0.2553
Epoch [1/1], Batch [121/428], Loss: 2.3064
Epoch [1/1], Batch [122/428], Loss: 0.2142
Epoch [1/1], Batch [123/428], Loss: 0.7768
Epoch [1/1], Batch [124/428], Loss: 1.9885
Epoch [1/1], Batch [125/428], Loss: 2.4572
Epoch [1/1], Batch [126/428], Loss: 1.2537
Epoch [1/1], Batch [127/428], Loss: 4.1630
Epoch [1/1], Batch [128/428], Loss: 2.8585
Epoch [1/1], Batch [129/428], Loss: 0.8827
Epoch [1/1], Batch [130/428], Loss: 3.5961
Epoch [1/1], Batch [131/428], Loss: 2.2984
Epoch [1/1], Batch [132/428], Loss: 2.1792
Epoch [1/1], Batch [133/428], Loss: 2.4066
Epoch [1/1], Batch [134/428], Loss: 0.2902
Epoch [1/1], Batch [135/428], Loss: 2.5789
Epoch [1/1], Batch [136/428], Loss: 2.6732
Epoch [1/1], Batch [137/428], Loss: 0.7991
Epoch [1/1], Batch [138/428], Loss: 2.5820
Epoch [1/1], Batch [139/428], Loss: 2.8820
Epoch [1/1], Batch [140/428], Loss: 1.8857
Epoch [1/1], Batch [141/428], Loss: 2.4083
Epoch [1/1], Batch [142/428], Loss: 1.3359
Epoch [1/1], Batch [143/428], Loss: 0.3324
Epoch [1/1], Batch [144/428], Loss: 4.1980
Epoch [1/1], Batch [145/428], Loss: 0.8626
Epoch [1/1], Batch [146/428], Loss: 1.2106
Epoch [1/1], Batch [147/428], Loss: 2.0960
Epoch [1/1], Batch [148/428], Loss: 2.2657
Epoch [1/1], Batch [149/428], Loss: 0.1317
Epoch [1/1], Batch [150/428], Loss: 0.2083
Epoch [1/1], Batch [151/428], Loss: 2.0816
Epoch [1/1], Batch [152/428], Loss: 0.4281
Epoch [1/1], Batch [153/428], Loss: 0.5304
Epoch [1/1], Batch [154/428], Loss: 0.1590
Epoch [1/1], Batch [155/428], Loss: 2.2014
Epoch [1/1], Batch [156/428], Loss: 2.2295
Epoch [1/1], Batch [157/428], Loss: 0.4801
Epoch [1/1], Batch [158/428], Loss: 0.9579
Epoch [1/1], Batch [159/428], Loss: 2.2085
Epoch [1/1], Batch [160/428], Loss: 0.7296
Epoch [1/1], Batch [161/428], Loss: 2.1752
Epoch [1/1], Batch [162/428], Loss: 0.1228
Epoch [1/1], Batch [163/428], Loss: 2.6281
Epoch [1/1], Batch [164/428], Loss: 1.3114
Epoch [1/1], Batch [165/428], Loss: 0.3026
Epoch [1/1], Batch [166/428], Loss: 1.1665
Epoch [1/1], Batch [167/428], Loss: 0.3001
Epoch [1/1], Batch [168/428], Loss: 2.2110
Epoch [1/1], Batch [169/428], Loss: 0.6830
Epoch [1/1], Batch [170/428], Loss: 1.4289
Epoch [1/1], Batch [171/428], Loss: 1.1318
Epoch [1/1], Batch [172/428], Loss: 0.6799
Epoch [1/1], Batch [173/428], Loss: 2.9931
Epoch [1/1], Batch [174/428], Loss: 2.4046
Epoch [1/1], Batch [175/428], Loss: 2.0455
Epoch [1/1], Batch [176/428], Loss: 1.8430
Epoch [1/1], Batch [177/428], Loss: 0.1684
Epoch [1/1], Batch [178/428], Loss: 2.5472
Epoch [1/1], Batch [179/428], Loss: 0.7784
Epoch [1/1], Batch [180/428], Loss: 0.1230
Epoch [1/1], Batch [181/428], Loss: 0.2919
Epoch [1/1], Batch [182/428], Loss: 2.5918
Epoch [1/1], Batch [183/428], Loss: 0.1122
Epoch [1/1], Batch [184/428], Loss: 0.7747
Epoch [1/1], Batch [185/428], Loss: 1.9989
Epoch [1/1], Batch [186/428], Loss: 0.2934
Epoch [1/1], Batch [187/428], Loss: 0.4434
Epoch [1/1], Batch [188/428], Loss: 0.6892
Epoch [1/1], Batch [189/428], Loss: 2.2068
Epoch [1/1], Batch [190/428], Loss: 1.0455
Epoch [1/1], Batch [191/428], Loss: 2.0436
Epoch [1/1], Batch [192/428], Loss: 1.8624
Epoch [1/1], Batch [193/428], Loss: 1.9928
Epoch [1/1], Batch [194/428], Loss: 1.4474
Epoch [1/1], Batch [195/428], Loss: 2.4937
Epoch [1/1], Batch [196/428], Loss: 1.4749
Epoch [1/1], Batch [197/428], Loss: 2.1043
Epoch [1/1], Batch [198/428], Loss: 1.6156
Epoch [1/1], Batch [199/428], Loss: 0.3920
Epoch [1/1], Batch [200/428], Loss: 0.0722
Epoch [1/1], Batch [201/428], Loss: 1.9962
Epoch [1/1], Batch [202/428], Loss: 4.6090
Epoch [1/1], Batch [203/428], Loss: 2.5206
Epoch [1/1], Batch [204/428], Loss: 2.3195
Epoch [1/1], Batch [205/428], Loss: 0.7630
Epoch [1/1], Batch [206/428], Loss: 1.8339
Epoch [1/1], Batch [207/428], Loss: 2.1826
Epoch [1/1], Batch [208/428], Loss: 0.3860
Epoch [1/1], Batch [209/428], Loss: 0.6369
Epoch [1/1], Batch [210/428], Loss: 0.9859
Epoch [1/1], Batch [211/428], Loss: 0.8393
Epoch [1/1], Batch [212/428], Loss: 2.3652
Epoch [1/1], Batch [213/428], Loss: 2.2638
Epoch [1/1], Batch [214/428], Loss: 2.3095
Epoch [1/1], Batch [215/428], Loss: 2.5772
Epoch [1/1], Batch [216/428], Loss: 1.6393
Epoch [1/1], Batch [217/428], Loss: 0.6261
Epoch [1/1], Batch [218/428], Loss: 0.2566
Epoch [1/1], Batch [219/428], Loss: 0.4610
Epoch [1/1], Batch [220/428], Loss: 2.9498
Epoch [1/1], Batch [221/428], Loss: 2.4533
Epoch [1/1], Batch [222/428], Loss: 0.1666
Epoch [1/1], Batch [223/428], Loss: 1.9259
Epoch [1/1], Batch [224/428], Loss: 0.1626
Epoch [1/1], Batch [225/428], Loss: 0.2901
Epoch [1/1], Batch [226/428], Loss: 2.1983
Epoch [1/1], Batch [227/428], Loss: 2.0571
Epoch [1/1], Batch [228/428], Loss: 2.0334
Epoch [1/1], Batch [229/428], Loss: 0.2000
Epoch [1/1], Batch [230/428], Loss: 1.4531
Epoch [1/1], Batch [231/428], Loss: 0.3115
Epoch [1/1], Batch [232/428], Loss: 1.9864
Epoch [1/1], Batch [233/428], Loss: 0.5449
Epoch [1/1], Batch [234/428], Loss: 1.8752
Epoch [1/1], Batch [235/428], Loss: 0.9718
Epoch [1/1], Batch [236/428], Loss: 2.4028
Epoch [1/1], Batch [237/428], Loss: 2.1498
Epoch [1/1], Batch [238/428], Loss: 2.7862
Epoch [1/1], Batch [239/428], Loss: 0.0517
Epoch [1/1], Batch [240/428], Loss: 1.1449
Epoch [1/1], Batch [241/428], Loss: 0.1895
Epoch [1/1], Batch [242/428], Loss: 0.1135
Epoch [1/1], Batch [243/428], Loss: 2.5591
Epoch [1/1], Batch [244/428], Loss: 1.1507
Epoch [1/1], Batch [245/428], Loss: 1.9172
Epoch [1/1], Batch [246/428], Loss: 1.9231
Epoch [1/1], Batch [247/428], Loss: 1.7659
Epoch [1/1], Batch [248/428], Loss: 0.0571
Epoch [1/1], Batch [249/428], Loss: 0.2491
Epoch [1/1], Batch [250/428], Loss: 0.1598
Epoch [1/1], Batch [251/428], Loss: 2.7113
Epoch [1/1], Batch [252/428], Loss: 3.0941
Epoch [1/1], Batch [253/428], Loss: 0.0513
Epoch [1/1], Batch [254/428], Loss: 2.3876
Epoch [1/1], Batch [255/428], Loss: 0.5564
Epoch [1/1], Batch [256/428], Loss: 1.1316
Epoch [1/1], Batch [257/428], Loss: 1.7173
Epoch [1/1], Batch [258/428], Loss: 0.0238
Epoch [1/1], Batch [259/428], Loss: 3.6851
Epoch [1/1], Batch [260/428], Loss: 0.0154
Epoch [1/1], Batch [261/428], Loss: 4.0148
Epoch [1/1], Batch [262/428], Loss: 1.6311
Epoch [1/1], Batch [263/428], Loss: 2.6647
Epoch [1/1], Batch [264/428], Loss: 0.5206
Epoch [1/1], Batch [265/428], Loss: 0.0436
Epoch [1/1], Batch [266/428], Loss: 0.4337
Epoch [1/1], Batch [267/428], Loss: 0.1894
Epoch [1/1], Batch [268/428], Loss: 0.7328
Epoch [1/1], Batch [269/428], Loss: 1.9289
Epoch [1/1], Batch [270/428], Loss: 2.0840
Epoch [1/1], Batch [271/428], Loss: 1.3276
Epoch [1/1], Batch [272/428], Loss: 2.0304
Epoch [1/1], Batch [273/428], Loss: 0.2965
Epoch [1/1], Batch [274/428], Loss: 0.0172
Epoch [1/1], Batch [275/428], Loss: 1.9599
Epoch [1/1], Batch [276/428], Loss: 2.5009
Epoch [1/1], Batch [277/428], Loss: 2.2588
Epoch [1/1], Batch [278/428], Loss: 2.8226
Epoch [1/1], Batch [279/428], Loss: 0.3191
Epoch [1/1], Batch [280/428], Loss: 1.7806
Epoch [1/1], Batch [281/428], Loss: 1.9891
Epoch [1/1], Batch [282/428], Loss: 0.6164
Epoch [1/1], Batch [283/428], Loss: 2.3796
Epoch [1/1], Batch [284/428], Loss: 0.3122
Epoch [1/1], Batch [285/428], Loss: 2.8479
Epoch [1/1], Batch [286/428], Loss: 1.9053
Epoch [1/1], Batch [287/428], Loss: 2.8745
Epoch [1/1], Batch [288/428], Loss: 2.6375
Epoch [1/1], Batch [289/428], Loss: 0.0133
Epoch [1/1], Batch [290/428], Loss: 1.7456
Epoch [1/1], Batch [291/428], Loss: 0.1230
Epoch [1/1], Batch [292/428], Loss: 1.1550
Epoch [1/1], Batch [293/428], Loss: 1.9162
Epoch [1/1], Batch [294/428], Loss: 0.0672
Epoch [1/1], Batch [295/428], Loss: 4.3879
Epoch [1/1], Batch [296/428], Loss: 2.2852
Epoch [1/1], Batch [297/428], Loss: 2.1671
Epoch [1/1], Batch [298/428], Loss: 1.9715
Epoch [1/1], Batch [299/428], Loss: 1.5831
Epoch [1/1], Batch [300/428], Loss: 0.0254
Epoch [1/1], Batch [301/428], Loss: 0.1010
Epoch [1/1], Batch [302/428], Loss: 1.7194
Epoch [1/1], Batch [303/428], Loss: 1.8980
Epoch [1/1], Batch [304/428], Loss: 1.9063
Epoch [1/1], Batch [305/428], Loss: 0.5490
Epoch [1/1], Batch [306/428], Loss: 1.9750
Epoch [1/1], Batch [307/428], Loss: 1.2165
Epoch [1/1], Batch [308/428], Loss: 0.0931
Epoch [1/1], Batch [309/428], Loss: 1.9111
Epoch [1/1], Batch [310/428], Loss: 0.0217
Epoch [1/1], Batch [311/428], Loss: 0.1544
Epoch [1/1], Batch [312/428], Loss: 3.4011
Epoch [1/1], Batch [313/428], Loss: 2.5905
Epoch [1/1], Batch [314/428], Loss: 0.0121
Epoch [1/1], Batch [315/428], Loss: 1.5008
Epoch [1/1], Batch [316/428], Loss: 2.2711
Epoch [1/1], Batch [317/428], Loss: 3.4586
Epoch [1/1], Batch [318/428], Loss: 0.0259
Epoch [1/1], Batch [319/428], Loss: 1.0452
Epoch [1/1], Batch [320/428], Loss: 1.3596
Epoch [1/1], Batch [321/428], Loss: 2.6549
Epoch [1/1], Batch [322/428], Loss: 1.6969
Epoch [1/1], Batch [323/428], Loss: 2.0967
Epoch [1/1], Batch [324/428], Loss: 1.0185
Epoch [1/1], Batch [325/428], Loss: 1.4693
Epoch [1/1], Batch [326/428], Loss: 0.0092
Epoch [1/1], Batch [327/428], Loss: 0.5515
Epoch [1/1], Batch [328/428], Loss: 0.0183
Epoch [1/1], Batch [329/428], Loss: 2.6851
Epoch [1/1], Batch [330/428], Loss: 0.0844
Epoch [1/1], Batch [331/428], Loss: 0.0892
Epoch [1/1], Batch [332/428], Loss: 2.1126
Epoch [1/1], Batch [333/428], Loss: 2.2671
Epoch [1/1], Batch [334/428], Loss: 0.0405
Epoch [1/1], Batch [335/428], Loss: 0.7594
Epoch [1/1], Batch [336/428], Loss: 2.0077
Epoch [1/1], Batch [337/428], Loss: 1.3005
Epoch [1/1], Batch [338/428], Loss: 1.4031
Epoch [1/1], Batch [339/428], Loss: 2.2038
Epoch [1/1], Batch [340/428], Loss: 2.4095
Epoch [1/1], Batch [341/428], Loss: 2.4253
Epoch [1/1], Batch [342/428], Loss: 1.2110
Epoch [1/1], Batch [343/428], Loss: 1.5401
Epoch [1/1], Batch [344/428], Loss: 1.0675
Epoch [1/1], Batch [345/428], Loss: 1.2863
Epoch [1/1], Batch [346/428], Loss: 0.0104
Epoch [1/1], Batch [347/428], Loss: 1.9611
Epoch [1/1], Batch [348/428], Loss: 2.1639
Epoch [1/1], Batch [349/428], Loss: 1.2657
Epoch [1/1], Batch [350/428], Loss: 2.7920
Epoch [1/1], Batch [351/428], Loss: 0.0356
Epoch [1/1], Batch [352/428], Loss: 0.4833
Epoch [1/1], Batch [353/428], Loss: 1.4121
Epoch [1/1], Batch [354/428], Loss: 0.9613
Epoch [1/1], Batch [355/428], Loss: 1.8342
Epoch [1/1], Batch [356/428], Loss: 2.8375
Epoch [1/1], Batch [357/428], Loss: 0.2987
Epoch [1/1], Batch [358/428], Loss: 0.9024
Epoch [1/1], Batch [359/428], Loss: 0.0876
Epoch [1/1], Batch [360/428], Loss: 0.4279
Epoch [1/1], Batch [361/428], Loss: 1.1074
Epoch [1/1], Batch [362/428], Loss: 1.8412
Epoch [1/1], Batch [363/428], Loss: 0.0047
Epoch [1/1], Batch [364/428], Loss: 0.0308
Epoch [1/1], Batch [365/428], Loss: 0.2785
Epoch [1/1], Batch [366/428], Loss: 1.5380
Epoch [1/1], Batch [367/428], Loss: 0.0033
Epoch [1/1], Batch [368/428], Loss: 1.7442
Epoch [1/1], Batch [369/428], Loss: 0.0990
Epoch [1/1], Batch [370/428], Loss: 0.0420
Epoch [1/1], Batch [371/428], Loss: 0.0198
Epoch [1/1], Batch [372/428], Loss: 2.8189
Epoch [1/1], Batch [373/428], Loss: 1.2969
Epoch [1/1], Batch [374/428], Loss: 1.6765
Epoch [1/1], Batch [375/428], Loss: 1.5066
Epoch [1/1], Batch [376/428], Loss: 1.8733
Epoch [1/1], Batch [377/428], Loss: 1.1915
Epoch [1/1], Batch [378/428], Loss: 1.2648
Epoch [1/1], Batch [379/428], Loss: 4.4354
Epoch [1/1], Batch [380/428], Loss: 0.1434
Epoch [1/1], Batch [381/428], Loss: 0.7082
Epoch [1/1], Batch [382/428], Loss: 1.4363
Epoch [1/1], Batch [383/428], Loss: 0.0228
Epoch [1/1], Batch [384/428], Loss: 1.4197
Epoch [1/1], Batch [385/428], Loss: 1.9134
Epoch [1/1], Batch [386/428], Loss: 2.0429
Epoch [1/1], Batch [387/428], Loss: 1.2252
Epoch [1/1], Batch [388/428], Loss: 1.5319
Epoch [1/1], Batch [389/428], Loss: 1.3025
Epoch [1/1], Batch [390/428], Loss: 0.5359
Epoch [1/1], Batch [391/428], Loss: 3.0357
Epoch [1/1], Batch [392/428], Loss: 5.1274
Epoch [1/1], Batch [393/428], Loss: 2.1585
Epoch [1/1], Batch [394/428], Loss: 0.3885
Epoch [1/1], Batch [395/428], Loss: 2.7739
Epoch [1/1], Batch [396/428], Loss: 1.5639
Epoch [1/1], Batch [397/428], Loss: 3.9023
Epoch [1/1], Batch [398/428], Loss: 0.0444
Epoch [1/1], Batch [399/428], Loss: 1.8621
Epoch [1/1], Batch [400/428], Loss: 3.8430
Epoch [1/1], Batch [401/428], Loss: 2.4061
Epoch [1/1], Batch [402/428], Loss: 1.4259
Epoch [1/1], Batch [403/428], Loss: 1.3894
Epoch [1/1], Batch [404/428], Loss: 1.8685
Epoch [1/1], Batch [405/428], Loss: 0.8841
Epoch [1/1], Batch [406/428], Loss: 0.0027
Epoch [1/1], Batch [407/428], Loss: 0.0632
Epoch [1/1], Batch [408/428], Loss: 2.1381
Epoch [1/1], Batch [409/428], Loss: 3.2185
Epoch [1/1], Batch [410/428], Loss: 0.6812
Epoch [1/1], Batch [411/428], Loss: 1.3309
Epoch [1/1], Batch [412/428], Loss: 4.3017
Epoch [1/1], Batch [413/428], Loss: 1.3024
Epoch [1/1], Batch [414/428], Loss: 1.9522
Epoch [1/1], Batch [415/428], Loss: 0.3593
Epoch [1/1], Batch [416/428], Loss: 2.6060
Epoch [1/1], Batch [417/428], Loss: 0.9930
Epoch [1/1], Batch [418/428], Loss: 0.4396
Epoch [1/1], Batch [419/428], Loss: 0.2834
Epoch [1/1], Batch [420/428], Loss: 3.0017
Epoch [1/1], Batch [421/428], Loss: 2.2022
Epoch [1/1], Batch [422/428], Loss: 2.3529
Epoch [1/1], Batch [423/428], Loss: 4.7406
Epoch [1/1], Batch [424/428], Loss: 4.3463
Epoch [1/1], Batch [425/428], Loss: 0.2682
Epoch [1/1], Batch [426/428], Loss: 0.0521
Epoch [1/1], Batch [427/428], Loss: 1.1928
Epoch [1/1], Batch [428/428], Loss: 0.0031
Epoch [1] Training Time: 338.55 seconds
Epoch [1/1], Average Loss: 1.6044, Training Accuracy: 0.4089
Epoch [1], Validation Loss: 1.6582, Validation Accuracy: 0.4194
Epoch [1] Validation Time: 19.38 seconds
--------------------------------------------------

Running trial 9 with config: {'batch_size': 1, 'lr': 0.0002998227711778014, 'num_epochs': 3, 'unfreeze_epoch': 3, 'max_length': 48000, 'device': device(type='cpu')}
Epoch [1/3], Batch [1/428], Loss: 1.6047
Epoch [1/3], Batch [2/428], Loss: 3.4218
Epoch [1/3], Batch [3/428], Loss: 1.4506
Epoch [1/3], Batch [4/428], Loss: 1.6336
Epoch [1/3], Batch [5/428], Loss: 1.2311
Epoch [1/3], Batch [6/428], Loss: 3.5518
Epoch [1/3], Batch [7/428], Loss: 2.7532
Epoch [1/3], Batch [8/428], Loss: 1.7067
Epoch [1/3], Batch [9/428], Loss: 2.7802
Epoch [1/3], Batch [10/428], Loss: 4.7928
Epoch [1/3], Batch [11/428], Loss: 0.7359
Epoch [1/3], Batch [12/428], Loss: 5.3837
Epoch [1/3], Batch [13/428], Loss: 1.2006
Epoch [1/3], Batch [14/428], Loss: 2.8253
Epoch [1/3], Batch [15/428], Loss: 1.2534
Epoch [1/3], Batch [16/428], Loss: 2.2489
Epoch [1/3], Batch [17/428], Loss: 4.2399
Epoch [1/3], Batch [18/428], Loss: 2.8936
Epoch [1/3], Batch [19/428], Loss: 1.0613
Epoch [1/3], Batch [20/428], Loss: 0.8614
Epoch [1/3], Batch [21/428], Loss: 0.9492
Epoch [1/3], Batch [22/428], Loss: 1.4992
Epoch [1/3], Batch [23/428], Loss: 1.5558
Epoch [1/3], Batch [24/428], Loss: 2.8311
Epoch [1/3], Batch [25/428], Loss: 1.4506
Epoch [1/3], Batch [26/428], Loss: 1.3471
Epoch [1/3], Batch [27/428], Loss: 1.3214
Epoch [1/3], Batch [28/428], Loss: 4.0816
Epoch [1/3], Batch [29/428], Loss: 1.5362
Epoch [1/3], Batch [30/428], Loss: 1.4880
Epoch [1/3], Batch [31/428], Loss: 1.6376
Epoch [1/3], Batch [32/428], Loss: 2.5677
Epoch [1/3], Batch [33/428], Loss: 3.0068
Epoch [1/3], Batch [34/428], Loss: 1.0997
Epoch [1/3], Batch [35/428], Loss: 2.0555
Epoch [1/3], Batch [36/428], Loss: 4.1273
Epoch [1/3], Batch [37/428], Loss: 2.0869
Epoch [1/3], Batch [38/428], Loss: 0.3841
Epoch [1/3], Batch [39/428], Loss: 2.4887
Epoch [1/3], Batch [40/428], Loss: 0.6778
Epoch [1/3], Batch [41/428], Loss: 3.8385
Epoch [1/3], Batch [42/428], Loss: 1.6547
Epoch [1/3], Batch [43/428], Loss: 2.7080
Epoch [1/3], Batch [44/428], Loss: 3.2672
Epoch [1/3], Batch [45/428], Loss: 2.5316
Epoch [1/3], Batch [46/428], Loss: 1.2054
Epoch [1/3], Batch [47/428], Loss: 1.1291
Epoch [1/3], Batch [48/428], Loss: 1.4273
Epoch [1/3], Batch [49/428], Loss: 2.2623
Epoch [1/3], Batch [50/428], Loss: 1.7444
Epoch [1/3], Batch [51/428], Loss: 1.4197
Epoch [1/3], Batch [52/428], Loss: 0.8348
Epoch [1/3], Batch [53/428], Loss: 1.0017
Epoch [1/3], Batch [54/428], Loss: 1.6094
Epoch [1/3], Batch [55/428], Loss: 0.6772
Epoch [1/3], Batch [56/428], Loss: 1.8425
Epoch [1/3], Batch [57/428], Loss: 2.5837
Epoch [1/3], Batch [58/428], Loss: 0.7510
Epoch [1/3], Batch [59/428], Loss: 3.2464
Epoch [1/3], Batch [60/428], Loss: 2.6695
Epoch [1/3], Batch [61/428], Loss: 4.0757
Epoch [1/3], Batch [62/428], Loss: 1.0196
Epoch [1/3], Batch [63/428], Loss: 0.9028
Epoch [1/3], Batch [64/428], Loss: 1.9723
Epoch [1/3], Batch [65/428], Loss: 1.8004
Epoch [1/3], Batch [66/428], Loss: 2.4568
Epoch [1/3], Batch [67/428], Loss: 1.2343
Epoch [1/3], Batch [68/428], Loss: 1.0672
Epoch [1/3], Batch [69/428], Loss: 0.9970
Epoch [1/3], Batch [70/428], Loss: 1.0831
Epoch [1/3], Batch [71/428], Loss: 0.5138
Epoch [1/3], Batch [72/428], Loss: 1.3062
Epoch [1/3], Batch [73/428], Loss: 1.1682
Epoch [1/3], Batch [74/428], Loss: 2.1029
Epoch [1/3], Batch [75/428], Loss: 2.3418
Epoch [1/3], Batch [76/428], Loss: 0.5798
Epoch [1/3], Batch [77/428], Loss: 3.3443
Epoch [1/3], Batch [78/428], Loss: 0.6645
Epoch [1/3], Batch [79/428], Loss: 1.3178
Epoch [1/3], Batch [80/428], Loss: 0.3598
Epoch [1/3], Batch [81/428], Loss: 2.6751
Epoch [1/3], Batch [82/428], Loss: 0.4617
Epoch [1/3], Batch [83/428], Loss: 1.3848
Epoch [1/3], Batch [84/428], Loss: 1.2444
Epoch [1/3], Batch [85/428], Loss: 0.8230
Epoch [1/3], Batch [86/428], Loss: 2.4012
Epoch [1/3], Batch [87/428], Loss: 0.4400
Epoch [1/3], Batch [88/428], Loss: 1.8525
Epoch [1/3], Batch [89/428], Loss: 0.5323
Epoch [1/3], Batch [90/428], Loss: 0.8082
Epoch [1/3], Batch [91/428], Loss: 0.1338
Epoch [1/3], Batch [92/428], Loss: 0.0811
Epoch [1/3], Batch [93/428], Loss: 3.9261
Epoch [1/3], Batch [94/428], Loss: 0.1617
Epoch [1/3], Batch [95/428], Loss: 1.7555
Epoch [1/3], Batch [96/428], Loss: 1.7292
Epoch [1/3], Batch [97/428], Loss: 1.3792
Epoch [1/3], Batch [98/428], Loss: 3.0221
Epoch [1/3], Batch [99/428], Loss: 0.5999
Epoch [1/3], Batch [100/428], Loss: 0.7157
Epoch [1/3], Batch [101/428], Loss: 2.3079
Epoch [1/3], Batch [102/428], Loss: 3.2419
Epoch [1/3], Batch [103/428], Loss: 3.4993
Epoch [1/3], Batch [104/428], Loss: 0.3812
Epoch [1/3], Batch [105/428], Loss: 0.0305
Epoch [1/3], Batch [106/428], Loss: 0.0143
Epoch [1/3], Batch [107/428], Loss: 0.1909
Epoch [1/3], Batch [108/428], Loss: 0.1726
Epoch [1/3], Batch [109/428], Loss: 0.0116
Epoch [1/3], Batch [110/428], Loss: 0.0191
Epoch [1/3], Batch [111/428], Loss: 1.7091
Epoch [1/3], Batch [112/428], Loss: 1.1122
Epoch [1/3], Batch [113/428], Loss: 2.4368
Epoch [1/3], Batch [114/428], Loss: 2.0259
Epoch [1/3], Batch [115/428], Loss: 2.0489
Epoch [1/3], Batch [116/428], Loss: 0.0754
Epoch [1/3], Batch [117/428], Loss: 0.5810
Epoch [1/3], Batch [118/428], Loss: 0.7631
Epoch [1/3], Batch [119/428], Loss: 3.3151
Epoch [1/3], Batch [120/428], Loss: 0.0036
Epoch [1/3], Batch [121/428], Loss: 3.4066
Epoch [1/3], Batch [122/428], Loss: 1.8367
Epoch [1/3], Batch [123/428], Loss: 2.5144
Epoch [1/3], Batch [124/428], Loss: 2.3551
Epoch [1/3], Batch [125/428], Loss: 2.8465
Epoch [1/3], Batch [126/428], Loss: 1.2182
Epoch [1/3], Batch [127/428], Loss: 2.4580
Epoch [1/3], Batch [128/428], Loss: 0.5561
Epoch [1/3], Batch [129/428], Loss: 0.0028
Epoch [1/3], Batch [130/428], Loss: 1.7641
Epoch [1/3], Batch [131/428], Loss: 0.8484
Epoch [1/3], Batch [132/428], Loss: 0.0022
Epoch [1/3], Batch [133/428], Loss: 1.0238
Epoch [1/3], Batch [134/428], Loss: 0.7009
Epoch [1/3], Batch [135/428], Loss: 0.0022
Epoch [1/3], Batch [136/428], Loss: 1.0651
Epoch [1/3], Batch [137/428], Loss: 2.1294
Epoch [1/3], Batch [138/428], Loss: 0.9350
Epoch [1/3], Batch [139/428], Loss: 4.6317
Epoch [1/3], Batch [140/428], Loss: 0.6435
Epoch [1/3], Batch [141/428], Loss: 0.0515
Epoch [1/3], Batch [142/428], Loss: 0.0059
Epoch [1/3], Batch [143/428], Loss: 1.7223
Epoch [1/3], Batch [144/428], Loss: 2.3669
Epoch [1/3], Batch [145/428], Loss: 1.4336
Epoch [1/3], Batch [146/428], Loss: 0.6706
Epoch [1/3], Batch [147/428], Loss: 0.4426
Epoch [1/3], Batch [148/428], Loss: 0.0016
Epoch [1/3], Batch [149/428], Loss: 1.2214
Epoch [1/3], Batch [150/428], Loss: 0.0015
Epoch [1/3], Batch [151/428], Loss: 2.3017
Epoch [1/3], Batch [152/428], Loss: 0.1440
Epoch [1/3], Batch [153/428], Loss: 2.0564
Epoch [1/3], Batch [154/428], Loss: 1.1313
Epoch [1/3], Batch [155/428], Loss: 4.9666
Epoch [1/3], Batch [156/428], Loss: 0.3352
Epoch [1/3], Batch [157/428], Loss: 0.0016
Epoch [1/3], Batch [158/428], Loss: 0.3406
Epoch [1/3], Batch [159/428], Loss: 1.9353
Epoch [1/3], Batch [160/428], Loss: 0.3160
Epoch [1/3], Batch [161/428], Loss: 0.2974
Epoch [1/3], Batch [162/428], Loss: 3.0084
Epoch [1/3], Batch [163/428], Loss: 3.1347
Epoch [1/3], Batch [164/428], Loss: 0.2797
Epoch [1/3], Batch [165/428], Loss: 0.0013
Epoch [1/3], Batch [166/428], Loss: 2.0059
Epoch [1/3], Batch [167/428], Loss: 1.0481
Epoch [1/3], Batch [168/428], Loss: 7.3719
Epoch [1/3], Batch [169/428], Loss: 1.5477
Epoch [1/3], Batch [170/428], Loss: 3.5091
Epoch [1/3], Batch [171/428], Loss: 2.8430
Epoch [1/3], Batch [172/428], Loss: 1.7865
Epoch [1/3], Batch [173/428], Loss: 2.2809
Epoch [1/3], Batch [174/428], Loss: 0.0030
Epoch [1/3], Batch [175/428], Loss: 2.3331
Epoch [1/3], Batch [176/428], Loss: 3.8672
Epoch [1/3], Batch [177/428], Loss: 0.0018
Epoch [1/3], Batch [178/428], Loss: 0.0759
Epoch [1/3], Batch [179/428], Loss: 1.7028
Epoch [1/3], Batch [180/428], Loss: 0.1182
Epoch [1/3], Batch [181/428], Loss: 1.0734
Epoch [1/3], Batch [182/428], Loss: 0.1759
Epoch [1/3], Batch [183/428], Loss: 6.4131
Epoch [1/3], Batch [184/428], Loss: 0.8501
Epoch [1/3], Batch [185/428], Loss: 0.5095
Epoch [1/3], Batch [186/428], Loss: 0.3883
Epoch [1/3], Batch [187/428], Loss: 0.0022
Epoch [1/3], Batch [188/428], Loss: 2.2862
Epoch [1/3], Batch [189/428], Loss: 0.0468
Epoch [1/3], Batch [190/428], Loss: 2.3905
Epoch [1/3], Batch [191/428], Loss: 0.0044
Epoch [1/3], Batch [192/428], Loss: 1.9587
Epoch [1/3], Batch [193/428], Loss: 0.1155
Epoch [1/3], Batch [194/428], Loss: 0.0038
Epoch [1/3], Batch [195/428], Loss: 0.2287
Epoch [1/3], Batch [196/428], Loss: 0.0888
Epoch [1/3], Batch [197/428], Loss: 2.0014
Epoch [1/3], Batch [198/428], Loss: 2.4318
Epoch [1/3], Batch [199/428], Loss: 2.1512
Epoch [1/3], Batch [200/428], Loss: 2.8644
Epoch [1/3], Batch [201/428], Loss: 0.1361
Epoch [1/3], Batch [202/428], Loss: 4.4497
Epoch [1/3], Batch [203/428], Loss: 0.1459
Epoch [1/3], Batch [204/428], Loss: 3.1501
Epoch [1/3], Batch [205/428], Loss: 0.2570
Epoch [1/3], Batch [206/428], Loss: 1.3265
Epoch [1/3], Batch [207/428], Loss: 1.4770
Epoch [1/3], Batch [208/428], Loss: 0.0606
Epoch [1/3], Batch [209/428], Loss: 2.8089
Epoch [1/3], Batch [210/428], Loss: 6.7267
Epoch [1/3], Batch [211/428], Loss: 3.1503
Epoch [1/3], Batch [212/428], Loss: 2.1355
Epoch [1/3], Batch [213/428], Loss: 1.5532
Epoch [1/3], Batch [214/428], Loss: 0.2425
Epoch [1/3], Batch [215/428], Loss: 0.0140
Epoch [1/3], Batch [216/428], Loss: 0.0018
Epoch [1/3], Batch [217/428], Loss: 0.8283
Epoch [1/3], Batch [218/428], Loss: 0.4678
Epoch [1/3], Batch [219/428], Loss: 2.5869
Epoch [1/3], Batch [220/428], Loss: 2.8502
Epoch [1/3], Batch [221/428], Loss: 2.3835
Epoch [1/3], Batch [222/428], Loss: 2.7149
Epoch [1/3], Batch [223/428], Loss: 0.5211
Epoch [1/3], Batch [224/428], Loss: 0.0015
Epoch [1/3], Batch [225/428], Loss: 2.5259
Epoch [1/3], Batch [226/428], Loss: 2.2559
Epoch [1/3], Batch [227/428], Loss: 4.5222
Epoch [1/3], Batch [228/428], Loss: 3.6456
Epoch [1/3], Batch [229/428], Loss: 4.7064
Epoch [1/3], Batch [230/428], Loss: 3.1899
Epoch [1/3], Batch [231/428], Loss: 1.4562
Epoch [1/3], Batch [232/428], Loss: 2.5760
Epoch [1/3], Batch [233/428], Loss: 2.0310
Epoch [1/3], Batch [234/428], Loss: 1.6867
Epoch [1/3], Batch [235/428], Loss: 1.9714
Epoch [1/3], Batch [236/428], Loss: 1.0447
Epoch [1/3], Batch [237/428], Loss: 1.3230
Epoch [1/3], Batch [238/428], Loss: 1.4523
Epoch [1/3], Batch [239/428], Loss: 0.2139
Epoch [1/3], Batch [240/428], Loss: 1.8723
Epoch [1/3], Batch [241/428], Loss: 0.0021
Epoch [1/3], Batch [242/428], Loss: 2.5891
Epoch [1/3], Batch [243/428], Loss: 1.7222
Epoch [1/3], Batch [244/428], Loss: 1.1618
Epoch [1/3], Batch [245/428], Loss: 1.7972
Epoch [1/3], Batch [246/428], Loss: 0.0032
Epoch [1/3], Batch [247/428], Loss: 0.0021
Epoch [1/3], Batch [248/428], Loss: 1.3187
Epoch [1/3], Batch [249/428], Loss: 0.0055
Epoch [1/3], Batch [250/428], Loss: 0.5585
Epoch [1/3], Batch [251/428], Loss: 0.8631
Epoch [1/3], Batch [252/428], Loss: 0.1962
Epoch [1/3], Batch [253/428], Loss: 0.0160
Epoch [1/3], Batch [254/428], Loss: 0.0086
Epoch [1/3], Batch [255/428], Loss: 4.6987
Epoch [1/3], Batch [256/428], Loss: 2.8490
Epoch [1/3], Batch [257/428], Loss: 0.0494
Epoch [1/3], Batch [258/428], Loss: 1.6857
Epoch [1/3], Batch [259/428], Loss: 0.6006
Epoch [1/3], Batch [260/428], Loss: 2.6454
Epoch [1/3], Batch [261/428], Loss: 0.3068
Epoch [1/3], Batch [262/428], Loss: 1.8956
Epoch [1/3], Batch [263/428], Loss: 1.6810
Epoch [1/3], Batch [264/428], Loss: 1.8667
Epoch [1/3], Batch [265/428], Loss: 1.1961
Epoch [1/3], Batch [266/428], Loss: 0.3678
Epoch [1/3], Batch [267/428], Loss: 0.0166
Epoch [1/3], Batch [268/428], Loss: 1.3560
Epoch [1/3], Batch [269/428], Loss: 1.1688
Epoch [1/3], Batch [270/428], Loss: 2.0116
Epoch [1/3], Batch [271/428], Loss: 2.8055
Epoch [1/3], Batch [272/428], Loss: 2.8001
Epoch [1/3], Batch [273/428], Loss: 1.6243
Epoch [1/3], Batch [274/428], Loss: 0.9835
Epoch [1/3], Batch [275/428], Loss: 0.8875
Epoch [1/3], Batch [276/428], Loss: 1.1202
Epoch [1/3], Batch [277/428], Loss: 0.4361
Epoch [1/3], Batch [278/428], Loss: 0.1887
Epoch [1/3], Batch [279/428], Loss: 1.5414
Epoch [1/3], Batch [280/428], Loss: 2.0080
Epoch [1/3], Batch [281/428], Loss: 0.4201
Epoch [1/3], Batch [282/428], Loss: 0.3398
Epoch [1/3], Batch [283/428], Loss: 0.0019
Epoch [1/3], Batch [284/428], Loss: 0.8910
Epoch [1/3], Batch [285/428], Loss: 1.0067
Epoch [1/3], Batch [286/428], Loss: 2.0255
Epoch [1/3], Batch [287/428], Loss: 1.9199
Epoch [1/3], Batch [288/428], Loss: 1.4528
Epoch [1/3], Batch [289/428], Loss: 0.8326
Epoch [1/3], Batch [290/428], Loss: 1.1885
Epoch [1/3], Batch [291/428], Loss: 0.9390
Epoch [1/3], Batch [292/428], Loss: 1.9771
Epoch [1/3], Batch [293/428], Loss: 1.1380
Epoch [1/3], Batch [294/428], Loss: 1.7788
Epoch [1/3], Batch [295/428], Loss: 2.1939
Epoch [1/3], Batch [296/428], Loss: 2.9260
Epoch [1/3], Batch [297/428], Loss: 0.0416
Epoch [1/3], Batch [298/428], Loss: 2.2476
Epoch [1/3], Batch [299/428], Loss: 1.7892
Epoch [1/3], Batch [300/428], Loss: 1.7089
Epoch [1/3], Batch [301/428], Loss: 0.0046
Epoch [1/3], Batch [302/428], Loss: 3.9494
Epoch [1/3], Batch [303/428], Loss: 2.1776
Epoch [1/3], Batch [304/428], Loss: 1.6737
Epoch [1/3], Batch [305/428], Loss: 0.0021
Epoch [1/3], Batch [306/428], Loss: 6.5076
Epoch [1/3], Batch [307/428], Loss: 2.7378
Epoch [1/3], Batch [308/428], Loss: 0.0040
Epoch [1/3], Batch [309/428], Loss: 0.1916
Epoch [1/3], Batch [310/428], Loss: 1.3223
Epoch [1/3], Batch [311/428], Loss: 0.0779
Epoch [1/3], Batch [312/428], Loss: 1.8131
Epoch [1/3], Batch [313/428], Loss: 0.0019
Epoch [1/3], Batch [314/428], Loss: 0.5468
Epoch [1/3], Batch [315/428], Loss: 4.0564
Epoch [1/3], Batch [316/428], Loss: 1.7597
Epoch [1/3], Batch [317/428], Loss: 1.5425
Epoch [1/3], Batch [318/428], Loss: 6.0965
Epoch [1/3], Batch [319/428], Loss: 1.1102
Epoch [1/3], Batch [320/428], Loss: 0.6150
Epoch [1/3], Batch [321/428], Loss: 1.9153
Epoch [1/3], Batch [322/428], Loss: 1.8204
Epoch [1/3], Batch [323/428], Loss: 2.5875
Epoch [1/3], Batch [324/428], Loss: 0.6939
Epoch [1/3], Batch [325/428], Loss: 0.9267
Epoch [1/3], Batch [326/428], Loss: 1.8193
Epoch [1/3], Batch [327/428], Loss: 0.7562
Epoch [1/3], Batch [328/428], Loss: 0.3075
Epoch [1/3], Batch [329/428], Loss: 1.1173
Epoch [1/3], Batch [330/428], Loss: 0.0824
Epoch [1/3], Batch [331/428], Loss: 0.0846
Epoch [1/3], Batch [332/428], Loss: 0.6762
Epoch [1/3], Batch [333/428], Loss: 2.8893
Epoch [1/3], Batch [334/428], Loss: 0.5690
Epoch [1/3], Batch [335/428], Loss: 3.2747
Epoch [1/3], Batch [336/428], Loss: 0.0267
Epoch [1/3], Batch [337/428], Loss: 1.3258
Epoch [1/3], Batch [338/428], Loss: 0.8579
Epoch [1/3], Batch [339/428], Loss: 0.0233
Epoch [1/3], Batch [340/428], Loss: 1.1398
Epoch [1/3], Batch [341/428], Loss: 1.7640
Epoch [1/3], Batch [342/428], Loss: 1.0052
Epoch [1/3], Batch [343/428], Loss: 2.4617
Epoch [1/3], Batch [344/428], Loss: 0.0045
Epoch [1/3], Batch [345/428], Loss: 2.7241
Epoch [1/3], Batch [346/428], Loss: 0.2584
Epoch [1/3], Batch [347/428], Loss: 2.3176
Epoch [1/3], Batch [348/428], Loss: 0.1290
Epoch [1/3], Batch [349/428], Loss: 0.5786
Epoch [1/3], Batch [350/428], Loss: 1.6513
Epoch [1/3], Batch [351/428], Loss: 2.2407
Epoch [1/3], Batch [352/428], Loss: 0.9162
Epoch [1/3], Batch [353/428], Loss: 0.0035
Epoch [1/3], Batch [354/428], Loss: 1.7352
Epoch [1/3], Batch [355/428], Loss: 0.0056
Epoch [1/3], Batch [356/428], Loss: 1.7881
Epoch [1/3], Batch [357/428], Loss: 0.0574
Epoch [1/3], Batch [358/428], Loss: 1.7583
Epoch [1/3], Batch [359/428], Loss: 2.9792
Epoch [1/3], Batch [360/428], Loss: 2.0380
Epoch [1/3], Batch [361/428], Loss: 1.9519
Epoch [1/3], Batch [362/428], Loss: 2.2720
Epoch [1/3], Batch [363/428], Loss: 3.4490
Epoch [1/3], Batch [364/428], Loss: 2.1051
Epoch [1/3], Batch [365/428], Loss: 0.9399
Epoch [1/3], Batch [366/428], Loss: 1.4359
Epoch [1/3], Batch [367/428], Loss: 2.0958
Epoch [1/3], Batch [368/428], Loss: 1.8763
Epoch [1/3], Batch [369/428], Loss: 0.0015
Epoch [1/3], Batch [370/428], Loss: 0.2888
Epoch [1/3], Batch [371/428], Loss: 0.0044
Epoch [1/3], Batch [372/428], Loss: 2.1332
Epoch [1/3], Batch [373/428], Loss: 0.8074
Epoch [1/3], Batch [374/428], Loss: 5.0957
Epoch [1/3], Batch [375/428], Loss: 1.0007
Epoch [1/3], Batch [376/428], Loss: 0.6881
Epoch [1/3], Batch [377/428], Loss: 1.2763
Epoch [1/3], Batch [378/428], Loss: 0.0020
Epoch [1/3], Batch [379/428], Loss: 2.2353
Epoch [1/3], Batch [380/428], Loss: 2.1057
Epoch [1/3], Batch [381/428], Loss: 0.0015
Epoch [1/3], Batch [382/428], Loss: 2.9055
Epoch [1/3], Batch [383/428], Loss: 2.4200
Epoch [1/3], Batch [384/428], Loss: 1.7866
Epoch [1/3], Batch [385/428], Loss: 0.4463
Epoch [1/3], Batch [386/428], Loss: 1.8924
Epoch [1/3], Batch [387/428], Loss: 0.0026
Epoch [1/3], Batch [388/428], Loss: 2.0942
Epoch [1/3], Batch [389/428], Loss: 1.7992
Epoch [1/3], Batch [390/428], Loss: 1.2866
Epoch [1/3], Batch [391/428], Loss: 1.3126
Epoch [1/3], Batch [392/428], Loss: 3.2021
Epoch [1/3], Batch [393/428], Loss: 1.4584
Epoch [1/3], Batch [394/428], Loss: 1.9546
Epoch [1/3], Batch [395/428], Loss: 1.7070
Epoch [1/3], Batch [396/428], Loss: 1.5653
Epoch [1/3], Batch [397/428], Loss: 1.1495
Epoch [1/3], Batch [398/428], Loss: 1.1997
Epoch [1/3], Batch [399/428], Loss: 0.9896
Epoch [1/3], Batch [400/428], Loss: 2.3034
Epoch [1/3], Batch [401/428], Loss: 0.1186
Epoch [1/3], Batch [402/428], Loss: 0.0873
Epoch [1/3], Batch [403/428], Loss: 1.8865
Epoch [1/3], Batch [404/428], Loss: 0.3679
Epoch [1/3], Batch [405/428], Loss: 1.8910
Epoch [1/3], Batch [406/428], Loss: 2.4291
Epoch [1/3], Batch [407/428], Loss: 4.6918
Epoch [1/3], Batch [408/428], Loss: 1.4283
Epoch [1/3], Batch [409/428], Loss: 1.6894
Epoch [1/3], Batch [410/428], Loss: 0.0829
Epoch [1/3], Batch [411/428], Loss: 0.0277
Epoch [1/3], Batch [412/428], Loss: 1.4067
Epoch [1/3], Batch [413/428], Loss: 1.3655
Epoch [1/3], Batch [414/428], Loss: 0.0034
Epoch [1/3], Batch [415/428], Loss: 0.1670
Epoch [1/3], Batch [416/428], Loss: 0.0048
Epoch [1/3], Batch [417/428], Loss: 0.0540
Epoch [1/3], Batch [418/428], Loss: 1.3906
Epoch [1/3], Batch [419/428], Loss: 0.0017
Epoch [1/3], Batch [420/428], Loss: 1.5703
Epoch [1/3], Batch [421/428], Loss: 0.0472
Epoch [1/3], Batch [422/428], Loss: 0.1816
Epoch [1/3], Batch [423/428], Loss: 0.0013
Epoch [1/3], Batch [424/428], Loss: 1.8455
Epoch [1/3], Batch [425/428], Loss: 1.5046
Epoch [1/3], Batch [426/428], Loss: 0.3447
Epoch [1/3], Batch [427/428], Loss: 0.6460
Epoch [1/3], Batch [428/428], Loss: 2.2884
Epoch [1] Training Time: 132.94 seconds
Epoch [1/3], Average Loss: 1.5158, Training Accuracy: 0.4322
Epoch [1], Validation Loss: 1.7134, Validation Accuracy: 0.4211
Epoch [1] Validation Time: 7.24 seconds
--------------------------------------------------
Epoch [2/3], Batch [1/428], Loss: 0.7758
Epoch [2/3], Batch [2/428], Loss: 0.0011
Epoch [2/3], Batch [3/428], Loss: 0.1037
Epoch [2/3], Batch [4/428], Loss: 0.7431
Epoch [2/3], Batch [5/428], Loss: 0.0013
Epoch [2/3], Batch [6/428], Loss: 1.4675
Epoch [2/3], Batch [7/428], Loss: 0.9904
Epoch [2/3], Batch [8/428], Loss: 0.0677
Epoch [2/3], Batch [9/428], Loss: 1.5203
Epoch [2/3], Batch [10/428], Loss: 0.0007
Epoch [2/3], Batch [11/428], Loss: 1.1214
Epoch [2/3], Batch [12/428], Loss: 1.3584
Epoch [2/3], Batch [13/428], Loss: 0.7217
Epoch [2/3], Batch [14/428], Loss: 7.4027
Epoch [2/3], Batch [15/428], Loss: 0.4380
Epoch [2/3], Batch [16/428], Loss: 1.7756
Epoch [2/3], Batch [17/428], Loss: 1.6630
Epoch [2/3], Batch [18/428], Loss: 0.0010
Epoch [2/3], Batch [19/428], Loss: 0.0010
Epoch [2/3], Batch [20/428], Loss: 1.6338
Epoch [2/3], Batch [21/428], Loss: 2.6000
Epoch [2/3], Batch [22/428], Loss: 1.9937
Epoch [2/3], Batch [23/428], Loss: 1.0263
Epoch [2/3], Batch [24/428], Loss: 0.0056
Epoch [2/3], Batch [25/428], Loss: 1.5394
Epoch [2/3], Batch [26/428], Loss: 3.1868
Epoch [2/3], Batch [27/428], Loss: 0.8585
Epoch [2/3], Batch [28/428], Loss: 0.0013
Epoch [2/3], Batch [29/428], Loss: 0.7077
Epoch [2/3], Batch [30/428], Loss: 0.8786
Epoch [2/3], Batch [31/428], Loss: 2.5263
Epoch [2/3], Batch [32/428], Loss: 0.0292
Epoch [2/3], Batch [33/428], Loss: 1.6210
Epoch [2/3], Batch [34/428], Loss: 0.3139
Epoch [2/3], Batch [35/428], Loss: 0.0185
Epoch [2/3], Batch [36/428], Loss: 1.5065
Epoch [2/3], Batch [37/428], Loss: 0.3695
Epoch [2/3], Batch [38/428], Loss: 3.2502
Epoch [2/3], Batch [39/428], Loss: 1.2960
Epoch [2/3], Batch [40/428], Loss: 1.3377
Epoch [2/3], Batch [41/428], Loss: 0.0453
Epoch [2/3], Batch [42/428], Loss: 2.1421
Epoch [2/3], Batch [43/428], Loss: 2.1432
Epoch [2/3], Batch [44/428], Loss: 1.6931
Epoch [2/3], Batch [45/428], Loss: 0.0115
Epoch [2/3], Batch [46/428], Loss: 0.8716
Epoch [2/3], Batch [47/428], Loss: 1.2239
Epoch [2/3], Batch [48/428], Loss: 0.6930
Epoch [2/3], Batch [49/428], Loss: 2.4186
Epoch [2/3], Batch [50/428], Loss: 2.7350
Epoch [2/3], Batch [51/428], Loss: 0.0006
Epoch [2/3], Batch [52/428], Loss: 0.0487
Epoch [2/3], Batch [53/428], Loss: 0.7525
Epoch [2/3], Batch [54/428], Loss: 2.3597
Epoch [2/3], Batch [55/428], Loss: 0.0008
Epoch [2/3], Batch [56/428], Loss: 1.9837
Epoch [2/3], Batch [57/428], Loss: 1.9271
Epoch [2/3], Batch [58/428], Loss: 0.0006
Epoch [2/3], Batch [59/428], Loss: 2.5518
Epoch [2/3], Batch [60/428], Loss: 0.0136
Epoch [2/3], Batch [61/428], Loss: 1.5243
Epoch [2/3], Batch [62/428], Loss: 0.0010
Epoch [2/3], Batch [63/428], Loss: 1.3284
Epoch [2/3], Batch [64/428], Loss: 0.0925
Epoch [2/3], Batch [65/428], Loss: 0.0004
Epoch [2/3], Batch [66/428], Loss: 2.6670
Epoch [2/3], Batch [67/428], Loss: 1.2630
Epoch [2/3], Batch [68/428], Loss: 0.5580
Epoch [2/3], Batch [69/428], Loss: 0.0031
Epoch [2/3], Batch [70/428], Loss: 0.8514
Epoch [2/3], Batch [71/428], Loss: 1.2696
Epoch [2/3], Batch [72/428], Loss: 0.5052
Epoch [2/3], Batch [73/428], Loss: 1.6937
Epoch [2/3], Batch [74/428], Loss: 0.0181
Epoch [2/3], Batch [75/428], Loss: 1.9611
Epoch [2/3], Batch [76/428], Loss: 0.0004
Epoch [2/3], Batch [77/428], Loss: 0.4744
Epoch [2/3], Batch [78/428], Loss: 0.0011
Epoch [2/3], Batch [79/428], Loss: 1.8175
Epoch [2/3], Batch [80/428], Loss: 0.0005
Epoch [2/3], Batch [81/428], Loss: 1.0208
Epoch [2/3], Batch [82/428], Loss: 1.5812
Epoch [2/3], Batch [83/428], Loss: 0.4417
Epoch [2/3], Batch [84/428], Loss: 3.5658
Epoch [2/3], Batch [85/428], Loss: 2.6515
Epoch [2/3], Batch [86/428], Loss: 1.7626
Epoch [2/3], Batch [87/428], Loss: 0.9367
Epoch [2/3], Batch [88/428], Loss: 1.4794
Epoch [2/3], Batch [89/428], Loss: 0.0180
Epoch [2/3], Batch [90/428], Loss: 1.7229
Epoch [2/3], Batch [91/428], Loss: 0.0747
Epoch [2/3], Batch [92/428], Loss: 0.0762
Epoch [2/3], Batch [93/428], Loss: 0.0383
Epoch [2/3], Batch [94/428], Loss: 1.4536
Epoch [2/3], Batch [95/428], Loss: 1.8250
Epoch [2/3], Batch [96/428], Loss: 1.8355
Epoch [2/3], Batch [97/428], Loss: 2.7508
Epoch [2/3], Batch [98/428], Loss: 1.1467
Epoch [2/3], Batch [99/428], Loss: 2.2414
Epoch [2/3], Batch [100/428], Loss: 0.0005
Epoch [2/3], Batch [101/428], Loss: 4.3980
Epoch [2/3], Batch [102/428], Loss: 2.4624
Epoch [2/3], Batch [103/428], Loss: 1.4445
Epoch [2/3], Batch [104/428], Loss: 3.3301
Epoch [2/3], Batch [105/428], Loss: 3.4536
Epoch [2/3], Batch [106/428], Loss: 1.8121
Epoch [2/3], Batch [107/428], Loss: 0.8582
Epoch [2/3], Batch [108/428], Loss: 2.0399
Epoch [2/3], Batch [109/428], Loss: 0.0376
Epoch [2/3], Batch [110/428], Loss: 3.3167
Epoch [2/3], Batch [111/428], Loss: 0.5873
Epoch [2/3], Batch [112/428], Loss: 1.1947
Epoch [2/3], Batch [113/428], Loss: 2.6376
Epoch [2/3], Batch [114/428], Loss: 0.0521
Epoch [2/3], Batch [115/428], Loss: 0.0008
Epoch [2/3], Batch [116/428], Loss: 2.1666
Epoch [2/3], Batch [117/428], Loss: 1.7460
Epoch [2/3], Batch [118/428], Loss: 0.5768
Epoch [2/3], Batch [119/428], Loss: 0.4103
Epoch [2/3], Batch [120/428], Loss: 1.4741
Epoch [2/3], Batch [121/428], Loss: 0.0005
Epoch [2/3], Batch [122/428], Loss: 1.0375
Epoch [2/3], Batch [123/428], Loss: 1.4626
Epoch [2/3], Batch [124/428], Loss: 0.0535
Epoch [2/3], Batch [125/428], Loss: 1.1500
Epoch [2/3], Batch [126/428], Loss: 0.0017
Epoch [2/3], Batch [127/428], Loss: 6.9285
Epoch [2/3], Batch [128/428], Loss: 2.4169
Epoch [2/3], Batch [129/428], Loss: 1.9109
Epoch [2/3], Batch [130/428], Loss: 1.0913
Epoch [2/3], Batch [131/428], Loss: 1.2777
Epoch [2/3], Batch [132/428], Loss: 1.0608
Epoch [2/3], Batch [133/428], Loss: 2.0763
Epoch [2/3], Batch [134/428], Loss: 1.3946
Epoch [2/3], Batch [135/428], Loss: 2.5226
Epoch [2/3], Batch [136/428], Loss: 1.9102
Epoch [2/3], Batch [137/428], Loss: 1.7794
Epoch [2/3], Batch [138/428], Loss: 0.0214
Epoch [2/3], Batch [139/428], Loss: 0.0023
Epoch [2/3], Batch [140/428], Loss: 0.0280
Epoch [2/3], Batch [141/428], Loss: 0.9379
Epoch [2/3], Batch [142/428], Loss: 1.1343
Epoch [2/3], Batch [143/428], Loss: 2.3881
Epoch [2/3], Batch [144/428], Loss: 1.4046
Epoch [2/3], Batch [145/428], Loss: 1.5565
Epoch [2/3], Batch [146/428], Loss: 0.7121
Epoch [2/3], Batch [147/428], Loss: 4.0209
Epoch [2/3], Batch [148/428], Loss: 2.9106
Epoch [2/3], Batch [149/428], Loss: 0.1140
Epoch [2/3], Batch [150/428], Loss: 1.6079
Epoch [2/3], Batch [151/428], Loss: 0.2734
Epoch [2/3], Batch [152/428], Loss: 0.0149
Epoch [2/3], Batch [153/428], Loss: 5.2141
Epoch [2/3], Batch [154/428], Loss: 0.0015
Epoch [2/3], Batch [155/428], Loss: 1.2896
Epoch [2/3], Batch [156/428], Loss: 0.0008
Epoch [2/3], Batch [157/428], Loss: 1.1781
Epoch [2/3], Batch [158/428], Loss: 2.8814
Epoch [2/3], Batch [159/428], Loss: 0.0021
Epoch [2/3], Batch [160/428], Loss: 0.1137
Epoch [2/3], Batch [161/428], Loss: 1.1693
Epoch [2/3], Batch [162/428], Loss: 0.6500
Epoch [2/3], Batch [163/428], Loss: 8.4219
Epoch [2/3], Batch [164/428], Loss: 1.3643
Epoch [2/3], Batch [165/428], Loss: 3.2536
Epoch [2/3], Batch [166/428], Loss: 0.7341
Epoch [2/3], Batch [167/428], Loss: 1.0029
Epoch [2/3], Batch [168/428], Loss: 0.5368
Epoch [2/3], Batch [169/428], Loss: 0.1720
Epoch [2/3], Batch [170/428], Loss: 0.1102
Epoch [2/3], Batch [171/428], Loss: 4.6024
Epoch [2/3], Batch [172/428], Loss: 1.8333
Epoch [2/3], Batch [173/428], Loss: 1.1006
Epoch [2/3], Batch [174/428], Loss: 1.7170
Epoch [2/3], Batch [175/428], Loss: 0.0373
Epoch [2/3], Batch [176/428], Loss: 3.3461
Epoch [2/3], Batch [177/428], Loss: 1.3278
Epoch [2/3], Batch [178/428], Loss: 0.8936
Epoch [2/3], Batch [179/428], Loss: 0.6074
Epoch [2/3], Batch [180/428], Loss: 1.6648
Epoch [2/3], Batch [181/428], Loss: 0.8738
Epoch [2/3], Batch [182/428], Loss: 0.0318
Epoch [2/3], Batch [183/428], Loss: 0.0005
Epoch [2/3], Batch [184/428], Loss: 0.1564
Epoch [2/3], Batch [185/428], Loss: 2.2848
Epoch [2/3], Batch [186/428], Loss: 2.7494
Epoch [2/3], Batch [187/428], Loss: 1.8032
Epoch [2/3], Batch [188/428], Loss: 3.6070
Epoch [2/3], Batch [189/428], Loss: 0.0229
Epoch [2/3], Batch [190/428], Loss: 1.2822
Epoch [2/3], Batch [191/428], Loss: 0.7252
Epoch [2/3], Batch [192/428], Loss: 2.1532
Epoch [2/3], Batch [193/428], Loss: 0.0929
Epoch [2/3], Batch [194/428], Loss: 0.0003
Epoch [2/3], Batch [195/428], Loss: 3.9849
Epoch [2/3], Batch [196/428], Loss: 0.9252
Epoch [2/3], Batch [197/428], Loss: 0.0008
Epoch [2/3], Batch [198/428], Loss: 2.7765
Epoch [2/3], Batch [199/428], Loss: 0.1979
Epoch [2/3], Batch [200/428], Loss: 0.2841
Epoch [2/3], Batch [201/428], Loss: 2.1443
Epoch [2/3], Batch [202/428], Loss: 2.4755
Epoch [2/3], Batch [203/428], Loss: 4.1642
Epoch [2/3], Batch [204/428], Loss: 0.3782
Epoch [2/3], Batch [205/428], Loss: 0.0009
Epoch [2/3], Batch [206/428], Loss: 0.3465
Epoch [2/3], Batch [207/428], Loss: 0.4726
Epoch [2/3], Batch [208/428], Loss: 1.5525
Epoch [2/3], Batch [209/428], Loss: 1.9182
Epoch [2/3], Batch [210/428], Loss: 4.3737
Epoch [2/3], Batch [211/428], Loss: 0.8287
Epoch [2/3], Batch [212/428], Loss: 0.0036
Epoch [2/3], Batch [213/428], Loss: 1.1244
Epoch [2/3], Batch [214/428], Loss: 1.4690
Epoch [2/3], Batch [215/428], Loss: 0.2378
Epoch [2/3], Batch [216/428], Loss: 0.3233
Epoch [2/3], Batch [217/428], Loss: 0.1632
Epoch [2/3], Batch [218/428], Loss: 0.0918
Epoch [2/3], Batch [219/428], Loss: 1.4657
Epoch [2/3], Batch [220/428], Loss: 0.9701
Epoch [2/3], Batch [221/428], Loss: 4.2979
Epoch [2/3], Batch [222/428], Loss: 5.5152
Epoch [2/3], Batch [223/428], Loss: 0.0082
Epoch [2/3], Batch [224/428], Loss: 0.0031
Epoch [2/3], Batch [225/428], Loss: 3.4708
Epoch [2/3], Batch [226/428], Loss: 0.2129
Epoch [2/3], Batch [227/428], Loss: 2.3854
Epoch [2/3], Batch [228/428], Loss: 3.4470
Epoch [2/3], Batch [229/428], Loss: 0.0313
Epoch [2/3], Batch [230/428], Loss: 1.5840
Epoch [2/3], Batch [231/428], Loss: 1.7490
Epoch [2/3], Batch [232/428], Loss: 3.2017
Epoch [2/3], Batch [233/428], Loss: 1.7092
Epoch [2/3], Batch [234/428], Loss: 0.6890
Epoch [2/3], Batch [235/428], Loss: 6.4850
Epoch [2/3], Batch [236/428], Loss: 0.9098
Epoch [2/3], Batch [237/428], Loss: 1.9485
Epoch [2/3], Batch [238/428], Loss: 1.0381
Epoch [2/3], Batch [239/428], Loss: 0.1215
Epoch [2/3], Batch [240/428], Loss: 0.8236
Epoch [2/3], Batch [241/428], Loss: 0.0315
Epoch [2/3], Batch [242/428], Loss: 0.3279
Epoch [2/3], Batch [243/428], Loss: 1.0721
Epoch [2/3], Batch [244/428], Loss: 0.9945
Epoch [2/3], Batch [245/428], Loss: 0.0429
Epoch [2/3], Batch [246/428], Loss: 0.4419
Epoch [2/3], Batch [247/428], Loss: 3.1245
Epoch [2/3], Batch [248/428], Loss: 4.7389
Epoch [2/3], Batch [249/428], Loss: 0.1493
Epoch [2/3], Batch [250/428], Loss: 0.1925
Epoch [2/3], Batch [251/428], Loss: 0.0020
Epoch [2/3], Batch [252/428], Loss: 1.2215
Epoch [2/3], Batch [253/428], Loss: 1.7341
Epoch [2/3], Batch [254/428], Loss: 0.5353
Epoch [2/3], Batch [255/428], Loss: 0.0011
Epoch [2/3], Batch [256/428], Loss: 0.3877
Epoch [2/3], Batch [257/428], Loss: 0.0019
Epoch [2/3], Batch [258/428], Loss: 0.2203
Epoch [2/3], Batch [259/428], Loss: 0.9621
Epoch [2/3], Batch [260/428], Loss: 0.8705
Epoch [2/3], Batch [261/428], Loss: 0.6683
Epoch [2/3], Batch [262/428], Loss: 1.5482
Epoch [2/3], Batch [263/428], Loss: 0.7788
Epoch [2/3], Batch [264/428], Loss: 0.0214
Epoch [2/3], Batch [265/428], Loss: 0.4961
Epoch [2/3], Batch [266/428], Loss: 0.8961
Epoch [2/3], Batch [267/428], Loss: 1.4825
Epoch [2/3], Batch [268/428], Loss: 0.0073
Epoch [2/3], Batch [269/428], Loss: 2.7876
Epoch [2/3], Batch [270/428], Loss: 0.0278
Epoch [2/3], Batch [271/428], Loss: 2.8413
Epoch [2/3], Batch [272/428], Loss: 3.1421
Epoch [2/3], Batch [273/428], Loss: 0.0367
Epoch [2/3], Batch [274/428], Loss: 0.2118
Epoch [2/3], Batch [275/428], Loss: 0.0014
Epoch [2/3], Batch [276/428], Loss: 0.0541
Epoch [2/3], Batch [277/428], Loss: 1.9755
Epoch [2/3], Batch [278/428], Loss: 0.0312
Epoch [2/3], Batch [279/428], Loss: 0.0020
Epoch [2/3], Batch [280/428], Loss: 0.0014
Epoch [2/3], Batch [281/428], Loss: 2.1014
Epoch [2/3], Batch [282/428], Loss: 1.0102
Epoch [2/3], Batch [283/428], Loss: 2.1545
Epoch [2/3], Batch [284/428], Loss: 0.0015
Epoch [2/3], Batch [285/428], Loss: 0.0019
Epoch [2/3], Batch [286/428], Loss: 1.2110
Epoch [2/3], Batch [287/428], Loss: 0.4966
Epoch [2/3], Batch [288/428], Loss: 1.4044
Epoch [2/3], Batch [289/428], Loss: 1.0103
Epoch [2/3], Batch [290/428], Loss: 1.9466
Epoch [2/3], Batch [291/428], Loss: 1.7848
Epoch [2/3], Batch [292/428], Loss: 5.4344
Epoch [2/3], Batch [293/428], Loss: 0.0010
Epoch [2/3], Batch [294/428], Loss: 2.0546
Epoch [2/3], Batch [295/428], Loss: 0.0011
Epoch [2/3], Batch [296/428], Loss: 0.0462
Epoch [2/3], Batch [297/428], Loss: 3.2387
Epoch [2/3], Batch [298/428], Loss: 1.4357
Epoch [2/3], Batch [299/428], Loss: 1.0001
Epoch [2/3], Batch [300/428], Loss: 2.0724
Epoch [2/3], Batch [301/428], Loss: 0.0816
Epoch [2/3], Batch [302/428], Loss: 1.8699
Epoch [2/3], Batch [303/428], Loss: 1.8506
Epoch [2/3], Batch [304/428], Loss: 1.9073
Epoch [2/3], Batch [305/428], Loss: 0.4572
Epoch [2/3], Batch [306/428], Loss: 1.2821
Epoch [2/3], Batch [307/428], Loss: 1.4530
Epoch [2/3], Batch [308/428], Loss: 4.5824
Epoch [2/3], Batch [309/428], Loss: 1.4069
Epoch [2/3], Batch [310/428], Loss: 1.3662
Epoch [2/3], Batch [311/428], Loss: 0.0193
Epoch [2/3], Batch [312/428], Loss: 0.8590
Epoch [2/3], Batch [313/428], Loss: 0.4314
Epoch [2/3], Batch [314/428], Loss: 0.0561
Epoch [2/3], Batch [315/428], Loss: 1.8789
Epoch [2/3], Batch [316/428], Loss: 1.5019
Epoch [2/3], Batch [317/428], Loss: 2.1550
Epoch [2/3], Batch [318/428], Loss: 1.7966
Epoch [2/3], Batch [319/428], Loss: 0.0033
Epoch [2/3], Batch [320/428], Loss: 0.4224
Epoch [2/3], Batch [321/428], Loss: 0.0008
Epoch [2/3], Batch [322/428], Loss: 0.0013
Epoch [2/3], Batch [323/428], Loss: 1.6687
Epoch [2/3], Batch [324/428], Loss: 0.1832
Epoch [2/3], Batch [325/428], Loss: 2.9007
Epoch [2/3], Batch [326/428], Loss: 1.0161
Epoch [2/3], Batch [327/428], Loss: 1.4868
Epoch [2/3], Batch [328/428], Loss: 1.4349
Epoch [2/3], Batch [329/428], Loss: 0.3012
Epoch [2/3], Batch [330/428], Loss: 0.0008
Epoch [2/3], Batch [331/428], Loss: 0.6751
Epoch [2/3], Batch [332/428], Loss: 0.0010
Epoch [2/3], Batch [333/428], Loss: 0.0328
Epoch [2/3], Batch [334/428], Loss: 2.2260
Epoch [2/3], Batch [335/428], Loss: 3.8380
Epoch [2/3], Batch [336/428], Loss: 0.1253
Epoch [2/3], Batch [337/428], Loss: 1.3280
Epoch [2/3], Batch [338/428], Loss: 2.2300
Epoch [2/3], Batch [339/428], Loss: 1.0461
Epoch [2/3], Batch [340/428], Loss: 0.9935
Epoch [2/3], Batch [341/428], Loss: 2.5539
Epoch [2/3], Batch [342/428], Loss: 0.9756
Epoch [2/3], Batch [343/428], Loss: 3.8233
Epoch [2/3], Batch [344/428], Loss: 0.1997
Epoch [2/3], Batch [345/428], Loss: 1.4330
Epoch [2/3], Batch [346/428], Loss: 0.0221
Epoch [2/3], Batch [347/428], Loss: 0.0008
Epoch [2/3], Batch [348/428], Loss: 0.0036
Epoch [2/3], Batch [349/428], Loss: 0.0027
Epoch [2/3], Batch [350/428], Loss: 0.0113
Epoch [2/3], Batch [351/428], Loss: 1.4909
Epoch [2/3], Batch [352/428], Loss: 0.0725
Epoch [2/3], Batch [353/428], Loss: 0.9238
Epoch [2/3], Batch [354/428], Loss: 1.6319
Epoch [2/3], Batch [355/428], Loss: 2.2327
Epoch [2/3], Batch [356/428], Loss: 2.1533
Epoch [2/3], Batch [357/428], Loss: 2.6611
Epoch [2/3], Batch [358/428], Loss: 1.4196
Epoch [2/3], Batch [359/428], Loss: 1.3497
Epoch [2/3], Batch [360/428], Loss: 1.5363
Epoch [2/3], Batch [361/428], Loss: 0.0088
Epoch [2/3], Batch [362/428], Loss: 2.3648
Epoch [2/3], Batch [363/428], Loss: 1.8989
Epoch [2/3], Batch [364/428], Loss: 2.2353
Epoch [2/3], Batch [365/428], Loss: 0.0567
Epoch [2/3], Batch [366/428], Loss: 0.0823
Epoch [2/3], Batch [367/428], Loss: 2.4956
Epoch [2/3], Batch [368/428], Loss: 0.0018
Epoch [2/3], Batch [369/428], Loss: 2.0527
Epoch [2/3], Batch [370/428], Loss: 1.5790
Epoch [2/3], Batch [371/428], Loss: 1.3375
Epoch [2/3], Batch [372/428], Loss: 1.1013
Epoch [2/3], Batch [373/428], Loss: 1.4388
Epoch [2/3], Batch [374/428], Loss: 1.9551
Epoch [2/3], Batch [375/428], Loss: 1.5287
Epoch [2/3], Batch [376/428], Loss: 0.8443
Epoch [2/3], Batch [377/428], Loss: 1.7788
Epoch [2/3], Batch [378/428], Loss: 2.0843
Epoch [2/3], Batch [379/428], Loss: 1.0413
Epoch [2/3], Batch [380/428], Loss: 0.0579
Epoch [2/3], Batch [381/428], Loss: 1.2320
Epoch [2/3], Batch [382/428], Loss: 1.4871
Epoch [2/3], Batch [383/428], Loss: 0.0269
Epoch [2/3], Batch [384/428], Loss: 0.6723
Epoch [2/3], Batch [385/428], Loss: 1.2585
Epoch [2/3], Batch [386/428], Loss: 0.0007
Epoch [2/3], Batch [387/428], Loss: 1.1402
Epoch [2/3], Batch [388/428], Loss: 1.3155
Epoch [2/3], Batch [389/428], Loss: 0.9968
Epoch [2/3], Batch [390/428], Loss: 1.7251
Epoch [2/3], Batch [391/428], Loss: 0.0010
Epoch [2/3], Batch [392/428], Loss: 1.7854
Epoch [2/3], Batch [393/428], Loss: 1.7769
Epoch [2/3], Batch [394/428], Loss: 0.0004
Epoch [2/3], Batch [395/428], Loss: 0.0411
Epoch [2/3], Batch [396/428], Loss: 1.7195
Epoch [2/3], Batch [397/428], Loss: 0.0358
Epoch [2/3], Batch [398/428], Loss: 0.0009
Epoch [2/3], Batch [399/428], Loss: 0.6418
Epoch [2/3], Batch [400/428], Loss: 2.2436
Epoch [2/3], Batch [401/428], Loss: 0.0033
Epoch [2/3], Batch [402/428], Loss: 0.0149
Epoch [2/3], Batch [403/428], Loss: 0.8014
Epoch [2/3], Batch [404/428], Loss: 0.3573
Epoch [2/3], Batch [405/428], Loss: 0.0036
Epoch [2/3], Batch [406/428], Loss: 0.5573
Epoch [2/3], Batch [407/428], Loss: 0.0264
Epoch [2/3], Batch [408/428], Loss: 1.8216
Epoch [2/3], Batch [409/428], Loss: 0.1861
Epoch [2/3], Batch [410/428], Loss: 2.9149
Epoch [2/3], Batch [411/428], Loss: 0.0155
Epoch [2/3], Batch [412/428], Loss: 0.0004
Epoch [2/3], Batch [413/428], Loss: 0.0012
Epoch [2/3], Batch [414/428], Loss: 1.6387
Epoch [2/3], Batch [415/428], Loss: 0.0848
Epoch [2/3], Batch [416/428], Loss: 0.4807
Epoch [2/3], Batch [417/428], Loss: 2.0365
Epoch [2/3], Batch [418/428], Loss: 2.6112
Epoch [2/3], Batch [419/428], Loss: 0.0301
Epoch [2/3], Batch [420/428], Loss: 0.9391
Epoch [2/3], Batch [421/428], Loss: 0.6236
Epoch [2/3], Batch [422/428], Loss: 1.1205
Epoch [2/3], Batch [423/428], Loss: 3.5543
Epoch [2/3], Batch [424/428], Loss: 1.2427
Epoch [2/3], Batch [425/428], Loss: 2.1008
Epoch [2/3], Batch [426/428], Loss: 1.5628
Epoch [2/3], Batch [427/428], Loss: 1.4954
Epoch [2/3], Batch [428/428], Loss: 1.1601
Epoch [2] Training Time: 136.37 seconds
Epoch [2/3], Average Loss: 1.2405, Training Accuracy: 0.5257
Epoch [2], Validation Loss: 1.7480, Validation Accuracy: 0.4671
Epoch [2] Validation Time: 7.25 seconds
--------------------------------------------------
Epoch [3/3], Batch [1/428], Loss: 2.3669
Epoch [3/3], Batch [2/428], Loss: 1.1347
Epoch [3/3], Batch [3/428], Loss: 1.1907
Epoch [3/3], Batch [4/428], Loss: 1.2148
Epoch [3/3], Batch [5/428], Loss: 1.3727
Epoch [3/3], Batch [6/428], Loss: 2.5458
Epoch [3/3], Batch [7/428], Loss: 0.7738
Epoch [3/3], Batch [8/428], Loss: 0.0005
Epoch [3/3], Batch [9/428], Loss: 0.0004
Epoch [3/3], Batch [10/428], Loss: 0.7762
Epoch [3/3], Batch [11/428], Loss: 2.7944
Epoch [3/3], Batch [12/428], Loss: 0.0119
Epoch [3/3], Batch [13/428], Loss: 2.2420
Epoch [3/3], Batch [14/428], Loss: 0.1755
Epoch [3/3], Batch [15/428], Loss: 3.9288
Epoch [3/3], Batch [16/428], Loss: 1.4040
Epoch [3/3], Batch [17/428], Loss: 0.0007
Epoch [3/3], Batch [18/428], Loss: 0.0074
Epoch [3/3], Batch [19/428], Loss: 0.0006
Epoch [3/3], Batch [20/428], Loss: 1.4703
Epoch [3/3], Batch [21/428], Loss: 0.8260
Epoch [3/3], Batch [22/428], Loss: 1.3597
Epoch [3/3], Batch [23/428], Loss: 1.6024
Epoch [3/3], Batch [24/428], Loss: 0.0432
Epoch [3/3], Batch [25/428], Loss: 1.8991
Epoch [3/3], Batch [26/428], Loss: 0.0004
Epoch [3/3], Batch [27/428], Loss: 1.5563
Epoch [3/3], Batch [28/428], Loss: 4.3014
Epoch [3/3], Batch [29/428], Loss: 0.2926
Epoch [3/3], Batch [30/428], Loss: 0.7411
Epoch [3/3], Batch [31/428], Loss: 6.9910
Epoch [3/3], Batch [32/428], Loss: 4.9191
Epoch [3/3], Batch [33/428], Loss: 1.2197
Epoch [3/3], Batch [34/428], Loss: 0.0325
Epoch [3/3], Batch [35/428], Loss: 1.5545
Epoch [3/3], Batch [36/428], Loss: 4.5196
Epoch [3/3], Batch [37/428], Loss: 0.5373
Epoch [3/3], Batch [38/428], Loss: 0.0289
Epoch [3/3], Batch [39/428], Loss: 3.2891
Epoch [3/3], Batch [40/428], Loss: 1.8301
Epoch [3/3], Batch [41/428], Loss: 0.0008
Epoch [3/3], Batch [42/428], Loss: 0.0669
Epoch [3/3], Batch [43/428], Loss: 1.2131
Epoch [3/3], Batch [44/428], Loss: 3.8482
Epoch [3/3], Batch [45/428], Loss: 0.6212
Epoch [3/3], Batch [46/428], Loss: 5.1149
Epoch [3/3], Batch [47/428], Loss: 0.9898
Epoch [3/3], Batch [48/428], Loss: 0.0007
Epoch [3/3], Batch [49/428], Loss: 1.0033
Epoch [3/3], Batch [50/428], Loss: 1.0956
Epoch [3/3], Batch [51/428], Loss: 0.0091
Epoch [3/3], Batch [52/428], Loss: 1.0227
Epoch [3/3], Batch [53/428], Loss: 1.2179
Epoch [3/3], Batch [54/428], Loss: 0.5837
Epoch [3/3], Batch [55/428], Loss: 0.2840
Epoch [3/3], Batch [56/428], Loss: 0.0074
Epoch [3/3], Batch [57/428], Loss: 2.0248
Epoch [3/3], Batch [58/428], Loss: 1.1914
Epoch [3/3], Batch [59/428], Loss: 0.9511
Epoch [3/3], Batch [60/428], Loss: 1.8172
Epoch [3/3], Batch [61/428], Loss: 5.2112
Epoch [3/3], Batch [62/428], Loss: 0.1317
Epoch [3/3], Batch [63/428], Loss: 1.2208
Epoch [3/3], Batch [64/428], Loss: 2.8131
Epoch [3/3], Batch [65/428], Loss: 0.8013
Epoch [3/3], Batch [66/428], Loss: 1.2547
Epoch [3/3], Batch [67/428], Loss: 1.8902
Epoch [3/3], Batch [68/428], Loss: 0.6484
Epoch [3/3], Batch [69/428], Loss: 1.4761
Epoch [3/3], Batch [70/428], Loss: 1.3235
Epoch [3/3], Batch [71/428], Loss: 0.0010
Epoch [3/3], Batch [72/428], Loss: 2.7387
Epoch [3/3], Batch [73/428], Loss: 1.0463
Epoch [3/3], Batch [74/428], Loss: 0.0008
Epoch [3/3], Batch [75/428], Loss: 1.9823
Epoch [3/3], Batch [76/428], Loss: 0.8857
Epoch [3/3], Batch [77/428], Loss: 0.1073
Epoch [3/3], Batch [78/428], Loss: 1.1436
Epoch [3/3], Batch [79/428], Loss: 0.0008
Epoch [3/3], Batch [80/428], Loss: 1.1475
Epoch [3/3], Batch [81/428], Loss: 0.0210
Epoch [3/3], Batch [82/428], Loss: 4.6359
Epoch [3/3], Batch [83/428], Loss: 0.3037
Epoch [3/3], Batch [84/428], Loss: 2.8043
Epoch [3/3], Batch [85/428], Loss: 1.3100
Epoch [3/3], Batch [86/428], Loss: 0.0021
Epoch [3/3], Batch [87/428], Loss: 1.6996
Epoch [3/3], Batch [88/428], Loss: 1.3454
Epoch [3/3], Batch [89/428], Loss: 1.1174
Epoch [3/3], Batch [90/428], Loss: 1.0123
Epoch [3/3], Batch [91/428], Loss: 1.0483
Epoch [3/3], Batch [92/428], Loss: 0.0077
Epoch [3/3], Batch [93/428], Loss: 1.3369
Epoch [3/3], Batch [94/428], Loss: 1.5037
Epoch [3/3], Batch [95/428], Loss: 1.8675
Epoch [3/3], Batch [96/428], Loss: 0.0018
Epoch [3/3], Batch [97/428], Loss: 0.0421
Epoch [3/3], Batch [98/428], Loss: 1.4498
Epoch [3/3], Batch [99/428], Loss: 0.7791
Epoch [3/3], Batch [100/428], Loss: 0.1897
Epoch [3/3], Batch [101/428], Loss: 0.0134
Epoch [3/3], Batch [102/428], Loss: 1.2584
Epoch [3/3], Batch [103/428], Loss: 0.0256
Epoch [3/3], Batch [104/428], Loss: 0.9983
Epoch [3/3], Batch [105/428], Loss: 2.2472
Epoch [3/3], Batch [106/428], Loss: 1.0383
Epoch [3/3], Batch [107/428], Loss: 0.9557
Epoch [3/3], Batch [108/428], Loss: 0.3590
Epoch [3/3], Batch [109/428], Loss: 0.1344
Epoch [3/3], Batch [110/428], Loss: 0.0114
Epoch [3/3], Batch [111/428], Loss: 1.8640
Epoch [3/3], Batch [112/428], Loss: 0.9217
Epoch [3/3], Batch [113/428], Loss: 3.6294
Epoch [3/3], Batch [114/428], Loss: 1.6158
Epoch [3/3], Batch [115/428], Loss: 1.4888
Epoch [3/3], Batch [116/428], Loss: 0.9142
Epoch [3/3], Batch [117/428], Loss: 2.4058
Epoch [3/3], Batch [118/428], Loss: 3.0699
Epoch [3/3], Batch [119/428], Loss: 0.3567
Epoch [3/3], Batch [120/428], Loss: 0.0015
Epoch [3/3], Batch [121/428], Loss: 1.0010
Epoch [3/3], Batch [122/428], Loss: 1.4491
Epoch [3/3], Batch [123/428], Loss: 2.2222
Epoch [3/3], Batch [124/428], Loss: 0.1113
Epoch [3/3], Batch [125/428], Loss: 0.9638
Epoch [3/3], Batch [126/428], Loss: 0.0911
Epoch [3/3], Batch [127/428], Loss: 1.0562
Epoch [3/3], Batch [128/428], Loss: 2.6153
Epoch [3/3], Batch [129/428], Loss: 1.0636
Epoch [3/3], Batch [130/428], Loss: 0.9030
Epoch [3/3], Batch [131/428], Loss: 0.9563
Epoch [3/3], Batch [132/428], Loss: 0.5529
Epoch [3/3], Batch [133/428], Loss: 0.0008
Epoch [3/3], Batch [134/428], Loss: 2.2535
Epoch [3/3], Batch [135/428], Loss: 2.0974
Epoch [3/3], Batch [136/428], Loss: 1.7769
Epoch [3/3], Batch [137/428], Loss: 1.4347
Epoch [3/3], Batch [138/428], Loss: 3.0640
Epoch [3/3], Batch [139/428], Loss: 0.0174
Epoch [3/3], Batch [140/428], Loss: 0.9248
Epoch [3/3], Batch [141/428], Loss: 0.3334
Epoch [3/3], Batch [142/428], Loss: 4.4934
Epoch [3/3], Batch [143/428], Loss: 0.9331
Epoch [3/3], Batch [144/428], Loss: 2.8823
Epoch [3/3], Batch [145/428], Loss: 0.0186
Epoch [3/3], Batch [146/428], Loss: 0.0138
Epoch [3/3], Batch [147/428], Loss: 0.0014
Epoch [3/3], Batch [148/428], Loss: 0.0429
Epoch [3/3], Batch [149/428], Loss: 0.4142
Epoch [3/3], Batch [150/428], Loss: 1.6772
Epoch [3/3], Batch [151/428], Loss: 1.4861
Epoch [3/3], Batch [152/428], Loss: 0.7661
Epoch [3/3], Batch [153/428], Loss: 0.7198
Epoch [3/3], Batch [154/428], Loss: 1.3411
Epoch [3/3], Batch [155/428], Loss: 0.4976
Epoch [3/3], Batch [156/428], Loss: 0.5905
Epoch [3/3], Batch [157/428], Loss: 1.3313
Epoch [3/3], Batch [158/428], Loss: 0.0009
Epoch [3/3], Batch [159/428], Loss: 2.5454
Epoch [3/3], Batch [160/428], Loss: 0.9036
Epoch [3/3], Batch [161/428], Loss: 0.8244
Epoch [3/3], Batch [162/428], Loss: 0.1378
Epoch [3/3], Batch [163/428], Loss: 1.1663
Epoch [3/3], Batch [164/428], Loss: 0.0023
Epoch [3/3], Batch [165/428], Loss: 0.7286
Epoch [3/3], Batch [166/428], Loss: 0.4100
Epoch [3/3], Batch [167/428], Loss: 0.0009
Epoch [3/3], Batch [168/428], Loss: 1.1883
Epoch [3/3], Batch [169/428], Loss: 0.0039
Epoch [3/3], Batch [170/428], Loss: 1.1134
Epoch [3/3], Batch [171/428], Loss: 1.7795
Epoch [3/3], Batch [172/428], Loss: 1.1365
Epoch [3/3], Batch [173/428], Loss: 2.1979
Epoch [3/3], Batch [174/428], Loss: 5.9014
Epoch [3/3], Batch [175/428], Loss: 3.9344
Epoch [3/3], Batch [176/428], Loss: 0.9196
Epoch [3/3], Batch [177/428], Loss: 0.9659
Epoch [3/3], Batch [178/428], Loss: 1.1058
Epoch [3/3], Batch [179/428], Loss: 3.1008
Epoch [3/3], Batch [180/428], Loss: 2.6199
Epoch [3/3], Batch [181/428], Loss: 4.9151
Epoch [3/3], Batch [182/428], Loss: 0.0008
Epoch [3/3], Batch [183/428], Loss: 0.0144
Epoch [3/3], Batch [184/428], Loss: 0.0164
Epoch [3/3], Batch [185/428], Loss: 1.1424
Epoch [3/3], Batch [186/428], Loss: 1.2587
Epoch [3/3], Batch [187/428], Loss: 0.0677
Epoch [3/3], Batch [188/428], Loss: 0.6577
Epoch [3/3], Batch [189/428], Loss: 0.0006
Epoch [3/3], Batch [190/428], Loss: 0.9526
Epoch [3/3], Batch [191/428], Loss: 0.0270[INFO 06-13 19:57:11] ax.service.ax_client: Completed trial 9 with data: {'objective': (np.float64(-0.503515), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 19:57:14] ax.service.ax_client: Generated new trial 10 with parameters {'lr': 0.000275, 'num_epochs': 4, 'unfreeze_epoch': 2, 'max_length': 112000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [3/3], Batch [192/428], Loss: 0.0244
Epoch [3/3], Batch [193/428], Loss: 2.5688
Epoch [3/3], Batch [194/428], Loss: 0.7710
Epoch [3/3], Batch [195/428], Loss: 0.0025
Epoch [3/3], Batch [196/428], Loss: 4.1591
Epoch [3/3], Batch [197/428], Loss: 8.4310
Epoch [3/3], Batch [198/428], Loss: 1.3227
Epoch [3/3], Batch [199/428], Loss: 2.3237
Epoch [3/3], Batch [200/428], Loss: 0.8469
Epoch [3/3], Batch [201/428], Loss: 0.0610
Epoch [3/3], Batch [202/428], Loss: 0.0142
Epoch [3/3], Batch [203/428], Loss: 0.0590
Epoch [3/3], Batch [204/428], Loss: 2.0509
Epoch [3/3], Batch [205/428], Loss: 1.3467
Epoch [3/3], Batch [206/428], Loss: 0.0010
Epoch [3/3], Batch [207/428], Loss: 1.4802
Epoch [3/3], Batch [208/428], Loss: 0.0098
Epoch [3/3], Batch [209/428], Loss: 0.4372
Epoch [3/3], Batch [210/428], Loss: 0.0011
Epoch [3/3], Batch [211/428], Loss: 0.0007
Epoch [3/3], Batch [212/428], Loss: 0.9844
Epoch [3/3], Batch [213/428], Loss: 2.4919
Epoch [3/3], Batch [214/428], Loss: 1.3132
Epoch [3/3], Batch [215/428], Loss: 0.0188
Epoch [3/3], Batch [216/428], Loss: 0.3111
Epoch [3/3], Batch [217/428], Loss: 0.9711
Epoch [3/3], Batch [218/428], Loss: 0.0004
Epoch [3/3], Batch [219/428], Loss: 1.5666
Epoch [3/3], Batch [220/428], Loss: 0.4237
Epoch [3/3], Batch [221/428], Loss: 1.7979
Epoch [3/3], Batch [222/428], Loss: 3.9535
Epoch [3/3], Batch [223/428], Loss: 0.0454
Epoch [3/3], Batch [224/428], Loss: 0.5447
Epoch [3/3], Batch [225/428], Loss: 1.5200
Epoch [3/3], Batch [226/428], Loss: 2.9281
Epoch [3/3], Batch [227/428], Loss: 4.6714
Epoch [3/3], Batch [228/428], Loss: 0.0007
Epoch [3/3], Batch [229/428], Loss: 0.0022
Epoch [3/3], Batch [230/428], Loss: 0.1011
Epoch [3/3], Batch [231/428], Loss: 1.3495
Epoch [3/3], Batch [232/428], Loss: 3.3848
Epoch [3/3], Batch [233/428], Loss: 3.2318
Epoch [3/3], Batch [234/428], Loss: 0.0729
Epoch [3/3], Batch [235/428], Loss: 1.9378
Epoch [3/3], Batch [236/428], Loss: 0.3151
Epoch [3/3], Batch [237/428], Loss: 0.0004
Epoch [3/3], Batch [238/428], Loss: 0.3914
Epoch [3/3], Batch [239/428], Loss: 0.0112
Epoch [3/3], Batch [240/428], Loss: 1.1315
Epoch [3/3], Batch [241/428], Loss: 0.1004
Epoch [3/3], Batch [242/428], Loss: 2.9555
Epoch [3/3], Batch [243/428], Loss: 1.2225
Epoch [3/3], Batch [244/428], Loss: 2.1684
Epoch [3/3], Batch [245/428], Loss: 0.6703
Epoch [3/3], Batch [246/428], Loss: 0.0006
Epoch [3/3], Batch [247/428], Loss: 1.1163
Epoch [3/3], Batch [248/428], Loss: 0.0214
Epoch [3/3], Batch [249/428], Loss: 1.3955
Epoch [3/3], Batch [250/428], Loss: 0.0899
Epoch [3/3], Batch [251/428], Loss: 1.3709
Epoch [3/3], Batch [252/428], Loss: 0.5225
Epoch [3/3], Batch [253/428], Loss: 1.4176
Epoch [3/3], Batch [254/428], Loss: 1.1459
Epoch [3/3], Batch [255/428], Loss: 0.4480
Epoch [3/3], Batch [256/428], Loss: 1.8758
Epoch [3/3], Batch [257/428], Loss: 1.1886
Epoch [3/3], Batch [258/428], Loss: 0.3592
Epoch [3/3], Batch [259/428], Loss: 0.0113
Epoch [3/3], Batch [260/428], Loss: 1.9765
Epoch [3/3], Batch [261/428], Loss: 0.0013
Epoch [3/3], Batch [262/428], Loss: 1.4298
Epoch [3/3], Batch [263/428], Loss: 0.0300
Epoch [3/3], Batch [264/428], Loss: 1.0301
Epoch [3/3], Batch [265/428], Loss: 0.6521
Epoch [3/3], Batch [266/428], Loss: 0.0006
Epoch [3/3], Batch [267/428], Loss: 1.2410
Epoch [3/3], Batch [268/428], Loss: 0.9274
Epoch [3/3], Batch [269/428], Loss: 0.1160
Epoch [3/3], Batch [270/428], Loss: 2.4469
Epoch [3/3], Batch [271/428], Loss: 1.0141
Epoch [3/3], Batch [272/428], Loss: 0.5992
Epoch [3/3], Batch [273/428], Loss: 1.0471
Epoch [3/3], Batch [274/428], Loss: 0.2942
Epoch [3/3], Batch [275/428], Loss: 0.2804
Epoch [3/3], Batch [276/428], Loss: 1.7818
Epoch [3/3], Batch [277/428], Loss: 0.0753
Epoch [3/3], Batch [278/428], Loss: 0.0071
Epoch [3/3], Batch [279/428], Loss: 0.0217
Epoch [3/3], Batch [280/428], Loss: 0.0053
Epoch [3/3], Batch [281/428], Loss: 0.3735
Epoch [3/3], Batch [282/428], Loss: 0.0010
Epoch [3/3], Batch [283/428], Loss: 2.0751
Epoch [3/3], Batch [284/428], Loss: 0.8669
Epoch [3/3], Batch [285/428], Loss: 0.0013
Epoch [3/3], Batch [286/428], Loss: 1.1650
Epoch [3/3], Batch [287/428], Loss: 0.6092
Epoch [3/3], Batch [288/428], Loss: 0.4703
Epoch [3/3], Batch [289/428], Loss: 0.5985
Epoch [3/3], Batch [290/428], Loss: 0.2538
Epoch [3/3], Batch [291/428], Loss: 0.5012
Epoch [3/3], Batch [292/428], Loss: 0.0009
Epoch [3/3], Batch [293/428], Loss: 1.6771
Epoch [3/3], Batch [294/428], Loss: 0.0099
Epoch [3/3], Batch [295/428], Loss: 1.1353
Epoch [3/3], Batch [296/428], Loss: 0.2238
Epoch [3/3], Batch [297/428], Loss: 0.0062
Epoch [3/3], Batch [298/428], Loss: 1.2691
Epoch [3/3], Batch [299/428], Loss: 0.7561
Epoch [3/3], Batch [300/428], Loss: 0.8696
Epoch [3/3], Batch [301/428], Loss: 1.6940
Epoch [3/3], Batch [302/428], Loss: 3.9595
Epoch [3/3], Batch [303/428], Loss: 0.0008
Epoch [3/3], Batch [304/428], Loss: 0.0012
Epoch [3/3], Batch [305/428], Loss: 1.0697
Epoch [3/3], Batch [306/428], Loss: 1.3748
Epoch [3/3], Batch [307/428], Loss: 0.1344
Epoch [3/3], Batch [308/428], Loss: 0.4119
Epoch [3/3], Batch [309/428], Loss: 5.1927
Epoch [3/3], Batch [310/428], Loss: 1.1459
Epoch [3/3], Batch [311/428], Loss: 0.1896
Epoch [3/3], Batch [312/428], Loss: 1.9913
Epoch [3/3], Batch [313/428], Loss: 1.1945
Epoch [3/3], Batch [314/428], Loss: 0.0007
Epoch [3/3], Batch [315/428], Loss: 1.0458
Epoch [3/3], Batch [316/428], Loss: 1.4343
Epoch [3/3], Batch [317/428], Loss: 4.4633
Epoch [3/3], Batch [318/428], Loss: 0.1785
Epoch [3/3], Batch [319/428], Loss: 0.0010
Epoch [3/3], Batch [320/428], Loss: 2.5622
Epoch [3/3], Batch [321/428], Loss: 0.6555
Epoch [3/3], Batch [322/428], Loss: 1.7650
Epoch [3/3], Batch [323/428], Loss: 1.6262
Epoch [3/3], Batch [324/428], Loss: 0.8723
Epoch [3/3], Batch [325/428], Loss: 0.0007
Epoch [3/3], Batch [326/428], Loss: 1.9793
Epoch [3/3], Batch [327/428], Loss: 0.0332
Epoch [3/3], Batch [328/428], Loss: 0.3214
Epoch [3/3], Batch [329/428], Loss: 2.0087
Epoch [3/3], Batch [330/428], Loss: 0.4028
Epoch [3/3], Batch [331/428], Loss: 0.0010
Epoch [3/3], Batch [332/428], Loss: 0.0007
Epoch [3/3], Batch [333/428], Loss: 2.2963
Epoch [3/3], Batch [334/428], Loss: 2.6249
Epoch [3/3], Batch [335/428], Loss: 1.9334
Epoch [3/3], Batch [336/428], Loss: 0.0006
Epoch [3/3], Batch [337/428], Loss: 1.7446
Epoch [3/3], Batch [338/428], Loss: 0.1100
Epoch [3/3], Batch [339/428], Loss: 0.0028
Epoch [3/3], Batch [340/428], Loss: 0.0239
Epoch [3/3], Batch [341/428], Loss: 0.1212
Epoch [3/3], Batch [342/428], Loss: 2.1892
Epoch [3/3], Batch [343/428], Loss: 1.3891
Epoch [3/3], Batch [344/428], Loss: 0.8808
Epoch [3/3], Batch [345/428], Loss: 0.0032
Epoch [3/3], Batch [346/428], Loss: 1.8744
Epoch [3/3], Batch [347/428], Loss: 0.0308
Epoch [3/3], Batch [348/428], Loss: 0.9883
Epoch [3/3], Batch [349/428], Loss: 0.0019
Epoch [3/3], Batch [350/428], Loss: 1.5971
Epoch [3/3], Batch [351/428], Loss: 0.0599
Epoch [3/3], Batch [352/428], Loss: 2.8446
Epoch [3/3], Batch [353/428], Loss: 2.7584
Epoch [3/3], Batch [354/428], Loss: 1.9986
Epoch [3/3], Batch [355/428], Loss: 0.0588
Epoch [3/3], Batch [356/428], Loss: 1.6983
Epoch [3/3], Batch [357/428], Loss: 6.9493
Epoch [3/3], Batch [358/428], Loss: 0.0246
Epoch [3/3], Batch [359/428], Loss: 1.4735
Epoch [3/3], Batch [360/428], Loss: 3.4311
Epoch [3/3], Batch [361/428], Loss: 1.1286
Epoch [3/3], Batch [362/428], Loss: 0.2454
Epoch [3/3], Batch [363/428], Loss: 2.4517
Epoch [3/3], Batch [364/428], Loss: 1.1688
Epoch [3/3], Batch [365/428], Loss: 1.4062
Epoch [3/3], Batch [366/428], Loss: 1.7825
Epoch [3/3], Batch [367/428], Loss: 2.8950
Epoch [3/3], Batch [368/428], Loss: 0.3442
Epoch [3/3], Batch [369/428], Loss: 1.4292
Epoch [3/3], Batch [370/428], Loss: 0.5325
Epoch [3/3], Batch [371/428], Loss: 0.2702
Epoch [3/3], Batch [372/428], Loss: 0.9528
Epoch [3/3], Batch [373/428], Loss: 1.2363
Epoch [3/3], Batch [374/428], Loss: 0.0146
Epoch [3/3], Batch [375/428], Loss: 4.1357
Epoch [3/3], Batch [376/428], Loss: 0.4572
Epoch [3/3], Batch [377/428], Loss: 0.8964
Epoch [3/3], Batch [378/428], Loss: 0.0012
Epoch [3/3], Batch [379/428], Loss: 0.5695
Epoch [3/3], Batch [380/428], Loss: 1.0347
Epoch [3/3], Batch [381/428], Loss: 0.1348
Epoch [3/3], Batch [382/428], Loss: 1.0514
Epoch [3/3], Batch [383/428], Loss: 0.0014
Epoch [3/3], Batch [384/428], Loss: 1.2012
Epoch [3/3], Batch [385/428], Loss: 1.1057
Epoch [3/3], Batch [386/428], Loss: 1.4309
Epoch [3/3], Batch [387/428], Loss: 0.9942
Epoch [3/3], Batch [388/428], Loss: 0.0133
Epoch [3/3], Batch [389/428], Loss: 1.2887
Epoch [3/3], Batch [390/428], Loss: 2.0184
Epoch [3/3], Batch [391/428], Loss: 2.4125
Epoch [3/3], Batch [392/428], Loss: 2.0615
Epoch [3/3], Batch [393/428], Loss: 0.3264
Epoch [3/3], Batch [394/428], Loss: 0.1424
Epoch [3/3], Batch [395/428], Loss: 1.5972
Epoch [3/3], Batch [396/428], Loss: 2.2139
Epoch [3/3], Batch [397/428], Loss: 1.5254
Epoch [3/3], Batch [398/428], Loss: 3.1639
Epoch [3/3], Batch [399/428], Loss: 1.0145
Epoch [3/3], Batch [400/428], Loss: 0.7520
Epoch [3/3], Batch [401/428], Loss: 0.2920
Epoch [3/3], Batch [402/428], Loss: 1.0764
Epoch [3/3], Batch [403/428], Loss: 0.0012
Epoch [3/3], Batch [404/428], Loss: 0.5454
Epoch [3/3], Batch [405/428], Loss: 1.8028
Epoch [3/3], Batch [406/428], Loss: 0.8097
Epoch [3/3], Batch [407/428], Loss: 0.0863
Epoch [3/3], Batch [408/428], Loss: 0.2740
Epoch [3/3], Batch [409/428], Loss: 0.0132
Epoch [3/3], Batch [410/428], Loss: 0.1411
Epoch [3/3], Batch [411/428], Loss: 0.0465
Epoch [3/3], Batch [412/428], Loss: 1.0551
Epoch [3/3], Batch [413/428], Loss: 0.7699
Epoch [3/3], Batch [414/428], Loss: 1.3733
Epoch [3/3], Batch [415/428], Loss: 0.2864
Epoch [3/3], Batch [416/428], Loss: 0.0004
Epoch [3/3], Batch [417/428], Loss: 1.2489
Epoch [3/3], Batch [418/428], Loss: 0.1467
Epoch [3/3], Batch [419/428], Loss: 0.6084
Epoch [3/3], Batch [420/428], Loss: 0.6667
Epoch [3/3], Batch [421/428], Loss: 1.6892
Epoch [3/3], Batch [422/428], Loss: 0.0040
Epoch [3/3], Batch [423/428], Loss: 1.5050
Epoch [3/3], Batch [424/428], Loss: 1.1025
Epoch [3/3], Batch [425/428], Loss: 1.0614
Epoch [3/3], Batch [426/428], Loss: 1.4600
Epoch [3/3], Batch [427/428], Loss: 0.0009
Epoch [3/3], Batch [428/428], Loss: 1.2827
Epoch [3] Training Time: 135.78 seconds
Epoch [3/3], Average Loss: 1.1457, Training Accuracy: 0.5794
Epoch [3], Validation Loss: 1.5730, Validation Accuracy: 0.5035
Epoch [3] Validation Time: 7.31 seconds
--------------------------------------------------

Running trial 10 with config: {'batch_size': 1, 'lr': 0.0002746832279022365, 'num_epochs': 4, 'unfreeze_epoch': 2, 'max_length': 112000, 'device': device(type='cpu')}
Epoch [1/4], Batch [1/428], Loss: 1.8687
Epoch [1/4], Batch [2/428], Loss: 2.5101
Epoch [1/4], Batch [3/428], Loss: 0.7904
Epoch [1/4], Batch [4/428], Loss: 3.0952
Epoch [1/4], Batch [5/428], Loss: 2.3723
Epoch [1/4], Batch [6/428], Loss: 1.0372
Epoch [1/4], Batch [7/428], Loss: 3.7337
Epoch [1/4], Batch [8/428], Loss: 1.0181
Epoch [1/4], Batch [9/428], Loss: 1.0926
Epoch [1/4], Batch [10/428], Loss: 1.8928
Epoch [1/4], Batch [11/428], Loss: 0.4614
Epoch [1/4], Batch [12/428], Loss: 3.3883
Epoch [1/4], Batch [13/428], Loss: 2.3823
Epoch [1/4], Batch [14/428], Loss: 1.7161
Epoch [1/4], Batch [15/428], Loss: 3.3872
Epoch [1/4], Batch [16/428], Loss: 0.3381
Epoch [1/4], Batch [17/428], Loss: 2.4663
Epoch [1/4], Batch [18/428], Loss: 2.8073
Epoch [1/4], Batch [19/428], Loss: 2.9448
Epoch [1/4], Batch [20/428], Loss: 0.2426
Epoch [1/4], Batch [21/428], Loss: 0.2017
Epoch [1/4], Batch [22/428], Loss: 1.6830
Epoch [1/4], Batch [23/428], Loss: 3.1039
Epoch [1/4], Batch [24/428], Loss: 3.2647
Epoch [1/4], Batch [25/428], Loss: 4.0199
Epoch [1/4], Batch [26/428], Loss: 0.3176
Epoch [1/4], Batch [27/428], Loss: 2.3604
Epoch [1/4], Batch [28/428], Loss: 2.1412
Epoch [1/4], Batch [29/428], Loss: 0.0669
Epoch [1/4], Batch [30/428], Loss: 1.7766
Epoch [1/4], Batch [31/428], Loss: 1.9163
Epoch [1/4], Batch [32/428], Loss: 0.4656
Epoch [1/4], Batch [33/428], Loss: 2.0976
Epoch [1/4], Batch [34/428], Loss: 2.8987
Epoch [1/4], Batch [35/428], Loss: 1.8410
Epoch [1/4], Batch [36/428], Loss: 1.7387
Epoch [1/4], Batch [37/428], Loss: 2.9629
Epoch [1/4], Batch [38/428], Loss: 1.7140
Epoch [1/4], Batch [39/428], Loss: 0.1578
Epoch [1/4], Batch [40/428], Loss: 2.3060
Epoch [1/4], Batch [41/428], Loss: 0.1244
Epoch [1/4], Batch [42/428], Loss: 0.5626
Epoch [1/4], Batch [43/428], Loss: 3.1244
Epoch [1/4], Batch [44/428], Loss: 1.3302
Epoch [1/4], Batch [45/428], Loss: 1.4856
Epoch [1/4], Batch [46/428], Loss: 1.8145
Epoch [1/4], Batch [47/428], Loss: 2.2599
Epoch [1/4], Batch [48/428], Loss: 2.5215
Epoch [1/4], Batch [49/428], Loss: 2.6642
Epoch [1/4], Batch [50/428], Loss: 1.2865
Epoch [1/4], Batch [51/428], Loss: 2.2368
Epoch [1/4], Batch [52/428], Loss: 1.9900
Epoch [1/4], Batch [53/428], Loss: 1.1336
Epoch [1/4], Batch [54/428], Loss: 2.4339
Epoch [1/4], Batch [55/428], Loss: 2.2318
Epoch [1/4], Batch [56/428], Loss: 1.0358
Epoch [1/4], Batch [57/428], Loss: 1.6159
Epoch [1/4], Batch [58/428], Loss: 2.3451
Epoch [1/4], Batch [59/428], Loss: 0.7725
Epoch [1/4], Batch [60/428], Loss: 1.8326
Epoch [1/4], Batch [61/428], Loss: 1.6900
Epoch [1/4], Batch [62/428], Loss: 1.9046
Epoch [1/4], Batch [63/428], Loss: 2.1680
Epoch [1/4], Batch [64/428], Loss: 0.0729
Epoch [1/4], Batch [65/428], Loss: 2.2862
Epoch [1/4], Batch [66/428], Loss: 2.2534
Epoch [1/4], Batch [67/428], Loss: 2.1017
Epoch [1/4], Batch [68/428], Loss: 2.5903
Epoch [1/4], Batch [69/428], Loss: 1.7052
Epoch [1/4], Batch [70/428], Loss: 2.0335
Epoch [1/4], Batch [71/428], Loss: 2.0836
Epoch [1/4], Batch [72/428], Loss: 1.7000
Epoch [1/4], Batch [73/428], Loss: 1.4789
Epoch [1/4], Batch [74/428], Loss: 2.2905
Epoch [1/4], Batch [75/428], Loss: 2.5138
Epoch [1/4], Batch [76/428], Loss: 1.9083
Epoch [1/4], Batch [77/428], Loss: 1.2913
Epoch [1/4], Batch [78/428], Loss: 0.4143
Epoch [1/4], Batch [79/428], Loss: 0.4156
Epoch [1/4], Batch [80/428], Loss: 2.0312
Epoch [1/4], Batch [81/428], Loss: 2.9691
Epoch [1/4], Batch [82/428], Loss: 1.1820
Epoch [1/4], Batch [83/428], Loss: 0.0649
Epoch [1/4], Batch [84/428], Loss: 0.4467
Epoch [1/4], Batch [85/428], Loss: 0.4047
Epoch [1/4], Batch [86/428], Loss: 0.1089
Epoch [1/4], Batch [87/428], Loss: 0.5567
Epoch [1/4], Batch [88/428], Loss: 1.8062
Epoch [1/4], Batch [89/428], Loss: 0.0092
Epoch [1/4], Batch [90/428], Loss: 0.7561
Epoch [1/4], Batch [91/428], Loss: 0.3248
Epoch [1/4], Batch [92/428], Loss: 0.2652
Epoch [1/4], Batch [93/428], Loss: 0.4277
Epoch [1/4], Batch [94/428], Loss: 1.9074
Epoch [1/4], Batch [95/428], Loss: 2.9335
Epoch [1/4], Batch [96/428], Loss: 0.3468
Epoch [1/4], Batch [97/428], Loss: 0.1595
Epoch [1/4], Batch [98/428], Loss: 1.8286
Epoch [1/4], Batch [99/428], Loss: 2.5910
Epoch [1/4], Batch [100/428], Loss: 4.3003
Epoch [1/4], Batch [101/428], Loss: 0.0053
Epoch [1/4], Batch [102/428], Loss: 0.0050
Epoch [1/4], Batch [103/428], Loss: 0.2540
Epoch [1/4], Batch [104/428], Loss: 0.1900
Epoch [1/4], Batch [105/428], Loss: 0.2348
Epoch [1/4], Batch [106/428], Loss: 1.6184
Epoch [1/4], Batch [107/428], Loss: 1.9756
Epoch [1/4], Batch [108/428], Loss: 2.3875
Epoch [1/4], Batch [109/428], Loss: 1.7230
Epoch [1/4], Batch [110/428], Loss: 3.1938
Epoch [1/4], Batch [111/428], Loss: 1.8946
Epoch [1/4], Batch [112/428], Loss: 3.0138
Epoch [1/4], Batch [113/428], Loss: 2.3441
Epoch [1/4], Batch [114/428], Loss: 3.2387
Epoch [1/4], Batch [115/428], Loss: 1.1024
Epoch [1/4], Batch [116/428], Loss: 1.6128
Epoch [1/4], Batch [117/428], Loss: 2.4087
Epoch [1/4], Batch [118/428], Loss: 2.6382
Epoch [1/4], Batch [119/428], Loss: 1.9003
Epoch [1/4], Batch [120/428], Loss: 1.6759
Epoch [1/4], Batch [121/428], Loss: 0.2714
Epoch [1/4], Batch [122/428], Loss: 2.5000
Epoch [1/4], Batch [123/428], Loss: 0.1020
Epoch [1/4], Batch [124/428], Loss: 1.8580
Epoch [1/4], Batch [125/428], Loss: 0.5204
Epoch [1/4], Batch [126/428], Loss: 0.0044
Epoch [1/4], Batch [127/428], Loss: 2.3788
Epoch [1/4], Batch [128/428], Loss: 1.5340
Epoch [1/4], Batch [129/428], Loss: 1.5767
Epoch [1/4], Batch [130/428], Loss: 1.9499
Epoch [1/4], Batch [131/428], Loss: 0.0022
Epoch [1/4], Batch [132/428], Loss: 1.2227
Epoch [1/4], Batch [133/428], Loss: 0.0148
Epoch [1/4], Batch [134/428], Loss: 1.1947
Epoch [1/4], Batch [135/428], Loss: 1.2995
Epoch [1/4], Batch [136/428], Loss: 0.3035
Epoch [1/4], Batch [137/428], Loss: 1.4432
Epoch [1/4], Batch [138/428], Loss: 0.0129
Epoch [1/4], Batch [139/428], Loss: 2.9843
Epoch [1/4], Batch [140/428], Loss: 1.6530
Epoch [1/4], Batch [141/428], Loss: 0.8521
Epoch [1/4], Batch [142/428], Loss: 1.6946
Epoch [1/4], Batch [143/428], Loss: 1.5368
Epoch [1/4], Batch [144/428], Loss: 2.6430
Epoch [1/4], Batch [145/428], Loss: 2.5012
Epoch [1/4], Batch [146/428], Loss: 4.1262
Epoch [1/4], Batch [147/428], Loss: 2.2739
Epoch [1/4], Batch [148/428], Loss: 2.3570
Epoch [1/4], Batch [149/428], Loss: 3.0694
Epoch [1/4], Batch [150/428], Loss: 0.3443
Epoch [1/4], Batch [151/428], Loss: 2.2897
Epoch [1/4], Batch [152/428], Loss: 3.8771
Epoch [1/4], Batch [153/428], Loss: 0.5621
Epoch [1/4], Batch [154/428], Loss: 0.1827
Epoch [1/4], Batch [155/428], Loss: 0.0063
Epoch [1/4], Batch [156/428], Loss: 4.4259
Epoch [1/4], Batch [157/428], Loss: 0.9170
Epoch [1/4], Batch [158/428], Loss: 2.2145
Epoch [1/4], Batch [159/428], Loss: 0.0020
Epoch [1/4], Batch [160/428], Loss: 1.1788
Epoch [1/4], Batch [161/428], Loss: 0.4742
Epoch [1/4], Batch [162/428], Loss: 0.0018
Epoch [1/4], Batch [163/428], Loss: 1.2721
Epoch [1/4], Batch [164/428], Loss: 0.9371
Epoch [1/4], Batch [165/428], Loss: 0.8818
Epoch [1/4], Batch [166/428], Loss: 1.9132
Epoch [1/4], Batch [167/428], Loss: 1.3108
Epoch [1/4], Batch [168/428], Loss: 1.7178
Epoch [1/4], Batch [169/428], Loss: 0.1230
Epoch [1/4], Batch [170/428], Loss: 0.0047
Epoch [1/4], Batch [171/428], Loss: 1.0216
Epoch [1/4], Batch [172/428], Loss: 1.0030
Epoch [1/4], Batch [173/428], Loss: 2.8804
Epoch [1/4], Batch [174/428], Loss: 1.9199
Epoch [1/4], Batch [175/428], Loss: 0.7492
Epoch [1/4], Batch [176/428], Loss: 1.3055
Epoch [1/4], Batch [177/428], Loss: 3.4101
Epoch [1/4], Batch [178/428], Loss: 1.3539
Epoch [1/4], Batch [179/428], Loss: 0.7484
Epoch [1/4], Batch [180/428], Loss: 0.5942
Epoch [1/4], Batch [181/428], Loss: 0.8280
Epoch [1/4], Batch [182/428], Loss: 2.1248
Epoch [1/4], Batch [183/428], Loss: 1.8126
Epoch [1/4], Batch [184/428], Loss: 0.0903
Epoch [1/4], Batch [185/428], Loss: 0.0015
Epoch [1/4], Batch [186/428], Loss: 0.6253
Epoch [1/4], Batch [187/428], Loss: 0.0050
Epoch [1/4], Batch [188/428], Loss: 2.0970
Epoch [1/4], Batch [189/428], Loss: 2.3070
Epoch [1/4], Batch [190/428], Loss: 0.0425
Epoch [1/4], Batch [191/428], Loss: 0.0058
Epoch [1/4], Batch [192/428], Loss: 1.8079
Epoch [1/4], Batch [193/428], Loss: 1.3817
Epoch [1/4], Batch [194/428], Loss: 0.2854
Epoch [1/4], Batch [195/428], Loss: 1.7170
Epoch [1/4], Batch [196/428], Loss: 0.5356
Epoch [1/4], Batch [197/428], Loss: 1.5880
Epoch [1/4], Batch [198/428], Loss: 0.7343
Epoch [1/4], Batch [199/428], Loss: 2.5273
Epoch [1/4], Batch [200/428], Loss: 0.0282
Epoch [1/4], Batch [201/428], Loss: 2.7509
Epoch [1/4], Batch [202/428], Loss: 0.0215
Epoch [1/4], Batch [203/428], Loss: 2.8581
Epoch [1/4], Batch [204/428], Loss: 0.0016
Epoch [1/4], Batch [205/428], Loss: 3.4537
Epoch [1/4], Batch [206/428], Loss: 0.6930
Epoch [1/4], Batch [207/428], Loss: 1.0617
Epoch [1/4], Batch [208/428], Loss: 0.5672
Epoch [1/4], Batch [209/428], Loss: 1.9465
Epoch [1/4], Batch [210/428], Loss: 3.6539
Epoch [1/4], Batch [211/428], Loss: 0.5495
Epoch [1/4], Batch [212/428], Loss: 0.7091
Epoch [1/4], Batch [213/428], Loss: 1.2793
Epoch [1/4], Batch [214/428], Loss: 0.7996
Epoch [1/4], Batch [215/428], Loss: 1.7227
Epoch [1/4], Batch [216/428], Loss: 0.3701
Epoch [1/4], Batch [217/428], Loss: 0.0010
Epoch [1/4], Batch [218/428], Loss: 1.3431
Epoch [1/4], Batch [219/428], Loss: 0.9882
Epoch [1/4], Batch [220/428], Loss: 2.0088
Epoch [1/4], Batch [221/428], Loss: 0.1645
Epoch [1/4], Batch [222/428], Loss: 0.4123
Epoch [1/4], Batch [223/428], Loss: 1.4344
Epoch [1/4], Batch [224/428], Loss: 0.0968
Epoch [1/4], Batch [225/428], Loss: 1.3267
Epoch [1/4], Batch [226/428], Loss: 2.7160
Epoch [1/4], Batch [227/428], Loss: 2.6177
Epoch [1/4], Batch [228/428], Loss: 1.7675
Epoch [1/4], Batch [229/428], Loss: 0.4608
Epoch [1/4], Batch [230/428], Loss: 0.4217
Epoch [1/4], Batch [231/428], Loss: 0.0320
Epoch [1/4], Batch [232/428], Loss: 0.0238
Epoch [1/4], Batch [233/428], Loss: 0.0027
Epoch [1/4], Batch [234/428], Loss: 0.7615
Epoch [1/4], Batch [235/428], Loss: 2.4430
Epoch [1/4], Batch [236/428], Loss: 0.0125
Epoch [1/4], Batch [237/428], Loss: 3.2747
Epoch [1/4], Batch [238/428], Loss: 0.0023
Epoch [1/4], Batch [239/428], Loss: 0.0057
Epoch [1/4], Batch [240/428], Loss: 0.0025
Epoch [1/4], Batch [241/428], Loss: 0.0113
Epoch [1/4], Batch [242/428], Loss: 0.1447
Epoch [1/4], Batch [243/428], Loss: 2.7014
Epoch [1/4], Batch [244/428], Loss: 2.4180
Epoch [1/4], Batch [245/428], Loss: 0.7606
Epoch [1/4], Batch [246/428], Loss: 2.2039
Epoch [1/4], Batch [247/428], Loss: 0.5548
Epoch [1/4], Batch [248/428], Loss: 0.0007
Epoch [1/4], Batch [249/428], Loss: 2.0546
Epoch [1/4], Batch [250/428], Loss: 1.6885
Epoch [1/4], Batch [251/428], Loss: 0.2594
Epoch [1/4], Batch [252/428], Loss: 2.6277
Epoch [1/4], Batch [253/428], Loss: 2.4564
Epoch [1/4], Batch [254/428], Loss: 0.6222
Epoch [1/4], Batch [255/428], Loss: 1.8604
Epoch [1/4], Batch [256/428], Loss: 3.8174
Epoch [1/4], Batch [257/428], Loss: 0.4913
Epoch [1/4], Batch [258/428], Loss: 1.8507
Epoch [1/4], Batch [259/428], Loss: 2.8968
Epoch [1/4], Batch [260/428], Loss: 0.7730
Epoch [1/4], Batch [261/428], Loss: 2.1648
Epoch [1/4], Batch [262/428], Loss: 1.5161
Epoch [1/4], Batch [263/428], Loss: 0.0011
Epoch [1/4], Batch [264/428], Loss: 4.3922
Epoch [1/4], Batch [265/428], Loss: 1.7192
Epoch [1/4], Batch [266/428], Loss: 1.6608
Epoch [1/4], Batch [267/428], Loss: 2.4613
Epoch [1/4], Batch [268/428], Loss: 1.2396
Epoch [1/4], Batch [269/428], Loss: 1.8275
Epoch [1/4], Batch [270/428], Loss: 0.4551
Epoch [1/4], Batch [271/428], Loss: 0.8280
Epoch [1/4], Batch [272/428], Loss: 0.2397
Epoch [1/4], Batch [273/428], Loss: 1.3017
Epoch [1/4], Batch [274/428], Loss: 3.5662
Epoch [1/4], Batch [275/428], Loss: 1.2559
Epoch [1/4], Batch [276/428], Loss: 2.1976
Epoch [1/4], Batch [277/428], Loss: 1.6587
Epoch [1/4], Batch [278/428], Loss: 1.6122
Epoch [1/4], Batch [279/428], Loss: 0.0024
Epoch [1/4], Batch [280/428], Loss: 0.9800
Epoch [1/4], Batch [281/428], Loss: 0.4948
Epoch [1/4], Batch [282/428], Loss: 0.6624
Epoch [1/4], Batch [283/428], Loss: 2.4623
Epoch [1/4], Batch [284/428], Loss: 0.8749
Epoch [1/4], Batch [285/428], Loss: 0.9676
Epoch [1/4], Batch [286/428], Loss: 0.0750
Epoch [1/4], Batch [287/428], Loss: 1.9395
Epoch [1/4], Batch [288/428], Loss: 0.1623
Epoch [1/4], Batch [289/428], Loss: 0.2393
Epoch [1/4], Batch [290/428], Loss: 2.5255
Epoch [1/4], Batch [291/428], Loss: 1.5923
Epoch [1/4], Batch [292/428], Loss: 1.7408
Epoch [1/4], Batch [293/428], Loss: 2.2427
Epoch [1/4], Batch [294/428], Loss: 1.6493
Epoch [1/4], Batch [295/428], Loss: 0.0305
Epoch [1/4], Batch [296/428], Loss: 0.1179
Epoch [1/4], Batch [297/428], Loss: 1.3009
Epoch [1/4], Batch [298/428], Loss: 2.2043
Epoch [1/4], Batch [299/428], Loss: 1.8420
Epoch [1/4], Batch [300/428], Loss: 0.0112
Epoch [1/4], Batch [301/428], Loss: 1.6083
Epoch [1/4], Batch [302/428], Loss: 0.0005
Epoch [1/4], Batch [303/428], Loss: 0.7162
Epoch [1/4], Batch [304/428], Loss: 1.8614
Epoch [1/4], Batch [305/428], Loss: 1.3410
Epoch [1/4], Batch [306/428], Loss: 1.8731
Epoch [1/4], Batch [307/428], Loss: 2.1701
Epoch [1/4], Batch [308/428], Loss: 0.1242
Epoch [1/4], Batch [309/428], Loss: 2.9474
Epoch [1/4], Batch [310/428], Loss: 2.0430
Epoch [1/4], Batch [311/428], Loss: 0.1510
Epoch [1/4], Batch [312/428], Loss: 1.5875
Epoch [1/4], Batch [313/428], Loss: 0.2189
Epoch [1/4], Batch [314/428], Loss: 2.6664
Epoch [1/4], Batch [315/428], Loss: 4.1130
Epoch [1/4], Batch [316/428], Loss: 0.0002
Epoch [1/4], Batch [317/428], Loss: 0.4453
Epoch [1/4], Batch [318/428], Loss: 0.7043
Epoch [1/4], Batch [319/428], Loss: 1.1580
Epoch [1/4], Batch [320/428], Loss: 0.0002
Epoch [1/4], Batch [321/428], Loss: 0.5692
Epoch [1/4], Batch [322/428], Loss: 2.7197
Epoch [1/4], Batch [323/428], Loss: 0.0161
Epoch [1/4], Batch [324/428], Loss: 0.1839
Epoch [1/4], Batch [325/428], Loss: 0.1368
Epoch [1/4], Batch [326/428], Loss: 1.1618
Epoch [1/4], Batch [327/428], Loss: 0.0023
Epoch [1/4], Batch [328/428], Loss: 0.0955
Epoch [1/4], Batch [329/428], Loss: 1.6714
Epoch [1/4], Batch [330/428], Loss: 0.0107
Epoch [1/4], Batch [331/428], Loss: 0.0337
Epoch [1/4], Batch [332/428], Loss: 2.2067
Epoch [1/4], Batch [333/428], Loss: 0.0006
Epoch [1/4], Batch [334/428], Loss: 0.9561
Epoch [1/4], Batch [335/428], Loss: 4.4978
Epoch [1/4], Batch [336/428], Loss: 0.1013
Epoch [1/4], Batch [337/428], Loss: 3.9822
Epoch [1/4], Batch [338/428], Loss: 0.3215
Epoch [1/4], Batch [339/428], Loss: 1.6231
Epoch [1/4], Batch [340/428], Loss: 0.0033
Epoch [1/4], Batch [341/428], Loss: 1.4536
Epoch [1/4], Batch [342/428], Loss: 3.7384
Epoch [1/4], Batch [343/428], Loss: 2.2137
Epoch [1/4], Batch [344/428], Loss: 0.0915
Epoch [1/4], Batch [345/428], Loss: 0.8863
Epoch [1/4], Batch [346/428], Loss: 0.4532
Epoch [1/4], Batch [347/428], Loss: 1.4489
Epoch [1/4], Batch [348/428], Loss: 3.7886
Epoch [1/4], Batch [349/428], Loss: 1.6249
Epoch [1/4], Batch [350/428], Loss: 0.8215
Epoch [1/4], Batch [351/428], Loss: 0.0001
Epoch [1/4], Batch [352/428], Loss: 0.0745
Epoch [1/4], Batch [353/428], Loss: 1.3714
Epoch [1/4], Batch [354/428], Loss: 1.3843
Epoch [1/4], Batch [355/428], Loss: 1.1558
Epoch [1/4], Batch [356/428], Loss: 2.2903
Epoch [1/4], Batch [357/428], Loss: 1.3742
Epoch [1/4], Batch [358/428], Loss: 0.9595
Epoch [1/4], Batch [359/428], Loss: 1.3796
Epoch [1/4], Batch [360/428], Loss: 1.0324
Epoch [1/4], Batch [361/428], Loss: 0.6697
Epoch [1/4], Batch [362/428], Loss: 1.0672
Epoch [1/4], Batch [363/428], Loss: 0.0292
Epoch [1/4], Batch [364/428], Loss: 0.0657
Epoch [1/4], Batch [365/428], Loss: 2.2138
Epoch [1/4], Batch [366/428], Loss: 0.0045
Epoch [1/4], Batch [367/428], Loss: 0.0002
Epoch [1/4], Batch [368/428], Loss: 0.0362
Epoch [1/4], Batch [369/428], Loss: 0.7476
Epoch [1/4], Batch [370/428], Loss: 0.5948
Epoch [1/4], Batch [371/428], Loss: 1.8559
Epoch [1/4], Batch [372/428], Loss: 2.9915
Epoch [1/4], Batch [373/428], Loss: 0.8463
Epoch [1/4], Batch [374/428], Loss: 2.0668
Epoch [1/4], Batch [375/428], Loss: 2.5869
Epoch [1/4], Batch [376/428], Loss: 0.7542
Epoch [1/4], Batch [377/428], Loss: 1.3445
Epoch [1/4], Batch [378/428], Loss: 4.0380
Epoch [1/4], Batch [379/428], Loss: 1.8654
Epoch [1/4], Batch [380/428], Loss: 1.5098
Epoch [1/4], Batch [381/428], Loss: 1.9110
Epoch [1/4], Batch [382/428], Loss: 0.1509
Epoch [1/4], Batch [383/428], Loss: 2.0740
Epoch [1/4], Batch [384/428], Loss: 2.2362
Epoch [1/4], Batch [385/428], Loss: 0.0785
Epoch [1/4], Batch [386/428], Loss: 2.5875
Epoch [1/4], Batch [387/428], Loss: 0.0043
Epoch [1/4], Batch [388/428], Loss: 1.4183
Epoch [1/4], Batch [389/428], Loss: 1.2486
Epoch [1/4], Batch [390/428], Loss: 1.1235
Epoch [1/4], Batch [391/428], Loss: 0.0824
Epoch [1/4], Batch [392/428], Loss: 3.5620
Epoch [1/4], Batch [393/428], Loss: 0.0001
Epoch [1/4], Batch [394/428], Loss: 2.6325
Epoch [1/4], Batch [395/428], Loss: 0.1476
Epoch [1/4], Batch [396/428], Loss: 1.2616
Epoch [1/4], Batch [397/428], Loss: 0.0008
Epoch [1/4], Batch [398/428], Loss: 0.8677
Epoch [1/4], Batch [399/428], Loss: 1.5698
Epoch [1/4], Batch [400/428], Loss: 0.2201
Epoch [1/4], Batch [401/428], Loss: 9.8438
Epoch [1/4], Batch [402/428], Loss: 1.0066
Epoch [1/4], Batch [403/428], Loss: 2.3179
Epoch [1/4], Batch [404/428], Loss: 1.9920
Epoch [1/4], Batch [405/428], Loss: 0.0990
Epoch [1/4], Batch [406/428], Loss: 1.5399
Epoch [1/4], Batch [407/428], Loss: 1.2256
Epoch [1/4], Batch [408/428], Loss: 1.9104
Epoch [1/4], Batch [409/428], Loss: 0.0011
Epoch [1/4], Batch [410/428], Loss: 0.0162
Epoch [1/4], Batch [411/428], Loss: 2.2029
Epoch [1/4], Batch [412/428], Loss: 0.0334
Epoch [1/4], Batch [413/428], Loss: 1.8252
Epoch [1/4], Batch [414/428], Loss: 0.4631
Epoch [1/4], Batch [415/428], Loss: 0.8335
Epoch [1/4], Batch [416/428], Loss: 0.9578
Epoch [1/4], Batch [417/428], Loss: 0.0789
Epoch [1/4], Batch [418/428], Loss: 1.8597
Epoch [1/4], Batch [419/428], Loss: 2.0334
Epoch [1/4], Batch [420/428], Loss: 0.0001
Epoch [1/4], Batch [421/428], Loss: 1.5534
Epoch [1/4], Batch [422/428], Loss: 0.0001
Epoch [1/4], Batch [423/428], Loss: 1.5041
Epoch [1/4], Batch [424/428], Loss: 0.0354
Epoch [1/4], Batch [425/428], Loss: 6.8553
Epoch [1/4], Batch [426/428], Loss: 0.0832
Epoch [1/4], Batch [427/428], Loss: 0.0417
Epoch [1/4], Batch [428/428], Loss: 1.0789
Epoch [1] Training Time: 238.87 seconds
Epoch [1/4], Average Loss: 1.4013, Training Accuracy: 0.4790
Epoch [1], Validation Loss: 1.6977, Validation Accuracy: 0.4677
Epoch [1] Validation Time: 14.28 seconds
--------------------------------------------------
Epoch [2/4], Batch [1/428], Loss: 1.4039
Epoch [2/4], Batch [2/428], Loss: 0.0450
Epoch [2/4], Batch [3/428], Loss: 1.0118
Epoch [2/4], Batch [4/428], Loss: 1.1704
Epoch [2/4], Batch [5/428], Loss: 1.3211
Epoch [2/4], Batch [6/428], Loss: 0.0142
Epoch [2/4], Batch [7/428], Loss: 0.0001
Epoch [2/4], Batch [8/428], Loss: 0.2174
Epoch [2/4], Batch [9/428], Loss: 2.2146
Epoch [2/4], Batch [10/428], Loss: 4.3355
Epoch [2/4], Batch [11/428], Loss: 0.0002
Epoch [2/4], Batch [12/428], Loss: 2.3645
Epoch [2/4], Batch [13/428], Loss: 0.0001
Epoch [2/4], Batch [14/428], Loss: 0.4409
Epoch [2/4], Batch [15/428], Loss: 0.8874
Epoch [2/4], Batch [16/428], Loss: 2.1323
Epoch [2/4], Batch [17/428], Loss: 2.6569
Epoch [2/4], Batch [18/428], Loss: 0.9076
Epoch [2/4], Batch [19/428], Loss: 2.1627
Epoch [2/4], Batch [20/428], Loss: 4.1842
Epoch [2/4], Batch [21/428], Loss: 4.1739
Epoch [2/4], Batch [22/428], Loss: 0.2850
Epoch [2/4], Batch [23/428], Loss: 0.1064
Epoch [2/4], Batch [24/428], Loss: 1.0989
Epoch [2/4], Batch [25/428], Loss: 1.9021
Epoch [2/4], Batch [26/428], Loss: 2.1533
Epoch [2/4], Batch [27/428], Loss: 0.0151
Epoch [2/4], Batch [28/428], Loss: 3.7206
Epoch [2/4], Batch [29/428], Loss: 0.0186
Epoch [2/4], Batch [30/428], Loss: 1.0078
Epoch [2/4], Batch [31/428], Loss: 1.2836
Epoch [2/4], Batch [32/428], Loss: 3.7192
Epoch [2/4], Batch [33/428], Loss: 1.2647
Epoch [2/4], Batch [34/428], Loss: 1.8102
Epoch [2/4], Batch [35/428], Loss: 0.0202
Epoch [2/4], Batch [36/428], Loss: 3.0465
Epoch [2/4], Batch [37/428], Loss: 0.8457
Epoch [2/4], Batch [38/428], Loss: 0.0207
Epoch [2/4], Batch [39/428], Loss: 0.0002
Epoch [2/4], Batch [40/428], Loss: 0.7243
Epoch [2/4], Batch [41/428], Loss: 0.4575
Epoch [2/4], Batch [42/428], Loss: 0.0280
Epoch [2/4], Batch [43/428], Loss: 4.6561
Epoch [2/4], Batch [44/428], Loss: 1.1614
Epoch [2/4], Batch [45/428], Loss: 0.0973
Epoch [2/4], Batch [46/428], Loss: 1.3605
Epoch [2/4], Batch [47/428], Loss: 2.2622
Epoch [2/4], Batch [48/428], Loss: 0.0953
Epoch [2/4], Batch [49/428], Loss: 0.2323
Epoch [2/4], Batch [50/428], Loss: 1.1961
Epoch [2/4], Batch [51/428], Loss: 2.3221
Epoch [2/4], Batch [52/428], Loss: 0.0011
Epoch [2/4], Batch [53/428], Loss: 0.2382
Epoch [2/4], Batch [54/428], Loss: 0.0030
Epoch [2/4], Batch [55/428], Loss: 3.0200
Epoch [2/4], Batch [56/428], Loss: 4.2823
Epoch [2/4], Batch [57/428], Loss: 1.3228
Epoch [2/4], Batch [58/428], Loss: 0.7965
Epoch [2/4], Batch [59/428], Loss: 0.3352
Epoch [2/4], Batch [60/428], Loss: 1.8854
Epoch [2/4], Batch [61/428], Loss: 0.0003
Epoch [2/4], Batch [62/428], Loss: 0.2342
Epoch [2/4], Batch [63/428], Loss: 1.8490
Epoch [2/4], Batch [64/428], Loss: 2.2576
Epoch [2/4], Batch [65/428], Loss: 0.6517
Epoch [2/4], Batch [66/428], Loss: 0.9779
Epoch [2/4], Batch [67/428], Loss: 0.0001
Epoch [2/4], Batch [68/428], Loss: 0.7745
Epoch [2/4], Batch [69/428], Loss: 1.0326
Epoch [2/4], Batch [70/428], Loss: 0.0384
Epoch [2/4], Batch [71/428], Loss: 1.1354
Epoch [2/4], Batch [72/428], Loss: 1.2187
Epoch [2/4], Batch [73/428], Loss: 0.3977
Epoch [2/4], Batch [74/428], Loss: 0.0080
Epoch [2/4], Batch [75/428], Loss: 1.9316
Epoch [2/4], Batch [76/428], Loss: 0.5419
Epoch [2/4], Batch [77/428], Loss: 1.8243
Epoch [2/4], Batch [78/428], Loss: 0.0014
Epoch [2/4], Batch [79/428], Loss: 2.0662
Epoch [2/4], Batch [80/428], Loss: 0.0008
Epoch [2/4], Batch [81/428], Loss: 0.0739
Epoch [2/4], Batch [82/428], Loss: 1.4751
Epoch [2/4], Batch [83/428], Loss: 0.1609
Epoch [2/4], Batch [84/428], Loss: 0.0131
Epoch [2/4], Batch [85/428], Loss: 1.3542
Epoch [2/4], Batch [86/428], Loss: 0.2511
Epoch [2/4], Batch [87/428], Loss: 1.1131
Epoch [2/4], Batch [88/428], Loss: 0.0007
Epoch [2/4], Batch [89/428], Loss: 0.0002
Epoch [2/4], Batch [90/428], Loss: 0.0001
Epoch [2/4], Batch [91/428], Loss: 0.0003
Epoch [2/4], Batch [92/428], Loss: 2.3342
Epoch [2/4], Batch [93/428], Loss: 0.0001
Epoch [2/4], Batch [94/428], Loss: 0.7736
Epoch [2/4], Batch [95/428], Loss: 0.6030
Epoch [2/4], Batch [96/428], Loss: 0.0017
Epoch [2/4], Batch [97/428], Loss: 0.0004
Epoch [2/4], Batch [98/428], Loss: 0.0106
Epoch [2/4], Batch [99/428], Loss: 0.0749
Epoch [2/4], Batch [100/428], Loss: 4.5649
Epoch [2/4], Batch [101/428], Loss: 0.3266
Epoch [2/4], Batch [102/428], Loss: 2.0798
Epoch [2/4], Batch [103/428], Loss: 0.0259
Epoch [2/4], Batch [104/428], Loss: 0.1569
Epoch [2/4], Batch [105/428], Loss: 0.7216
Epoch [2/4], Batch [106/428], Loss: 0.7646
Epoch [2/4], Batch [107/428], Loss: 0.0227
Epoch [2/4], Batch [108/428], Loss: 0.0018
Epoch [2/4], Batch [109/428], Loss: 0.9377
Epoch [2/4], Batch [110/428], Loss: 0.0988
Epoch [2/4], Batch [111/428], Loss: 0.3898
Epoch [2/4], Batch [112/428], Loss: 2.2469
Epoch [2/4], Batch [113/428], Loss: 0.0466
Epoch [2/4], Batch [114/428], Loss: 2.5194
Epoch [2/4], Batch [115/428], Loss: 0.7430
Epoch [2/4], Batch [116/428], Loss: 0.0130
Epoch [2/4], Batch [117/428], Loss: 3.5343
Epoch [2/4], Batch [118/428], Loss: 1.3359
Epoch [2/4], Batch [119/428], Loss: 0.0186
Epoch [2/4], Batch [120/428], Loss: 4.0520
Epoch [2/4], Batch [121/428], Loss: 5.8616
Epoch [2/4], Batch [122/428], Loss: 0.0097
Epoch [2/4], Batch [123/428], Loss: 3.7270
Epoch [2/4], Batch [124/428], Loss: 0.0035
Epoch [2/4], Batch [125/428], Loss: 2.8344
Epoch [2/4], Batch [126/428], Loss: 0.0181
Epoch [2/4], Batch [127/428], Loss: 0.0210
Epoch [2/4], Batch [128/428], Loss: 1.9987
Epoch [2/4], Batch [129/428], Loss: 1.2669
Epoch [2/4], Batch [130/428], Loss: 0.6381
Epoch [2/4], Batch [131/428], Loss: 0.3102
Epoch [2/4], Batch [132/428], Loss: 0.0408
Epoch [2/4], Batch [133/428], Loss: 2.3039
Epoch [2/4], Batch [134/428], Loss: 0.7317
Epoch [2/4], Batch [135/428], Loss: 0.0128
Epoch [2/4], Batch [136/428], Loss: 0.0097
Epoch [2/4], Batch [137/428], Loss: 0.0042
Epoch [2/4], Batch [138/428], Loss: 2.8038
Epoch [2/4], Batch [139/428], Loss: 1.4817
Epoch [2/4], Batch [140/428], Loss: 0.7176
Epoch [2/4], Batch [141/428], Loss: 0.1726
Epoch [2/4], Batch [142/428], Loss: 1.5545
Epoch [2/4], Batch [143/428], Loss: 7.0648
Epoch [2/4], Batch [144/428], Loss: 0.0148
Epoch [2/4], Batch [145/428], Loss: 1.4401
Epoch [2/4], Batch [146/428], Loss: 0.1031
Epoch [2/4], Batch [147/428], Loss: 1.2664
Epoch [2/4], Batch [148/428], Loss: 0.1280
Epoch [2/4], Batch [149/428], Loss: 0.0305
Epoch [2/4], Batch [150/428], Loss: 1.2204
Epoch [2/4], Batch [151/428], Loss: 0.9599
Epoch [2/4], Batch [152/428], Loss: 2.4449
Epoch [2/4], Batch [153/428], Loss: 0.4280
Epoch [2/4], Batch [154/428], Loss: 2.4669
Epoch [2/4], Batch [155/428], Loss: 1.2297
Epoch [2/4], Batch [156/428], Loss: 1.3081
Epoch [2/4], Batch [157/428], Loss: 0.3532
Epoch [2/4], Batch [158/428], Loss: 1.1611
Epoch [2/4], Batch [159/428], Loss: 5.2014
Epoch [2/4], Batch [160/428], Loss: 1.6746
Epoch [2/4], Batch [161/428], Loss: 1.2165
Epoch [2/4], Batch [162/428], Loss: 2.8064
Epoch [2/4], Batch [163/428], Loss: 1.6627
Epoch [2/4], Batch [164/428], Loss: 4.8154
Epoch [2/4], Batch [165/428], Loss: 2.7044
Epoch [2/4], Batch [166/428], Loss: 0.0002
Epoch [2/4], Batch [167/428], Loss: 0.0745
Epoch [2/4], Batch [168/428], Loss: 3.3991
Epoch [2/4], Batch [169/428], Loss: 0.7561
Epoch [2/4], Batch [170/428], Loss: 1.7557
Epoch [2/4], Batch [171/428], Loss: 0.0001
Epoch [2/4], Batch [172/428], Loss: 0.0573
Epoch [2/4], Batch [173/428], Loss: 2.6314
Epoch [2/4], Batch [174/428], Loss: 1.3340
Epoch [2/4], Batch [175/428], Loss: 0.0206
Epoch [2/4], Batch [176/428], Loss: 0.9578
Epoch [2/4], Batch [177/428], Loss: 0.0408
Epoch [2/4], Batch [178/428], Loss: 0.8200
Epoch [2/4], Batch [179/428], Loss: 0.8700
Epoch [2/4], Batch [180/428], Loss: 2.8770
Epoch [2/4], Batch [181/428], Loss: 2.1568
Epoch [2/4], Batch [182/428], Loss: 4.3808
Epoch [2/4], Batch [183/428], Loss: 1.9123
Epoch [2/4], Batch [184/428], Loss: 0.9455
Epoch [2/4], Batch [185/428], Loss: 0.0073
Epoch [2/4], Batch [186/428], Loss: 0.5288
Epoch [2/4], Batch [187/428], Loss: 1.0387
Epoch [2/4], Batch [188/428], Loss: 0.0751
Epoch [2/4], Batch [189/428], Loss: 0.0343
Epoch [2/4], Batch [190/428], Loss: 2.8570
Epoch [2/4], Batch [191/428], Loss: 2.1079
Epoch [2/4], Batch [192/428], Loss: 1.0369
Epoch [2/4], Batch [193/428], Loss: 2.1275
Epoch [2/4], Batch [194/428], Loss: 0.0553
Epoch [2/4], Batch [195/428], Loss: 0.0002
Epoch [2/4], Batch [196/428], Loss: 2.3557
Epoch [2/4], Batch [197/428], Loss: 1.2960
Epoch [2/4], Batch [198/428], Loss: 1.7454
Epoch [2/4], Batch [199/428], Loss: 1.1066
Epoch [2/4], Batch [200/428], Loss: 0.9168
Epoch [2/4], Batch [201/428], Loss: 0.1218
Epoch [2/4], Batch [202/428], Loss: 0.0011
Epoch [2/4], Batch [203/428], Loss: 0.0079
Epoch [2/4], Batch [204/428], Loss: 0.3629
Epoch [2/4], Batch [205/428], Loss: 0.0730
Epoch [2/4], Batch [206/428], Loss: 4.2861
Epoch [2/4], Batch [207/428], Loss: 3.3843
Epoch [2/4], Batch [208/428], Loss: 2.8247
Epoch [2/4], Batch [209/428], Loss: 5.6173
Epoch [2/4], Batch [210/428], Loss: 1.2899
Epoch [2/4], Batch [211/428], Loss: 0.6749
Epoch [2/4], Batch [212/428], Loss: 0.3170
Epoch [2/4], Batch [213/428], Loss: 1.0036
Epoch [2/4], Batch [214/428], Loss: 0.1979
Epoch [2/4], Batch [215/428], Loss: 0.0000
Epoch [2/4], Batch [216/428], Loss: 3.9916
Epoch [2/4], Batch [217/428], Loss: 1.3530
Epoch [2/4], Batch [218/428], Loss: 1.5836
Epoch [2/4], Batch [219/428], Loss: 1.3048
Epoch [2/4], Batch [220/428], Loss: 0.1610
Epoch [2/4], Batch [221/428], Loss: 0.0779
Epoch [2/4], Batch [222/428], Loss: 6.8628
Epoch [2/4], Batch [223/428], Loss: 0.1382
Epoch [2/4], Batch [224/428], Loss: 1.5737
Epoch [2/4], Batch [225/428], Loss: 0.0006
Epoch [2/4], Batch [226/428], Loss: 0.7424
Epoch [2/4], Batch [227/428], Loss: 0.0028
Epoch [2/4], Batch [228/428], Loss: 0.0371
Epoch [2/4], Batch [229/428], Loss: 2.3622
Epoch [2/4], Batch [230/428], Loss: 0.0002
Epoch [2/4], Batch [231/428], Loss: 6.0719
Epoch [2/4], Batch [232/428], Loss: 0.0001
Epoch [2/4], Batch [233/428], Loss: 0.1360
Epoch [2/4], Batch [234/428], Loss: 0.1573
Epoch [2/4], Batch [235/428], Loss: 2.1655
Epoch [2/4], Batch [236/428], Loss: 2.5018
Epoch [2/4], Batch [237/428], Loss: 0.1177
Epoch [2/4], Batch [238/428], Loss: 1.3460
Epoch [2/4], Batch [239/428], Loss: 0.0075
Epoch [2/4], Batch [240/428], Loss: 0.4558
Epoch [2/4], Batch [241/428], Loss: 0.2331
Epoch [2/4], Batch [242/428], Loss: 0.0001
Epoch [2/4], Batch [243/428], Loss: 0.4552
Epoch [2/4], Batch [244/428], Loss: 0.0032
Epoch [2/4], Batch [245/428], Loss: 0.1393
Epoch [2/4], Batch [246/428], Loss: 0.0000
Epoch [2/4], Batch [247/428], Loss: 0.0198
Epoch [2/4], Batch [248/428], Loss: 0.2946
Epoch [2/4], Batch [249/428], Loss: 0.9435
Epoch [2/4], Batch [250/428], Loss: 0.0000
Epoch [2/4], Batch [251/428], Loss: 0.3293
Epoch [2/4], Batch [252/428], Loss: 2.8984
Epoch [2/4], Batch [253/428], Loss: 1.1058
Epoch [2/4], Batch [254/428], Loss: 0.1043
Epoch [2/4], Batch [255/428], Loss: 0.5719
Epoch [2/4], Batch [256/428], Loss: 2.5969
Epoch [2/4], Batch [257/428], Loss: 1.9489
Epoch [2/4], Batch [258/428], Loss: 3.3915
Epoch [2/4], Batch [259/428], Loss: 3.3071
Epoch [2/4], Batch [260/428], Loss: 0.5730
Epoch [2/4], Batch [261/428], Loss: 3.2143
Epoch [2/4], Batch [262/428], Loss: 0.0016
Epoch [2/4], Batch [263/428], Loss: 3.0668
Epoch [2/4], Batch [264/428], Loss: 2.0424
Epoch [2/4], Batch [265/428], Loss: 0.0196
Epoch [2/4], Batch [266/428], Loss: 0.1410
Epoch [2/4], Batch [267/428], Loss: 2.5898
Epoch [2/4], Batch [268/428], Loss: 0.2473
Epoch [2/4], Batch [269/428], Loss: 2.1719
Epoch [2/4], Batch [270/428], Loss: 1.6070
Epoch [2/4], Batch [271/428], Loss: 0.6663
Epoch [2/4], Batch [272/428], Loss: 1.9016
Epoch [2/4], Batch [273/428], Loss: 0.0066
Epoch [2/4], Batch [274/428], Loss: 0.0751
Epoch [2/4], Batch [275/428], Loss: 0.1889
Epoch [2/4], Batch [276/428], Loss: 1.4058
Epoch [2/4], Batch [277/428], Loss: 1.3076
Epoch [2/4], Batch [278/428], Loss: 1.1689
Epoch [2/4], Batch [279/428], Loss: 1.5828
Epoch [2/4], Batch [280/428], Loss: 0.0938
Epoch [2/4], Batch [281/428], Loss: 0.9973
Epoch [2/4], Batch [282/428], Loss: 0.0005
Epoch [2/4], Batch [283/428], Loss: 0.1764
Epoch [2/4], Batch [284/428], Loss: 0.1810
Epoch [2/4], Batch [285/428], Loss: 0.0005
Epoch [2/4], Batch [286/428], Loss: 0.8805
Epoch [2/4], Batch [287/428], Loss: 4.0017
Epoch [2/4], Batch [288/428], Loss: 1.8575
Epoch [2/4], Batch [289/428], Loss: 0.2095
Epoch [2/4], Batch [290/428], Loss: 2.1988
Epoch [2/4], Batch [291/428], Loss: 0.1155
Epoch [2/4], Batch [292/428], Loss: 0.0224
Epoch [2/4], Batch [293/428], Loss: 0.0045
Epoch [2/4], Batch [294/428], Loss: 2.4923
Epoch [2/4], Batch [295/428], Loss: 0.2649
Epoch [2/4], Batch [296/428], Loss: 0.0001
Epoch [2/4], Batch [297/428], Loss: 0.0302
Epoch [2/4], Batch [298/428], Loss: 2.3626
Epoch [2/4], Batch [299/428], Loss: 0.9503
Epoch [2/4], Batch [300/428], Loss: 0.5186
Epoch [2/4], Batch [301/428], Loss: 1.7587
Epoch [2/4], Batch [302/428], Loss: 2.8134
Epoch [2/4], Batch [303/428], Loss: 4.6893
Epoch [2/4], Batch [304/428], Loss: 2.1312
Epoch [2/4], Batch [305/428], Loss: 0.0037
Epoch [2/4], Batch [306/428], Loss: 1.3428
Epoch [2/4], Batch [307/428], Loss: 3.5672
Epoch [2/4], Batch [308/428], Loss: 0.0000
Epoch [2/4], Batch [309/428], Loss: 0.0632
Epoch [2/4], Batch [310/428], Loss: 0.0684
Epoch [2/4], Batch [311/428], Loss: 0.3482
Epoch [2/4], Batch [312/428], Loss: 0.9317
Epoch [2/4], Batch [313/428], Loss: 0.0761
Epoch [2/4], Batch [314/428], Loss: 1.5932
Epoch [2/4], Batch [315/428], Loss: 0.0103
Epoch [2/4], Batch [316/428], Loss: 0.0458
Epoch [2/4], Batch [317/428], Loss: 2.3217
Epoch [2/4], Batch [318/428], Loss: 0.0022
Epoch [2/4], Batch [319/428], Loss: 2.0998
Epoch [2/4], Batch [320/428], Loss: 0.4869
Epoch [2/4], Batch [321/428], Loss: 3.8686
Epoch [2/4], Batch [322/428], Loss: 2.4869
Epoch [2/4], Batch [323/428], Loss: 0.4091
Epoch [2/4], Batch [324/428], Loss: 0.0465
Epoch [2/4], Batch [325/428], Loss: 2.1218
Epoch [2/4], Batch [326/428], Loss: 0.8464
Epoch [2/4], Batch [327/428], Loss: 0.3598
Epoch [2/4], Batch [328/428], Loss: 1.3530
Epoch [2/4], Batch [329/428], Loss: 0.0003
Epoch [2/4], Batch [330/428], Loss: 1.2686
Epoch [2/4], Batch [331/428], Loss: 1.9667
Epoch [2/4], Batch [332/428], Loss: 0.4190
Epoch [2/4], Batch [333/428], Loss: 1.1395
Epoch [2/4], Batch [334/428], Loss: 0.2886
Epoch [2/4], Batch [335/428], Loss: 4.8912
Epoch [2/4], Batch [336/428], Loss: 0.0062
Epoch [2/4], Batch [337/428], Loss: 1.0343
Epoch [2/4], Batch [338/428], Loss: 1.0692
Epoch [2/4], Batch [339/428], Loss: 1.4138
Epoch [2/4], Batch [340/428], Loss: 2.4412
Epoch [2/4], Batch [341/428], Loss: 0.0002
Epoch [2/4], Batch [342/428], Loss: 0.0138
Epoch [2/4], Batch [343/428], Loss: 2.3978
Epoch [2/4], Batch [344/428], Loss: 0.5786
Epoch [2/4], Batch [345/428], Loss: 0.5975
Epoch [2/4], Batch [346/428], Loss: 0.3527
Epoch [2/4], Batch [347/428], Loss: 0.0292
Epoch [2/4], Batch [348/428], Loss: 1.6138
Epoch [2/4], Batch [349/428], Loss: 0.0000
Epoch [2/4], Batch [350/428], Loss: 5.2340
Epoch [2/4], Batch [351/428], Loss: 1.4037
Epoch [2/4], Batch [352/428], Loss: 0.7825
Epoch [2/4], Batch [353/428], Loss: 0.3289
Epoch [2/4], Batch [354/428], Loss: 0.0003
Epoch [2/4], Batch [355/428], Loss: 2.6698
Epoch [2/4], Batch [356/428], Loss: 3.6844
Epoch [2/4], Batch [357/428], Loss: 5.3915
Epoch [2/4], Batch [358/428], Loss: 0.9661
Epoch [2/4], Batch [359/428], Loss: 1.5809
Epoch [2/4], Batch [360/428], Loss: 0.0039
Epoch [2/4], Batch [361/428], Loss: 0.4133
Epoch [2/4], Batch [362/428], Loss: 1.0206
Epoch [2/4], Batch [363/428], Loss: 0.9389
Epoch [2/4], Batch [364/428], Loss: 0.0648
Epoch [2/4], Batch [365/428], Loss: 7.8562
Epoch [2/4], Batch [366/428], Loss: 1.1255
Epoch [2/4], Batch [367/428], Loss: 3.8979
Epoch [2/4], Batch [368/428], Loss: 0.8139
Epoch [2/4], Batch [369/428], Loss: 0.0081
Epoch [2/4], Batch [370/428], Loss: 1.1193
Epoch [2/4], Batch [371/428], Loss: 2.8280
Epoch [2/4], Batch [372/428], Loss: 1.4387
Epoch [2/4], Batch [373/428], Loss: 1.7641
Epoch [2/4], Batch [374/428], Loss: 0.6908
Epoch [2/4], Batch [375/428], Loss: 0.2628
Epoch [2/4], Batch [376/428], Loss: 0.9566
Epoch [2/4], Batch [377/428], Loss: 0.2151
Epoch [2/4], Batch [378/428], Loss: 1.1146
Epoch [2/4], Batch [379/428], Loss: 0.4022
Epoch [2/4], Batch [380/428], Loss: 0.2036
Epoch [2/4], Batch [381/428], Loss: 1.7368
Epoch [2/4], Batch [382/428], Loss: 0.0035
Epoch [2/4], Batch [383/428], Loss: 0.0244
Epoch [2/4], Batch [384/428], Loss: 0.1812
Epoch [2/4], Batch [385/428], Loss: 1.9308
Epoch [2/4], Batch [386/428], Loss: 11.1103
Epoch [2/4], Batch [387/428], Loss: 0.2201
Epoch [2/4], Batch [388/428], Loss: 0.8194
Epoch [2/4], Batch [389/428], Loss: 0.1007
Epoch [2/4], Batch [390/428], Loss: 3.5531
Epoch [2/4], Batch [391/428], Loss: 1.3151
Epoch [2/4], Batch [392/428], Loss: 3.2143
Epoch [2/4], Batch [393/428], Loss: 0.6692
Epoch [2/4], Batch [394/428], Loss: 2.3653
Epoch [2/4], Batch [395/428], Loss: 0.1651
Epoch [2/4], Batch [396/428], Loss: 1.6782
Epoch [2/4], Batch [397/428], Loss: 0.0984
Epoch [2/4], Batch [398/428], Loss: 1.4304
Epoch [2/4], Batch [399/428], Loss: 0.3682
Epoch [2/4], Batch [400/428], Loss: 1.5657
Epoch [2/4], Batch [401/428], Loss: 1.6797
Epoch [2/4], Batch [402/428], Loss: 0.3898
Epoch [2/4], Batch [403/428], Loss: 1.4768
Epoch [2/4], Batch [404/428], Loss: 1.5381
Epoch [2/4], Batch [405/428], Loss: 0.2806
Epoch [2/4], Batch [406/428], Loss: 0.0001
Epoch [2/4], Batch [407/428], Loss: 0.8564
Epoch [2/4], Batch [408/428], Loss: 3.0785
Epoch [2/4], Batch [409/428], Loss: 0.0021
Epoch [2/4], Batch [410/428], Loss: 1.4617
Epoch [2/4], Batch [411/428], Loss: 0.0210
Epoch [2/4], Batch [412/428], Loss: 0.3004
Epoch [2/4], Batch [413/428], Loss: 0.3216
Epoch [2/4], Batch [414/428], Loss: 0.0010
Epoch [2/4], Batch [415/428], Loss: 1.0942
Epoch [2/4], Batch [416/428], Loss: 0.2779
Epoch [2/4], Batch [417/428], Loss: 1.7194
Epoch [2/4], Batch [418/428], Loss: 1.9191
Epoch [2/4], Batch [419/428], Loss: 0.7862
Epoch [2/4], Batch [420/428], Loss: 3.4119
Epoch [2/4], Batch [421/428], Loss: 3.0947
Epoch [2/4], Batch [422/428], Loss: 1.2386
Epoch [2/4], Batch [423/428], Loss: 0.5572
Epoch [2/4], Batch [424/428], Loss: 0.0006
Epoch [2/4], Batch [425/428], Loss: 0.8871
Epoch [2/4], Batch [426/428], Loss: 0.1055
Epoch [2/4], Batch [427/428], Loss: 0.1829
Epoch [2/4], Batch [428/428], Loss: 0.1046
Epoch [2] Training Time: 236.70 seconds
Epoch [2/4], Average Loss: 1.2140, Training Accuracy: 0.5864
Epoch [2], Validation Loss: 1.4236, Validation Accuracy: 0.5096
Epoch [2] Validation Time: 14.32 seconds
--------------------------------------------------
Epoch 3: Unfreezing feature extractor layers...
Epoch [3/4], Batch [1/428], Loss: 0.1234
Epoch [3/4], Batch [2/428], Loss: 21.6353
Epoch [3/4], Batch [3/428], Loss: 7.4622
Epoch [3/4], Batch [4/428], Loss: 0.1941
Epoch [3/4], Batch [5/428], Loss: 25.5755
Epoch [3/4], Batch [6/428], Loss: 21.4420
Epoch [3/4], Batch [7/428], Loss: 11.5673
Epoch [3/4], Batch [8/428], Loss: 10.0777
Epoch [3/4], Batch [9/428], Loss: 13.0260
Epoch [3/4], Batch [10/428], Loss: 14.5017
Epoch [3/4], Batch [11/428], Loss: 5.0932
Epoch [3/4], Batch [12/428], Loss: 1.0982
Epoch [3/4], Batch [13/428], Loss: 5.3353
Epoch [3/4], Batch [14/428], Loss: 3.9445
Epoch [3/4], Batch [15/428], Loss: 9.1425
Epoch [3/4], Batch [16/428], Loss: 11.7178
Epoch [3/4], Batch [17/428], Loss: 0.2653
Epoch [3/4], Batch [18/428], Loss: 5.0315
Epoch [3/4], Batch [19/428], Loss: 0.0726
Epoch [3/4], Batch [20/428], Loss: 3.4322
Epoch [3/4], Batch [21/428], Loss: 6.7849
Epoch [3/4], Batch [22/428], Loss: 1.0129
Epoch [3/4], Batch [23/428], Loss: 5.7208
Epoch [3/4], Batch [24/428], Loss: 3.7294
Epoch [3/4], Batch [25/428], Loss: 8.8262
Epoch [3/4], Batch [26/428], Loss: 5.5510
Epoch [3/4], Batch [27/428], Loss: 8.8338
Epoch [3/4], Batch [28/428], Loss: 6.0950
Epoch [3/4], Batch [29/428], Loss: 2.1796
Epoch [3/4], Batch [30/428], Loss: 0.8287
Epoch [3/4], Batch [31/428], Loss: 2.9790
Epoch [3/4], Batch [32/428], Loss: 0.0485
Epoch [3/4], Batch [33/428], Loss: 7.2090
Epoch [3/4], Batch [34/428], Loss: 10.2027
Epoch [3/4], Batch [35/428], Loss: 5.2599
Epoch [3/4], Batch [36/428], Loss: 5.4962
Epoch [3/4], Batch [37/428], Loss: 8.1228
Epoch [3/4], Batch [38/428], Loss: 0.4650
Epoch [3/4], Batch [39/428], Loss: 2.1800
Epoch [3/4], Batch [40/428], Loss: 5.1646
Epoch [3/4], Batch [41/428], Loss: 5.9091
Epoch [3/4], Batch [42/428], Loss: 2.3577
Epoch [3/4], Batch [43/428], Loss: 2.1647
Epoch [3/4], Batch [44/428], Loss: 1.4802
Epoch [3/4], Batch [45/428], Loss: 4.1663
Epoch [3/4], Batch [46/428], Loss: 1.8663
Epoch [3/4], Batch [47/428], Loss: 3.8257
Epoch [3/4], Batch [48/428], Loss: 1.3943
Epoch [3/4], Batch [49/428], Loss: 0.8898
Epoch [3/4], Batch [50/428], Loss: 4.7669
Epoch [3/4], Batch [51/428], Loss: 2.4425
Epoch [3/4], Batch [52/428], Loss: 5.9866
Epoch [3/4], Batch [53/428], Loss: 3.6671
Epoch [3/4], Batch [54/428], Loss: 3.9340
Epoch [3/4], Batch [55/428], Loss: 5.5595
Epoch [3/4], Batch [56/428], Loss: 3.6691
Epoch [3/4], Batch [57/428], Loss: 3.1795
Epoch [3/4], Batch [58/428], Loss: 3.4293
Epoch [3/4], Batch [59/428], Loss: 4.2356
Epoch [3/4], Batch [60/428], Loss: 1.2189
Epoch [3/4], Batch [61/428], Loss: 1.5054
Epoch [3/4], Batch [62/428], Loss: 0.5698
Epoch [3/4], Batch [63/428], Loss: 4.4852
Epoch [3/4], Batch [64/428], Loss: 3.8073
Epoch [3/4], Batch [65/428], Loss: 5.7435
Epoch [3/4], Batch [66/428], Loss: 4.5662
Epoch [3/4], Batch [67/428], Loss: 5.2156
Epoch [3/4], Batch [68/428], Loss: 2.4052
Epoch [3/4], Batch [69/428], Loss: 1.4493
Epoch [3/4], Batch [70/428], Loss: 3.7569
Epoch [3/4], Batch [71/428], Loss: 3.1944
Epoch [3/4], Batch [72/428], Loss: 2.5122
Epoch [3/4], Batch [73/428], Loss: 5.2936
Epoch [3/4], Batch [74/428], Loss: 3.3929
Epoch [3/4], Batch [75/428], Loss: 1.8608
Epoch [3/4], Batch [76/428], Loss: 3.5586
Epoch [3/4], Batch [77/428], Loss: 5.4593
Epoch [3/4], Batch [78/428], Loss: 0.5044
Epoch [3/4], Batch [79/428], Loss: 1.6691
Epoch [3/4], Batch [80/428], Loss: 2.5983
Epoch [3/4], Batch [81/428], Loss: 1.3046
Epoch [3/4], Batch [82/428], Loss: 3.9327
Epoch [3/4], Batch [83/428], Loss: 1.3280
Epoch [3/4], Batch [84/428], Loss: 1.4559
Epoch [3/4], Batch [85/428], Loss: 3.5400
Epoch [3/4], Batch [86/428], Loss: 1.1089
Epoch [3/4], Batch [87/428], Loss: 1.2170
Epoch [3/4], Batch [88/428], Loss: 1.6841
Epoch [3/4], Batch [89/428], Loss: 0.9410
Epoch [3/4], Batch [90/428], Loss: 2.1229
Epoch [3/4], Batch [91/428], Loss: 5.9679
Epoch [3/4], Batch [92/428], Loss: 0.6256
Epoch [3/4], Batch [93/428], Loss: 0.5208
Epoch [3/4], Batch [94/428], Loss: 5.9058
Epoch [3/4], Batch [95/428], Loss: 0.2573
Epoch [3/4], Batch [96/428], Loss: 5.9592
Epoch [3/4], Batch [97/428], Loss: 0.1050
Epoch [3/4], Batch [98/428], Loss: 5.7198
Epoch [3/4], Batch [99/428], Loss: 0.0405
Epoch [3/4], Batch [100/428], Loss: 5.5407
Epoch [3/4], Batch [101/428], Loss: 6.6175
Epoch [3/4], Batch [102/428], Loss: 6.0654
Epoch [3/4], Batch [103/428], Loss: 5.5317
Epoch [3/4], Batch [104/428], Loss: 5.0270
Epoch [3/4], Batch [105/428], Loss: 0.1082
Epoch [3/4], Batch [106/428], Loss: 5.7685
Epoch [3/4], Batch [107/428], Loss: 5.2221
Epoch [3/4], Batch [108/428], Loss: 0.3543
Epoch [3/4], Batch [109/428], Loss: 4.3120
Epoch [3/4], Batch [110/428], Loss: 1.6809
Epoch [3/4], Batch [111/428], Loss: 0.7923
Epoch [3/4], Batch [112/428], Loss: 2.9248
Epoch [3/4], Batch [113/428], Loss: 2.5277
Epoch [3/4], Batch [114/428], Loss: 1.4607
Epoch [3/4], Batch [115/428], Loss: 1.4718
Epoch [3/4], Batch [116/428], Loss: 2.9221
Epoch [3/4], Batch [117/428], Loss: 6.0226
Epoch [3/4], Batch [118/428], Loss: 2.9206
Epoch [3/4], Batch [119/428], Loss: 2.3925
Epoch [3/4], Batch [120/428], Loss: 3.1761
Epoch [3/4], Batch [121/428], Loss: 2.2425
Epoch [3/4], Batch [122/428], Loss: 2.9483
Epoch [3/4], Batch [123/428], Loss: 2.5868
Epoch [3/4], Batch [124/428], Loss: 1.7188
Epoch [3/4], Batch [125/428], Loss: 1.1893
Epoch [3/4], Batch [126/428], Loss: 1.5489
Epoch [3/4], Batch [127/428], Loss: 4.7413
Epoch [3/4], Batch [128/428], Loss: 0.9494
Epoch [3/4], Batch [129/428], Loss: 1.6333
Epoch [3/4], Batch [130/428], Loss: 1.8789
Epoch [3/4], Batch [131/428], Loss: 0.4560
Epoch [3/4], Batch [132/428], Loss: 2.0723
Epoch [3/4], Batch [133/428], Loss: 4.1034
Epoch [3/4], Batch [134/428], Loss: 3.7456
Epoch [3/4], Batch [135/428], Loss: 2.4275
Epoch [3/4], Batch [136/428], Loss: 5.6105
Epoch [3/4], Batch [137/428], Loss: 5.4507
Epoch [3/4], Batch [138/428], Loss: 1.6874
Epoch [3/4], Batch [139/428], Loss: 1.2263
Epoch [3/4], Batch [140/428], Loss: 4.6985
Epoch [3/4], Batch [141/428], Loss: 1.6380
Epoch [3/4], Batch [142/428], Loss: 1.6441
Epoch [3/4], Batch [143/428], Loss: 5.4833
Epoch [3/4], Batch [144/428], Loss: 1.2625
Epoch [3/4], Batch [145/428], Loss: 5.2486
Epoch [3/4], Batch [146/428], Loss: 0.7342
Epoch [3/4], Batch [147/428], Loss: 3.2237
Epoch [3/4], Batch [148/428], Loss: 2.6685
Epoch [3/4], Batch [149/428], Loss: 4.5862
Epoch [3/4], Batch [150/428], Loss: 2.9718
Epoch [3/4], Batch [151/428], Loss: 3.0846
Epoch [3/4], Batch [152/428], Loss: 0.6166
Epoch [3/4], Batch [153/428], Loss: 3.0529
Epoch [3/4], Batch [154/428], Loss: 2.4476
Epoch [3/4], Batch [155/428], Loss: 0.9619
Epoch [3/4], Batch [156/428], Loss: 2.2353
Epoch [3/4], Batch [157/428], Loss: 1.9900
Epoch [3/4], Batch [158/428], Loss: 1.6209
Epoch [3/4], Batch [159/428], Loss: 1.7179
Epoch [3/4], Batch [160/428], Loss: 1.8508
Epoch [3/4], Batch [161/428], Loss: 2.8859
Epoch [3/4], Batch [162/428], Loss: 1.7857
Epoch [3/4], Batch [163/428], Loss: 0.6186
Epoch [3/4], Batch [164/428], Loss: 2.6535
Epoch [3/4], Batch [165/428], Loss: 1.5098
Epoch [3/4], Batch [166/428], Loss: 2.8693
Epoch [3/4], Batch [167/428], Loss: 0.7961
Epoch [3/4], Batch [168/428], Loss: 2.4352
Epoch [3/4], Batch [169/428], Loss: 2.2039
Epoch [3/4], Batch [170/428], Loss: 6.4243
Epoch [3/4], Batch [171/428], Loss: 1.1704
Epoch [3/4], Batch [172/428], Loss: 1.2559
Epoch [3/4], Batch [173/428], Loss: 3.4606
Epoch [3/4], Batch [174/428], Loss: 1.2920
Epoch [3/4], Batch [175/428], Loss: 1.2118
Epoch [3/4], Batch [176/428], Loss: 4.6287
Epoch [3/4], Batch [177/428], Loss: 5.5511
Epoch [3/4], Batch [178/428], Loss: 0.6481
Epoch [3/4], Batch [179/428], Loss: 2.9934
Epoch [3/4], Batch [180/428], Loss: 3.2932
Epoch [3/4], Batch [181/428], Loss: 2.5726
Epoch [3/4], Batch [182/428], Loss: 2.4876
Epoch [3/4], Batch [183/428], Loss: 2.1765
Epoch [3/4], Batch [184/428], Loss: 1.9597
Epoch [3/4], Batch [185/428], Loss: 2.4130
Epoch [3/4], Batch [186/428], Loss: 1.3248
Epoch [3/4], Batch [187/428], Loss: 2.0274
Epoch [3/4], Batch [188/428], Loss: 1.3499
Epoch [3/4], Batch [189/428], Loss: 1.2569
Epoch [3/4], Batch [190/428], Loss: 1.0423
Epoch [3/4], Batch [191/428], Loss: 3.4740
Epoch [3/4], Batch [192/428], Loss: 4.5171
Epoch [3/4], Batch [193/428], Loss: 1.9471
Epoch [3/4], Batch [194/428], Loss: 0.4385
Epoch [3/4], Batch [195/428], Loss: 4.6589
Epoch [3/4], Batch [196/428], Loss: 3.3724
Epoch [3/4], Batch [197/428], Loss: 6.3657
Epoch [3/4], Batch [198/428], Loss: 2.4062
Epoch [3/4], Batch [199/428], Loss: 0.3957
Epoch [3/4], Batch [200/428], Loss: 2.3205
Epoch [3/4], Batch [201/428], Loss: 0.4728
Epoch [3/4], Batch [202/428], Loss: 0.4895
Epoch [3/4], Batch [203/428], Loss: 0.4086
Epoch [3/4], Batch [204/428], Loss: 2.7150
Epoch [3/4], Batch [205/428], Loss: 0.2500
Epoch [3/4], Batch [206/428], Loss: 4.0200
Epoch [3/4], Batch [207/428], Loss: 4.6238
Epoch [3/4], Batch [208/428], Loss: 3.8533
Epoch [3/4], Batch [209/428], Loss: 0.1431
Epoch [3/4], Batch [210/428], Loss: 3.4858
Epoch [3/4], Batch [211/428], Loss: 3.1568
Epoch [3/4], Batch [212/428], Loss: 4.5147
Epoch [3/4], Batch [213/428], Loss: 0.2277
Epoch [3/4], Batch [214/428], Loss: 3.2858
Epoch [3/4], Batch [215/428], Loss: 6.4673
Epoch [3/4], Batch [216/428], Loss: 3.4435
Epoch [3/4], Batch [217/428], Loss: 2.9072
Epoch [3/4], Batch [218/428], Loss: 0.7532
Epoch [3/4], Batch [219/428], Loss: 2.3024
Epoch [3/4], Batch [220/428], Loss: 1.3176
Epoch [3/4], Batch [221/428], Loss: 1.5876
Epoch [3/4], Batch [222/428], Loss: 1.2932
Epoch [3/4], Batch [223/428], Loss: 4.5707
Epoch [3/4], Batch [224/428], Loss: 1.2511
Epoch [3/4], Batch [225/428], Loss: 1.0999
Epoch [3/4], Batch [226/428], Loss: 3.1087
Epoch [3/4], Batch [227/428], Loss: 2.9360
Epoch [3/4], Batch [228/428], Loss: 4.3086
Epoch [3/4], Batch [229/428], Loss: 0.4983
Epoch [3/4], Batch [230/428], Loss: 4.8224
Epoch [3/4], Batch [231/428], Loss: 2.0652
Epoch [3/4], Batch [232/428], Loss: 3.6746
Epoch [3/4], Batch [233/428], Loss: 0.3941
Epoch [3/4], Batch [234/428], Loss: 2.6149
Epoch [3/4], Batch [235/428], Loss: 0.3988
Epoch [3/4], Batch [236/428], Loss: 0.3753
Epoch [3/4], Batch [237/428], Loss: 4.0721
Epoch [3/4], Batch [238/428], Loss: 2.6867
Epoch [3/4], Batch [239/428], Loss: 2.9951
Epoch [3/4], Batch [240/428], Loss: 2.2004
Epoch [3/4], Batch [241/428], Loss: 3.5968
Epoch [3/4], Batch [242/428], Loss: 0.6560
Epoch [3/4], Batch [243/428], Loss: 3.4692
Epoch [3/4], Batch [244/428], Loss: 2.1007
Epoch [3/4], Batch [245/428], Loss: 1.1707
Epoch [3/4], Batch [246/428], Loss: 3.1298
Epoch [3/4], Batch [247/428], Loss: 3.0088
Epoch [3/4], Batch [248/428], Loss: 3.2148
Epoch [3/4], Batch [249/428], Loss: 3.4138
Epoch [3/4], Batch [250/428], Loss: 3.2402
Epoch [3/4], Batch [251/428], Loss: 1.2001
Epoch [3/4], Batch [252/428], Loss: 2.3982
Epoch [3/4], Batch [253/428], Loss: 2.5655
Epoch [3/4], Batch [254/428], Loss: 1.5851
Epoch [3/4], Batch [255/428], Loss: 2.4778
Epoch [3/4], Batch [256/428], Loss: 3.4664
Epoch [3/4], Batch [257/428], Loss: 1.6289
Epoch [3/4], Batch [258/428], Loss: 1.2838
Epoch [3/4], Batch [259/428], Loss: 2.0410
Epoch [3/4], Batch [260/428], Loss: 3.1668
Epoch [3/4], Batch [261/428], Loss: 1.1088
Epoch [3/4], Batch [262/428], Loss: 1.3219
Epoch [3/4], Batch [263/428], Loss: 3.7118
Epoch [3/4], Batch [264/428], Loss: 0.9185
Epoch [3/4], Batch [265/428], Loss: 3.7961
Epoch [3/4], Batch [266/428], Loss: 4.0713
Epoch [3/4], Batch [267/428], Loss: 3.2451
Epoch [3/4], Batch [268/428], Loss: 3.2491
Epoch [3/4], Batch [269/428], Loss: 2.8622
Epoch [3/4], Batch [270/428], Loss: 2.7953
Epoch [3/4], Batch [271/428], Loss: 1.8146
Epoch [3/4], Batch [272/428], Loss: 1.5033
Epoch [3/4], Batch [273/428], Loss: 3.5931
Epoch [3/4], Batch [274/428], Loss: 2.7201
Epoch [3/4], Batch [275/428], Loss: 2.7746
Epoch [3/4], Batch [276/428], Loss: 0.6151
Epoch [3/4], Batch [277/428], Loss: 0.4698
Epoch [3/4], Batch [278/428], Loss: 3.3685
Epoch [3/4], Batch [279/428], Loss: 2.7930
Epoch [3/4], Batch [280/428], Loss: 0.2199
Epoch [3/4], Batch [281/428], Loss: 3.6956
Epoch [3/4], Batch [282/428], Loss: 3.7904
Epoch [3/4], Batch [283/428], Loss: 4.1848
Epoch [3/4], Batch [284/428], Loss: 4.5257
Epoch [3/4], Batch [285/428], Loss: 4.2048
Epoch [3/4], Batch [286/428], Loss: 4.0718
Epoch [3/4], Batch [287/428], Loss: 2.8445
Epoch [3/4], Batch [288/428], Loss: 2.3877
Epoch [3/4], Batch [289/428], Loss: 2.4817
Epoch [3/4], Batch [290/428], Loss: 1.9774
Epoch [3/4], Batch [291/428], Loss: 1.9346
Epoch [3/4], Batch [292/428], Loss: 1.9033
Epoch [3/4], Batch [293/428], Loss: 3.2431
Epoch [3/4], Batch [294/428], Loss: 1.4749
Epoch [3/4], Batch [295/428], Loss: 4.1294
Epoch [3/4], Batch [296/428], Loss: 2.2553
Epoch [3/4], Batch [297/428], Loss: 3.0968
Epoch [3/4], Batch [298/428], Loss: 3.1060
Epoch [3/4], Batch [299/428], Loss: 0.8925
Epoch [3/4], Batch [300/428], Loss: 4.9298
Epoch [3/4], Batch [301/428], Loss: 2.2723
Epoch [3/4], Batch [302/428], Loss: 2.0772
Epoch [3/4], Batch [303/428], Loss: 2.3752
Epoch [3/4], Batch [304/428], Loss: 2.8753
Epoch [3/4], Batch [305/428], Loss: 1.0066
Epoch [3/4], Batch [306/428], Loss: 2.5512
Epoch [3/4], Batch [307/428], Loss: 1.6651
Epoch [3/4], Batch [308/428], Loss: 1.4474
Epoch [3/4], Batch [309/428], Loss: 4.3159
Epoch [3/4], Batch [310/428], Loss: 2.0166
Epoch [3/4], Batch [311/428], Loss: 0.8657
Epoch [3/4], Batch [312/428], Loss: 4.0232
Epoch [3/4], Batch [313/428], Loss: 0.5485
Epoch [3/4], Batch [314/428], Loss: 0.4165
Epoch [3/4], Batch [315/428], Loss: 0.2865
Epoch [3/4], Batch [316/428], Loss: 3.1571
Epoch [3/4], Batch [317/428], Loss: 4.0220
Epoch [3/4], Batch [318/428], Loss: 3.9383
Epoch [3/4], Batch [319/428], Loss: 3.6875
Epoch [3/4], Batch [320/428], Loss: 3.2834
Epoch [3/4], Batch [321/428], Loss: 0.1385
Epoch [3/4], Batch [322/428], Loss: 2.5596
Epoch [3/4], Batch [323/428], Loss: 4.2607
Epoch [3/4], Batch [324/428], Loss: 0.3098
Epoch [3/4], Batch [325/428], Loss: 5.5937
Epoch [3/4], Batch [326/428], Loss: 0.4097
Epoch [3/4], Batch [327/428], Loss: 4.1807
Epoch [3/4], Batch [328/428], Loss: 3.9448
Epoch [3/4], Batch [329/428], Loss: 1.2649
Epoch [3/4], Batch [330/428], Loss: 0.5802
Epoch [3/4], Batch [331/428], Loss: 2.8625
Epoch [3/4], Batch [332/428], Loss: 4.7588
Epoch [3/4], Batch [333/428], Loss: 5.2138
Epoch [3/4], Batch [334/428], Loss: 2.2641
Epoch [3/4], Batch [335/428], Loss: 1.2349
Epoch [3/4], Batch [336/428], Loss: 1.9057
Epoch [3/4], Batch [337/428], Loss: 1.2052
Epoch [3/4], Batch [338/428], Loss: 1.5478
Epoch [3/4], Batch [339/428], Loss: 1.4794
Epoch [3/4], Batch [340/428], Loss: 2.3285
Epoch [3/4], Batch [341/428], Loss: 1.4294
Epoch [3/4], Batch [342/428], Loss: 1.0605
Epoch [3/4], Batch [343/428], Loss: 1.3588
Epoch [3/4], Batch [344/428], Loss: 0.8879
Epoch [3/4], Batch [345/428], Loss: 1.3364
Epoch [3/4], Batch [346/428], Loss: 3.4700
Epoch [3/4], Batch [347/428], Loss: 5.5801
Epoch [3/4], Batch [348/428], Loss: 2.1834
Epoch [3/4], Batch [349/428], Loss: 1.0500
Epoch [3/4], Batch [350/428], Loss: 2.1026
Epoch [3/4], Batch [351/428], Loss: 3.4879
Epoch [3/4], Batch [352/428], Loss: 4.2503
Epoch [3/4], Batch [353/428], Loss: 4.6911
Epoch [3/4], Batch [354/428], Loss: 2.9609
Epoch [3/4], Batch [355/428], Loss: 1.8082
Epoch [3/4], Batch [356/428], Loss: 3.0203
Epoch [3/4], Batch [357/428], Loss: 2.8168
Epoch [3/4], Batch [358/428], Loss: 1.8222
Epoch [3/4], Batch [359/428], Loss: 2.2004
Epoch [3/4], Batch [360/428], Loss: 2.9759
Epoch [3/4], Batch [361/428], Loss: 1.6541
Epoch [3/4], Batch [362/428], Loss: 1.7063
Epoch [3/4], Batch [363/428], Loss: 1.7509
Epoch [3/4], Batch [364/428], Loss: 2.7263
Epoch [3/4], Batch [365/428], Loss: 0.9405
Epoch [3/4], Batch [366/428], Loss: 0.8154
Epoch [3/4], Batch [367/428], Loss: 2.0343
Epoch [3/4], Batch [368/428], Loss: 2.6741
Epoch [3/4], Batch [369/428], Loss: 4.9090
Epoch [3/4], Batch [370/428], Loss: 2.7715
Epoch [3/4], Batch [371/428], Loss: 2.6600
Epoch [3/4], Batch [372/428], Loss: 2.3841
Epoch [3/4], Batch [373/428], Loss: 1.9578
Epoch [3/4], Batch [374/428], Loss: 2.8373
Epoch [3/4], Batch [375/428], Loss: 1.2356
Epoch [3/4], Batch [376/428], Loss: 4.9311
Epoch [3/4], Batch [377/428], Loss: 2.6492
Epoch [3/4], Batch [378/428], Loss: 4.8285
Epoch [3/4], Batch [379/428], Loss: 1.0595
Epoch [3/4], Batch [380/428], Loss: 4.4536
Epoch [3/4], Batch [381/428], Loss: 4.1780
Epoch [3/4], Batch [382/428], Loss: 1.9354
Epoch [3/4], Batch [383/428], Loss: 1.8759
Epoch [3/4], Batch [384/428], Loss: 1.7312
Epoch [3/4], Batch [385/428], Loss: 1.2788
Epoch [3/4], Batch [386/428], Loss: 3.4915
Epoch [3/4], Batch [387/428], Loss: 2.7020
Epoch [3/4], Batch [388/428], Loss: 1.1752
Epoch [3/4], Batch [389/428], Loss: 3.0051
Epoch [3/4], Batch [390/428], Loss: 0.9287
Epoch [3/4], Batch [391/428], Loss: 2.1049
Epoch [3/4], Batch [392/428], Loss: 0.7128
Epoch [3/4], Batch [393/428], Loss: 2.8539
Epoch [3/4], Batch [394/428], Loss: 2.3701
Epoch [3/4], Batch [395/428], Loss: 3.5915
Epoch [3/4], Batch [396/428], Loss: 3.2613
Epoch [3/4], Batch [397/428], Loss: 3.2159
Epoch [3/4], Batch [398/428], Loss: 1.9971
Epoch [3/4], Batch [399/428], Loss: 1.5672
Epoch [3/4], Batch [400/428], Loss: 1.0340
Epoch [3/4], Batch [401/428], Loss: 3.8296
Epoch [3/4], Batch [402/428], Loss: 1.6852
Epoch [3/4], Batch [403/428], Loss: 3.4459
Epoch [3/4], Batch [404/428], Loss: 1.1241
Epoch [3/4], Batch [405/428], Loss: 3.2200
Epoch [3/4], Batch [406/428], Loss: 0.9561
Epoch [3/4], Batch [407/428], Loss: 2.8434
Epoch [3/4], Batch [408/428], Loss: 3.6446
Epoch [3/4], Batch [409/428], Loss: 1.7655
Epoch [3/4], Batch [410/428], Loss: 1.7323
Epoch [3/4], Batch [411/428], Loss: 1.5069
Epoch [3/4], Batch [412/428], Loss: 1.7469
Epoch [3/4], Batch [413/428], Loss: 1.2607
Epoch [3/4], Batch [414/428], Loss: 3.2166
Epoch [3/4], Batch [415/428], Loss: 3.2349
Epoch [3/4], Batch [416/428], Loss: 3.7151
Epoch [3/4], Batch [417/428], Loss: 1.1608
Epoch [3/4], Batch [418/428], Loss: 2.9183
Epoch [3/4], Batch [419/428], Loss: 3.2981
Epoch [3/4], Batch [420/428], Loss: 1.3850
Epoch [3/4], Batch [421/428], Loss: 3.1147
Epoch [3/4], Batch [422/428], Loss: 0.9274
Epoch [3/4], Batch [423/428], Loss: 2.1338
Epoch [3/4], Batch [424/428], Loss: 1.9935
Epoch [3/4], Batch [425/428], Loss: 2.9061
Epoch [3/4], Batch [426/428], Loss: 2.3436
Epoch [3/4], Batch [427/428], Loss: 1.1788
Epoch [3/4], Batch [428/428], Loss: 2.1304
Epoch [3] Training Time: 392.81 seconds
Epoch [3/4], Average Loss: 2.9727, Training Accuracy: 0.1799
Epoch [3], Validation Loss: 2.2051, Validation Accuracy: 0.1429
Epoch [3] Validation Time: 16.63 seconds
--------------------------------------------------
Epoch [4/4], Batch [1/428], Loss: 3.0150
Epoch [4/4], Batch [2/428], Loss: 3.0254
Epoch [4/4], Batch [3/428], Loss: 2.8758
Epoch [4/4], Batch [4/428], Loss: 1.2091
Epoch [4/4], Batch [5/428], Loss: 1.1797
Epoch [4/4], Batch [6/428], Loss: 1.5461
Epoch [4/4], Batch [7/428], Loss: 2.8416
Epoch [4/4], Batch [8/428], Loss: 2.7792
Epoch [4/4], Batch [9/428], Loss: 3.1298
Epoch [4/4], Batch [10/428], Loss: 2.5456
Epoch [4/4], Batch [11/428], Loss: 1.6885
Epoch [4/4], Batch [12/428], Loss: 2.2956
Epoch [4/4], Batch [13/428], Loss: 1.1281
Epoch [4/4], Batch [14/428], Loss: 2.1929
Epoch [4/4], Batch [15/428], Loss: 2.0586
Epoch [4/4], Batch [16/428], Loss: 1.7450
Epoch [4/4], Batch [17/428], Loss: 1.7859
Epoch [4/4], Batch [18/428], Loss: 2.9761
Epoch [4/4], Batch [19/428], Loss: 2.4887
Epoch [4/4], Batch [20/428], Loss: 1.4868
Epoch [4/4], Batch [21/428], Loss: 1.5584
Epoch [4/4], Batch [22/428], Loss: 2.5433
Epoch [4/4], Batch [23/428], Loss: 2.4514
Epoch [4/4], Batch [24/428], Loss: 1.9413
Epoch [4/4], Batch [25/428], Loss: 1.5114
Epoch [4/4], Batch [26/428], Loss: 2.1314
Epoch [4/4], Batch [27/428], Loss: 2.6795
Epoch [4/4], Batch [28/428], Loss: 1.9336
Epoch [4/4], Batch [29/428], Loss: 3.3977
Epoch [4/4], Batch [30/428], Loss: 2.4872
Epoch [4/4], Batch [31/428], Loss: 1.4858
Epoch [4/4], Batch [32/428], Loss: 3.2804
Epoch [4/4], Batch [33/428], Loss: 2.0753
Epoch [4/4], Batch [34/428], Loss: 3.0869
Epoch [4/4], Batch [35/428], Loss: 2.2465
Epoch [4/4], Batch [36/428], Loss: 1.4651
Epoch [4/4], Batch [37/428], Loss: 1.4163
Epoch [4/4], Batch [38/428], Loss: 1.7310
Epoch [4/4], Batch [39/428], Loss: 2.3096
Epoch [4/4], Batch [40/428], Loss: 1.2847
Epoch [4/4], Batch [41/428], Loss: 2.4493
Epoch [4/4], Batch [42/428], Loss: 2.2829
Epoch [4/4], Batch [43/428], Loss: 1.1268
Epoch [4/4], Batch [44/428], Loss: 2.5099
Epoch [4/4], Batch [45/428], Loss: 1.0090
Epoch [4/4], Batch [46/428], Loss: 2.0596
Epoch [4/4], Batch [47/428], Loss: 2.6369
Epoch [4/4], Batch [48/428], Loss: 2.6033
Epoch [4/4], Batch [49/428], Loss: 0.8690
Epoch [4/4], Batch [50/428], Loss: 0.8258
Epoch [4/4], Batch [51/428], Loss: 0.7499
Epoch [4/4], Batch [52/428], Loss: 0.6376
Epoch [4/4], Batch [53/428], Loss: 2.4783
Epoch [4/4], Batch [54/428], Loss: 0.4704
Epoch [4/4], Batch [55/428], Loss: 3.0953
Epoch [4/4], Batch [56/428], Loss: 2.9100
Epoch [4/4], Batch [57/428], Loss: 3.1071
Epoch [4/4], Batch [58/428], Loss: 3.6891
Epoch [4/4], Batch [59/428], Loss: 3.1121
Epoch [4/4], Batch [60/428], Loss: 0.3284
Epoch [4/4], Batch [61/428], Loss: 3.1292
Epoch [4/4], Batch [62/428], Loss: 3.0081
Epoch [4/4], Batch [63/428], Loss: 2.9275
Epoch [4/4], Batch [64/428], Loss: 3.5882
Epoch [4/4], Batch [65/428], Loss: 0.4180
Epoch [4/4], Batch [66/428], Loss: 3.0929
Epoch [4/4], Batch [67/428], Loss: 2.8146
Epoch [4/4], Batch [68/428], Loss: 2.5825
Epoch [4/4], Batch [69/428], Loss: 2.2407
Epoch [4/4], Batch [70/428], Loss: 2.6657
Epoch [4/4], Batch [71/428], Loss: 2.5733
Epoch [4/4], Batch [72/428], Loss: 2.2058
Epoch [4/4], Batch [73/428], Loss: 2.2697
Epoch [4/4], Batch [74/428], Loss: 2.5891
Epoch [4/4], Batch [75/428], Loss: 1.8626
Epoch [4/4], Batch [76/428], Loss: 2.8373
Epoch [4/4], Batch [77/428], Loss: 2.4688
Epoch [4/4], Batch [78/428], Loss: 1.6546
Epoch [4/4], Batch [79/428], Loss: 2.6756
Epoch [4/4], Batch [80/428], Loss: 1.9931
Epoch [4/4], Batch [81/428], Loss: 1.5068
Epoch [4/4], Batch [82/428], Loss: 1.5922
Epoch [4/4], Batch [83/428], Loss: 2.2359
Epoch [4/4], Batch [84/428], Loss: 2.2963
Epoch [4/4], Batch [85/428], Loss: 1.5527
Epoch [4/4], Batch [86/428], Loss: 1.3925
Epoch [4/4], Batch [87/428], Loss: 2.8781
Epoch [4/4], Batch [88/428], Loss: 1.4180
Epoch [4/4], Batch [89/428], Loss: 1.3381
Epoch [4/4], Batch [90/428], Loss: 2.8891
Epoch [4/4], Batch [91/428], Loss: 1.4395
Epoch [4/4], Batch [92/428], Loss: 2.4120
Epoch [4/4], Batch [93/428], Loss: 2.4179
Epoch [4/4], Batch [94/428], Loss: 2.5241
Epoch [4/4], Batch [95/428], Loss: 1.4626
Epoch [4/4], Batch [96/428], Loss: 2.5957
Epoch [4/4], Batch [97/428], Loss: 2.5258
Epoch [4/4], Batch [98/428], Loss: 1.3470
Epoch [4/4], Batch [99/428], Loss: 1.3251
Epoch [4/4], Batch [100/428], Loss: 2.0563
Epoch [4/4], Batch [101/428], Loss: 2.7653
Epoch [4/4], Batch [102/428], Loss: 1.2715
Epoch [4/4], Batch [103/428], Loss: 1.9095
Epoch [4/4], Batch [104/428], Loss: 1.1684
Epoch [4/4], Batch [105/428], Loss: 3.2028
Epoch [4/4], Batch [106/428], Loss: 2.5699
Epoch [4/4], Batch [107/428], Loss: 2.5400
Epoch [4/4], Batch [108/428], Loss: 1.7088
Epoch [4/4], Batch [109/428], Loss: 2.3468
Epoch [4/4], Batch [110/428], Loss: 2.8224
Epoch [4/4], Batch [111/428], Loss: 2.0556
Epoch [4/4], Batch [112/428], Loss: 3.1260
Epoch [4/4], Batch [113/428], Loss: 1.9133
Epoch [4/4], Batch [114/428], Loss: 1.9105
Epoch [4/4], Batch [115/428], Loss: 1.6666
Epoch [4/4], Batch [116/428], Loss: 1.4622
Epoch [4/4], Batch [117/428], Loss: 2.9035
Epoch [4/4], Batch [118/428], Loss: 1.4788
Epoch [4/4], Batch [119/428], Loss: 1.4330
Epoch [4/4], Batch [120/428], Loss: 3.0876
Epoch [4/4], Batch [121/428], Loss: 1.8382
Epoch [4/4], Batch [122/428], Loss: 1.2512
Epoch [4/4], Batch [123/428], Loss: 2.5903
Epoch [4/4], Batch [124/428], Loss: 3.1013
Epoch [4/4], Batch [125/428], Loss: 2.6994
Epoch [4/4], Batch [126/428], Loss: 1.7809
Epoch [4/4], Batch [127/428], Loss: 1.2757
Epoch [4/4], Batch [128/428], Loss: 2.9527
Epoch [4/4], Batch [129/428], Loss: 2.5429
Epoch [4/4], Batch [130/428], Loss: 2.7131
Epoch [4/4], Batch [131/428], Loss: 1.2787
Epoch [4/4], Batch [132/428], Loss: 3.0264
Epoch [4/4], Batch [133/428], Loss: 1.7007
Epoch [4/4], Batch [134/428], Loss: 2.2153
Epoch [4/4], Batch [135/428], Loss: 1.8654
Epoch [4/4], Batch [136/428], Loss: 2.6251
Epoch [4/4], Batch [137/428], Loss: 2.1483
Epoch [4/4], Batch [138/428], Loss: 1.6842
Epoch [4/4], Batch [139/428], Loss: 1.4944
Epoch [4/4], Batch [140/428], Loss: 1.5258
Epoch [4/4], Batch [141/428], Loss: 2.5084
Epoch [4/4], Batch [142/428], Loss: 1.4659
Epoch [4/4], Batch [143/428], Loss: 2.2798
Epoch [4/4], Batch [144/428], Loss: 2.3687
Epoch [4/4], Batch [145/428], Loss: 1.7652
Epoch [4/4], Batch [146/428], Loss: 2.1773
Epoch [4/4], Batch [147/428], Loss: 1.2949
Epoch [4/4], Batch [148/428], Loss: 1.7230
Epoch [4/4], Batch [149/428], Loss: 2.9993
Epoch [4/4], Batch [150/428], Loss: 1.2472
Epoch [4/4], Batch [151/428], Loss: 2.1710
Epoch [4/4], Batch [152/428], Loss: 1.7397
Epoch [4/4], Batch [153/428], Loss: 2.5385
Epoch [4/4], Batch [154/428], Loss: 1.7464
Epoch [4/4], Batch [155/428], Loss: 1.1816
Epoch [4/4], Batch [156/428], Loss: 1.5770
Epoch [4/4], Batch [157/428], Loss: 1.1897
Epoch [4/4], Batch [158/428], Loss: 2.4588
Epoch [4/4], Batch [159/428], Loss: 2.9492
Epoch [4/4], Batch [160/428], Loss: 1.5123
Epoch [4/4], Batch [161/428], Loss: 1.7263
Epoch [4/4], Batch [162/428], Loss: 2.9135
Epoch [4/4], Batch [163/428], Loss: 1.6830
Epoch [4/4], Batch [164/428], Loss: 2.3806
Epoch [4/4], Batch [165/428], Loss: 3.0848
Epoch [4/4], Batch [166/428], Loss: 1.3638
Epoch [4/4], Batch [167/428], Loss: 1.3858
Epoch [4/4], Batch [168/428], Loss: 2.9756
Epoch [4/4], Batch [169/428], Loss: 2.8440
Epoch [4/4], Batch [170/428], Loss: 2.8717
Epoch [4/4], Batch [171/428], Loss: 2.5213
Epoch [4/4], Batch [172/428], Loss: 1.3048
Epoch [4/4], Batch [173/428], Loss: 2.2688
Epoch [4/4], Batch [174/428], Loss: 2.1086
Epoch [4/4], Batch [175/428], Loss: 1.2283
Epoch [4/4], Batch [176/428], Loss: 2.7729
Epoch [4/4], Batch [177/428], Loss: 1.1972
Epoch [4/4], Batch [178/428], Loss: 2.4278
Epoch [4/4], Batch [179/428], Loss: 1.1006[INFO 06-13 20:19:21] ax.service.ax_client: Completed trial 10 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 20:19:24] ax.service.ax_client: Generated new trial 11 with parameters {'lr': 0.000194, 'num_epochs': 1, 'unfreeze_epoch': 0, 'max_length': 64000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder
[INFO 06-13 20:24:10] ax.service.ax_client: Completed trial 11 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 20:24:13] ax.service.ax_client: Generated new trial 12 with parameters {'lr': 0.001, 'num_epochs': 6, 'unfreeze_epoch': 0, 'max_length': 112000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [4/4], Batch [180/428], Loss: 2.4619
Epoch [4/4], Batch [181/428], Loss: 2.7606
Epoch [4/4], Batch [182/428], Loss: 2.4992
Epoch [4/4], Batch [183/428], Loss: 0.9504
Epoch [4/4], Batch [184/428], Loss: 2.5421
Epoch [4/4], Batch [185/428], Loss: 3.1103
Epoch [4/4], Batch [186/428], Loss: 0.8712
Epoch [4/4], Batch [187/428], Loss: 2.3276
Epoch [4/4], Batch [188/428], Loss: 3.1567
Epoch [4/4], Batch [189/428], Loss: 0.7648
Epoch [4/4], Batch [190/428], Loss: 3.0472
Epoch [4/4], Batch [191/428], Loss: 2.4168
Epoch [4/4], Batch [192/428], Loss: 2.7747
Epoch [4/4], Batch [193/428], Loss: 0.7446
Epoch [4/4], Batch [194/428], Loss: 2.5515
Epoch [4/4], Batch [195/428], Loss: 0.7285
Epoch [4/4], Batch [196/428], Loss: 2.5741
Epoch [4/4], Batch [197/428], Loss: 2.3164
Epoch [4/4], Batch [198/428], Loss: 3.2158
Epoch [4/4], Batch [199/428], Loss: 0.7233
Epoch [4/4], Batch [200/428], Loss: 1.9971
Epoch [4/4], Batch [201/428], Loss: 2.5389
Epoch [4/4], Batch [202/428], Loss: 2.4543
Epoch [4/4], Batch [203/428], Loss: 1.7127
Epoch [4/4], Batch [204/428], Loss: 2.3644
Epoch [4/4], Batch [205/428], Loss: 0.9147
Epoch [4/4], Batch [206/428], Loss: 2.3637
Epoch [4/4], Batch [207/428], Loss: 3.1739
Epoch [4/4], Batch [208/428], Loss: 2.8044
Epoch [4/4], Batch [209/428], Loss: 2.1730
Epoch [4/4], Batch [210/428], Loss: 1.1929
Epoch [4/4], Batch [211/428], Loss: 1.3074
Epoch [4/4], Batch [212/428], Loss: 1.2542
Epoch [4/4], Batch [213/428], Loss: 1.3457
Epoch [4/4], Batch [214/428], Loss: 1.3315
Epoch [4/4], Batch [215/428], Loss: 1.1218
Epoch [4/4], Batch [216/428], Loss: 1.3292
Epoch [4/4], Batch [217/428], Loss: 1.2683
Epoch [4/4], Batch [218/428], Loss: 2.9846
Epoch [4/4], Batch [219/428], Loss: 1.1293
Epoch [4/4], Batch [220/428], Loss: 3.0972
Epoch [4/4], Batch [221/428], Loss: 2.9276
Epoch [4/4], Batch [222/428], Loss: 2.8812
Epoch [4/4], Batch [223/428], Loss: 2.2109
Epoch [4/4], Batch [224/428], Loss: 0.8413
Epoch [4/4], Batch [225/428], Loss: 1.5711
Epoch [4/4], Batch [226/428], Loss: 2.2127
Epoch [4/4], Batch [227/428], Loss: 2.1672
Epoch [4/4], Batch [228/428], Loss: 3.7983
Epoch [4/4], Batch [229/428], Loss: 0.8315
Epoch [4/4], Batch [230/428], Loss: 1.8667
Epoch [4/4], Batch [231/428], Loss: 1.7871
Epoch [4/4], Batch [232/428], Loss: 1.5959
Epoch [4/4], Batch [233/428], Loss: 0.9245
Epoch [4/4], Batch [234/428], Loss: 1.3113
Epoch [4/4], Batch [235/428], Loss: 3.0177
Epoch [4/4], Batch [236/428], Loss: 1.0883
Epoch [4/4], Batch [237/428], Loss: 2.4598
Epoch [4/4], Batch [238/428], Loss: 2.9936
Epoch [4/4], Batch [239/428], Loss: 1.1542
Epoch [4/4], Batch [240/428], Loss: 2.8642
Epoch [4/4], Batch [241/428], Loss: 1.1337
Epoch [4/4], Batch [242/428], Loss: 2.3637
Epoch [4/4], Batch [243/428], Loss: 3.7631
Epoch [4/4], Batch [244/428], Loss: 1.0388
Epoch [4/4], Batch [245/428], Loss: 1.1825
Epoch [4/4], Batch [246/428], Loss: 3.1005
Epoch [4/4], Batch [247/428], Loss: 0.9575
Epoch [4/4], Batch [248/428], Loss: 3.4357
Epoch [4/4], Batch [249/428], Loss: 3.3474
Epoch [4/4], Batch [250/428], Loss: 3.7346
Epoch [4/4], Batch [251/428], Loss: 2.1045
Epoch [4/4], Batch [252/428], Loss: 0.8497
Epoch [4/4], Batch [253/428], Loss: 0.8278
Epoch [4/4], Batch [254/428], Loss: 3.1189
Epoch [4/4], Batch [255/428], Loss: 1.9681
Epoch [4/4], Batch [256/428], Loss: 1.8902
Epoch [4/4], Batch [257/428], Loss: 2.2514
Epoch [4/4], Batch [258/428], Loss: 0.8049
Epoch [4/4], Batch [259/428], Loss: 0.7976
Epoch [4/4], Batch [260/428], Loss: 0.7813
Epoch [4/4], Batch [261/428], Loss: 0.7138
Epoch [4/4], Batch [262/428], Loss: 2.5801
Epoch [4/4], Batch [263/428], Loss: 2.6329
Epoch [4/4], Batch [264/428], Loss: 1.8675
Epoch [4/4], Batch [265/428], Loss: 1.8451
Epoch [4/4], Batch [266/428], Loss: 3.2550
Epoch [4/4], Batch [267/428], Loss: 3.1955
Epoch [4/4], Batch [268/428], Loss: 3.0956
Epoch [4/4], Batch [269/428], Loss: 2.9590
Epoch [4/4], Batch [270/428], Loss: 1.5260
Epoch [4/4], Batch [271/428], Loss: 2.5841
Epoch [4/4], Batch [272/428], Loss: 2.2786
Epoch [4/4], Batch [273/428], Loss: 1.2834
Epoch [4/4], Batch [274/428], Loss: 1.1294
Epoch [4/4], Batch [275/428], Loss: 1.1649
Epoch [4/4], Batch [276/428], Loss: 1.3184
Epoch [4/4], Batch [277/428], Loss: 1.9063
Epoch [4/4], Batch [278/428], Loss: 3.0788
Epoch [4/4], Batch [279/428], Loss: 3.0519
Epoch [4/4], Batch [280/428], Loss: 1.0058
Epoch [4/4], Batch [281/428], Loss: 3.0226
Epoch [4/4], Batch [282/428], Loss: 2.9606
Epoch [4/4], Batch [283/428], Loss: 1.8265
Epoch [4/4], Batch [284/428], Loss: 2.7807
Epoch [4/4], Batch [285/428], Loss: 2.3851
Epoch [4/4], Batch [286/428], Loss: 3.8555
Epoch [4/4], Batch [287/428], Loss: 1.0998
Epoch [4/4], Batch [288/428], Loss: 2.2264
Epoch [4/4], Batch [289/428], Loss: 2.2433
Epoch [4/4], Batch [290/428], Loss: 1.1808
Epoch [4/4], Batch [291/428], Loss: 1.9892
Epoch [4/4], Batch [292/428], Loss: 3.5690
Epoch [4/4], Batch [293/428], Loss: 1.9603
Epoch [4/4], Batch [294/428], Loss: 1.9086
Epoch [4/4], Batch [295/428], Loss: 2.0302
Epoch [4/4], Batch [296/428], Loss: 1.9576
Epoch [4/4], Batch [297/428], Loss: 1.7406
Epoch [4/4], Batch [298/428], Loss: 1.5954
Epoch [4/4], Batch [299/428], Loss: 1.6620
Epoch [4/4], Batch [300/428], Loss: 3.0876
Epoch [4/4], Batch [301/428], Loss: 3.0116
Epoch [4/4], Batch [302/428], Loss: 1.3733
Epoch [4/4], Batch [303/428], Loss: 1.6462
Epoch [4/4], Batch [304/428], Loss: 1.5961
Epoch [4/4], Batch [305/428], Loss: 2.0408
Epoch [4/4], Batch [306/428], Loss: 1.4131
Epoch [4/4], Batch [307/428], Loss: 1.2885
Epoch [4/4], Batch [308/428], Loss: 2.4548
Epoch [4/4], Batch [309/428], Loss: 2.3779
Epoch [4/4], Batch [310/428], Loss: 2.2298
Epoch [4/4], Batch [311/428], Loss: 2.2662
Epoch [4/4], Batch [312/428], Loss: 1.2970
Epoch [4/4], Batch [313/428], Loss: 1.3021
Epoch [4/4], Batch [314/428], Loss: 3.2749
Epoch [4/4], Batch [315/428], Loss: 3.2823
Epoch [4/4], Batch [316/428], Loss: 3.1999
Epoch [4/4], Batch [317/428], Loss: 3.0387
Epoch [4/4], Batch [318/428], Loss: 2.8048
Epoch [4/4], Batch [319/428], Loss: 1.7145
Epoch [4/4], Batch [320/428], Loss: 1.2291
Epoch [4/4], Batch [321/428], Loss: 2.1636
Epoch [4/4], Batch [322/428], Loss: 3.7843
Epoch [4/4], Batch [323/428], Loss: 1.3052
Epoch [4/4], Batch [324/428], Loss: 1.5937
Epoch [4/4], Batch [325/428], Loss: 1.5081
Epoch [4/4], Batch [326/428], Loss: 1.3571
Epoch [4/4], Batch [327/428], Loss: 1.3526
Epoch [4/4], Batch [328/428], Loss: 2.3788
Epoch [4/4], Batch [329/428], Loss: 2.3631
Epoch [4/4], Batch [330/428], Loss: 1.7018
Epoch [4/4], Batch [331/428], Loss: 1.2573
Epoch [4/4], Batch [332/428], Loss: 1.6968
Epoch [4/4], Batch [333/428], Loss: 3.5972
Epoch [4/4], Batch [334/428], Loss: 1.1409
Epoch [4/4], Batch [335/428], Loss: 1.0511
Epoch [4/4], Batch [336/428], Loss: 0.9832
Epoch [4/4], Batch [337/428], Loss: 1.6226
Epoch [4/4], Batch [338/428], Loss: 3.5752
Epoch [4/4], Batch [339/428], Loss: 1.7554
Epoch [4/4], Batch [340/428], Loss: 1.7881
Epoch [4/4], Batch [341/428], Loss: 3.6327
Epoch [4/4], Batch [342/428], Loss: 0.7020
Epoch [4/4], Batch [343/428], Loss: 3.3118
Epoch [4/4], Batch [344/428], Loss: 0.6755
Epoch [4/4], Batch [345/428], Loss: 1.8592
Epoch [4/4], Batch [346/428], Loss: 3.0710
Epoch [4/4], Batch [347/428], Loss: 3.6142
Epoch [4/4], Batch [348/428], Loss: 0.6180
Epoch [4/4], Batch [349/428], Loss: 0.5876
Epoch [4/4], Batch [350/428], Loss: 4.1475
Epoch [4/4], Batch [351/428], Loss: 1.9760
Epoch [4/4], Batch [352/428], Loss: 1.9841
Epoch [4/4], Batch [353/428], Loss: 3.3546
Epoch [4/4], Batch [354/428], Loss: 0.5580
Epoch [4/4], Batch [355/428], Loss: 1.7821
Epoch [4/4], Batch [356/428], Loss: 3.9083
Epoch [4/4], Batch [357/428], Loss: 1.6582
Epoch [4/4], Batch [358/428], Loss: 2.7255
Epoch [4/4], Batch [359/428], Loss: 2.9772
Epoch [4/4], Batch [360/428], Loss: 3.3060
Epoch [4/4], Batch [361/428], Loss: 0.8792
Epoch [4/4], Batch [362/428], Loss: 2.6616
Epoch [4/4], Batch [363/428], Loss: 1.2190
Epoch [4/4], Batch [364/428], Loss: 2.4222
Epoch [4/4], Batch [365/428], Loss: 1.1145
Epoch [4/4], Batch [366/428], Loss: 2.1259
Epoch [4/4], Batch [367/428], Loss: 1.1627
Epoch [4/4], Batch [368/428], Loss: 1.1348
Epoch [4/4], Batch [369/428], Loss: 2.7651
Epoch [4/4], Batch [370/428], Loss: 1.4748
Epoch [4/4], Batch [371/428], Loss: 2.7075
Epoch [4/4], Batch [372/428], Loss: 1.0213
Epoch [4/4], Batch [373/428], Loss: 2.5841
Epoch [4/4], Batch [374/428], Loss: 1.6806
Epoch [4/4], Batch [375/428], Loss: 1.6865
Epoch [4/4], Batch [376/428], Loss: 1.6810
Epoch [4/4], Batch [377/428], Loss: 1.5935
Epoch [4/4], Batch [378/428], Loss: 3.2419
Epoch [4/4], Batch [379/428], Loss: 3.3087
Epoch [4/4], Batch [380/428], Loss: 3.1441
Epoch [4/4], Batch [381/428], Loss: 3.1899
Epoch [4/4], Batch [382/428], Loss: 1.3772
Epoch [4/4], Batch [383/428], Loss: 1.4991
Epoch [4/4], Batch [384/428], Loss: 1.5473
Epoch [4/4], Batch [385/428], Loss: 1.5956
Epoch [4/4], Batch [386/428], Loss: 2.7584
Epoch [4/4], Batch [387/428], Loss: 1.2848
Epoch [4/4], Batch [388/428], Loss: 2.1540
Epoch [4/4], Batch [389/428], Loss: 1.6379
Epoch [4/4], Batch [390/428], Loss: 2.5681
Epoch [4/4], Batch [391/428], Loss: 1.7473
Epoch [4/4], Batch [392/428], Loss: 1.7088
Epoch [4/4], Batch [393/428], Loss: 2.2926
Epoch [4/4], Batch [394/428], Loss: 1.3880
Epoch [4/4], Batch [395/428], Loss: 1.5732
Epoch [4/4], Batch [396/428], Loss: 1.7680
Epoch [4/4], Batch [397/428], Loss: 2.0739
Epoch [4/4], Batch [398/428], Loss: 2.3255
Epoch [4/4], Batch [399/428], Loss: 1.8973
Epoch [4/4], Batch [400/428], Loss: 2.3381
Epoch [4/4], Batch [401/428], Loss: 1.4270
Epoch [4/4], Batch [402/428], Loss: 3.8416
Epoch [4/4], Batch [403/428], Loss: 1.5352
Epoch [4/4], Batch [404/428], Loss: 2.1635
Epoch [4/4], Batch [405/428], Loss: 1.3452
Epoch [4/4], Batch [406/428], Loss: 2.3834
Epoch [4/4], Batch [407/428], Loss: 2.1630
Epoch [4/4], Batch [408/428], Loss: 1.0571
Epoch [4/4], Batch [409/428], Loss: 3.7293
Epoch [4/4], Batch [410/428], Loss: 3.6508
Epoch [4/4], Batch [411/428], Loss: 2.1524
Epoch [4/4], Batch [412/428], Loss: 2.3712
Epoch [4/4], Batch [413/428], Loss: 2.0389
Epoch [4/4], Batch [414/428], Loss: 2.0317
Epoch [4/4], Batch [415/428], Loss: 2.3280
Epoch [4/4], Batch [416/428], Loss: 2.2136
Epoch [4/4], Batch [417/428], Loss: 1.9468
Epoch [4/4], Batch [418/428], Loss: 1.1091
Epoch [4/4], Batch [419/428], Loss: 1.1495
Epoch [4/4], Batch [420/428], Loss: 2.4504
Epoch [4/4], Batch [421/428], Loss: 1.7646
Epoch [4/4], Batch [422/428], Loss: 1.1518
Epoch [4/4], Batch [423/428], Loss: 1.9448
Epoch [4/4], Batch [424/428], Loss: 1.1371
Epoch [4/4], Batch [425/428], Loss: 1.0898
Epoch [4/4], Batch [426/428], Loss: 1.7916
Epoch [4/4], Batch [427/428], Loss: 2.0724
Epoch [4/4], Batch [428/428], Loss: 3.4383
Epoch [4] Training Time: 395.39 seconds
Epoch [4/4], Average Loss: 2.0852, Training Accuracy: 0.2173
Epoch [4], Validation Loss: 2.1935, Validation Accuracy: 0.1429
Epoch [4] Validation Time: 16.58 seconds
--------------------------------------------------

Running trial 11 with config: {'batch_size': 1, 'lr': 0.00019435063294890285, 'num_epochs': 1, 'unfreeze_epoch': 0, 'max_length': 64000, 'device': device(type='cpu')}
Epoch 1: Unfreezing feature extractor layers...
Epoch [1/1], Batch [1/428], Loss: 2.1642
Epoch [1/1], Batch [2/428], Loss: 5.9513
Epoch [1/1], Batch [3/428], Loss: 5.2870
Epoch [1/1], Batch [4/428], Loss: 8.1974
Epoch [1/1], Batch [5/428], Loss: 2.9312
Epoch [1/1], Batch [6/428], Loss: 7.3563
Epoch [1/1], Batch [7/428], Loss: 4.4825
Epoch [1/1], Batch [8/428], Loss: 7.0461
Epoch [1/1], Batch [9/428], Loss: 4.4085
Epoch [1/1], Batch [10/428], Loss: 12.7235
Epoch [1/1], Batch [11/428], Loss: 3.9159
Epoch [1/1], Batch [12/428], Loss: 2.4314
Epoch [1/1], Batch [13/428], Loss: 0.4984
Epoch [1/1], Batch [14/428], Loss: 8.9239
Epoch [1/1], Batch [15/428], Loss: 6.3956
Epoch [1/1], Batch [16/428], Loss: 5.9156
Epoch [1/1], Batch [17/428], Loss: 7.7719
Epoch [1/1], Batch [18/428], Loss: 3.5084
Epoch [1/1], Batch [19/428], Loss: 1.5472
Epoch [1/1], Batch [20/428], Loss: 3.6049
Epoch [1/1], Batch [21/428], Loss: 4.7125
Epoch [1/1], Batch [22/428], Loss: 4.1025
Epoch [1/1], Batch [23/428], Loss: 3.2579
Epoch [1/1], Batch [24/428], Loss: 5.6406
Epoch [1/1], Batch [25/428], Loss: 1.2656
Epoch [1/1], Batch [26/428], Loss: 1.3864
Epoch [1/1], Batch [27/428], Loss: 1.8678
Epoch [1/1], Batch [28/428], Loss: 2.3170
Epoch [1/1], Batch [29/428], Loss: 2.5705
Epoch [1/1], Batch [30/428], Loss: 1.8463
Epoch [1/1], Batch [31/428], Loss: 1.3550
Epoch [1/1], Batch [32/428], Loss: 1.2607
Epoch [1/1], Batch [33/428], Loss: 3.6149
Epoch [1/1], Batch [34/428], Loss: 0.5552
Epoch [1/1], Batch [35/428], Loss: 4.2035
Epoch [1/1], Batch [36/428], Loss: 0.1131
Epoch [1/1], Batch [37/428], Loss: 9.4937
Epoch [1/1], Batch [38/428], Loss: 10.1431
Epoch [1/1], Batch [39/428], Loss: 9.4332
Epoch [1/1], Batch [40/428], Loss: 5.1702
Epoch [1/1], Batch [41/428], Loss: 0.1027
Epoch [1/1], Batch [42/428], Loss: 5.9753
Epoch [1/1], Batch [43/428], Loss: 0.1921
Epoch [1/1], Batch [44/428], Loss: 6.0214
Epoch [1/1], Batch [45/428], Loss: 6.0618
Epoch [1/1], Batch [46/428], Loss: 0.3830
Epoch [1/1], Batch [47/428], Loss: 3.9923
Epoch [1/1], Batch [48/428], Loss: 3.2097
Epoch [1/1], Batch [49/428], Loss: 4.4250
Epoch [1/1], Batch [50/428], Loss: 1.3703
Epoch [1/1], Batch [51/428], Loss: 0.8066
Epoch [1/1], Batch [52/428], Loss: 0.3745
Epoch [1/1], Batch [53/428], Loss: 0.1124
Epoch [1/1], Batch [54/428], Loss: 5.9814
Epoch [1/1], Batch [55/428], Loss: 6.2987
Epoch [1/1], Batch [56/428], Loss: 8.1151
Epoch [1/1], Batch [57/428], Loss: 8.1587
Epoch [1/1], Batch [58/428], Loss: 7.1048
Epoch [1/1], Batch [59/428], Loss: 0.0087
Epoch [1/1], Batch [60/428], Loss: 6.0831
Epoch [1/1], Batch [61/428], Loss: 4.9002
Epoch [1/1], Batch [62/428], Loss: 4.5707
Epoch [1/1], Batch [63/428], Loss: 0.1187
Epoch [1/1], Batch [64/428], Loss: 6.7932
Epoch [1/1], Batch [65/428], Loss: 5.6937
Epoch [1/1], Batch [66/428], Loss: 3.2583
Epoch [1/1], Batch [67/428], Loss: 4.7587
Epoch [1/1], Batch [68/428], Loss: 4.2805
Epoch [1/1], Batch [69/428], Loss: 2.1245
Epoch [1/1], Batch [70/428], Loss: 1.0658
Epoch [1/1], Batch [71/428], Loss: 3.2034
Epoch [1/1], Batch [72/428], Loss: 2.0917
Epoch [1/1], Batch [73/428], Loss: 4.0566
Epoch [1/1], Batch [74/428], Loss: 1.4109
Epoch [1/1], Batch [75/428], Loss: 2.9986
Epoch [1/1], Batch [76/428], Loss: 0.7667
Epoch [1/1], Batch [77/428], Loss: 3.6874
Epoch [1/1], Batch [78/428], Loss: 3.0059
Epoch [1/1], Batch [79/428], Loss: 2.1580
Epoch [1/1], Batch [80/428], Loss: 0.5061
Epoch [1/1], Batch [81/428], Loss: 0.4625
Epoch [1/1], Batch [82/428], Loss: 3.8591
Epoch [1/1], Batch [83/428], Loss: 0.3038
Epoch [1/1], Batch [84/428], Loss: 6.2924
Epoch [1/1], Batch [85/428], Loss: 5.0455
Epoch [1/1], Batch [86/428], Loss: 0.1544
Epoch [1/1], Batch [87/428], Loss: 3.1316
Epoch [1/1], Batch [88/428], Loss: 4.9383
Epoch [1/1], Batch [89/428], Loss: 2.8082
Epoch [1/1], Batch [90/428], Loss: 3.3601
Epoch [1/1], Batch [91/428], Loss: 0.3763
Epoch [1/1], Batch [92/428], Loss: 0.4656
Epoch [1/1], Batch [93/428], Loss: 0.4429
Epoch [1/1], Batch [94/428], Loss: 0.3296
Epoch [1/1], Batch [95/428], Loss: 0.2040
Epoch [1/1], Batch [96/428], Loss: 5.6406
Epoch [1/1], Batch [97/428], Loss: 4.3276
Epoch [1/1], Batch [98/428], Loss: 4.6290
Epoch [1/1], Batch [99/428], Loss: 4.4218
Epoch [1/1], Batch [100/428], Loss: 0.0605
Epoch [1/1], Batch [101/428], Loss: 4.4411
Epoch [1/1], Batch [102/428], Loss: 6.1868
Epoch [1/1], Batch [103/428], Loss: 4.6405
Epoch [1/1], Batch [104/428], Loss: 5.0109
Epoch [1/1], Batch [105/428], Loss: 3.1574
Epoch [1/1], Batch [106/428], Loss: 4.3873
Epoch [1/1], Batch [107/428], Loss: 3.4748
Epoch [1/1], Batch [108/428], Loss: 3.4024
Epoch [1/1], Batch [109/428], Loss: 3.2107
Epoch [1/1], Batch [110/428], Loss: 2.5767
Epoch [1/1], Batch [111/428], Loss: 1.4797
Epoch [1/1], Batch [112/428], Loss: 1.8373
Epoch [1/1], Batch [113/428], Loss: 3.8465
Epoch [1/1], Batch [114/428], Loss: 1.4954
Epoch [1/1], Batch [115/428], Loss: 4.3312
Epoch [1/1], Batch [116/428], Loss: 2.2047
Epoch [1/1], Batch [117/428], Loss: 4.3616
Epoch [1/1], Batch [118/428], Loss: 2.6783
Epoch [1/1], Batch [119/428], Loss: 1.9847
Epoch [1/1], Batch [120/428], Loss: 3.5376
Epoch [1/1], Batch [121/428], Loss: 1.2351
Epoch [1/1], Batch [122/428], Loss: 3.6044
Epoch [1/1], Batch [123/428], Loss: 3.4158
Epoch [1/1], Batch [124/428], Loss: 1.5522
Epoch [1/1], Batch [125/428], Loss: 1.9959
Epoch [1/1], Batch [126/428], Loss: 1.2500
Epoch [1/1], Batch [127/428], Loss: 1.4927
Epoch [1/1], Batch [128/428], Loss: 1.1535
Epoch [1/1], Batch [129/428], Loss: 3.2194
Epoch [1/1], Batch [130/428], Loss: 1.3702
Epoch [1/1], Batch [131/428], Loss: 3.9210
Epoch [1/1], Batch [132/428], Loss: 3.9464
Epoch [1/1], Batch [133/428], Loss: 0.5079
Epoch [1/1], Batch [134/428], Loss: 3.3947
Epoch [1/1], Batch [135/428], Loss: 0.4330
Epoch [1/1], Batch [136/428], Loss: 1.9328
Epoch [1/1], Batch [137/428], Loss: 0.3517
Epoch [1/1], Batch [138/428], Loss: 3.5959
Epoch [1/1], Batch [139/428], Loss: 2.8305
Epoch [1/1], Batch [140/428], Loss: 2.5485
Epoch [1/1], Batch [141/428], Loss: 2.4540
Epoch [1/1], Batch [142/428], Loss: 2.7855
Epoch [1/1], Batch [143/428], Loss: 0.9674
Epoch [1/1], Batch [144/428], Loss: 1.1266
Epoch [1/1], Batch [145/428], Loss: 2.2312
Epoch [1/1], Batch [146/428], Loss: 2.2153
Epoch [1/1], Batch [147/428], Loss: 1.2479
Epoch [1/1], Batch [148/428], Loss: 1.4281
Epoch [1/1], Batch [149/428], Loss: 2.6165
Epoch [1/1], Batch [150/428], Loss: 1.3434
Epoch [1/1], Batch [151/428], Loss: 5.7818
Epoch [1/1], Batch [152/428], Loss: 1.1412
Epoch [1/1], Batch [153/428], Loss: 0.9244
Epoch [1/1], Batch [154/428], Loss: 2.2898
Epoch [1/1], Batch [155/428], Loss: 5.3007
Epoch [1/1], Batch [156/428], Loss: 0.4358
Epoch [1/1], Batch [157/428], Loss: 2.9690
Epoch [1/1], Batch [158/428], Loss: 2.5896
Epoch [1/1], Batch [159/428], Loss: 0.2921
Epoch [1/1], Batch [160/428], Loss: 3.5603
Epoch [1/1], Batch [161/428], Loss: 3.2074
Epoch [1/1], Batch [162/428], Loss: 2.9889
Epoch [1/1], Batch [163/428], Loss: 2.1248
Epoch [1/1], Batch [164/428], Loss: 0.5242
Epoch [1/1], Batch [165/428], Loss: 3.1368
Epoch [1/1], Batch [166/428], Loss: 0.7534
Epoch [1/1], Batch [167/428], Loss: 2.7788
Epoch [1/1], Batch [168/428], Loss: 1.5938
Epoch [1/1], Batch [169/428], Loss: 1.8097
Epoch [1/1], Batch [170/428], Loss: 2.4749
Epoch [1/1], Batch [171/428], Loss: 1.3461
Epoch [1/1], Batch [172/428], Loss: 1.8439
Epoch [1/1], Batch [173/428], Loss: 1.6047
Epoch [1/1], Batch [174/428], Loss: 3.8214
Epoch [1/1], Batch [175/428], Loss: 1.3554
Epoch [1/1], Batch [176/428], Loss: 1.4156
Epoch [1/1], Batch [177/428], Loss: 1.0381
Epoch [1/1], Batch [178/428], Loss: 2.1640
Epoch [1/1], Batch [179/428], Loss: 2.2857
Epoch [1/1], Batch [180/428], Loss: 3.7258
Epoch [1/1], Batch [181/428], Loss: 5.5877
Epoch [1/1], Batch [182/428], Loss: 1.5683
Epoch [1/1], Batch [183/428], Loss: 5.0202
Epoch [1/1], Batch [184/428], Loss: 1.2919
Epoch [1/1], Batch [185/428], Loss: 1.0502
Epoch [1/1], Batch [186/428], Loss: 0.7110
Epoch [1/1], Batch [187/428], Loss: 0.3850
Epoch [1/1], Batch [188/428], Loss: 3.3628
Epoch [1/1], Batch [189/428], Loss: 4.1652
Epoch [1/1], Batch [190/428], Loss: 4.9054
Epoch [1/1], Batch [191/428], Loss: 4.9307
Epoch [1/1], Batch [192/428], Loss: 3.6163
Epoch [1/1], Batch [193/428], Loss: 4.1346
Epoch [1/1], Batch [194/428], Loss: 2.4668
Epoch [1/1], Batch [195/428], Loss: 4.3243
Epoch [1/1], Batch [196/428], Loss: 3.9783
Epoch [1/1], Batch [197/428], Loss: 2.1307
Epoch [1/1], Batch [198/428], Loss: 6.0455
Epoch [1/1], Batch [199/428], Loss: 2.6575
Epoch [1/1], Batch [200/428], Loss: 2.9605
Epoch [1/1], Batch [201/428], Loss: 0.8891
Epoch [1/1], Batch [202/428], Loss: 5.2147
Epoch [1/1], Batch [203/428], Loss: 1.2117
Epoch [1/1], Batch [204/428], Loss: 1.0354
Epoch [1/1], Batch [205/428], Loss: 1.0744
Epoch [1/1], Batch [206/428], Loss: 1.9829
Epoch [1/1], Batch [207/428], Loss: 1.7574
Epoch [1/1], Batch [208/428], Loss: 0.9392
Epoch [1/1], Batch [209/428], Loss: 0.9010
Epoch [1/1], Batch [210/428], Loss: 2.0895
Epoch [1/1], Batch [211/428], Loss: 4.2313
Epoch [1/1], Batch [212/428], Loss: 1.3196
Epoch [1/1], Batch [213/428], Loss: 3.3611
Epoch [1/1], Batch [214/428], Loss: 0.7372
Epoch [1/1], Batch [215/428], Loss: 6.1981
Epoch [1/1], Batch [216/428], Loss: 3.6159
Epoch [1/1], Batch [217/428], Loss: 2.2539
Epoch [1/1], Batch [218/428], Loss: 5.5858
Epoch [1/1], Batch [219/428], Loss: 1.4281
Epoch [1/1], Batch [220/428], Loss: 1.3230
Epoch [1/1], Batch [221/428], Loss: 1.3792
Epoch [1/1], Batch [222/428], Loss: 1.1276
Epoch [1/1], Batch [223/428], Loss: 0.9332
Epoch [1/1], Batch [224/428], Loss: 1.5860
Epoch [1/1], Batch [225/428], Loss: 5.4493
Epoch [1/1], Batch [226/428], Loss: 3.9340
Epoch [1/1], Batch [227/428], Loss: 1.3432
Epoch [1/1], Batch [228/428], Loss: 2.7901
Epoch [1/1], Batch [229/428], Loss: 2.5237
Epoch [1/1], Batch [230/428], Loss: 2.2769
Epoch [1/1], Batch [231/428], Loss: 2.3570
Epoch [1/1], Batch [232/428], Loss: 1.9226
Epoch [1/1], Batch [233/428], Loss: 2.9003
Epoch [1/1], Batch [234/428], Loss: 2.0652
Epoch [1/1], Batch [235/428], Loss: 1.3843
Epoch [1/1], Batch [236/428], Loss: 2.2743
Epoch [1/1], Batch [237/428], Loss: 3.5053
Epoch [1/1], Batch [238/428], Loss: 1.6222
Epoch [1/1], Batch [239/428], Loss: 1.6024
Epoch [1/1], Batch [240/428], Loss: 1.7999
Epoch [1/1], Batch [241/428], Loss: 3.3069
Epoch [1/1], Batch [242/428], Loss: 1.2344
Epoch [1/1], Batch [243/428], Loss: 2.9256
Epoch [1/1], Batch [244/428], Loss: 2.6324
Epoch [1/1], Batch [245/428], Loss: 2.5134
Epoch [1/1], Batch [246/428], Loss: 0.9428
Epoch [1/1], Batch [247/428], Loss: 3.0757
Epoch [1/1], Batch [248/428], Loss: 2.6171
Epoch [1/1], Batch [249/428], Loss: 1.1784
Epoch [1/1], Batch [250/428], Loss: 3.2302
Epoch [1/1], Batch [251/428], Loss: 3.6277
Epoch [1/1], Batch [252/428], Loss: 3.1940
Epoch [1/1], Batch [253/428], Loss: 2.7304
Epoch [1/1], Batch [254/428], Loss: 2.6470
Epoch [1/1], Batch [255/428], Loss: 2.4551
Epoch [1/1], Batch [256/428], Loss: 2.8524
Epoch [1/1], Batch [257/428], Loss: 1.9517
Epoch [1/1], Batch [258/428], Loss: 1.9411
Epoch [1/1], Batch [259/428], Loss: 2.4891
Epoch [1/1], Batch [260/428], Loss: 2.3557
Epoch [1/1], Batch [261/428], Loss: 2.5211
Epoch [1/1], Batch [262/428], Loss: 1.4193
Epoch [1/1], Batch [263/428], Loss: 2.6859
Epoch [1/1], Batch [264/428], Loss: 1.2795
Epoch [1/1], Batch [265/428], Loss: 1.9693
Epoch [1/1], Batch [266/428], Loss: 1.4053
Epoch [1/1], Batch [267/428], Loss: 2.5213
Epoch [1/1], Batch [268/428], Loss: 1.1758
Epoch [1/1], Batch [269/428], Loss: 2.0365
Epoch [1/1], Batch [270/428], Loss: 3.1045
Epoch [1/1], Batch [271/428], Loss: 3.0750
Epoch [1/1], Batch [272/428], Loss: 1.8467
Epoch [1/1], Batch [273/428], Loss: 0.9148
Epoch [1/1], Batch [274/428], Loss: 1.5522
Epoch [1/1], Batch [275/428], Loss: 4.2159
Epoch [1/1], Batch [276/428], Loss: 1.1763
Epoch [1/1], Batch [277/428], Loss: 2.0565
Epoch [1/1], Batch [278/428], Loss: 2.9284
Epoch [1/1], Batch [279/428], Loss: 0.7000
Epoch [1/1], Batch [280/428], Loss: 3.0756
Epoch [1/1], Batch [281/428], Loss: 0.4596
Epoch [1/1], Batch [282/428], Loss: 2.9248
Epoch [1/1], Batch [283/428], Loss: 0.3056
Epoch [1/1], Batch [284/428], Loss: 3.0550
Epoch [1/1], Batch [285/428], Loss: 3.7491
Epoch [1/1], Batch [286/428], Loss: 2.9946
Epoch [1/1], Batch [287/428], Loss: 2.6992
Epoch [1/1], Batch [288/428], Loss: 4.2019
Epoch [1/1], Batch [289/428], Loss: 0.3640
Epoch [1/1], Batch [290/428], Loss: 4.8372
Epoch [1/1], Batch [291/428], Loss: 2.5968
Epoch [1/1], Batch [292/428], Loss: 4.4804
Epoch [1/1], Batch [293/428], Loss: 2.1436
Epoch [1/1], Batch [294/428], Loss: 0.9210
Epoch [1/1], Batch [295/428], Loss: 1.5613
Epoch [1/1], Batch [296/428], Loss: 1.1380
Epoch [1/1], Batch [297/428], Loss: 1.2537
Epoch [1/1], Batch [298/428], Loss: 3.0662
Epoch [1/1], Batch [299/428], Loss: 4.0355
Epoch [1/1], Batch [300/428], Loss: 2.6075
Epoch [1/1], Batch [301/428], Loss: 3.1669
Epoch [1/1], Batch [302/428], Loss: 3.0022
Epoch [1/1], Batch [303/428], Loss: 1.1946
Epoch [1/1], Batch [304/428], Loss: 1.4417
Epoch [1/1], Batch [305/428], Loss: 2.4677
Epoch [1/1], Batch [306/428], Loss: 0.9784
Epoch [1/1], Batch [307/428], Loss: 3.6534
Epoch [1/1], Batch [308/428], Loss: 2.0027
Epoch [1/1], Batch [309/428], Loss: 2.6050
Epoch [1/1], Batch [310/428], Loss: 2.3283
Epoch [1/1], Batch [311/428], Loss: 0.6419
Epoch [1/1], Batch [312/428], Loss: 1.3644
Epoch [1/1], Batch [313/428], Loss: 4.2495
Epoch [1/1], Batch [314/428], Loss: 2.9739
Epoch [1/1], Batch [315/428], Loss: 2.9008
Epoch [1/1], Batch [316/428], Loss: 4.1362
Epoch [1/1], Batch [317/428], Loss: 2.4406
Epoch [1/1], Batch [318/428], Loss: 2.1078
Epoch [1/1], Batch [319/428], Loss: 1.5805
Epoch [1/1], Batch [320/428], Loss: 1.3928
Epoch [1/1], Batch [321/428], Loss: 2.6250
Epoch [1/1], Batch [322/428], Loss: 1.8798
Epoch [1/1], Batch [323/428], Loss: 0.6597
Epoch [1/1], Batch [324/428], Loss: 3.2352
Epoch [1/1], Batch [325/428], Loss: 2.2142
Epoch [1/1], Batch [326/428], Loss: 2.2087
Epoch [1/1], Batch [327/428], Loss: 3.1418
Epoch [1/1], Batch [328/428], Loss: 3.2195
Epoch [1/1], Batch [329/428], Loss: 3.2050
Epoch [1/1], Batch [330/428], Loss: 2.3650
Epoch [1/1], Batch [331/428], Loss: 0.7770
Epoch [1/1], Batch [332/428], Loss: 3.0024
Epoch [1/1], Batch [333/428], Loss: 1.3352
Epoch [1/1], Batch [334/428], Loss: 1.9875
Epoch [1/1], Batch [335/428], Loss: 1.2047
Epoch [1/1], Batch [336/428], Loss: 1.7219
Epoch [1/1], Batch [337/428], Loss: 1.4826
Epoch [1/1], Batch [338/428], Loss: 3.9024
Epoch [1/1], Batch [339/428], Loss: 2.3768
Epoch [1/1], Batch [340/428], Loss: 2.4894
Epoch [1/1], Batch [341/428], Loss: 0.6760
Epoch [1/1], Batch [342/428], Loss: 2.3127
Epoch [1/1], Batch [343/428], Loss: 3.6542
Epoch [1/1], Batch [344/428], Loss: 2.4645
Epoch [1/1], Batch [345/428], Loss: 0.5020
Epoch [1/1], Batch [346/428], Loss: 4.1592
Epoch [1/1], Batch [347/428], Loss: 3.0604
Epoch [1/1], Batch [348/428], Loss: 0.4978
Epoch [1/1], Batch [349/428], Loss: 2.3631
Epoch [1/1], Batch [350/428], Loss: 2.3022
Epoch [1/1], Batch [351/428], Loss: 2.4305
Epoch [1/1], Batch [352/428], Loss: 3.5667
Epoch [1/1], Batch [353/428], Loss: 2.0775
Epoch [1/1], Batch [354/428], Loss: 1.8030
Epoch [1/1], Batch [355/428], Loss: 2.0278
Epoch [1/1], Batch [356/428], Loss: 1.4209
Epoch [1/1], Batch [357/428], Loss: 1.9162
Epoch [1/1], Batch [358/428], Loss: 1.7906
Epoch [1/1], Batch [359/428], Loss: 4.1750
Epoch [1/1], Batch [360/428], Loss: 1.3231
Epoch [1/1], Batch [361/428], Loss: 4.1932
Epoch [1/1], Batch [362/428], Loss: 0.8821
Epoch [1/1], Batch [363/428], Loss: 3.8762
Epoch [1/1], Batch [364/428], Loss: 0.5458
Epoch [1/1], Batch [365/428], Loss: 4.3722
Epoch [1/1], Batch [366/428], Loss: 4.5637
Epoch [1/1], Batch [367/428], Loss: 0.2408
Epoch [1/1], Batch [368/428], Loss: 0.1819
Epoch [1/1], Batch [369/428], Loss: 0.1202
Epoch [1/1], Batch [370/428], Loss: 0.0742
Epoch [1/1], Batch [371/428], Loss: 5.0828
Epoch [1/1], Batch [372/428], Loss: 5.2878
Epoch [1/1], Batch [373/428], Loss: 5.6672
Epoch [1/1], Batch [374/428], Loss: 0.0220
Epoch [1/1], Batch [375/428], Loss: 5.6562
Epoch [1/1], Batch [376/428], Loss: 6.4573
Epoch [1/1], Batch [377/428], Loss: 6.0274
Epoch [1/1], Batch [378/428], Loss: 6.3416
Epoch [1/1], Batch [379/428], Loss: 5.5279
Epoch [1/1], Batch [380/428], Loss: 0.0380
Epoch [1/1], Batch [381/428], Loss: 4.6011
Epoch [1/1], Batch [382/428], Loss: 0.0603
Epoch [1/1], Batch [383/428], Loss: 4.9448
Epoch [1/1], Batch [384/428], Loss: 3.9774
Epoch [1/1], Batch [385/428], Loss: 3.7516
Epoch [1/1], Batch [386/428], Loss: 5.1698
Epoch [1/1], Batch [387/428], Loss: 3.4376
Epoch [1/1], Batch [388/428], Loss: 4.6833
Epoch [1/1], Batch [389/428], Loss: 3.1515
Epoch [1/1], Batch [390/428], Loss: 3.9796
Epoch [1/1], Batch [391/428], Loss: 3.6814
Epoch [1/1], Batch [392/428], Loss: 3.6704
Epoch [1/1], Batch [393/428], Loss: 1.5792
Epoch [1/1], Batch [394/428], Loss: 1.7149
Epoch [1/1], Batch [395/428], Loss: 1.5648
Epoch [1/1], Batch [396/428], Loss: 2.9461
Epoch [1/1], Batch [397/428], Loss: 1.9567
Epoch [1/1], Batch [398/428], Loss: 1.1768
Epoch [1/1], Batch [399/428], Loss: 2.3953
Epoch [1/1], Batch [400/428], Loss: 2.2570
Epoch [1/1], Batch [401/428], Loss: 2.5022
Epoch [1/1], Batch [402/428], Loss: 2.5470
Epoch [1/1], Batch [403/428], Loss: 1.0246
Epoch [1/1], Batch [404/428], Loss: 2.6416
Epoch [1/1], Batch [405/428], Loss: 0.9495
Epoch [1/1], Batch [406/428], Loss: 2.6882
Epoch [1/1], Batch [407/428], Loss: 2.5767
Epoch [1/1], Batch [408/428], Loss: 2.7467
Epoch [1/1], Batch [409/428], Loss: 4.7708
Epoch [1/1], Batch [410/428], Loss: 2.0975
Epoch [1/1], Batch [411/428], Loss: 2.5292
Epoch [1/1], Batch [412/428], Loss: 1.1414
Epoch [1/1], Batch [413/428], Loss: 4.5520
Epoch [1/1], Batch [414/428], Loss: 2.1611
Epoch [1/1], Batch [415/428], Loss: 1.3257
Epoch [1/1], Batch [416/428], Loss: 1.2626
Epoch [1/1], Batch [417/428], Loss: 2.6389
Epoch [1/1], Batch [418/428], Loss: 3.9807
Epoch [1/1], Batch [419/428], Loss: 1.8420
Epoch [1/1], Batch [420/428], Loss: 2.8607
Epoch [1/1], Batch [421/428], Loss: 1.8530
Epoch [1/1], Batch [422/428], Loss: 2.4798
Epoch [1/1], Batch [423/428], Loss: 2.2671
Epoch [1/1], Batch [424/428], Loss: 3.0291
Epoch [1/1], Batch [425/428], Loss: 2.2470
Epoch [1/1], Batch [426/428], Loss: 2.4906
Epoch [1/1], Batch [427/428], Loss: 1.9349
Epoch [1/1], Batch [428/428], Loss: 2.0137
Epoch [1] Training Time: 275.73 seconds
Epoch [1/1], Average Loss: 2.7849, Training Accuracy: 0.1986
Epoch [1], Validation Loss: 2.0068, Validation Accuracy: 0.1429
Epoch [1] Validation Time: 8.92 seconds
--------------------------------------------------

Running trial 12 with config: {'batch_size': 1, 'lr': 0.001, 'num_epochs': 6, 'unfreeze_epoch': 0, 'max_length': 112000, 'device': device(type='cpu')}
Epoch 1: Unfreezing feature extractor layers...
Epoch [1/6], Batch [1/428], Loss: 0.3503
Epoch [1/6], Batch [2/428], Loss: 0.0000
Epoch [1/6], Batch [3/428], Loss: 26.4637
Epoch [1/6], Batch [4/428], Loss: 12.9497
Epoch [1/6], Batch [5/428], Loss: 15.7892
Epoch [1/6], Batch [6/428], Loss: 0.0049
Epoch [1/6], Batch [7/428], Loss: 4.8245
Epoch [1/6], Batch [8/428], Loss: 8.9690
Epoch [1/6], Batch [9/428], Loss: 3.8329
Epoch [1/6], Batch [10/428], Loss: 27.7152
Epoch [1/6], Batch [11/428], Loss: 9.1327
Epoch [1/6], Batch [12/428], Loss: 11.1943
Epoch [1/6], Batch [13/428], Loss: 0.0249
Epoch [1/6], Batch [14/428], Loss: 20.8191
Epoch [1/6], Batch [15/428], Loss: 17.9484
Epoch [1/6], Batch [16/428], Loss: 5.7049
Epoch [1/6], Batch [17/428], Loss: 2.8431
Epoch [1/6], Batch [18/428], Loss: 3.9281
Epoch [1/6], Batch [19/428], Loss: 4.2111
Epoch [1/6], Batch [20/428], Loss: 3.1807
Epoch [1/6], Batch [21/428], Loss: 5.0450
Epoch [1/6], Batch [22/428], Loss: 3.1558
Epoch [1/6], Batch [23/428], Loss: 0.9322
Epoch [1/6], Batch [24/428], Loss: 2.6084
Epoch [1/6], Batch [25/428], Loss: 1.1311
Epoch [1/6], Batch [26/428], Loss: 7.5053
Epoch [1/6], Batch [27/428], Loss: 7.2837
Epoch [1/6], Batch [28/428], Loss: 3.1815
Epoch [1/6], Batch [29/428], Loss: 0.8299
Epoch [1/6], Batch [30/428], Loss: 4.0707
Epoch [1/6], Batch [31/428], Loss: 2.6601
Epoch [1/6], Batch [32/428], Loss: 0.9125
Epoch [1/6], Batch [33/428], Loss: 4.1350
Epoch [1/6], Batch [34/428], Loss: 9.8804
Epoch [1/6], Batch [35/428], Loss: 0.0088
Epoch [1/6], Batch [36/428], Loss: 6.3518
Epoch [1/6], Batch [37/428], Loss: 6.5174
Epoch [1/6], Batch [38/428], Loss: 6.5156
Epoch [1/6], Batch [39/428], Loss: 0.0723
Epoch [1/6], Batch [40/428], Loss: 0.0943
Epoch [1/6], Batch [41/428], Loss: 4.3894
Epoch [1/6], Batch [42/428], Loss: 7.7741
Epoch [1/6], Batch [43/428], Loss: 4.2838
Epoch [1/6], Batch [44/428], Loss: 8.5652
Epoch [1/6], Batch [45/428], Loss: 2.9743
Epoch [1/6], Batch [46/428], Loss: 6.8104
Epoch [1/6], Batch [47/428], Loss: 0.6144
Epoch [1/6], Batch [48/428], Loss: 4.7043
Epoch [1/6], Batch [49/428], Loss: 3.5792
Epoch [1/6], Batch [50/428], Loss: 3.6396
Epoch [1/6], Batch [51/428], Loss: 3.3446
Epoch [1/6], Batch [52/428], Loss: 3.5792
Epoch [1/6], Batch [53/428], Loss: 2.0442
Epoch [1/6], Batch [54/428], Loss: 2.8633
Epoch [1/6], Batch [55/428], Loss: 2.1436
Epoch [1/6], Batch [56/428], Loss: 1.1587
Epoch [1/6], Batch [57/428], Loss: 1.2491
Epoch [1/6], Batch [58/428], Loss: 1.0265
Epoch [1/6], Batch [59/428], Loss: 5.4231
Epoch [1/6], Batch [60/428], Loss: 3.3986
Epoch [1/6], Batch [61/428], Loss: 5.2697
Epoch [1/6], Batch [62/428], Loss: 5.5221
Epoch [1/6], Batch [63/428], Loss: 4.5368
Epoch [1/6], Batch [64/428], Loss: 8.0981
Epoch [1/6], Batch [65/428], Loss: 7.5212
Epoch [1/6], Batch [66/428], Loss: 1.0389
Epoch [1/6], Batch [67/428], Loss: 1.8439
Epoch [1/6], Batch [68/428], Loss: 1.8527
Epoch [1/6], Batch [69/428], Loss: 2.6191
Epoch [1/6], Batch [70/428], Loss: 0.9485
Epoch [1/6], Batch [71/428], Loss: 0.7044
Epoch [1/6], Batch [72/428], Loss: 4.6378
Epoch [1/6], Batch [73/428], Loss: 4.2336
Epoch [1/6], Batch [74/428], Loss: 4.9735
Epoch [1/6], Batch [75/428], Loss: 4.9301
Epoch [1/6], Batch [76/428], Loss: 2.0649
Epoch [1/6], Batch [77/428], Loss: 4.8912
Epoch [1/6], Batch [78/428], Loss: 0.5709
Epoch [1/6], Batch [79/428], Loss: 3.7299
Epoch [1/6], Batch [80/428], Loss: 3.0746
Epoch [1/6], Batch [81/428], Loss: 4.0718
Epoch [1/6], Batch [82/428], Loss: 0.0817
Epoch [1/6], Batch [83/428], Loss: 5.1950
Epoch [1/6], Batch [84/428], Loss: 4.4261
Epoch [1/6], Batch [85/428], Loss: 5.2594
Epoch [1/6], Batch [86/428], Loss: 3.8209
Epoch [1/6], Batch [87/428], Loss: 2.0341
Epoch [1/6], Batch [88/428], Loss: 1.3330
Epoch [1/6], Batch [89/428], Loss: 2.6361
Epoch [1/6], Batch [90/428], Loss: 2.8159
Epoch [1/6], Batch [91/428], Loss: 2.2723
Epoch [1/6], Batch [92/428], Loss: 5.3037
Epoch [1/6], Batch [93/428], Loss: 0.8077
Epoch [1/6], Batch [94/428], Loss: 3.1791
Epoch [1/6], Batch [95/428], Loss: 1.5830
Epoch [1/6], Batch [96/428], Loss: 2.7964
Epoch [1/6], Batch [97/428], Loss: 1.0670
Epoch [1/6], Batch [98/428], Loss: 1.4591
Epoch [1/6], Batch [99/428], Loss: 7.3267
Epoch [1/6], Batch [100/428], Loss: 1.5350
Epoch [1/6], Batch [101/428], Loss: 1.3547
Epoch [1/6], Batch [102/428], Loss: 4.2464
Epoch [1/6], Batch [103/428], Loss: 1.6815
Epoch [1/6], Batch [104/428], Loss: 3.9837
Epoch [1/6], Batch [105/428], Loss: 0.5967
Epoch [1/6], Batch [106/428], Loss: 4.6586
Epoch [1/6], Batch [107/428], Loss: 3.1870
Epoch [1/6], Batch [108/428], Loss: 0.4340
Epoch [1/6], Batch [109/428], Loss: 7.5669
Epoch [1/6], Batch [110/428], Loss: 4.0847
Epoch [1/6], Batch [111/428], Loss: 7.0042
Epoch [1/6], Batch [112/428], Loss: 6.5342
Epoch [1/6], Batch [113/428], Loss: 0.6187
Epoch [1/6], Batch [114/428], Loss: 5.1763
Epoch [1/6], Batch [115/428], Loss: 0.6402
Epoch [1/6], Batch [116/428], Loss: 3.1381
Epoch [1/6], Batch [117/428], Loss: 2.9593
Epoch [1/6], Batch [118/428], Loss: 2.5216
Epoch [1/6], Batch [119/428], Loss: 0.7781
Epoch [1/6], Batch [120/428], Loss: 0.8900
Epoch [1/6], Batch [121/428], Loss: 0.9134
Epoch [1/6], Batch [122/428], Loss: 3.6213
Epoch [1/6], Batch [123/428], Loss: 3.6282
Epoch [1/6], Batch [124/428], Loss: 3.8941
Epoch [1/6], Batch [125/428], Loss: 0.6418
Epoch [1/6], Batch [126/428], Loss: 3.5389
Epoch [1/6], Batch [127/428], Loss: 0.5046
Epoch [1/6], Batch [128/428], Loss: 0.3920
Epoch [1/6], Batch [129/428], Loss: 2.8739
Epoch [1/6], Batch [130/428], Loss: 3.2368
Epoch [1/6], Batch [131/428], Loss: 0.2492
Epoch [1/6], Batch [132/428], Loss: 4.8063
Epoch [1/6], Batch [133/428], Loss: 3.9926
Epoch [1/6], Batch [134/428], Loss: 5.3242
Epoch [1/6], Batch [135/428], Loss: 5.0704
Epoch [1/6], Batch [136/428], Loss: 3.7243
Epoch [1/6], Batch [137/428], Loss: 3.5675
Epoch [1/6], Batch [138/428], Loss: 0.6334
Epoch [1/6], Batch [139/428], Loss: 1.3634
Epoch [1/6], Batch [140/428], Loss: 2.7826
Epoch [1/6], Batch [141/428], Loss: 2.3000
Epoch [1/6], Batch [142/428], Loss: 1.3172
Epoch [1/6], Batch [143/428], Loss: 1.4131
Epoch [1/6], Batch [144/428], Loss: 1.6158
Epoch [1/6], Batch [145/428], Loss: 1.7891
Epoch [1/6], Batch [146/428], Loss: 1.6613
Epoch [1/6], Batch [147/428], Loss: 3.2413
Epoch [1/6], Batch [148/428], Loss: 1.4747
Epoch [1/6], Batch [149/428], Loss: 1.3015
Epoch [1/6], Batch [150/428], Loss: 4.2230
Epoch [1/6], Batch [151/428], Loss: 2.4615
Epoch [1/6], Batch [152/428], Loss: 0.6458
Epoch [1/6], Batch [153/428], Loss: 3.2441
Epoch [1/6], Batch [154/428], Loss: 0.4042
Epoch [1/6], Batch [155/428], Loss: 3.6725
Epoch [1/6], Batch [156/428], Loss: 0.2328
Epoch [1/6], Batch [157/428], Loss: 0.1633
Epoch [1/6], Batch [158/428], Loss: 3.9740
Epoch [1/6], Batch [159/428], Loss: 4.0664
Epoch [1/6], Batch [160/428], Loss: 0.0647
Epoch [1/6], Batch [161/428], Loss: 0.0508
Epoch [1/6], Batch [162/428], Loss: 5.6971
Epoch [1/6], Batch [163/428], Loss: 5.5281
Epoch [1/6], Batch [164/428], Loss: 5.4905
Epoch [1/6], Batch [165/428], Loss: 6.1512
Epoch [1/6], Batch [166/428], Loss: 6.1559
Epoch [1/6], Batch [167/428], Loss: 4.3503
Epoch [1/6], Batch [168/428], Loss: 3.7255
Epoch [1/6], Batch [169/428], Loss: 4.4584
Epoch [1/6], Batch [170/428], Loss: 0.2386
Epoch [1/6], Batch [171/428], Loss: 3.8237
Epoch [1/6], Batch [172/428], Loss: 2.1986
Epoch [1/6], Batch [173/428], Loss: 3.9771
Epoch [1/6], Batch [174/428], Loss: 3.6160
Epoch [1/6], Batch [175/428], Loss: 2.3075
Epoch [1/6], Batch [176/428], Loss: 1.8411
Epoch [1/6], Batch [177/428], Loss: 2.0698
Epoch [1/6], Batch [178/428], Loss: 2.1296
Epoch [1/6], Batch [179/428], Loss: 5.9475
Epoch [1/6], Batch [180/428], Loss: 1.3557
Epoch [1/6], Batch [181/428], Loss: 2.5215
Epoch [1/6], Batch [182/428], Loss: 2.8594
Epoch [1/6], Batch [183/428], Loss: 2.6511
Epoch [1/6], Batch [184/428], Loss: 2.1898
Epoch [1/6], Batch [185/428], Loss: 2.3176
Epoch [1/6], Batch [186/428], Loss: 2.0242
Epoch [1/6], Batch [187/428], Loss: 1.7136
Epoch [1/6], Batch [188/428], Loss: 1.4831
Epoch [1/6], Batch [189/428], Loss: 4.8656
Epoch [1/6], Batch [190/428], Loss: 1.9675
Epoch [1/6], Batch [191/428], Loss: 3.9195
Epoch [1/6], Batch [192/428], Loss: 2.3675
Epoch [1/6], Batch [193/428], Loss: 0.9593
Epoch [1/6], Batch [194/428], Loss: 1.0486
Epoch [1/6], Batch [195/428], Loss: 3.6448
Epoch [1/6], Batch [196/428], Loss: 3.6542
Epoch [1/6], Batch [197/428], Loss: 0.8190
Epoch [1/6], Batch [198/428], Loss: 3.4440
Epoch [1/6], Batch [199/428], Loss: 0.6820
Epoch [1/6], Batch [200/428], Loss: 3.1823
Epoch [1/6], Batch [201/428], Loss: 4.1210
Epoch [1/6], Batch [202/428], Loss: 0.5381
Epoch [1/6], Batch [203/428], Loss: 2.5617
Epoch [1/6], Batch [204/428], Loss: 0.5056
Epoch [1/6], Batch [205/428], Loss: 2.3678
Epoch [1/6], Batch [206/428], Loss: 2.1425
Epoch [1/6], Batch [207/428], Loss: 1.7497
Epoch [1/6], Batch [208/428], Loss: 1.2410
Epoch [1/6], Batch [209/428], Loss: 4.6724
Epoch [1/6], Batch [210/428], Loss: 1.4397
Epoch [1/6], Batch [211/428], Loss: 0.3370
Epoch [1/6], Batch [212/428], Loss: 5.1208
Epoch [1/6], Batch [213/428], Loss: 0.1427
Epoch [1/6], Batch [214/428], Loss: 5.5670
Epoch [1/6], Batch [215/428], Loss: 3.4575
Epoch [1/6], Batch [216/428], Loss: 5.0274
Epoch [1/6], Batch [217/428], Loss: 3.5387
Epoch [1/6], Batch [218/428], Loss: 4.7751
Epoch [1/6], Batch [219/428], Loss: 4.1669
Epoch [1/6], Batch [220/428], Loss: 2.5358
Epoch [1/6], Batch [221/428], Loss: 2.0740
Epoch [1/6], Batch [222/428], Loss: 3.2741
Epoch [1/6], Batch [223/428], Loss: 4.3542
Epoch [1/6], Batch [224/428], Loss: 1.3598
Epoch [1/6], Batch [225/428], Loss: 2.5739
Epoch [1/6], Batch [226/428], Loss: 3.8999
Epoch [1/6], Batch [227/428], Loss: 3.7666
Epoch [1/6], Batch [228/428], Loss: 1.2979
Epoch [1/6], Batch [229/428], Loss: 0.8722
Epoch [1/6], Batch [230/428], Loss: 1.8727
Epoch [1/6], Batch [231/428], Loss: 1.4586
Epoch [1/6], Batch [232/428], Loss: 1.4393
Epoch [1/6], Batch [233/428], Loss: 3.5479
Epoch [1/6], Batch [234/428], Loss: 3.2854
Epoch [1/6], Batch [235/428], Loss: 1.0295
Epoch [1/6], Batch [236/428], Loss: 2.4456
Epoch [1/6], Batch [237/428], Loss: 1.8927
Epoch [1/6], Batch [238/428], Loss: 2.2745
Epoch [1/6], Batch [239/428], Loss: 0.7875
Epoch [1/6], Batch [240/428], Loss: 4.6044
Epoch [1/6], Batch [241/428], Loss: 8.1706
Epoch [1/6], Batch [242/428], Loss: 0.1579
Epoch [1/6], Batch [243/428], Loss: 8.5557
Epoch [1/6], Batch [244/428], Loss: 3.5475
Epoch [1/6], Batch [245/428], Loss: 0.0690
Epoch [1/6], Batch [246/428], Loss: 3.7460
Epoch [1/6], Batch [247/428], Loss: 0.0513
Epoch [1/6], Batch [248/428], Loss: 0.0413
Epoch [1/6], Batch [249/428], Loss: 5.6804
Epoch [1/6], Batch [250/428], Loss: 7.7182
Epoch [1/6], Batch [251/428], Loss: 4.8076
Epoch [1/6], Batch [252/428], Loss: 7.2025
Epoch [1/6], Batch [253/428], Loss: 5.8775
Epoch [1/6], Batch [254/428], Loss: 6.9881
Epoch [1/6], Batch [255/428], Loss: 0.1078
Epoch [1/6], Batch [256/428], Loss: 4.2063
Epoch [1/6], Batch [257/428], Loss: 5.5721
Epoch [1/6], Batch [258/428], Loss: 2.8908
Epoch [1/6], Batch [259/428], Loss: 2.4995
Epoch [1/6], Batch [260/428], Loss: 2.9448
Epoch [1/6], Batch [261/428], Loss: 1.4533
Epoch [1/6], Batch [262/428], Loss: 1.3048
Epoch [1/6], Batch [263/428], Loss: 1.4070
Epoch [1/6], Batch [264/428], Loss: 1.2577
Epoch [1/6], Batch [265/428], Loss: 1.1412
Epoch [1/6], Batch [266/428], Loss: 3.4516
Epoch [1/6], Batch [267/428], Loss: 3.9014
Epoch [1/6], Batch [268/428], Loss: 1.1276
Epoch [1/6], Batch [269/428], Loss: 2.4031
Epoch [1/6], Batch [270/428], Loss: 0.9390
Epoch [1/6], Batch [271/428], Loss: 0.9866
Epoch [1/6], Batch [272/428], Loss: 0.9416
Epoch [1/6], Batch [273/428], Loss: 3.6614
Epoch [1/6], Batch [274/428], Loss: 2.2431
Epoch [1/6], Batch [275/428], Loss: 2.0995
Epoch [1/6], Batch [276/428], Loss: 3.2462
Epoch [1/6], Batch [277/428], Loss: 3.5785
Epoch [1/6], Batch [278/428], Loss: 1.4540
Epoch [1/6], Batch [279/428], Loss: 0.8610
Epoch [1/6], Batch [280/428], Loss: 2.3971
Epoch [1/6], Batch [281/428], Loss: 0.9977
Epoch [1/6], Batch [282/428], Loss: 0.9904
Epoch [1/6], Batch [283/428], Loss: 2.7340
Epoch [1/6], Batch [284/428], Loss: 3.2370
Epoch [1/6], Batch [285/428], Loss: 2.9846
Epoch [1/6], Batch [286/428], Loss: 0.7954
Epoch [1/6], Batch [287/428], Loss: 2.8058
Epoch [1/6], Batch [288/428], Loss: 1.7502
Epoch [1/6], Batch [289/428], Loss: 5.5590
Epoch [1/6], Batch [290/428], Loss: 2.5325
Epoch [1/6], Batch [291/428], Loss: 3.0526
Epoch [1/6], Batch [292/428], Loss: 1.9502
Epoch [1/6], Batch [293/428], Loss: 2.0380
Epoch [1/6], Batch [294/428], Loss: 4.8971
Epoch [1/6], Batch [295/428], Loss: 1.6141
Epoch [1/6], Batch [296/428], Loss: 1.3335
Epoch [1/6], Batch [297/428], Loss: 1.8602
Epoch [1/6], Batch [298/428], Loss: 1.8648
Epoch [1/6], Batch [299/428], Loss: 2.9605
Epoch [1/6], Batch [300/428], Loss: 2.5004
Epoch [1/6], Batch [301/428], Loss: 1.5389
Epoch [1/6], Batch [302/428], Loss: 2.7145
Epoch [1/6], Batch [303/428], Loss: 4.0105
Epoch [1/6], Batch [304/428], Loss: 2.6529
Epoch [1/6], Batch [305/428], Loss: 2.5392
Epoch [1/6], Batch [306/428], Loss: 3.5082
Epoch [1/6], Batch [307/428], Loss: 2.4732
Epoch [1/6], Batch [308/428], Loss: 1.9684
Epoch [1/6], Batch [309/428], Loss: 2.0352
Epoch [1/6], Batch [310/428], Loss: 2.9663
Epoch [1/6], Batch [311/428], Loss: 1.9331
Epoch [1/6], Batch [312/428], Loss: 2.8731
Epoch [1/6], Batch [313/428], Loss: 1.9548
Epoch [1/6], Batch [314/428], Loss: 2.1714
Epoch [1/6], Batch [315/428], Loss: 2.4821
Epoch [1/6], Batch [316/428], Loss: 2.9149
Epoch [1/6], Batch [317/428], Loss: 1.3557
Epoch [1/6], Batch [318/428], Loss: 2.6182
Epoch [1/6], Batch [319/428], Loss: 1.3239
Epoch [1/6], Batch [320/428], Loss: 1.7233
Epoch [1/6], Batch [321/428], Loss: 1.2091
Epoch [1/6], Batch [322/428], Loss: 1.1088
Epoch [1/6], Batch [323/428], Loss: 2.4915
Epoch [1/6], Batch [324/428], Loss: 2.9073
Epoch [1/6], Batch [325/428], Loss: 2.5043
Epoch [1/6], Batch [326/428], Loss: 2.3830
Epoch [1/6], Batch [327/428], Loss: 2.1701
Epoch [1/6], Batch [328/428], Loss: 0.7999
Epoch [1/6], Batch [329/428], Loss: 2.4468
Epoch [1/6], Batch [330/428], Loss: 0.8025
Epoch [1/6], Batch [331/428], Loss: 4.0350
Epoch [1/6], Batch [332/428], Loss: 2.4996
Epoch [1/6], Batch [333/428], Loss: 2.7495
Epoch [1/6], Batch [334/428], Loss: 3.0262
Epoch [1/6], Batch [335/428], Loss: 3.8846
Epoch [1/6], Batch [336/428], Loss: 0.8766
Epoch [1/6], Batch [337/428], Loss: 0.8969
Epoch [1/6], Batch [338/428], Loss: 1.4816
Epoch [1/6], Batch [339/428], Loss: 3.2545
Epoch [1/6], Batch [340/428], Loss: 2.6842
Epoch [1/6], Batch [341/428], Loss: 1.5193
Epoch [1/6], Batch [342/428], Loss: 2.6493
Epoch [1/6], Batch [343/428], Loss: 2.1569
Epoch [1/6], Batch [344/428], Loss: 2.0770
Epoch [1/6], Batch [345/428], Loss: 3.8253
Epoch [1/6], Batch [346/428], Loss: 1.7186
Epoch [1/6], Batch [347/428], Loss: 3.7419
Epoch [1/6], Batch [348/428], Loss: 1.7330
Epoch [1/6], Batch [349/428], Loss: 1.6245
Epoch [1/6], Batch [350/428], Loss: 2.0012
Epoch [1/6], Batch [351/428], Loss: 1.4360
Epoch [1/6], Batch [352/428], Loss: 1.2673
Epoch [1/6], Batch [353/428], Loss: 2.2617
Epoch [1/6], Batch [354/428], Loss: 3.3312
Epoch [1/6], Batch [355/428], Loss: 0.7480
Epoch [1/6], Batch [356/428], Loss: 2.4712
Epoch [1/6], Batch [357/428], Loss: 2.5441
Epoch [1/6], Batch [358/428], Loss: 3.2833
Epoch [1/6], Batch [359/428], Loss: 0.4702
Epoch [1/6], Batch [360/428], Loss: 2.4980
Epoch [1/6], Batch [361/428], Loss: 2.9846
Epoch [1/6], Batch [362/428], Loss: 2.5277
Epoch [1/6], Batch [363/428], Loss: 3.1680
Epoch [1/6], Batch [364/428], Loss: 2.2500
Epoch [1/6], Batch [365/428], Loss: 2.0197
Epoch [1/6], Batch [366/428], Loss: 1.9734
Epoch [1/6], Batch [367/428], Loss: 1.5172
Epoch [1/6], Batch [368/428], Loss: 1.4400
Epoch [1/6], Batch [369/428], Loss: 3.7521
Epoch [1/6], Batch [370/428], Loss: 3.7732
Epoch [1/6], Batch [371/428], Loss: 1.9846
Epoch [1/6], Batch [372/428], Loss: 2.5931
Epoch [1/6], Batch [373/428], Loss: 1.5204
Epoch [1/6], Batch [374/428], Loss: 2.4089
Epoch [1/6], Batch [375/428], Loss: 2.1721
Epoch [1/6], Batch [376/428], Loss: 2.2965
Epoch [1/6], Batch [377/428], Loss: 1.6315
Epoch [1/6], Batch [378/428], Loss: 1.4037
Epoch [1/6], Batch [379/428], Loss: 4.0519
Epoch [1/6], Batch [380/428], Loss: 1.0056
Epoch [1/6], Batch [381/428], Loss: 1.7439
Epoch [1/6], Batch [382/428], Loss: 1.8003
Epoch [1/6], Batch [383/428], Loss: 0.6190
Epoch [1/6], Batch [384/428], Loss: 3.2818
Epoch [1/6], Batch [385/428], Loss: 3.3443
Epoch [1/6], Batch [386/428], Loss: 0.4522
Epoch [1/6], Batch [387/428], Loss: 3.9372
Epoch [1/6], Batch [388/428], Loss: 3.0430
Epoch [1/6], Batch [389/428], Loss: 3.5915
Epoch [1/6], Batch [390/428], Loss: 3.5401
Epoch [1/6], Batch [391/428], Loss: 0.4274
Epoch [1/6], Batch [392/428], Loss: 3.0817
Epoch [1/6], Batch [393/428], Loss: 3.1584
Epoch [1/6], Batch [394/428], Loss: 2.7922
Epoch [1/6], Batch [395/428], Loss: 2.6824
Epoch [1/6], Batch [396/428], Loss: 2.5153
Epoch [1/6], Batch [397/428], Loss: 2.4205
Epoch [1/6], Batch [398/428], Loss: 1.1417
Epoch [1/6], Batch [399/428], Loss: 1.8332
Epoch [1/6], Batch [400/428], Loss: 2.1370
Epoch [1/6], Batch [401/428], Loss: 1.4076
Epoch [1/6], Batch [402/428], Loss: 1.9642
Epoch [1/6], Batch [403/428], Loss: 2.0191
Epoch [1/6], Batch [404/428], Loss: 2.3162
Epoch [1/6], Batch [405/428], Loss: 4.1754
Epoch [1/6], Batch [406/428], Loss: 3.1643
Epoch [1/6], Batch [407/428], Loss: 3.1646
Epoch [1/6], Batch [408/428], Loss: 2.6124
Epoch [1/6], Batch [409/428], Loss: 1.7892
Epoch [1/6], Batch [410/428], Loss: 1.0777
Epoch [1/6], Batch [411/428], Loss: 1.5029
Epoch [1/6], Batch [412/428], Loss: 1.1396
Epoch [1/6], Batch [413/428], Loss: 1.5469
Epoch [1/6], Batch [414/428], Loss: 3.8011
Epoch [1/6], Batch [415/428], Loss: 2.5824
Epoch [1/6], Batch [416/428], Loss: 2.4785
Epoch [1/6], Batch [417/428], Loss: 1.2778
Epoch [1/6], Batch [418/428], Loss: 1.6526
Epoch [1/6], Batch [419/428], Loss: 3.3981
Epoch [1/6], Batch [420/428], Loss: 1.3185
Epoch [1/6], Batch [421/428], Loss: 1.6502
Epoch [1/6], Batch [422/428], Loss: 2.7245
Epoch [1/6], Batch [423/428], Loss: 2.6856
Epoch [1/6], Batch [424/428], Loss: 2.5653
Epoch [1/6], Batch [425/428], Loss: 2.9959
Epoch [1/6], Batch [426/428], Loss: 1.5230
Epoch [1/6], Batch [427/428], Loss: 1.8060
Epoch [1/6], Batch [428/428], Loss: 2.1044
Epoch [1] Training Time: 393.37 seconds
Epoch [1/6], Average Loss: 3.0350, Training Accuracy: 0.1846
Epoch [1], Validation Loss: 2.0520, Validation Accuracy: 0.1429
Epoch [1] Validation Time: 17.04 seconds
--------------------------------------------------
Epoch [2/6], Batch [1/428], Loss: 3.0072
Epoch [2/6], Batch [2/428], Loss: 1.7253
Epoch [2/6], Batch [3/428], Loss: 2.1894
Epoch [2/6], Batch [4/428], Loss: 2.4199
Epoch [2/6], Batch [5/428], Loss: 1.5198
Epoch [2/6], Batch [6/428], Loss: 1.6344
Epoch [2/6], Batch [7/428], Loss: 2.1494
Epoch [2/6], Batch [8/428], Loss: 2.0981
Epoch [2/6], Batch [9/428], Loss: 1.9691
Epoch [2/6], Batch [10/428], Loss: 1.3209
Epoch [2/6], Batch [11/428], Loss: 2.1173
Epoch [2/6], Batch [12/428], Loss: 1.6790
Epoch [2/6], Batch [13/428], Loss: 1.5205
Epoch [2/6], Batch [14/428], Loss: 2.0177
Epoch [2/6], Batch [15/428], Loss: 1.3271
Epoch [2/6], Batch [16/428], Loss: 1.4377
Epoch [2/6], Batch [17/428], Loss: 3.1031
Epoch [2/6], Batch [18/428], Loss: 3.9368
Epoch [2/6], Batch [19/428], Loss: 0.9977
Epoch [2/6], Batch [20/428], Loss: 1.5822
Epoch [2/6], Batch [21/428], Loss: 2.1620
Epoch [2/6], Batch [22/428], Loss: 0.8345
Epoch [2/6], Batch [23/428], Loss: 1.6000
Epoch [2/6], Batch [24/428], Loss: 1.5814
Epoch [2/6], Batch [25/428], Loss: 3.6348
Epoch [2/6], Batch [26/428], Loss: 0.7676
Epoch [2/6], Batch [27/428], Loss: 0.7437
Epoch [2/6], Batch [28/428], Loss: 2.4834
Epoch [2/6], Batch [29/428], Loss: 1.4336
Epoch [2/6], Batch [30/428], Loss: 2.5243
Epoch [2/6], Batch [31/428], Loss: 2.6848
Epoch [2/6], Batch [32/428], Loss: 2.5934
Epoch [2/6], Batch [33/428], Loss: 0.7594
Epoch [2/6], Batch [34/428], Loss: 2.2106
Epoch [2/6], Batch [35/428], Loss: 2.0953
Epoch [2/6], Batch [36/428], Loss: 0.8304
Epoch [2/6], Batch [37/428], Loss: 1.5613
Epoch [2/6], Batch [38/428], Loss: 3.6880
Epoch [2/6], Batch [39/428], Loss: 1.5409
Epoch [2/6], Batch [40/428], Loss: 2.1874
Epoch [2/6], Batch [41/428], Loss: 1.2677
Epoch [2/6], Batch [42/428], Loss: 1.2386
Epoch [2/6], Batch [43/428], Loss: 0.9837
Epoch [2/6], Batch [44/428], Loss: 0.8271
Epoch [2/6], Batch [45/428], Loss: 1.6277
Epoch [2/6], Batch [46/428], Loss: 1.7237
Epoch [2/6], Batch [47/428], Loss: 1.7552
Epoch [2/6], Batch [48/428], Loss: 3.7560
Epoch [2/6], Batch [49/428], Loss: 1.6195
Epoch [2/6], Batch [50/428], Loss: 1.4944
Epoch [2/6], Batch [51/428], Loss: 2.8440
Epoch [2/6], Batch [52/428], Loss: 2.4771
Epoch [2/6], Batch [53/428], Loss: 3.2900
Epoch [2/6], Batch [54/428], Loss: 0.8788
Epoch [2/6], Batch [55/428], Loss: 4.0326
Epoch [2/6], Batch [56/428], Loss: 2.7429
Epoch [2/6], Batch [57/428], Loss: 2.2392
Epoch [2/6], Batch [58/428], Loss: 0.5821
Epoch [2/6], Batch [59/428], Loss: 4.3057
Epoch [2/6], Batch [60/428], Loss: 2.5847
Epoch [2/6], Batch [61/428], Loss: 2.1204
Epoch [2/6], Batch [62/428], Loss: 0.5429
Epoch [2/6], Batch [63/428], Loss: 2.3903
Epoch [2/6], Batch [64/428], Loss: 2.9834
Epoch [2/6], Batch [65/428], Loss: 3.0114
Epoch [2/6], Batch [66/428], Loss: 3.5896
Epoch [2/6], Batch [67/428], Loss: 0.6737
Epoch [2/6], Batch [68/428], Loss: 1.8385
Epoch [2/6], Batch [69/428], Loss: 1.7060
Epoch [2/6], Batch [70/428], Loss: 3.6930
Epoch [2/6], Batch [71/428], Loss: 2.8101
Epoch [2/6], Batch [72/428], Loss: 2.6245
Epoch [2/6], Batch [73/428], Loss: 1.8762
Epoch [2/6], Batch [74/428], Loss: 1.1974
Epoch [2/6], Batch [75/428], Loss: 1.7614
Epoch [2/6], Batch [76/428], Loss: 2.4025
Epoch [2/6], Batch [77/428], Loss: 2.7715
Epoch [2/6], Batch [78/428], Loss: 1.4759
Epoch [2/6], Batch [79/428], Loss: 1.5632
Epoch [2/6], Batch [80/428], Loss: 2.1157
Epoch [2/6], Batch [81/428], Loss: 2.0057
Epoch [2/6], Batch [82/428], Loss: 1.6847
Epoch [2/6], Batch [83/428], Loss: 2.9881
Epoch [2/6], Batch [84/428], Loss: 2.4450
Epoch [2/6], Batch [85/428], Loss: 1.4692
Epoch [2/6], Batch [86/428], Loss: 2.7473
Epoch [2/6], Batch [87/428], Loss: 2.6692
Epoch [2/6], Batch [88/428], Loss: 1.9739
Epoch [2/6], Batch [89/428], Loss: 2.6268
Epoch [2/6], Batch [90/428], Loss: 2.2961
Epoch [2/6], Batch [91/428], Loss: 2.1748
Epoch [2/6], Batch [92/428], Loss: 2.0591
Epoch [2/6], Batch [93/428], Loss: 2.1987
Epoch [2/6], Batch [94/428], Loss: 2.1188
Epoch [2/6], Batch [95/428], Loss: 2.0495
Epoch [2/6], Batch [96/428], Loss: 1.4947
Epoch [2/6], Batch [97/428], Loss: 2.2273
Epoch [2/6], Batch [98/428], Loss: 2.5114
Epoch [2/6], Batch [99/428], Loss: 1.8281
Epoch [2/6], Batch [100/428], Loss: 1.8958
Epoch [2/6], Batch [101/428], Loss: 1.7422
Epoch [2/6], Batch [102/428], Loss: 1.7892
Epoch [2/6], Batch [103/428], Loss: 1.5590
Epoch [2/6], Batch [104/428], Loss: 1.4722
Epoch [2/6], Batch [105/428], Loss: 2.4946
Epoch [2/6], Batch [106/428], Loss: 1.6289
Epoch [2/6], Batch [107/428], Loss: 2.0223
Epoch [2/6], Batch [108/428], Loss: 1.5296
Epoch [2/6], Batch [109/428], Loss: 1.0826
Epoch [2/6], Batch [110/428], Loss: 2.5559
Epoch [2/6], Batch [111/428], Loss: 2.1270
Epoch [2/6], Batch [112/428], Loss: 1.3293
Epoch [2/6], Batch [113/428], Loss: 2.6181
Epoch [2/6], Batch [114/428], Loss: 2.5566
Epoch [2/6], Batch [115/428], Loss: 2.4916
Epoch [2/6], Batch [116/428], Loss: 1.9862
Epoch [2/6], Batch [117/428], Loss: 2.2351
Epoch [2/6], Batch [118/428], Loss: 3.7128
Epoch [2/6], Batch [119/428], Loss: 1.1612
Epoch [2/6], Batch [120/428], Loss: 1.1480
Epoch [2/6], Batch [121/428], Loss: 3.5355
Epoch [2/6], Batch [122/428], Loss: 1.0562
Epoch [2/6], Batch [123/428], Loss: 3.3931
Epoch [2/6], Batch [124/428], Loss: 2.3971
Epoch [2/6], Batch [125/428], Loss: 2.4879
Epoch [2/6], Batch [126/428], Loss: 0.8859
Epoch [2/6], Batch [127/428], Loss: 0.8299
Epoch [2/6], Batch [128/428], Loss: 2.4935
Epoch [2/6], Batch [129/428], Loss: 1.8391
Epoch [2/6], Batch [130/428], Loss: 2.9406
Epoch [2/6], Batch [131/428], Loss: 2.5245
Epoch [2/6], Batch [132/428], Loss: 2.6527
Epoch [2/6], Batch [133/428], Loss: 2.4811
Epoch [2/6], Batch [134/428], Loss: 0.7814
Epoch [2/6], Batch [135/428], Loss: 2.6156
Epoch [2/6], Batch [136/428], Loss: 0.8531
Epoch [2/6], Batch [137/428], Loss: 2.1005
Epoch [2/6], Batch [138/428], Loss: 2.5965
Epoch [2/6], Batch [139/428], Loss: 2.5850
Epoch [2/6], Batch [140/428], Loss: 3.4517
Epoch [2/6], Batch [141/428], Loss: 0.9933
Epoch [2/6], Batch [142/428], Loss: 2.3292
Epoch [2/6], Batch [143/428], Loss: 3.2761
Epoch [2/6], Batch [144/428], Loss: 3.1628
Epoch [2/6], Batch [145/428], Loss: 2.8354
Epoch [2/6], Batch [146/428], Loss: 2.7609
Epoch [2/6], Batch [147/428], Loss: 1.7890
Epoch [2/6], Batch [148/428], Loss: 2.4979
Epoch [2/6], Batch [149/428], Loss: 1.2683
Epoch [2/6], Batch [150/428], Loss: 2.4442
Epoch [2/6], Batch [151/428], Loss: 2.0466
Epoch [2/6], Batch [152/428], Loss: 2.5556
Epoch [2/6], Batch [153/428], Loss: 1.7158
Epoch [2/6], Batch [154/428], Loss: 2.3004
Epoch [2/6], Batch [155/428], Loss: 2.1767
Epoch [2/6], Batch [156/428], Loss: 1.7588
Epoch [2/6], Batch [157/428], Loss: 1.1854
Epoch [2/6], Batch [158/428], Loss: 1.8814
Epoch [2/6], Batch [159/428], Loss: 2.3486
Epoch [2/6], Batch [160/428], Loss: 0.9358
Epoch [2/6], Batch [161/428], Loss: 2.2030
Epoch [2/6], Batch [162/428], Loss: 2.0098
Epoch [2/6], Batch [163/428], Loss: 2.9753
Epoch [2/6], Batch [164/428], Loss: 2.5447
Epoch [2/6], Batch [165/428], Loss: 2.0937
Epoch [2/6], Batch [166/428], Loss: 2.8340
Epoch [2/6], Batch [167/428], Loss: 1.9096
Epoch [2/6], Batch [168/428], Loss: 2.7192
Epoch [2/6], Batch [169/428], Loss: 2.7896
Epoch [2/6], Batch [170/428], Loss: 2.6928
Epoch [2/6], Batch [171/428], Loss: 2.3527
Epoch [2/6], Batch [172/428], Loss: 1.4906
Epoch [2/6], Batch [173/428], Loss: 1.9346
Epoch [2/6], Batch [174/428], Loss: 2.3900
Epoch [2/6], Batch [175/428], Loss: 2.0043
Epoch [2/6], Batch [176/428], Loss: 1.8027
Epoch [2/6], Batch [177/428], Loss: 1.8976
Epoch [2/6], Batch [178/428], Loss: 1.6017
Epoch [2/6], Batch [179/428], Loss: 1.5957
Epoch [2/6], Batch [180/428], Loss: 1.8288
Epoch [2/6], Batch [181/428], Loss: 1.7724
Epoch [2/6], Batch [182/428], Loss: 1.6771
Epoch [2/6], Batch [183/428], Loss: 1.5702
Epoch [2/6], Batch [184/428], Loss: 2.4153
Epoch [2/6], Batch [185/428], Loss: 2.2943
Epoch [2/6], Batch [186/428], Loss: 2.3362
Epoch [2/6], Batch [187/428], Loss: 2.9912
Epoch [2/6], Batch [188/428], Loss: 2.9456
Epoch [2/6], Batch [189/428], Loss: 1.8722
Epoch [2/6], Batch [190/428], Loss: 1.7319
Epoch [2/6], Batch [191/428], Loss: 1.9403
Epoch [2/6], Batch [192/428], Loss: 1.2256
Epoch [2/6], Batch [193/428], Loss: 1.9381
Epoch [2/6], Batch [194/428], Loss: 1.9129
Epoch [2/6], Batch [195/428], Loss: 1.2392
Epoch [2/6], Batch [196/428], Loss: 1.7119
Epoch [2/6], Batch [197/428], Loss: 1.9347
Epoch [2/6], Batch [198/428], Loss: 1.9364
Epoch [2/6], Batch [199/428], Loss: 1.5689
Epoch [2/6], Batch [200/428], Loss: 1.3213
Epoch [2/6], Batch [201/428], Loss: 1.7801
Epoch [2/6], Batch [202/428], Loss: 2.9277
Epoch [2/6], Batch [203/428], Loss: 1.3686
Epoch [2/6], Batch [204/428], Loss: 1.3841
Epoch [2/6], Batch [205/428], Loss: 3.8873
Epoch [2/6], Batch [206/428], Loss: 2.8945
Epoch [2/6], Batch [207/428], Loss: 1.3616
Epoch [2/6], Batch [208/428], Loss: 1.2784
Epoch [2/6], Batch [209/428], Loss: 1.3191
Epoch [2/6], Batch [210/428], Loss: 1.2492
Epoch [2/6], Batch [211/428], Loss: 1.2360
Epoch [2/6], Batch [212/428], Loss: 1.1783
Epoch [2/6], Batch [213/428], Loss: 3.7732
Epoch [2/6], Batch [214/428], Loss: 2.0801
Epoch [2/6], Batch [215/428], Loss: 0.9890
Epoch [2/6], Batch [216/428], Loss: 3.2605
Epoch [2/6], Batch [217/428], Loss: 3.1331
Epoch [2/6], Batch [218/428], Loss: 2.2309
Epoch [2/6], Batch [219/428], Loss: 3.1438
Epoch [2/6], Batch [220/428], Loss: 3.0102
Epoch [2/6], Batch [221/428], Loss: 2.9131
Epoch [2/6], Batch [222/428], Loss: 1.4114
Epoch [2/6], Batch [223/428], Loss: 2.8351
Epoch [2/6], Batch [224/428], Loss: 1.0697
Epoch [2/6], Batch [225/428], Loss: 2.5270
Epoch [2/6], Batch [226/428], Loss: 1.4005
Epoch [2/6], Batch [227/428], Loss: 1.9909
Epoch [2/6], Batch [228/428], Loss: 2.9607
Epoch [2/6], Batch [229/428], Loss: 1.9133
Epoch [2/6], Batch [230/428], Loss: 1.8053
Epoch [2/6], Batch [231/428], Loss: 2.6843
Epoch [2/6], Batch [232/428], Loss: 2.3737
Epoch [2/6], Batch [233/428], Loss: 2.2897
Epoch [2/6], Batch [234/428], Loss: 2.2588
Epoch [2/6], Batch [235/428], Loss: 2.1519
Epoch [2/6], Batch [236/428], Loss: 1.3841
Epoch [2/6], Batch [237/428], Loss: 2.0805
Epoch [2/6], Batch [238/428], Loss: 1.2778
Epoch [2/6], Batch [239/428], Loss: 2.1721
Epoch [2/6], Batch [240/428], Loss: 3.0021
Epoch [2/6], Batch [241/428], Loss: 1.1224
Epoch [2/6], Batch [242/428], Loss: 1.8216
Epoch [2/6], Batch [243/428], Loss: 2.4574
Epoch [2/6], Batch [244/428], Loss: 2.3734
Epoch [2/6], Batch [245/428], Loss: 2.3535
Epoch [2/6], Batch [246/428], Loss: 2.2507
Epoch [2/6], Batch [247/428], Loss: 2.5592
Epoch [2/6], Batch [248/428], Loss: 1.9419
Epoch [2/6], Batch [249/428], Loss: 3.2648
Epoch [2/6], Batch [250/428], Loss: 3.2099
Epoch [2/6], Batch [251/428], Loss: 1.7406
Epoch [2/6], Batch [252/428], Loss: 2.4523
Epoch [2/6], Batch [253/428], Loss: 1.2566
Epoch [2/6], Batch [254/428], Loss: 2.3874
Epoch [2/6], Batch [255/428], Loss: 2.3324
Epoch [2/6], Batch [256/428], Loss: 2.2398
Epoch [2/6], Batch [257/428], Loss: 0.9818
Epoch [2/6], Batch [258/428], Loss: 2.2320
Epoch [2/6], Batch [259/428], Loss: 1.9973
Epoch [2/6], Batch [260/428], Loss: 0.8801
Epoch [2/6], Batch [261/428], Loss: 1.8159
Epoch [2/6], Batch [262/428], Loss: 1.7166
Epoch [2/6], Batch [263/428], Loss: 1.5538
Epoch [2/6], Batch [264/428], Loss: 2.6725
Epoch [2/6], Batch [265/428], Loss: 0.9450
Epoch [2/6], Batch [266/428], Loss: 0.9726
Epoch [2/6], Batch [267/428], Loss: 1.0859
Epoch [2/6], Batch [268/428], Loss: 3.5970
Epoch [2/6], Batch [269/428], Loss: 0.9489
Epoch [2/6], Batch [270/428], Loss: 0.8461
Epoch [2/6], Batch [271/428], Loss: 3.6613
Epoch [2/6], Batch [272/428], Loss: 3.1362
Epoch [2/6], Batch [273/428], Loss: 3.0572
Epoch [2/6], Batch [274/428], Loss: 3.0342
Epoch [2/6], Batch [275/428], Loss: 2.9602
Epoch [2/6], Batch [276/428], Loss: 1.6659
Epoch [2/6], Batch [277/428], Loss: 1.6725
Epoch [2/6], Batch [278/428], Loss: 3.2745
Epoch [2/6], Batch [279/428], Loss: 0.6180
Epoch [2/6], Batch [280/428], Loss: 0.6326
Epoch [2/6], Batch [281/428], Loss: 2.9622
Epoch [2/6], Batch [282/428], Loss: 0.6138
Epoch [2/6], Batch [283/428], Loss: 2.3114
Epoch [2/6], Batch [284/428], Loss: 2.2544
Epoch [2/6], Batch [285/428], Loss: 3.6828
Epoch [2/6], Batch [286/428], Loss: 3.3997
Epoch [2/6], Batch [287/428], Loss: 0.6529
Epoch [2/6], Batch [288/428], Loss: 3.1175
Epoch [2/6], Batch [289/428], Loss: 1.7932
Epoch [2/6], Batch [290/428], Loss: 1.6917
Epoch [2/6], Batch [291/428], Loss: 3.1381
Epoch [2/6], Batch [292/428], Loss: 2.3678
Epoch [2/6], Batch [293/428], Loss: 2.2933
Epoch [2/6], Batch [294/428], Loss: 1.2789
Epoch [2/6], Batch [295/428], Loss: 2.7718
Epoch [2/6], Batch [296/428], Loss: 3.4192
Epoch [2/6], Batch [297/428], Loss: 3.3386
Epoch [2/6], Batch [298/428], Loss: 1.4380
Epoch [2/6], Batch [299/428], Loss: 1.5165
Epoch [2/6], Batch [300/428], Loss: 1.5270
Epoch [2/6], Batch [301/428], Loss: 2.5413
Epoch [2/6], Batch [302/428], Loss: 1.4325
Epoch [2/6], Batch [303/428], Loss: 2.0796
Epoch [2/6], Batch [304/428], Loss: 2.9612
Epoch [2/6], Batch [305/428], Loss: 1.3155
Epoch [2/6], Batch [306/428], Loss: 1.2225
Epoch [2/6], Batch [307/428], Loss: 2.5856
Epoch [2/6], Batch [308/428], Loss: 1.7272
Epoch [2/6], Batch [309/428], Loss: 2.4311
Epoch [2/6], Batch [310/428], Loss: 1.0140
Epoch [2/6], Batch [311/428], Loss: 2.7596
Epoch [2/6], Batch [312/428], Loss: 2.6335
Epoch [2/6], Batch [313/428], Loss: 0.8974
Epoch [2/6], Batch [314/428], Loss: 2.0574
Epoch [2/6], Batch [315/428], Loss: 2.5667
Epoch [2/6], Batch [316/428], Loss: 2.6837
Epoch [2/6], Batch [317/428], Loss: 2.3989
Epoch [2/6], Batch [318/428], Loss: 2.8557
Epoch [2/6], Batch [319/428], Loss: 2.7917
Epoch [2/6], Batch [320/428], Loss: 2.4067
Epoch [2/6], Batch [321/428], Loss: 0.9677
Epoch [2/6], Batch [322/428], Loss: 0.9989
Epoch [2/6], Batch [323/428], Loss: 0.9546
Epoch [2/6], Batch [324/428], Loss: 0.9167
Epoch [2/6], Batch [325/428], Loss: 2.3287
Epoch [2/6], Batch [326/428], Loss: 2.3068
Epoch [2/6], Batch [327/428], Loss: 2.2209
Epoch [2/6], Batch [328/428], Loss: 2.3810
Epoch [2/6], Batch [329/428], Loss: 1.9915
Epoch [2/6], Batch [330/428], Loss: 2.7395
Epoch [2/6], Batch [331/428], Loss: 1.6952
Epoch [2/6], Batch [332/428], Loss: 2.2847
Epoch [2/6], Batch [333/428], Loss: 0.9320
Epoch [2/6], Batch [334/428], Loss: 2.5534
Epoch [2/6], Batch [335/428], Loss: 1.0059
Epoch [2/6], Batch [336/428], Loss: 2.5927
Epoch [2/6], Batch [337/428], Loss: 2.7263
Epoch [2/6], Batch [338/428], Loss: 3.7890
Epoch [2/6], Batch [339/428], Loss: 3.7771
Epoch [2/6], Batch [340/428], Loss: 2.1745
Epoch [2/6], Batch [341/428], Loss: 1.1314
Epoch [2/6], Batch [342/428], Loss: 3.4118
Epoch [2/6], Batch [343/428], Loss: 1.3448
Epoch [2/6], Batch [344/428], Loss: 2.5568
Epoch [2/6], Batch [345/428], Loss: 1.3478
Epoch [2/6], Batch [346/428], Loss: 1.2579
Epoch [2/6], Batch [347/428], Loss: 1.9862
Epoch [2/6], Batch [348/428], Loss: 2.7919
Epoch [2/6], Batch [349/428], Loss: 2.5845
Epoch [2/6], Batch [350/428], Loss: 2.3717
Epoch [2/6], Batch [351/428], Loss: 2.3006
Epoch [2/6], Batch [352/428], Loss: 1.4399
Epoch [2/6], Batch [353/428], Loss: 2.0992
Epoch [2/6], Batch [354/428], Loss: 1.4651
Epoch [2/6], Batch [355/428], Loss: 1.8438
Epoch [2/6], Batch [356/428], Loss: 1.4435
Epoch [2/6], Batch [357/428], Loss: 1.8208
Epoch [2/6], Batch [358/428], Loss: 1.8724
Epoch [2/6], Batch [359/428], Loss: 2.1944
Epoch [2/6], Batch [360/428], Loss: 1.3830
Epoch [2/6], Batch [361/428], Loss: 2.1890
Epoch [2/6], Batch [362/428], Loss: 1.3397
Epoch [2/6], Batch [363/428], Loss: 3.0201
Epoch [2/6], Batch [364/428], Loss: 1.9057
Epoch [2/6], Batch [365/428], Loss: 2.0577
Epoch [2/6], Batch [366/428], Loss: 1.4986
Epoch [2/6], Batch [367/428], Loss: 3.0448
Epoch [2/6], Batch [368/428], Loss: 3.0159
Epoch [2/6], Batch [369/428], Loss: 1.4849
Epoch [2/6], Batch [370/428], Loss: 1.4494
Epoch [2/6], Batch [371/428], Loss: 1.8064
Epoch [2/6], Batch [372/428], Loss: 1.9874
Epoch [2/6], Batch [373/428], Loss: 1.7043
Epoch [2/6], Batch [374/428], Loss: 2.7049
Epoch [2/6], Batch [375/428], Loss: 1.5491
Epoch [2/6], Batch [376/428], Loss: 2.0268
Epoch [2/6], Batch [377/428], Loss: 1.2889
Epoch [2/6], Batch [378/428], Loss: 2.4688
Epoch [2/6], Batch [379/428], Loss: 1.9768
Epoch [2/6], Batch [380/428], Loss: 3.2544
Epoch [2/6], Batch [381/428], Loss: 2.1384
Epoch [2/6], Batch [382/428], Loss: 3.1672
Epoch [2/6], Batch [383/428], Loss: 1.7997
Epoch [2/6], Batch [384/428], Loss: 3.0016
Epoch [2/6], Batch [385/428], Loss: 2.0049
Epoch [2/6], Batch [386/428], Loss: 1.5489
Epoch [2/6], Batch [387/428], Loss: 1.8495
Epoch [2/6], Batch [388/428], Loss: 1.6479
Epoch [2/6], Batch [389/428], Loss: 1.6313
Epoch [2/6], Batch [390/428], Loss: 2.3200
Epoch [2/6], Batch [391/428], Loss: 2.2975
Epoch [2/6], Batch [392/428], Loss: 2.2636
Epoch [2/6], Batch [393/428], Loss: 1.6294
Epoch [2/6], Batch [394/428], Loss: 2.1112
Epoch [2/6], Batch [395/428], Loss: 1.9527
Epoch [2/6], Batch [396/428], Loss: 1.8086
Epoch [2/6], Batch [397/428], Loss: 1.5716
Epoch [2/6], Batch [398/428], Loss: 1.9720
Epoch [2/6], Batch [399/428], Loss: 1.7418
Epoch [2/6], Batch [400/428], Loss: 1.4973
Epoch [2/6], Batch [401/428], Loss: 2.3773
Epoch [2/6], Batch [402/428], Loss: 3.9485
Epoch [2/6], Batch [403/428], Loss: 1.3931
Epoch [2/6], Batch [404/428], Loss: 1.5515
Epoch [2/6], Batch [405/428], Loss: 1.9147
Epoch [2/6], Batch [406/428], Loss: 2.2995
Epoch [2/6], Batch [407/428], Loss: 1.4496
Epoch [2/6], Batch [408/428], Loss: 1.3834
Epoch [2/6], Batch [409/428], Loss: 1.2931
Epoch [2/6], Batch [410/428], Loss: 1.2057
Epoch [2/6], Batch [411/428], Loss: 3.7193
Epoch [2/6], Batch [412/428], Loss: 2.5074
Epoch [2/6], Batch [413/428], Loss: 2.8690
Epoch [2/6], Batch [414/428], Loss: 1.7485
Epoch [2/6], Batch [415/428], Loss: 2.2494
Epoch [2/6], Batch [416/428], Loss: 2.2388
Epoch [2/6], Batch [417/428], Loss: 2.8805
Epoch [2/6], Batch [418/428], Loss: 2.5700
Epoch [2/6], Batch [419/428], Loss: 2.5303
Epoch [2/6], Batch [420/428], Loss: 2.3856
Epoch [2/6], Batch [421/428], Loss: 1.9433
Epoch [2/6], Batch [422/428], Loss: 2.3525
Epoch [2/6], Batch [423/428], Loss: 0.9903
Epoch [2/6], Batch [424/428], Loss: 1.0169
Epoch [2/6], Batch [425/428], Loss: 2.6292
Epoch [2/6], Batch [426/428], Loss: 1.0304
Epoch [2/6], Batch [427/428], Loss: 2.1974
Epoch [2/6], Batch [428/428], Loss: 2.1515
Epoch [2] Training Time: 397.63 seconds
Epoch [2/6], Average Loss: 2.0835, Training Accuracy: 0.1869
Epoch [2], Validation Loss: 2.0976, Validation Accuracy: 0.1429
Epoch [2] Validation Time: 17.04 seconds
--------------------------------------------------
Epoch [3/6], Batch [1/428], Loss: 0.9585
Epoch [3/6], Batch [2/428], Loss: 2.1266
Epoch [3/6], Batch [3/428], Loss: 2.1159
Epoch [3/6], Batch [4/428], Loss: 2.0917
Epoch [3/6], Batch [5/428], Loss: 2.2169
Epoch [3/6], Batch [6/428], Loss: 2.4968
Epoch [3/6], Batch [7/428], Loss: 2.3408
Epoch [3/6], Batch [8/428], Loss: 1.8769
Epoch [3/6], Batch [9/428], Loss: 1.8062
Epoch [3/6], Batch [10/428], Loss: 1.1398
Epoch [3/6], Batch [11/428], Loss: 1.1719
Epoch [3/6], Batch [12/428], Loss: 1.7820
Epoch [3/6], Batch [13/428], Loss: 1.7611
Epoch [3/6], Batch [14/428], Loss: 1.1969
Epoch [3/6], Batch [15/428], Loss: 2.4188
Epoch [3/6], Batch [16/428], Loss: 2.4074
Epoch [3/6], Batch [17/428], Loss: 1.6876
Epoch [3/6], Batch [18/428], Loss: 2.4091
Epoch [3/6], Batch [19/428], Loss: 2.5032
Epoch [3/6], Batch [20/428], Loss: 1.2420
Epoch [3/6], Batch [21/428], Loss: 3.6179
Epoch [3/6], Batch [22/428], Loss: 2.3698
Epoch [3/6], Batch [23/428], Loss: 1.2503
Epoch [3/6], Batch [24/428], Loss: 1.6290
Epoch [3/6], Batch [25/428], Loss: 3.4279
Epoch [3/6], Batch [26/428], Loss: 1.7738
Epoch [3/6], Batch [27/428], Loss: 2.2483
Epoch [3/6], Batch [28/428], Loss: 1.6277
Epoch [3/6], Batch [29/428], Loss: 2.4621
Epoch [3/6], Batch [30/428], Loss: 2.2266
Epoch [3/6], Batch [31/428], Loss: 1.3383
Epoch [3/6], Batch [32/428], Loss: 3.0161
Epoch [3/6], Batch [33/428], Loss: 2.1232
Epoch [3/6], Batch [34/428], Loss: 1.3800
Epoch [3/6], Batch [35/428], Loss: 2.0216
Epoch [3/6], Batch [36/428], Loss: 1.3572
Epoch [3/6], Batch [37/428], Loss: 1.8709
Epoch [3/6], Batch [38/428], Loss: 1.7426
Epoch [3/6], Batch [39/428], Loss: 1.6222
Epoch [3/6], Batch [40/428], Loss: 1.9237
Epoch [3/6], Batch [41/428], Loss: 2.5521
Epoch [3/6], Batch [42/428], Loss: 2.4084
Epoch [3/6], Batch [43/428], Loss: 2.4069
Epoch [3/6], Batch [44/428], Loss: 1.5071
Epoch [3/6], Batch [45/428], Loss: 1.4963
Epoch [3/6], Batch [46/428], Loss: 2.5736
Epoch [3/6], Batch [47/428], Loss: 2.2821
Epoch [3/6], Batch [48/428], Loss: 2.5634
Epoch [3/6], Batch [49/428], Loss: 1.0995
Epoch [3/6], Batch [50/428], Loss: 1.4662
Epoch [3/6], Batch [51/428], Loss: 1.4317
Epoch [3/6], Batch [52/428], Loss: 2.4805
Epoch [3/6], Batch [53/428], Loss: 2.6696
Epoch [3/6], Batch [54/428], Loss: 2.0519
Epoch [3/6], Batch [55/428], Loss: 1.9550
Epoch [3/6], Batch [56/428], Loss: 1.3081
Epoch [3/6], Batch [57/428], Loss: 2.4950
Epoch [3/6], Batch [58/428], Loss: 2.5652
Epoch [3/6], Batch [59/428], Loss: 1.7350
Epoch [3/6], Batch [60/428], Loss: 3.0536
Epoch [3/6], Batch [61/428], Loss: 2.4924
Epoch [3/6], Batch [62/428], Loss: 1.5292
Epoch [3/6], Batch [63/428], Loss: 1.4578
Epoch [3/6], Batch [64/428], Loss: 2.3741
Epoch [3/6], Batch [65/428], Loss: 2.9619
Epoch [3/6], Batch [66/428], Loss: 2.3691
Epoch [3/6], Batch [67/428], Loss: 1.4787
Epoch [3/6], Batch [68/428], Loss: 1.4914
Epoch [3/6], Batch [69/428], Loss: 2.1932
Epoch [3/6], Batch [70/428], Loss: 1.1454
Epoch [3/6], Batch [71/428], Loss: 2.3530
Epoch [3/6], Batch [72/428], Loss: 1.5072
Epoch [3/6], Batch [73/428], Loss: 2.6602
Epoch [3/6], Batch [74/428], Loss: 2.5202
Epoch [3/6], Batch [75/428], Loss: 2.8200
Epoch [3/6], Batch [76/428], Loss: 2.2665
Epoch [3/6], Batch [77/428], Loss: 1.2175
Epoch [3/6], Batch [78/428], Loss: 1.2322
Epoch [3/6], Batch [79/428], Loss: 1.5255
Epoch [3/6], Batch [80/428], Loss: 1.5228
Epoch [3/6], Batch [81/428], Loss: 2.1369
Epoch [3/6], Batch [82/428], Loss: 2.0790
Epoch [3/6], Batch [83/428], Loss: 1.9999
Epoch [3/6], Batch [84/428], Loss: 1.4630
Epoch [3/6], Batch [85/428], Loss: 2.9660
Epoch [3/6], Batch [86/428], Loss: 1.4415
Epoch [3/6], Batch [87/428], Loss: 2.5521
Epoch [3/6], Batch [88/428], Loss: 1.3281
Epoch [3/6], Batch [89/428], Loss: 1.2819
Epoch [3/6], Batch [90/428], Loss: 1.1879
Epoch [3/6], Batch [91/428], Loss: 2.8665
Epoch [3/6], Batch [92/428], Loss: 2.5492
Epoch [3/6], Batch [93/428], Loss: 1.8970
Epoch [3/6], Batch [94/428], Loss: 0.9598
Epoch [3/6], Batch [95/428], Loss: 2.7585
Epoch [3/6], Batch [96/428], Loss: 1.7626
Epoch [3/6], Batch [97/428], Loss: 0.8484
Epoch [3/6], Batch [98/428], Loss: 1.7867
Epoch [3/6], Batch [99/428], Loss: 0.7742
Epoch [3/6], Batch [100/428], Loss: 2.7810
Epoch [3/6], Batch [101/428], Loss: 2.3725
Epoch [3/6], Batch [102/428], Loss: 2.7546
Epoch [3/6], Batch [103/428], Loss: 1.8007
Epoch [3/6], Batch [104/428], Loss: 1.7657
Epoch [3/6], Batch [105/428], Loss: 0.7210
Epoch [3/6], Batch [106/428], Loss: 2.8690
Epoch [3/6], Batch [107/428], Loss: 3.2938
Epoch [3/6], Batch [108/428], Loss: 2.7690
Epoch [3/6], Batch [109/428], Loss: 2.8124
Epoch [3/6], Batch [110/428], Loss: 1.5565
Epoch [3/6], Batch [111/428], Loss: 2.3895
Epoch [3/6], Batch [112/428], Loss: 2.6582
Epoch [3/6], Batch [113/428], Loss: 3.1760
Epoch [3/6], Batch [114/428], Loss: 2.5419
Epoch [3/6], Batch [115/428], Loss: 1.3897
Epoch [3/6], Batch [116/428], Loss: 1.1204
Epoch [3/6], Batch [117/428], Loss: 2.4903
Epoch [3/6], Batch [118/428], Loss: 2.4596
Epoch [3/6], Batch [119/428], Loss: 1.2464
Epoch [3/6], Batch [120/428], Loss: 2.2640
Epoch [3/6], Batch [121/428], Loss: 2.1408
Epoch [3/6], Batch [122/428], Loss: 1.2729
Epoch [3/6], Batch [123/428], Loss: 2.0028
Epoch [3/6], Batch [124/428], Loss: 1.4848
Epoch [3/6], Batch [125/428], Loss: 2.9119
Epoch [3/6], Batch [126/428], Loss: 1.5128
Epoch [3/6], Batch [127/428], Loss: 1.6991
Epoch [3/6], Batch [128/428], Loss: 1.4142
Epoch [3/6], Batch [129/428], Loss: 2.8109
Epoch [3/6], Batch [130/428], Loss: 1.4258
Epoch [3/6], Batch [131/428], Loss: 2.4703
Epoch [3/6], Batch [132/428], Loss: 2.6579
Epoch [3/6], Batch [133/428], Loss: 1.3783
Epoch [3/6], Batch [134/428], Loss: 1.4820
Epoch [3/6], Batch [135/428], Loss: 2.4372
Epoch [3/6], Batch [136/428], Loss: 2.4113
Epoch [3/6], Batch [137/428], Loss: 3.0969
Epoch [3/6], Batch [138/428], Loss: 2.2784
Epoch [3/6], Batch [139/428], Loss: 1.4358
Epoch [3/6], Batch [140/428], Loss: 1.3585
Epoch [3/6], Batch [141/428], Loss: 1.3502
Epoch [3/6], Batch [142/428], Loss: 2.2847
Epoch [3/6], Batch [143/428], Loss: 2.9822
Epoch [3/6], Batch [144/428], Loss: 1.4395
Epoch [3/6], Batch [145/428], Loss: 2.2377
Epoch [3/6], Batch [146/428], Loss: 2.2505
Epoch [3/6], Batch [147/428], Loss: 1.4229
Epoch [3/6], Batch [148/428], Loss: 1.3308
Epoch [3/6], Batch [149/428], Loss: 2.2264
Epoch [3/6], Batch [150/428], Loss: 2.9543
Epoch [3/6], Batch [151/428], Loss: 2.1359
Epoch [3/6], Batch [152/428], Loss: 1.9788
Epoch [3/6], Batch [153/428], Loss: 2.1709
Epoch [3/6], Batch [154/428], Loss: 1.9527
Epoch [3/6], Batch [155/428], Loss: 2.9173
Epoch [3/6], Batch [156/428], Loss: 1.5054
Epoch [3/6], Batch [157/428], Loss: 1.5152
Epoch [3/6], Batch [158/428], Loss: 2.7937
Epoch [3/6], Batch [159/428], Loss: 1.5192
Epoch [3/6], Batch [160/428], Loss: 1.5099
Epoch [3/6], Batch [161/428], Loss: 1.8386
Epoch [3/6], Batch [162/428], Loss: 2.1775
Epoch [3/6], Batch [163/428], Loss: 1.8507
Epoch [3/6], Batch [164/428], Loss: 1.8243
Epoch [3/6], Batch [165/428], Loss: 1.7883
Epoch [3/6], Batch [166/428], Loss: 2.1668
Epoch [3/6], Batch [167/428], Loss: 2.1227
Epoch [3/6], Batch [168/428], Loss: 1.9643
Epoch [3/6], Batch [169/428], Loss: 1.9703
Epoch [3/6], Batch [170/428], Loss: 2.5205
Epoch [3/6], Batch [171/428], Loss: 1.5354
Epoch [3/6], Batch [172/428], Loss: 1.4928
Epoch [3/6], Batch [173/428], Loss: 1.4320
Epoch [3/6], Batch [174/428], Loss: 1.8719
Epoch [3/6], Batch [175/428], Loss: 1.2733
Epoch [3/6], Batch [176/428], Loss: 1.7863
Epoch [3/6], Batch [177/428], Loss: 2.1168
Epoch [3/6], Batch [178/428], Loss: 1.8552
Epoch [3/6], Batch [179/428], Loss: 3.4739
Epoch [3/6], Batch [180/428], Loss: 1.8501
Epoch [3/6], Batch [181/428], Loss: 2.5855
Epoch [3/6], Batch [182/428], Loss: 3.3541
Epoch [3/6], Batch [183/428], Loss: 1.0263
Epoch [3/6], Batch [184/428], Loss: 1.7560
Epoch [3/6], Batch [185/428], Loss: 3.1613
Epoch [3/6], Batch [186/428], Loss: 2.6591
Epoch [3/6], Batch [187/428], Loss: 2.1696
Epoch [3/6], Batch [188/428], Loss: 2.6497
Epoch [3/6], Batch [189/428], Loss: 2.1069
Epoch [3/6], Batch [190/428], Loss: 2.5607
Epoch [3/6], Batch [191/428], Loss: 2.4868
Epoch [3/6], Batch [192/428], Loss: 1.6238
Epoch [3/6], Batch [193/428], Loss: 2.1929
Epoch [3/6], Batch [194/428], Loss: 1.9130
Epoch [3/6], Batch [195/428], Loss: 1.4003
Epoch [3/6], Batch [196/428], Loss: 2.1231
Epoch [3/6], Batch [197/428], Loss: 1.4708
Epoch [3/6], Batch [198/428], Loss: 1.7706
Epoch [3/6], Batch [199/428], Loss: 1.4980
Epoch [3/6], Batch [200/428], Loss: 2.2682
Epoch [3/6], Batch [201/428], Loss: 1.8763
Epoch [3/6], Batch [202/428], Loss: 2.6039
Epoch [3/6], Batch [203/428], Loss: 1.4854
Epoch [3/6], Batch [204/428], Loss: 2.7228
Epoch [3/6], Batch [205/428], Loss: 2.5237
Epoch [3/6], Batch [206/428], Loss: 2.2517
Epoch [3/6], Batch [207/428], Loss: 2.3789
Epoch [3/6], Batch [208/428], Loss: 2.2019
Epoch [3/6], Batch [209/428], Loss: 1.4744
Epoch [3/6], Batch [210/428], Loss: 1.8482
Epoch [3/6], Batch [211/428], Loss: 2.7429
Epoch [3/6], Batch [212/428], Loss: 2.7250
Epoch [3/6], Batch [213/428], Loss: 1.5095
Epoch [3/6], Batch [214/428], Loss: 1.9588
Epoch [3/6], Batch [215/428], Loss: 1.9255
Epoch [3/6], Batch [216/428], Loss: 2.3245
Epoch [3/6], Batch [217/428], Loss: 1.4948
Epoch [3/6], Batch [218/428], Loss: 1.4590
Epoch [3/6], Batch [219/428], Loss: 2.0392
Epoch [3/6], Batch [220/428], Loss: 1.3778
Epoch [3/6], Batch [221/428], Loss: 2.0777
Epoch [3/6], Batch [222/428], Loss: 1.9076
Epoch [3/6], Batch [223/428], Loss: 2.4437
Epoch [3/6], Batch [224/428], Loss: 2.0575
Epoch [3/6], Batch [225/428], Loss: 1.8759
Epoch [3/6], Batch [226/428], Loss: 2.5103
Epoch [3/6], Batch [227/428], Loss: 1.7854
Epoch [3/6], Batch [228/428], Loss: 2.4127
Epoch [3/6], Batch [229/428], Loss: 1.2805
Epoch [3/6], Batch [230/428], Loss: 1.6070
Epoch [3/6], Batch [231/428], Loss: 1.3039
Epoch [3/6], Batch [232/428], Loss: 1.4947
Epoch [3/6], Batch [233/428], Loss: 2.3915
Epoch [3/6], Batch [234/428], Loss: 1.2871
Epoch [3/6], Batch [235/428], Loss: 2.5644
Epoch [3/6], Batch [236/428], Loss: 2.5707
Epoch [3/6], Batch [237/428], Loss: 2.3233
Epoch [3/6], Batch [238/428], Loss: 1.2386
Epoch [3/6], Batch [239/428], Loss: 1.2728
Epoch [3/6], Batch [240/428], Loss: 1.2156
Epoch [3/6], Batch [241/428], Loss: 1.2569
Epoch [3/6], Batch [242/428], Loss: 2.2274
Epoch [3/6], Batch [243/428], Loss: 2.1845
Epoch [3/6], Batch [244/428], Loss: 2.9577
Epoch [3/6], Batch [245/428], Loss: 2.6957
Epoch [3/6], Batch [246/428], Loss: 2.0368
Epoch [3/6], Batch [247/428], Loss: 1.1857
Epoch [3/6], Batch [248/428], Loss: 1.8918
Epoch [3/6], Batch [249/428], Loss: 2.5265
Epoch [3/6], Batch [250/428], Loss: 2.4880
Epoch [3/6], Batch [251/428], Loss: 2.4321
Epoch [3/6], Batch [252/428], Loss: 1.6260
Epoch [3/6], Batch [253/428], Loss: 2.9574
Epoch [3/6], Batch [254/428], Loss: 1.5744
Epoch [3/6], Batch [255/428], Loss: 1.4469
Epoch [3/6], Batch [256/428], Loss: 2.0805
Epoch [3/6], Batch [257/428], Loss: 2.0085
Epoch [3/6], Batch [258/428], Loss: 1.9150
Epoch [3/6], Batch [259/428], Loss: 1.7930
Epoch [3/6], Batch [260/428], Loss: 1.7862
Epoch [3/6], Batch [261/428], Loss: 1.8089
Epoch [3/6], Batch [262/428], Loss: 1.3415
Epoch [3/6], Batch [263/428], Loss: 3.0442
Epoch [3/6], Batch [264/428], Loss: 3.0473
Epoch [3/6], Batch [265/428], Loss: 1.3538
Epoch [3/6], Batch [266/428], Loss: 2.9434
Epoch [3/6], Batch [267/428], Loss: 1.3216
Epoch [3/6], Batch [268/428], Loss: 3.2444
Epoch [3/6], Batch [269/428], Loss: 1.2448
Epoch [3/6], Batch [270/428], Loss: 2.9162
Epoch [3/6], Batch [271/428], Loss: 2.5902
Epoch [3/6], Batch [272/428], Loss: 2.4163
Epoch [3/6], Batch [273/428], Loss: 1.3987
Epoch [3/6], Batch [274/428], Loss: 2.8108
Epoch [3/6], Batch [275/428], Loss: 1.1092
Epoch [3/6], Batch [276/428], Loss: 3.1182
Epoch [3/6], Batch [277/428], Loss: 1.4678
Epoch [3/6], Batch [278/428], Loss: 2.5044
Epoch [3/6], Batch [279/428], Loss: 2.4795
Epoch [3/6], Batch [280/428], Loss: 1.0909
Epoch [3/6], Batch [281/428], Loss: 1.0787
Epoch [3/6], Batch [282/428], Loss: 2.3801
Epoch [3/6], Batch [283/428], Loss: 1.0334
Epoch [3/6], Batch [284/428], Loss: 2.3394
Epoch [3/6], Batch [285/428], Loss: 2.1980
Epoch [3/6], Batch [286/428], Loss: 2.5741
Epoch [3/6], Batch [287/428], Loss: 2.4708
Epoch [3/6], Batch [288/428], Loss: 0.9486
Epoch [3/6], Batch [289/428], Loss: 0.9157
Epoch [3/6], Batch [290/428], Loss: 2.4455
Epoch [3/6], Batch [291/428], Loss: 2.4140
Epoch [3/6], Batch [292/428], Loss: 2.5574
Epoch [3/6], Batch [293/428], Loss: 2.1004
Epoch [3/6], Batch [294/428], Loss: 2.4786
Epoch [3/6], Batch [295/428], Loss: 0.8702
Epoch [3/6], Batch [296/428], Loss: 3.0553
Epoch [3/6], Batch [297/428], Loss: 2.2780
Epoch [3/6], Batch [298/428], Loss: 0.8904
Epoch [3/6], Batch [299/428], Loss: 2.2531
Epoch [3/6], Batch [300/428], Loss: 2.2639
Epoch [3/6], Batch [301/428], Loss: 2.1364
Epoch [3/6], Batch [302/428], Loss: 0.9146
Epoch [3/6], Batch [303/428], Loss: 0.9012
Epoch [3/6], Batch [304/428], Loss: 2.5222
Epoch [3/6], Batch [305/428], Loss: 2.5128
Epoch [3/6], Batch [306/428], Loss: 3.0024
Epoch [3/6], Batch [307/428], Loss: 0.8830
Epoch [3/6], Batch [308/428], Loss: 0.8687
Epoch [3/6], Batch [309/428], Loss: 0.8447
Epoch [3/6], Batch [310/428], Loss: 2.4031
Epoch [3/6], Batch [311/428], Loss: 2.2810
Epoch [3/6], Batch [312/428], Loss: 2.8872
Epoch [3/6], Batch [313/428], Loss: 0.7325
Epoch [3/6], Batch [314/428], Loss: 0.7237
Epoch [3/6], Batch [315/428], Loss: 2.9146
Epoch [3/6], Batch [316/428], Loss: 2.5988
Epoch [3/6], Batch [317/428], Loss: 2.2458
Epoch [3/6], Batch [318/428], Loss: 2.3680
Epoch [3/6], Batch [319/428], Loss: 2.2699
Epoch [3/6], Batch [320/428], Loss: 2.6022
Epoch [3/6], Batch [321/428], Loss: 2.1676
Epoch [3/6], Batch [322/428], Loss: 0.6995
Epoch [3/6], Batch [323/428], Loss: 2.7313
Epoch [3/6], Batch [324/428], Loss: 2.6861
Epoch [3/6], Batch [325/428], Loss: 1.9970
Epoch [3/6], Batch [326/428], Loss: 2.4793
Epoch [3/6], Batch [327/428], Loss: 1.8326
Epoch [3/6], Batch [328/428], Loss: 2.9498
Epoch [3/6], Batch [329/428], Loss: 2.3152
Epoch [3/6], Batch [330/428], Loss: 2.5372
Epoch [3/6], Batch [331/428], Loss: 1.0625
Epoch [3/6], Batch [332/428], Loss: 1.5444
Epoch [3/6], Batch [333/428], Loss: 2.8306
Epoch [3/6], Batch [334/428], Loss: 2.2120
Epoch [3/6], Batch [335/428], Loss: 2.4367
Epoch [3/6], Batch [336/428], Loss: 2.3719
Epoch [3/6], Batch [337/428], Loss: 1.3518
Epoch [3/6], Batch [338/428], Loss: 1.3788
Epoch [3/6], Batch [339/428], Loss: 2.3009
Epoch [3/6], Batch [340/428], Loss: 1.4249
Epoch [3/6], Batch [341/428], Loss: 1.3869
Epoch [3/6], Batch [342/428], Loss: 2.6199
Epoch [3/6], Batch [343/428], Loss: 2.5907
Epoch [3/6], Batch [344/428], Loss: 1.3526
Epoch [3/6], Batch [345/428], Loss: 2.4619
Epoch [3/6], Batch [346/428], Loss: 2.3493
Epoch [3/6], Batch [347/428], Loss: 2.0668
Epoch [3/6], Batch [348/428], Loss: 2.2407
Epoch [3/6], Batch [349/428], Loss: 2.2784
Epoch [3/6], Batch [350/428], Loss: 2.0729
Epoch [3/6], Batch [351/428], Loss: 1.9510
Epoch [3/6], Batch [352/428], Loss: 1.7853
Epoch [3/6], Batch [353/428], Loss: 2.2959
Epoch [3/6], Batch [354/428], Loss: 1.7700
Epoch [3/6], Batch [355/428], Loss: 1.8444
Epoch [3/6], Batch [356/428], Loss: 1.8034
Epoch [3/6], Batch [357/428], Loss: 2.2584
Epoch [3/6], Batch [358/428], Loss: 1.6817
Epoch [3/6], Batch [359/428], Loss: 1.5280
Epoch [3/6], Batch [360/428], Loss: 2.8447
Epoch [3/6], Batch [361/428], Loss: 1.8759
Epoch [3/6], Batch [362/428], Loss: 1.8473
Epoch [3/6], Batch [363/428], Loss: 1.8262
Epoch [3/6], Batch [364/428], Loss: 1.8165
Epoch [3/6], Batch [365/428], Loss: 1.7175
Epoch [3/6], Batch [366/428], Loss: 1.7648
Epoch [3/6], Batch [367/428], Loss: 1.7330
Epoch [3/6], Batch [368/428], Loss: 1.9512
Epoch [3/6], Batch [369/428], Loss: 1.6416
Epoch [3/6], Batch [370/428], Loss: 1.5682
Epoch [3/6], Batch [371/428], Loss: 1.9835
Epoch [3/6], Batch [372/428], Loss: 2.8935
Epoch [3/6], Batch [373/428], Loss: 1.6804
Epoch [3/6], Batch [374/428], Loss: 1.2918
Epoch [3/6], Batch [375/428], Loss: 1.7396
Epoch [3/6], Batch [376/428], Loss: 1.6908
Epoch [3/6], Batch [377/428], Loss: 1.9465
Epoch [3/6], Batch [378/428], Loss: 2.8366
Epoch [3/6], Batch [379/428], Loss: 2.7960
Epoch [3/6], Batch [380/428], Loss: 2.5733
Epoch [3/6], Batch [381/428], Loss: 1.1261
Epoch [3/6], Batch [382/428], Loss: 1.8889
Epoch [3/6], Batch [383/428], Loss: 2.5842
Epoch [3/6], Batch [384/428], Loss: 1.0948
Epoch [3/6], Batch [385/428], Loss: 1.9228
Epoch [3/6], Batch [386/428], Loss: 1.0557
Epoch [3/6], Batch [387/428], Loss: 1.9587
Epoch [3/6], Batch [388/428], Loss: 1.0046
Epoch [3/6], Batch [389/428], Loss: 0.9746
Epoch [3/6], Batch [390/428], Loss: 2.0226
Epoch [3/6], Batch [391/428], Loss: 0.8795
Epoch [3/6], Batch [392/428], Loss: 2.0384
Epoch [3/6], Batch [393/428], Loss: 3.6662
Epoch [3/6], Batch [394/428], Loss: 0.7733
Epoch [3/6], Batch [395/428], Loss: 0.7432
Epoch [3/6], Batch [396/428], Loss: 0.6954
Epoch [3/6], Batch [397/428], Loss: 0.6428
Epoch [3/6], Batch [398/428], Loss: 2.4802
Epoch [3/6], Batch [399/428], Loss: 0.5407
Epoch [3/6], Batch [400/428], Loss: 2.6344
Epoch [3/6], Batch [401/428], Loss: 0.4465
Epoch [3/6], Batch [402/428], Loss: 2.7261
Epoch [3/6], Batch [403/428], Loss: 0.3805
Epoch [3/6], Batch [404/428], Loss: 3.4975
Epoch [3/6], Batch [405/428], Loss: 2.8244
Epoch [3/6], Batch [406/428], Loss: 0.3138
Epoch [3/6], Batch [407/428], Loss: 3.0325
Epoch [3/6], Batch [408/428], Loss: 0.2928
Epoch [3/6], Batch [409/428], Loss: 3.6142
Epoch [3/6], Batch [410/428], Loss: 3.1568
Epoch [3/6], Batch [411/428], Loss: 3.0640
Epoch [3/6], Batch [412/428], Loss: 4.2624
Epoch [3/6], Batch [413/428], Loss: 3.0287
Epoch [3/6], Batch [414/428], Loss: 3.5036
Epoch [3/6], Batch [415/428], Loss: 0.2908
Epoch [3/6], Batch [416/428], Loss: 0.2899
Epoch [3/6], Batch [417/428], Loss: 0.2951
Epoch [3/6], Batch [418/428], Loss: 4.0150
Epoch [3/6], Batch [419/428], Loss: 2.8981
Epoch [3/6], Batch [420/428], Loss: 3.8974
Epoch [3/6], Batch [421/428], Loss: 3.5101
Epoch [3/6], Batch [422/428], Loss: 0.2957
Epoch [3/6], Batch [423/428], Loss: 3.0938
Epoch [3/6], Batch [424/428], Loss: 0.3035
Epoch [3/6], Batch [425/428], Loss: 3.5319
Epoch [3/6], Batch [426/428], Loss: 2.7542
Epoch [3/6], Batch [427/428], Loss: 3.0413
Epoch [3/6], Batch [428/428], Loss: 3.3869
Epoch [3] Training Time: 393.42 seconds
Epoch [3/6], Average Loss: 2.0161, Training Accuracy: 0.2196
Epoch [3], Validation Loss: 2.6246, Validation Accuracy: 0.1429
Epoch [3] Validation Time: 16.98 seconds
--------------------------------------------------
Epoch [4/6], Batch [1/428], Loss: 3.3157
Epoch [4/6], Batch [2/428], Loss: 3.2458
Epoch [4/6], Batch [3/428], Loss: 2.9913
Epoch [4/6], Batch [4/428], Loss: 0.4221
Epoch [4/6], Batch [5/428], Loss: 0.4282
Epoch [4/6], Batch [6/428], Loss: 2.9127
Epoch [4/6], Batch [7/428], Loss: 2.5027
Epoch [4/6], Batch [8/428], Loss: 3.0521
Epoch [4/6], Batch [9/428], Loss: 0.4634
Epoch [4/6], Batch [10/428], Loss: 2.8003
Epoch [4/6], Batch [11/428], Loss: 0.4864
Epoch [4/6], Batch [12/428], Loss: 2.7456
Epoch [4/6], Batch [13/428], Loss: 0.4972
Epoch [4/6], Batch [14/428], Loss: 2.9911
Epoch [4/6], Batch [15/428], Loss: 2.7211
Epoch [4/6], Batch [16/428], Loss: 0.5149
Epoch [4/6], Batch [17/428], Loss: 2.5962
Epoch [4/6], Batch [18/428], Loss: 2.7710
Epoch [4/6], Batch [19/428], Loss: 0.5088
Epoch [4/6], Batch [20/428], Loss: 2.4828
Epoch [4/6], Batch [21/428], Loss: 2.9267
Epoch [4/6], Batch [22/428], Loss: 2.4516
Epoch [4/6], Batch [23/428], Loss: 2.8804
Epoch [4/6], Batch [24/428], Loss: 0.5571
Epoch [4/6], Batch [25/428], Loss: 2.4591
Epoch [4/6], Batch [26/428], Loss: 0.5785
Epoch [4/6], Batch [27/428], Loss: 2.7253
Epoch [4/6], Batch [28/428], Loss: 0.5856
Epoch [4/6], Batch [29/428], Loss: 2.7724
Epoch [4/6], Batch [30/428], Loss: 2.2975
Epoch [4/6], Batch [31/428], Loss: 0.5946
Epoch [4/6], Batch [32/428], Loss: 2.2806
Epoch [4/6], Batch [33/428], Loss: 2.4398
Epoch [4/6], Batch [34/428], Loss: 2.4185
Epoch [4/6], Batch [35/428], Loss: 0.6138
Epoch [4/6], Batch [36/428], Loss: 0.6077
Epoch [4/6], Batch [37/428], Loss: 2.1728
Epoch [4/6], Batch [38/428], Loss: 2.3297
Epoch [4/6], Batch [39/428], Loss: 0.6180
Epoch [4/6], Batch [40/428], Loss: 3.0639
Epoch [4/6], Batch [41/428], Loss: 2.1201
Epoch [4/6], Batch [42/428], Loss: 2.8166
Epoch [4/6], Batch [43/428], Loss: 2.7655
Epoch [4/6], Batch [44/428], Loss: 2.9463
Epoch [4/6], Batch [45/428], Loss: 0.6498
Epoch [4/6], Batch [46/428], Loss: 2.9248
Epoch [4/6], Batch [47/428], Loss: 2.8822
Epoch [4/6], Batch [48/428], Loss: 3.0357
Epoch [4/6], Batch [49/428], Loss: 2.9764
Epoch [4/6], Batch [50/428], Loss: 1.9647
Epoch [4/6], Batch [51/428], Loss: 2.6654
Epoch [4/6], Batch [52/428], Loss: 2.5729
Epoch [4/6], Batch [53/428], Loss: 1.8909
Epoch [4/6], Batch [54/428], Loss: 2.4893
Epoch [4/6], Batch [55/428], Loss: 0.8766
Epoch [4/6], Batch [56/428], Loss: 2.4662
Epoch [4/6], Batch [57/428], Loss: 0.9191
Epoch [4/6], Batch [58/428], Loss: 2.2543
Epoch [4/6], Batch [59/428], Loss: 2.2632
Epoch [4/6], Batch [60/428], Loss: 0.9778
Epoch [4/6], Batch [61/428], Loss: 2.5720
Epoch [4/6], Batch [62/428], Loss: 2.8482
Epoch [4/6], Batch [63/428], Loss: 0.9977
Epoch [4/6], Batch [64/428], Loss: 2.0707
Epoch [4/6], Batch [65/428], Loss: 2.2962
Epoch [4/6], Batch [66/428], Loss: 1.9963
Epoch [4/6], Batch [67/428], Loss: 2.4313
Epoch [4/6], Batch [68/428], Loss: 2.2743
Epoch [4/6], Batch [69/428], Loss: 2.2563
Epoch [4/6], Batch [70/428], Loss: 1.0893
Epoch [4/6], Batch [71/428], Loss: 2.1751
Epoch [4/6], Batch [72/428], Loss: 1.1121
Epoch [4/6], Batch [73/428], Loss: 2.4608
Epoch [4/6], Batch [74/428], Loss: 2.8650
Epoch [4/6], Batch [75/428], Loss: 2.3055
Epoch [4/6], Batch [76/428], Loss: 2.4252
Epoch [4/6], Batch [77/428], Loss: 2.3962
Epoch [4/6], Batch [78/428], Loss: 2.1738
Epoch [4/6], Batch [79/428], Loss: 1.9634
Epoch [4/6], Batch [80/428], Loss: 2.7896
Epoch [4/6], Batch [81/428], Loss: 2.2246
Epoch [4/6], Batch [82/428], Loss: 1.9006
Epoch [4/6], Batch [83/428], Loss: 2.1764
Epoch [4/6], Batch [84/428], Loss: 2.6742
Epoch [4/6], Batch [85/428], Loss: 1.3220
Epoch [4/6], Batch [86/428], Loss: 1.8647
Epoch [4/6], Batch [87/428], Loss: 2.2202
Epoch [4/6], Batch [88/428], Loss: 2.2160
Epoch [4/6], Batch [89/428], Loss: 1.9925
Epoch [4/6], Batch [90/428], Loss: 1.9778
Epoch [4/6], Batch [91/428], Loss: 1.8131
Epoch [4/6], Batch [92/428], Loss: 1.9054
Epoch [4/6], Batch [93/428], Loss: 1.5010
Epoch [4/6], Batch [94/428], Loss: 2.1155
Epoch [4/6], Batch [95/428], Loss: 1.9981
Epoch [4/6], Batch [96/428], Loss: 1.8170
Epoch [4/6], Batch [97/428], Loss: 1.9812
Epoch [4/6], Batch [98/428], Loss: 1.7413
Epoch [4/6], Batch [99/428], Loss: 1.8210
Epoch [4/6], Batch [100/428], Loss: 2.0460
Epoch [4/6], Batch [101/428], Loss: 1.8182
Epoch [4/6], Batch [102/428], Loss: 1.6784
Epoch [4/6], Batch [103/428], Loss: 1.6943
Epoch [4/6], Batch [104/428], Loss: 1.6719
Epoch [4/6], Batch [105/428], Loss: 1.7599
Epoch [4/6], Batch [106/428], Loss: 1.7378
Epoch [4/6], Batch [107/428], Loss: 1.9921
Epoch [4/6], Batch [108/428], Loss: 1.9772
Epoch [4/6], Batch [109/428], Loss: 2.0151
Epoch [4/6], Batch [110/428], Loss: 1.9132
Epoch [4/6], Batch [111/428], Loss: 1.6443
Epoch [4/6], Batch [112/428], Loss: 1.5917
Epoch [4/6], Batch [113/428], Loss: 2.0224
Epoch [4/6], Batch [114/428], Loss: 1.5483
Epoch [4/6], Batch [115/428], Loss: 1.8344
Epoch [4/6], Batch [116/428], Loss: 1.5012
Epoch [4/6], Batch [117/428], Loss: 2.8793
Epoch [4/6], Batch [118/428], Loss: 1.6762
Epoch [4/6], Batch [119/428], Loss: 1.6582
Epoch [4/6], Batch [120/428], Loss: 1.7807
Epoch [4/6], Batch [121/428], Loss: 1.6366
Epoch [4/6], Batch [122/428], Loss: 1.7691
Epoch [4/6], Batch [123/428], Loss: 1.9798
Epoch [4/6], Batch [124/428], Loss: 1.5752
Epoch [4/6], Batch [125/428], Loss: 3.1245
Epoch [4/6], Batch [126/428], Loss: 1.4162
Epoch [4/6], Batch [127/428], Loss: 2.8717
Epoch [4/6], Batch [128/428], Loss: 2.8822
Epoch [4/6], Batch [129/428], Loss: 1.4937
Epoch [4/6], Batch [130/428], Loss: 2.2164
Epoch [4/6], Batch [131/428], Loss: 2.0653
Epoch [4/6], Batch [132/428], Loss: 1.4442
Epoch [4/6], Batch [133/428], Loss: 2.2034
Epoch [4/6], Batch [134/428], Loss: 2.0536
Epoch [4/6], Batch [135/428], Loss: 2.6323
Epoch [4/6], Batch [136/428], Loss: 2.6129
Epoch [4/6], Batch [137/428], Loss: 1.4144
Epoch [4/6], Batch [138/428], Loss: 2.1394
Epoch [4/6], Batch [139/428], Loss: 2.1180
Epoch [4/6], Batch [140/428], Loss: 2.0772
Epoch [4/6], Batch [141/428], Loss: 1.4193
Epoch [4/6], Batch [142/428], Loss: 1.9691
Epoch [4/6], Batch [143/428], Loss: 1.4204
Epoch [4/6], Batch [144/428], Loss: 1.3897
Epoch [4/6], Batch [145/428], Loss: 1.7298
Epoch [4/6], Batch [146/428], Loss: 1.3325
Epoch [4/6], Batch [147/428], Loss: 1.7582
Epoch [4/6], Batch [148/428], Loss: 2.3042
Epoch [4/6], Batch [149/428], Loss: 3.1972
Epoch [4/6], Batch [150/428], Loss: 2.1353
Epoch [4/6], Batch [151/428], Loss: 2.2954
Epoch [4/6], Batch [152/428], Loss: 2.1613
Epoch [4/6], Batch [153/428], Loss: 1.7843
Epoch [4/6], Batch [154/428], Loss: 2.1658
Epoch [4/6], Batch [155/428], Loss: 1.7729
Epoch [4/6], Batch [156/428], Loss: 2.1645
Epoch [4/6], Batch [157/428], Loss: 2.1555
Epoch [4/6], Batch [158/428], Loss: 1.9315
Epoch [4/6], Batch [159/428], Loss: 2.1164
Epoch [4/6], Batch [160/428], Loss: 2.0935
Epoch [4/6], Batch [161/428], Loss: 2.1146
Epoch [4/6], Batch [162/428], Loss: 3.1302
Epoch [4/6], Batch [163/428], Loss: 1.7310
Epoch [4/6], Batch [164/428], Loss: 1.9809
Epoch [4/6], Batch [165/428], Loss: 2.0437
Epoch [4/6], Batch [166/428], Loss: 1.9142
Epoch [4/6], Batch [167/428], Loss: 1.7176
Epoch [4/6], Batch [168/428], Loss: 1.9749
Epoch [4/6], Batch [169/428], Loss: 1.6926
Epoch [4/6], Batch [170/428], Loss: 1.6611
Epoch [4/6], Batch [171/428], Loss: 1.6848
Epoch [4/6], Batch [172/428], Loss: 3.0276
Epoch [4/6], Batch [173/428], Loss: 1.8677
Epoch [4/6], Batch [174/428], Loss: 1.6953
Epoch [4/6], Batch [175/428], Loss: 1.6059
Epoch [4/6], Batch [176/428], Loss: 1.8609
Epoch [4/6], Batch [177/428], Loss: 1.6675
Epoch [4/6], Batch [178/428], Loss: 1.8395
Epoch [4/6], Batch [179/428], Loss: 1.6455
Epoch [4/6], Batch [180/428], Loss: 1.6372
Epoch [4/6], Batch [181/428], Loss: 1.5746
Epoch [4/6], Batch [182/428], Loss: 2.1730
Epoch [4/6], Batch [183/428], Loss: 1.8381
Epoch [4/6], Batch [184/428], Loss: 1.8363
Epoch [4/6], Batch [185/428], Loss: 2.2100
Epoch [4/6], Batch [186/428], Loss: 2.1754
Epoch [4/6], Batch [187/428], Loss: 1.5129
Epoch [4/6], Batch [188/428], Loss: 1.7986
Epoch [4/6], Batch [189/428], Loss: 1.4754
Epoch [4/6], Batch [190/428], Loss: 1.4647
Epoch [4/6], Batch [191/428], Loss: 1.8200
Epoch [4/6], Batch [192/428], Loss: 1.4020
Epoch [4/6], Batch [193/428], Loss: 3.0736
Epoch [4/6], Batch [194/428], Loss: 1.3331
Epoch [4/6], Batch [195/428], Loss: 1.8637
Epoch [4/6], Batch [196/428], Loss: 1.8580
Epoch [4/6], Batch [197/428], Loss: 1.8451
Epoch [4/6], Batch [198/428], Loss: 1.2285
Epoch [4/6], Batch [199/428], Loss: 3.0724
Epoch [4/6], Batch [200/428], Loss: 1.1877
Epoch [4/6], Batch [201/428], Loss: 1.1478
Epoch [4/6], Batch [202/428], Loss: 1.1072
Epoch [4/6], Batch [203/428], Loss: 1.0651
Epoch [4/6], Batch [204/428], Loss: 1.0162
Epoch [4/6], Batch [205/428], Loss: 0.9624
Epoch [4/6], Batch [206/428], Loss: 2.9502
Epoch [4/6], Batch [207/428], Loss: 0.8567
Epoch [4/6], Batch [208/428], Loss: 0.8070
Epoch [4/6], Batch [209/428], Loss: 2.3411
Epoch [4/6], Batch [210/428], Loss: 2.0124
Epoch [4/6], Batch [211/428], Loss: 2.3322
Epoch [4/6], Batch [212/428], Loss: 2.0605
Epoch [4/6], Batch [213/428], Loss: 0.6217
Epoch [4/6], Batch [214/428], Loss: 0.6102
Epoch [4/6], Batch [215/428], Loss: 0.5816
Epoch [4/6], Batch [216/428], Loss: 2.8116
Epoch [4/6], Batch [217/428], Loss: 3.4543
Epoch [4/6], Batch [218/428], Loss: 0.5000
Epoch [4/6], Batch [219/428], Loss: 2.1951
Epoch [4/6], Batch [220/428], Loss: 2.6540
Epoch [4/6], Batch [221/428], Loss: 2.6838
Epoch [4/6], Batch [222/428], Loss: 2.7392
Epoch [4/6], Batch [223/428], Loss: 3.4781
Epoch [4/6], Batch [224/428], Loss: 2.5982
Epoch [4/6], Batch [225/428], Loss: 2.1957
Epoch [4/6], Batch [226/428], Loss: 2.9395
Epoch [4/6], Batch [227/428], Loss: 0.4994
Epoch [4/6], Batch [228/428], Loss: 0.5103
Epoch [4/6], Batch [229/428], Loss: 0.5064
Epoch [4/6], Batch [230/428], Loss: 2.7479
Epoch [4/6], Batch [231/428], Loss: 2.7609
Epoch [4/6], Batch [232/428], Loss: 2.1902
Epoch [4/6], Batch [233/428], Loss: 2.9228
Epoch [4/6], Batch [234/428], Loss: 0.5098
Epoch [4/6], Batch [235/428], Loss: 3.3277
Epoch [4/6], Batch [236/428], Loss: 2.1597
Epoch [4/6], Batch [237/428], Loss: 2.8192
Epoch [4/6], Batch [238/428], Loss: 2.6129
Epoch [4/6], Batch [239/428], Loss: 2.5826
Epoch [4/6], Batch [240/428], Loss: 3.2932
Epoch [4/6], Batch [241/428], Loss: 2.6598
Epoch [4/6], Batch [242/428], Loss: 3.2249
Epoch [4/6], Batch [243/428], Loss: 0.6440
Epoch [4/6], Batch [244/428], Loss: 1.9986
Epoch [4/6], Batch [245/428], Loss: 1.9854
Epoch [4/6], Batch [246/428], Loss: 0.7040
Epoch [4/6], Batch [247/428], Loss: 2.3027
Epoch [4/6], Batch [248/428], Loss: 2.2724
Epoch [4/6], Batch [249/428], Loss: 2.2244
Epoch [4/6], Batch [250/428], Loss: 0.7733
Epoch [4/6], Batch [251/428], Loss: 2.5766
Epoch [4/6], Batch [252/428], Loss: 1.8471
Epoch [4/6], Batch [253/428], Loss: 0.8241
Epoch [4/6], Batch [254/428], Loss: 0.8280
Epoch [4/6], Batch [255/428], Loss: 2.5408
Epoch [4/6], Batch [256/428], Loss: 1.9939
Epoch [4/6], Batch [257/428], Loss: 2.4909
Epoch [4/6], Batch [258/428], Loss: 2.5127
Epoch [4/6], Batch [259/428], Loss: 2.4514
Epoch [4/6], Batch [260/428], Loss: 0.8698
Epoch [4/6], Batch [261/428], Loss: 3.1334
Epoch [4/6], Batch [262/428], Loss: 3.1323
Epoch [4/6], Batch [263/428], Loss: 3.0828
Epoch [4/6], Batch [264/428], Loss: 1.8981
Epoch [4/6], Batch [265/428], Loss: 2.3024
Epoch [4/6], Batch [266/428], Loss: 2.9362
Epoch [4/6], Batch [267/428], Loss: 1.8391
Epoch [4/6], Batch [268/428], Loss: 0.9837
Epoch [4/6], Batch [269/428], Loss: 2.2127
Epoch [4/6], Batch [270/428], Loss: 1.7858
Epoch [4/6], Batch [271/428], Loss: 2.6476
Epoch [4/6], Batch [272/428], Loss: 2.3864
Epoch [4/6], Batch [273/428], Loss: 2.0798
Epoch [4/6], Batch [274/428], Loss: 2.0792
Epoch [4/6], Batch [275/428], Loss: 2.0023
Epoch [4/6], Batch [276/428], Loss: 2.3239
Epoch [4/6], Batch [277/428], Loss: 1.1980
Epoch [4/6], Batch [278/428], Loss: 1.8815
Epoch [4/6], Batch [279/428], Loss: 1.2238
Epoch [4/6], Batch [280/428], Loss: 2.1190
Epoch [4/6], Batch [281/428], Loss: 1.7328
Epoch [4/6], Batch [282/428], Loss: 2.2411
Epoch [4/6], Batch [283/428], Loss: 3.1254
Epoch [4/6], Batch [284/428], Loss: 2.3768
Epoch [4/6], Batch [285/428], Loss: 1.6051
Epoch [4/6], Batch [286/428], Loss: 1.5432
Epoch [4/6], Batch [287/428], Loss: 1.3771
Epoch [4/6], Batch [288/428], Loss: 1.9566
Epoch [4/6], Batch [289/428], Loss: 1.4167
Epoch [4/6], Batch [290/428], Loss: 3.0929
Epoch [4/6], Batch [291/428], Loss: 3.0412
Epoch [4/6], Batch [292/428], Loss: 3.0054
Epoch [4/6], Batch [293/428], Loss: 2.3310
Epoch [4/6], Batch [294/428], Loss: 1.4264
Epoch [4/6], Batch [295/428], Loss: 2.2798
Epoch [4/6], Batch [296/428], Loss: 2.2486
Epoch [4/6], Batch [297/428], Loss: 1.3798
Epoch [4/6], Batch [298/428], Loss: 1.4527
Epoch [4/6], Batch [299/428], Loss: 2.5336
Epoch [4/6], Batch [300/428], Loss: 2.4011
Epoch [4/6], Batch [301/428], Loss: 2.0336
Epoch [4/6], Batch [302/428], Loss: 1.9649
Epoch [4/6], Batch [303/428], Loss: 1.8929
Epoch [4/6], Batch [304/428], Loss: 1.8082
Epoch [4/6], Batch [305/428], Loss: 1.5493
Epoch [4/6], Batch [306/428], Loss: 1.5157
Epoch [4/6], Batch [307/428], Loss: 1.5197
Epoch [4/6], Batch [308/428], Loss: 2.5892
Epoch [4/6], Batch [309/428], Loss: 1.6262
Epoch [4/6], Batch [310/428], Loss: 1.5290
Epoch [4/6], Batch [311/428], Loss: 2.4385
Epoch [4/6], Batch [312/428], Loss: 1.4970
Epoch [4/6], Batch [313/428], Loss: 1.6715
Epoch [4/6], Batch [314/428], Loss: 1.6447
Epoch [4/6], Batch [315/428], Loss: 2.3303
Epoch [4/6], Batch [316/428], Loss: 2.6644
Epoch [4/6], Batch [317/428], Loss: 1.4743
Epoch [4/6], Batch [318/428], Loss: 2.4956
Epoch [4/6], Batch [319/428], Loss: 1.4494
Epoch [4/6], Batch [320/428], Loss: 2.6171
Epoch [4/6], Batch [321/428], Loss: 1.4223
Epoch [4/6], Batch [322/428], Loss: 1.4089
Epoch [4/6], Batch [323/428], Loss: 1.5773
Epoch [4/6], Batch [324/428], Loss: 1.3463
Epoch [4/6], Batch [325/428], Loss: 1.3227
Epoch [4/6], Batch [326/428], Loss: 1.6325
Epoch [4/6], Batch [327/428], Loss: 1.2455
Epoch [4/6], Batch [328/428], Loss: 2.4926
Epoch [4/6], Batch [329/428], Loss: 1.1547
Epoch [4/6], Batch [330/428], Loss: 1.6670
Epoch [4/6], Batch [331/428], Loss: 2.5449
Epoch [4/6], Batch [332/428], Loss: 2.9020
Epoch [4/6], Batch [333/428], Loss: 2.5355
Epoch [4/6], Batch [334/428], Loss: 1.0364
Epoch [4/6], Batch [335/428], Loss: 2.4692
Epoch [4/6], Batch [336/428], Loss: 2.4720
Epoch [4/6], Batch [337/428], Loss: 0.9788
Epoch [4/6], Batch [338/428], Loss: 0.9497
Epoch [4/6], Batch [339/428], Loss: 1.9833
Epoch [4/6], Batch [340/428], Loss: 2.9241
Epoch [4/6], Batch [341/428], Loss: 2.0432
Epoch [4/6], Batch [342/428], Loss: 2.0007
Epoch [4/6], Batch [343/428], Loss: 2.8890
Epoch [4/6], Batch [344/428], Loss: 2.8723
Epoch [4/6], Batch [345/428], Loss: 1.9222
Epoch [4/6], Batch [346/428], Loss: 2.0565
Epoch [4/6], Batch [347/428], Loss: 2.7166
Epoch [4/6], Batch [348/428], Loss: 2.4467
Epoch [4/6], Batch [349/428], Loss: 2.7262
Epoch [4/6], Batch [350/428], Loss: 0.9868
Epoch [4/6], Batch [351/428], Loss: 2.6393
Epoch [4/6], Batch [352/428], Loss: 2.6089
Epoch [4/6], Batch [353/428], Loss: 2.1008
Epoch [4/6], Batch [354/428], Loss: 2.0886
Epoch [4/6], Batch [355/428], Loss: 2.5251
Epoch [4/6], Batch [356/428], Loss: 2.0423
Epoch [4/6], Batch [357/428], Loss: 1.1085
Epoch [4/6], Batch [358/428], Loss: 1.9486
Epoch [4/6], Batch [359/428], Loss: 2.4217
Epoch [4/6], Batch [360/428], Loss: 2.3952
Epoch [4/6], Batch [361/428], Loss: 2.4212
Epoch [4/6], Batch [362/428], Loss: 1.7760
Epoch [4/6], Batch [363/428], Loss: 2.1761
Epoch [4/6], Batch [364/428], Loss: 2.2182
Epoch [4/6], Batch [365/428], Loss: 2.6290
Epoch [4/6], Batch [366/428], Loss: 2.1212
Epoch [4/6], Batch [367/428], Loss: 2.0899
Epoch [4/6], Batch [368/428], Loss: 1.6264
Epoch [4/6], Batch [369/428], Loss: 1.9796
Epoch [4/6], Batch [370/428], Loss: 1.4421
Epoch [4/6], Batch [371/428], Loss: 1.4585
Epoch [4/6], Batch [372/428], Loss: 2.6731
Epoch [4/6], Batch [373/428], Loss: 1.9544
Epoch [4/6], Batch [374/428], Loss: 1.5603
Epoch [4/6], Batch [375/428], Loss: 2.6219
Epoch [4/6], Batch [376/428], Loss: 2.5000
Epoch [4/6], Batch [377/428], Loss: 1.5321
Epoch [4/6], Batch [378/428], Loss: 1.8917
Epoch [4/6], Batch [379/428], Loss: 1.5415
Epoch [4/6], Batch [380/428], Loss: 1.5558
Epoch [4/6], Batch [381/428], Loss: 1.5263
Epoch [4/6], Batch [382/428], Loss: 1.5471
Epoch [4/6], Batch [383/428], Loss: 2.5691
Epoch [4/6], Batch [384/428], Loss: 2.5592
Epoch [4/6], Batch [385/428], Loss: 2.5677
Epoch [4/6], Batch [386/428], Loss: 2.5149
Epoch [4/6], Batch [387/428], Loss: 2.5138
Epoch [4/6], Batch [388/428], Loss: 2.3948
Epoch [4/6], Batch [389/428], Loss: 1.5023
Epoch [4/6], Batch [390/428], Loss: 1.9488
Epoch [4/6], Batch [391/428], Loss: 2.3901
Epoch [4/6], Batch [392/428], Loss: 1.4998
Epoch [4/6], Batch [393/428], Loss: 2.0494
Epoch [4/6], Batch [394/428], Loss: 2.0703
Epoch [4/6], Batch [395/428], Loss: 1.9616
Epoch [4/6], Batch [396/428], Loss: 1.6967
Epoch [4/6], Batch [397/428], Loss: 1.4935
Epoch [4/6], Batch [398/428], Loss: 1.4602
Epoch [4/6], Batch [399/428], Loss: 1.4562
Epoch [4/6], Batch [400/428], Loss: 2.6917
Epoch [4/6], Batch [401/428], Loss: 2.1505
Epoch [4/6], Batch [402/428], Loss: 2.2668
Epoch [4/6], Batch [403/428], Loss: 1.3574
Epoch [4/6], Batch [404/428], Loss: 2.2360
Epoch [4/6], Batch [405/428], Loss: 1.8706
Epoch [4/6], Batch [406/428], Loss: 1.3089
Epoch [4/6], Batch [407/428], Loss: 2.6872
Epoch [4/6], Batch [408/428], Loss: 2.6674
Epoch [4/6], Batch [409/428], Loss: 2.1124
Epoch [4/6], Batch [410/428], Loss: 1.9668
Epoch [4/6], Batch [411/428], Loss: 2.2316
Epoch [4/6], Batch [412/428], Loss: 2.2189
Epoch [4/6], Batch [413/428], Loss: 2.5385
Epoch [4/6], Batch [414/428], Loss: 2.0079
Epoch [4/6], Batch [415/428], Loss: 1.9636
Epoch [4/6], Batch [416/428], Loss: 2.1458
Epoch [4/6], Batch [417/428], Loss: 2.1195
Epoch [4/6], Batch [418/428], Loss: 2.4016
Epoch [4/6], Batch [419/428], Loss: 2.0575
Epoch [4/6], Batch [420/428], Loss: 2.3473
Epoch [4/6], Batch [421/428], Loss: 2.1335
Epoch [4/6], Batch [422/428], Loss: 2.2523
Epoch [4/6], Batch [423/428], Loss: 1.9238
Epoch [4/6], Batch [424/428], Loss: 2.2803
Epoch [4/6], Batch [425/428], Loss: 1.4699
Epoch [4/6], Batch [426/428], Loss: 2.0747
Epoch [4/6], Batch [427/428], Loss: 1.4899
Epoch [4/6], Batch [428/428], Loss: 1.4775
Epoch [4] Training Time: 393.94 seconds
Epoch [4/6], Average Loss: 2.0007, Training Accuracy: 0.2196
Epoch [4], Validation Loss: 1.9546, Validation Accuracy: 0.1429
Epoch [4] Validation Time: 16.81 seconds
--------------------------------------------------
Epoch [5/6], Batch [1/428], Loss: 1.4863
Epoch [5/6], Batch [2/428], Loss: 2.1178
Epoch [5/6], Batch [3/428], Loss: 1.4432
Epoch [5/6], Batch [4/428], Loss: 1.4433
Epoch [5/6], Batch [5/428], Loss: 2.2629
Epoch [5/6], Batch [6/428], Loss: 1.9330
Epoch [5/6], Batch [7/428], Loss: 1.8132
Epoch [5/6], Batch [8/428], Loss: 1.3701
Epoch [5/6], Batch [9/428], Loss: 1.9019
Epoch [5/6], Batch [10/428], Loss: 2.4018
Epoch [5/6], Batch [11/428], Loss: 2.1356
Epoch [5/6], Batch [12/428], Loss: 2.1458
Epoch [5/6], Batch [13/428], Loss: 2.1489
Epoch [5/6], Batch [14/428], Loss: 2.1153
Epoch [5/6], Batch [15/428], Loss: 2.2340
Epoch [5/6], Batch [16/428], Loss: 1.3365
Epoch [5/6], Batch [17/428], Loss: 2.4169
Epoch [5/6], Batch [18/428], Loss: 1.3326
Epoch [5/6], Batch [19/428], Loss: 2.0051
Epoch [5/6], Batch [20/428], Loss: 1.9088
Epoch [5/6], Batch [21/428], Loss: 2.3715
Epoch [5/6], Batch [22/428], Loss: 1.9009
Epoch [5/6], Batch [23/428], Loss: 1.9388
Epoch [5/6], Batch [24/428], Loss: 2.2862
Epoch [5/6], Batch [25/428], Loss: 1.3213
Epoch [5/6], Batch [26/428], Loss: 2.3891
Epoch [5/6], Batch [27/428], Loss: 1.8934
Epoch [5/6], Batch [28/428], Loss: 1.9596
Epoch [5/6], Batch [29/428], Loss: 1.3454
Epoch [5/6], Batch [30/428], Loss: 2.2848
Epoch [5/6], Batch [31/428], Loss: 1.8815
Epoch [5/6], Batch [32/428], Loss: 1.3440
Epoch [5/6], Batch [33/428], Loss: 1.9869
Epoch [5/6], Batch [34/428], Loss: 1.8599
Epoch [5/6], Batch [35/428], Loss: 1.8482
Epoch [5/6], Batch [36/428], Loss: 1.9720
Epoch [5/6], Batch [37/428], Loss: 1.8548
Epoch [5/6], Batch [38/428], Loss: 1.9552
Epoch [5/6], Batch [39/428], Loss: 1.9474
Epoch [5/6], Batch [40/428], Loss: 1.8343
Epoch [5/6], Batch [41/428], Loss: 1.3744
Epoch [5/6], Batch [42/428], Loss: 1.8087
Epoch [5/6], Batch [43/428], Loss: 2.5555
Epoch [5/6], Batch [44/428], Loss: 1.8662
Epoch [5/6], Batch [45/428], Loss: 2.5313
Epoch [5/6], Batch [46/428], Loss: 1.7964
Epoch [5/6], Batch [47/428], Loss: 1.7703
Epoch [5/6], Batch [48/428], Loss: 2.5222
Epoch [5/6], Batch [49/428], Loss: 1.4237
Epoch [5/6], Batch [50/428], Loss: 1.8146
Epoch [5/6], Batch [51/428], Loss: 1.7265
Epoch [5/6], Batch [52/428], Loss: 2.4453
Epoch [5/6], Batch [53/428], Loss: 1.4429
Epoch [5/6], Batch [54/428], Loss: 1.4325
Epoch [5/6], Batch [55/428], Loss: 1.4098
Epoch [5/6], Batch [56/428], Loss: 1.7946
Epoch [5/6], Batch [57/428], Loss: 1.6664
Epoch [5/6], Batch [58/428], Loss: 1.7764
Epoch [5/6], Batch [59/428], Loss: 1.9282
Epoch [5/6], Batch [60/428], Loss: 2.7017
Epoch [5/6], Batch [61/428], Loss: 2.6818
Epoch [5/6], Batch [62/428], Loss: 1.3986
Epoch [5/6], Batch [63/428], Loss: 1.7421
Epoch [5/6], Batch [64/428], Loss: 2.5699
Epoch [5/6], Batch [65/428], Loss: 2.5993
Epoch [5/6], Batch [66/428], Loss: 2.4155
Epoch [5/6], Batch [67/428], Loss: 1.3946
Epoch [5/6], Batch [68/428], Loss: 2.3789
Epoch [5/6], Batch [69/428], Loss: 2.3160
Epoch [5/6], Batch [70/428], Loss: 2.3063
Epoch [5/6], Batch [71/428], Loss: 2.0218
Epoch [5/6], Batch [72/428], Loss: 1.7491
Epoch [5/6], Batch [73/428], Loss: 1.7475
Epoch [5/6], Batch [74/428], Loss: 1.7260
Epoch [5/6], Batch [75/428], Loss: 2.5244
Epoch [5/6], Batch [76/428], Loss: 1.7293
Epoch [5/6], Batch [77/428], Loss: 2.1634
Epoch [5/6], Batch [78/428], Loss: 2.6237
Epoch [5/6], Batch [79/428], Loss: 2.4172
Epoch [5/6], Batch [80/428], Loss: 1.7458
Epoch [5/6], Batch [81/428], Loss: 2.6007
Epoch [5/6], Batch [82/428], Loss: 1.4945
Epoch [5/6], Batch [83/428], Loss: 1.4933
Epoch [5/6], Batch [84/428], Loss: 2.5748
Epoch [5/6], Batch [85/428], Loss: 2.5461
Epoch [5/6], Batch [86/428], Loss: 2.3497
Epoch [5/6], Batch [87/428], Loss: 2.0701
Epoch [5/6], Batch [88/428], Loss: 2.4812
Epoch [5/6], Batch [89/428], Loss: 2.0472
Epoch [5/6], Batch [90/428], Loss: 2.1684
Epoch [5/6], Batch [91/428], Loss: 2.0162
Epoch [5/6], Batch [92/428], Loss: 2.2789
Epoch [5/6], Batch [93/428], Loss: 1.8174
Epoch [5/6], Batch [94/428], Loss: 1.7976
Epoch [5/6], Batch [95/428], Loss: 2.1732
Epoch [5/6], Batch [96/428], Loss: 1.9339
Epoch [5/6], Batch [97/428], Loss: 1.5727
Epoch [5/6], Batch [98/428], Loss: 1.5816
Epoch [5/6], Batch [99/428], Loss: 1.5601
Epoch [5/6], Batch [100/428], Loss: 2.2219
Epoch [5/6], Batch [101/428], Loss: 1.8455
Epoch [5/6], Batch [102/428], Loss: 2.1705
Epoch [5/6], Batch [103/428], Loss: 2.3101
Epoch [5/6], Batch [104/428], Loss: 1.9803
Epoch [5/6], Batch [105/428], Loss: 2.2804
Epoch [5/6], Batch [106/428], Loss: 1.8478
Epoch [5/6], Batch [107/428], Loss: 2.0039
Epoch [5/6], Batch [108/428], Loss: 1.9985
Epoch [5/6], Batch [109/428], Loss: 2.1980
Epoch [5/6], Batch [110/428], Loss: 1.8191
Epoch [5/6], Batch [111/428], Loss: 1.8826
Epoch [5/6], Batch [112/428], Loss: 1.5993
Epoch [5/6], Batch [113/428], Loss: 2.2311
Epoch [5/6], Batch [114/428], Loss: 1.5887
Epoch [5/6], Batch [115/428], Loss: 1.8001
Epoch [5/6], Batch [116/428], Loss: 1.5877
Epoch [5/6], Batch [117/428], Loss: 1.5761
Epoch [5/6], Batch [118/428], Loss: 1.9058
Epoch [5/6], Batch [119/428], Loss: 1.5454
Epoch [5/6], Batch [120/428], Loss: 1.8910
Epoch [5/6], Batch [121/428], Loss: 2.2075
Epoch [5/6], Batch [122/428], Loss: 2.2598
Epoch [5/6], Batch [123/428], Loss: 2.2174
Epoch [5/6], Batch [124/428], Loss: 2.2659
Epoch [5/6], Batch [125/428], Loss: 2.2125
Epoch [5/6], Batch [126/428], Loss: 2.1603
Epoch [5/6], Batch [127/428], Loss: 1.8516
Epoch [5/6], Batch [128/428], Loss: 1.8609
Epoch [5/6], Batch [129/428], Loss: 1.8420
Epoch [5/6], Batch [130/428], Loss: 2.0855
Epoch [5/6], Batch [131/428], Loss: 1.5117
Epoch [5/6], Batch [132/428], Loss: 1.5092
Epoch [5/6], Batch [133/428], Loss: 1.4962
Epoch [5/6], Batch [134/428], Loss: 2.0169
Epoch [5/6], Batch [135/428], Loss: 2.2501
Epoch [5/6], Batch [136/428], Loss: 1.9535
Epoch [5/6], Batch [137/428], Loss: 1.4688
Epoch [5/6], Batch [138/428], Loss: 1.8048
Epoch [5/6], Batch [139/428], Loss: 1.4583
Epoch [5/6], Batch [140/428], Loss: 2.2178
Epoch [5/6], Batch [141/428], Loss: 1.4276
Epoch [5/6], Batch [142/428], Loss: 2.4214
Epoch [5/6], Batch [143/428], Loss: 1.3989
Epoch [5/6], Batch [144/428], Loss: 2.2527
Epoch [5/6], Batch [145/428], Loss: 1.3642
Epoch [5/6], Batch [146/428], Loss: 2.0633
Epoch [5/6], Batch [147/428], Loss: 1.8448
Epoch [5/6], Batch [148/428], Loss: 2.2611
Epoch [5/6], Batch [149/428], Loss: 2.2532
Epoch [5/6], Batch [150/428], Loss: 1.3026
Epoch [5/6], Batch [151/428], Loss: 2.2362
Epoch [5/6], Batch [152/428], Loss: 1.8545
Epoch [5/6], Batch [153/428], Loss: 2.2114
Epoch [5/6], Batch [154/428], Loss: 1.9061
Epoch [5/6], Batch [155/428], Loss: 2.2672
Epoch [5/6], Batch [156/428], Loss: 2.1600
Epoch [5/6], Batch [157/428], Loss: 1.9026
Epoch [5/6], Batch [158/428], Loss: 2.2521
Epoch [5/6], Batch [159/428], Loss: 2.1657
Epoch [5/6], Batch [160/428], Loss: 2.0734
Epoch [5/6], Batch [161/428], Loss: 1.3115
Epoch [5/6], Batch [162/428], Loss: 2.0336
Epoch [5/6], Batch [163/428], Loss: 2.2039
Epoch [5/6], Batch [164/428], Loss: 1.9822
Epoch [5/6], Batch [165/428], Loss: 2.6644
Epoch [5/6], Batch [166/428], Loss: 1.9306
Epoch [5/6], Batch [167/428], Loss: 1.9014
Epoch [5/6], Batch [168/428], Loss: 1.3578
Epoch [5/6], Batch [169/428], Loss: 1.9725
Epoch [5/6], Batch [170/428], Loss: 2.1450
Epoch [5/6], Batch [171/428], Loss: 1.7710
Epoch [5/6], Batch [172/428], Loss: 2.1358
Epoch [5/6], Batch [173/428], Loss: 1.9917
Epoch [5/6], Batch [174/428], Loss: 2.1069
Epoch [5/6], Batch [175/428], Loss: 1.4054
Epoch [5/6], Batch [176/428], Loss: 2.0677
Epoch [5/6], Batch [177/428], Loss: 2.0344
Epoch [5/6], Batch [178/428], Loss: 2.3085
Epoch [5/6], Batch [179/428], Loss: 1.4363
Epoch [5/6], Batch [180/428], Loss: 2.0779
Epoch [5/6], Batch [181/428], Loss: 2.1021
Epoch [5/6], Batch [182/428], Loss: 1.6490
Epoch [5/6], Batch [183/428], Loss: 1.4240
Epoch [5/6], Batch [184/428], Loss: 1.4446
Epoch [5/6], Batch [185/428], Loss: 1.8911
Epoch [5/6], Batch [186/428], Loss: 2.0698
Epoch [5/6], Batch [187/428], Loss: 2.3760
Epoch [5/6], Batch [188/428], Loss: 1.6537
Epoch [5/6], Batch [189/428], Loss: 2.3654
Epoch [5/6], Batch [190/428], Loss: 1.6466
Epoch [5/6], Batch [191/428], Loss: 2.8324
Epoch [5/6], Batch [192/428], Loss: 2.1442
Epoch [5/6], Batch [193/428], Loss: 1.4264
Epoch [5/6], Batch [194/428], Loss: 1.8472
Epoch [5/6], Batch [195/428], Loss: 1.8459
Epoch [5/6], Batch [196/428], Loss: 2.3178
Epoch [5/6], Batch [197/428], Loss: 1.8109
Epoch [5/6], Batch [198/428], Loss: 1.7880
Epoch [5/6], Batch [199/428], Loss: 1.4496
Epoch [5/6], Batch [200/428], Loss: 1.6481
Epoch [5/6], Batch [201/428], Loss: 2.2800
Epoch [5/6], Batch [202/428], Loss: 2.2065
Epoch [5/6], Batch [203/428], Loss: 2.1420
Epoch [5/6], Batch [204/428], Loss: 2.2475
Epoch [5/6], Batch [205/428], Loss: 2.1328
Epoch [5/6], Batch [206/428], Loss: 2.8510
Epoch [5/6], Batch [207/428], Loss: 1.6855
Epoch [5/6], Batch [208/428], Loss: 2.2190
Epoch [5/6], Batch [209/428], Loss: 1.6718
Epoch [5/6], Batch [210/428], Loss: 1.7083
Epoch [5/6], Batch [211/428], Loss: 1.5111
Epoch [5/6], Batch [212/428], Loss: 1.5430
Epoch [5/6], Batch [213/428], Loss: 1.7095
Epoch [5/6], Batch [214/428], Loss: 1.7097
Epoch [5/6], Batch [215/428], Loss: 1.5363
Epoch [5/6], Batch [216/428], Loss: 2.1389
Epoch [5/6], Batch [217/428], Loss: 2.1413
Epoch [5/6], Batch [218/428], Loss: 1.6794
Epoch [5/6], Batch [219/428], Loss: 2.0988
Epoch [5/6], Batch [220/428], Loss: 1.6554
Epoch [5/6], Batch [221/428], Loss: 2.2489
Epoch [5/6], Batch [222/428], Loss: 1.5249
Epoch [5/6], Batch [223/428], Loss: 1.5266
Epoch [5/6], Batch [224/428], Loss: 1.6020
Epoch [5/6], Batch [225/428], Loss: 2.2505
Epoch [5/6], Batch [226/428], Loss: 1.7436
Epoch [5/6], Batch [227/428], Loss: 2.2541
Epoch [5/6], Batch [228/428], Loss: 1.5208
Epoch [5/6], Batch [229/428], Loss: 1.5654
Epoch [5/6], Batch [230/428], Loss: 1.5168
Epoch [5/6], Batch [231/428], Loss: 1.4926
Epoch [5/6], Batch [232/428], Loss: 1.5484
Epoch [5/6], Batch [233/428], Loss: 1.4725
Epoch [5/6], Batch [234/428], Loss: 2.0588
Epoch [5/6], Batch [235/428], Loss: 1.4424
Epoch [5/6], Batch [236/428], Loss: 1.5175
Epoch [5/6], Batch [237/428], Loss: 2.0327
Epoch [5/6], Batch [238/428], Loss: 1.4019
Epoch [5/6], Batch [239/428], Loss: 1.3967
Epoch [5/6], Batch [240/428], Loss: 1.3685
Epoch [5/6], Batch [241/428], Loss: 2.3242
Epoch [5/6], Batch [242/428], Loss: 1.3261
Epoch [5/6], Batch [243/428], Loss: 2.3195
Epoch [5/6], Batch [244/428], Loss: 1.5323
Epoch [5/6], Batch [245/428], Loss: 2.0207
Epoch [5/6], Batch [246/428], Loss: 1.2548
Epoch [5/6], Batch [247/428], Loss: 2.0323
Epoch [5/6], Batch [248/428], Loss: 1.2215
Epoch [5/6], Batch [249/428], Loss: 2.4854
Epoch [5/6], Batch [250/428], Loss: 1.1866
Epoch [5/6], Batch [251/428], Loss: 2.4868
Epoch [5/6], Batch [252/428], Loss: 1.1575
Epoch [5/6], Batch [253/428], Loss: 2.1258
Epoch [5/6], Batch [254/428], Loss: 1.6361
Epoch [5/6], Batch [255/428], Loss: 1.6504
Epoch [5/6], Batch [256/428], Loss: 3.2871
Epoch [5/6], Batch [257/428], Loss: 1.6408
Epoch [5/6], Batch [258/428], Loss: 2.4424
Epoch [5/6], Batch [259/428], Loss: 1.0911
Epoch [5/6], Batch [260/428], Loss: 1.6175
Epoch [5/6], Batch [261/428], Loss: 1.6003
Epoch [5/6], Batch [262/428], Loss: 2.3791
Epoch [5/6], Batch [263/428], Loss: 2.2004
Epoch [5/6], Batch [264/428], Loss: 2.2084
Epoch [5/6], Batch [265/428], Loss: 2.2023
Epoch [5/6], Batch [266/428], Loss: 2.4245
Epoch [5/6], Batch [267/428], Loss: 1.5261
Epoch [5/6], Batch [268/428], Loss: 2.1134
Epoch [5/6], Batch [269/428], Loss: 1.1415
Epoch [5/6], Batch [270/428], Loss: 1.1510
Epoch [5/6], Batch [271/428], Loss: 2.1223
Epoch [5/6], Batch [272/428], Loss: 2.3540
Epoch [5/6], Batch [273/428], Loss: 2.3889
Epoch [5/6], Batch [274/428], Loss: 2.0989
Epoch [5/6], Batch [275/428], Loss: 1.1653
Epoch [5/6], Batch [276/428], Loss: 2.0836
Epoch [5/6], Batch [277/428], Loss: 1.1474
Epoch [5/6], Batch [278/428], Loss: 1.1503
Epoch [5/6], Batch [279/428], Loss: 1.1473
Epoch [5/6], Batch [280/428], Loss: 2.1506
Epoch [5/6], Batch [281/428], Loss: 2.0182
Epoch [5/6], Batch [282/428], Loss: 2.1452
Epoch [5/6], Batch [283/428], Loss: 3.3462
Epoch [5/6], Batch [284/428], Loss: 2.1247
Epoch [5/6], Batch [285/428], Loss: 2.5601
Epoch [5/6], Batch [286/428], Loss: 1.6846
Epoch [5/6], Batch [287/428], Loss: 1.6879
Epoch [5/6], Batch [288/428], Loss: 1.6888
Epoch [5/6], Batch [289/428], Loss: 1.6777
Epoch [5/6], Batch [290/428], Loss: 2.5430
Epoch [5/6], Batch [291/428], Loss: 1.1278
Epoch [5/6], Batch [292/428], Loss: 2.0638
Epoch [5/6], Batch [293/428], Loss: 1.6089
Epoch [5/6], Batch [294/428], Loss: 1.1504
Epoch [5/6], Batch [295/428], Loss: 1.1451
Epoch [5/6], Batch [296/428], Loss: 1.1432
Epoch [5/6], Batch [297/428], Loss: 2.0312
Epoch [5/6], Batch [298/428], Loss: 1.1309
Epoch [5/6], Batch [299/428], Loss: 1.5788
Epoch [5/6], Batch [300/428], Loss: 1.1209
Epoch [5/6], Batch [301/428], Loss: 1.1010
Epoch [5/6], Batch [302/428], Loss: 2.0184
Epoch [5/6], Batch [303/428], Loss: 2.4595
Epoch [5/6], Batch [304/428], Loss: 2.5580
Epoch [5/6], Batch [305/428], Loss: 3.3473
Epoch [5/6], Batch [306/428], Loss: 1.0435
Epoch [5/6], Batch [307/428], Loss: 1.0222
Epoch [5/6], Batch [308/428], Loss: 1.6293
Epoch [5/6], Batch [309/428], Loss: 2.4953
Epoch [5/6], Batch [310/428], Loss: 2.5602
Epoch [5/6], Batch [311/428], Loss: 0.9885
Epoch [5/6], Batch [312/428], Loss: 2.4644
Epoch [5/6], Batch [313/428], Loss: 2.5377
Epoch [5/6], Batch [314/428], Loss: 2.4445
Epoch [5/6], Batch [315/428], Loss: 0.9765
Epoch [5/6], Batch [316/428], Loss: 1.7031
Epoch [5/6], Batch [317/428], Loss: 2.3813
Epoch [5/6], Batch [318/428], Loss: 0.9578
Epoch [5/6], Batch [319/428], Loss: 2.4694
Epoch [5/6], Batch [320/428], Loss: 0.9544
Epoch [5/6], Batch [321/428], Loss: 2.3402
Epoch [5/6], Batch [322/428], Loss: 2.4126
Epoch [5/6], Batch [323/428], Loss: 2.3899
Epoch [5/6], Batch [324/428], Loss: 1.7657
Epoch [5/6], Batch [325/428], Loss: 3.3159
Epoch [5/6], Batch [326/428], Loss: 1.7522
Epoch [5/6], Batch [327/428], Loss: 0.9426
Epoch [5/6], Batch [328/428], Loss: 2.1845
Epoch [5/6], Batch [329/428], Loss: 2.3031
Epoch [5/6], Batch [330/428], Loss: 3.2840
Epoch [5/6], Batch [331/428], Loss: 2.1943
Epoch [5/6], Batch [332/428], Loss: 2.4082
Epoch [5/6], Batch [333/428], Loss: 2.3872
Epoch [5/6], Batch [334/428], Loss: 2.1693
Epoch [5/6], Batch [335/428], Loss: 3.1734
Epoch [5/6], Batch [336/428], Loss: 1.0227
Epoch [5/6], Batch [337/428], Loss: 1.7670
Epoch [5/6], Batch [338/428], Loss: 1.0425
Epoch [5/6], Batch [339/428], Loss: 1.0102
Epoch [5/6], Batch [340/428], Loss: 2.2427
Epoch [5/6], Batch [341/428], Loss: 2.2539
Epoch [5/6], Batch [342/428], Loss: 1.0121
Epoch [5/6], Batch [343/428], Loss: 2.1405
Epoch [5/6], Batch [344/428], Loss: 0.9979
Epoch [5/6], Batch [345/428], Loss: 2.4037
Epoch [5/6], Batch [346/428], Loss: 0.9987
Epoch [5/6], Batch [347/428], Loss: 2.1201
Epoch [5/6], Batch [348/428], Loss: 2.1228
Epoch [5/6], Batch [349/428], Loss: 2.4150
Epoch [5/6], Batch [350/428], Loss: 2.3520
Epoch [5/6], Batch [351/428], Loss: 2.0769
Epoch [5/6], Batch [352/428], Loss: 2.4062
Epoch [5/6], Batch [353/428], Loss: 0.9753
Epoch [5/6], Batch [354/428], Loss: 0.9806
Epoch [5/6], Batch [355/428], Loss: 3.0291
Epoch [5/6], Batch [356/428], Loss: 2.2361
Epoch [5/6], Batch [357/428], Loss: 3.0173
Epoch [5/6], Batch [358/428], Loss: 3.0005
Epoch [5/6], Batch [359/428], Loss: 2.3415
Epoch [5/6], Batch [360/428], Loss: 2.1945
Epoch [5/6], Batch [361/428], Loss: 0.9741
Epoch [5/6], Batch [362/428], Loss: 2.3951
Epoch [5/6], Batch [363/428], Loss: 2.8272
Epoch [5/6], Batch [364/428], Loss: 2.1036
Epoch [5/6], Batch [365/428], Loss: 2.7841
Epoch [5/6], Batch [366/428], Loss: 2.0150
Epoch [5/6], Batch [367/428], Loss: 2.1697
Epoch [5/6], Batch [368/428], Loss: 2.2820
Epoch [5/6], Batch [369/428], Loss: 1.0285
Epoch [5/6], Batch [370/428], Loss: 2.3473
Epoch [5/6], Batch [371/428], Loss: 1.0525
Epoch [5/6], Batch [372/428], Loss: 2.5303
Epoch [5/6], Batch [373/428], Loss: 1.0562
Epoch [5/6], Batch [374/428], Loss: 2.0254
Epoch [5/6], Batch [375/428], Loss: 2.0176
Epoch [5/6], Batch [376/428], Loss: 1.0462
Epoch [5/6], Batch [377/428], Loss: 2.1927
Epoch [5/6], Batch [378/428], Loss: 2.1690
Epoch [5/6], Batch [379/428], Loss: 2.1751
Epoch [5/6], Batch [380/428], Loss: 1.0461
Epoch [5/6], Batch [381/428], Loss: 1.0486
Epoch [5/6], Batch [382/428], Loss: 2.1198
Epoch [5/6], Batch [383/428], Loss: 2.4371
Epoch [5/6], Batch [384/428], Loss: 1.0400
Epoch [5/6], Batch [385/428], Loss: 2.0042
Epoch [5/6], Batch [386/428], Loss: 2.4175
Epoch [5/6], Batch [387/428], Loss: 2.0061
Epoch [5/6], Batch [388/428], Loss: 2.0892
Epoch [5/6], Batch [389/428], Loss: 1.9742
Epoch [5/6], Batch [390/428], Loss: 1.0149
Epoch [5/6], Batch [391/428], Loss: 2.3988
Epoch [5/6], Batch [392/428], Loss: 1.0274
Epoch [5/6], Batch [393/428], Loss: 2.0285
Epoch [5/6], Batch [394/428], Loss: 2.3601
Epoch [5/6], Batch [395/428], Loss: 1.0293
Epoch [5/6], Batch [396/428], Loss: 1.9611
Epoch [5/6], Batch [397/428], Loss: 2.3662
Epoch [5/6], Batch [398/428], Loss: 1.0193
Epoch [5/6], Batch [399/428], Loss: 1.0026
Epoch [5/6], Batch [400/428], Loss: 2.3523
Epoch [5/6], Batch [401/428], Loss: 1.0012
Epoch [5/6], Batch [402/428], Loss: 2.5723
Epoch [5/6], Batch [403/428], Loss: 2.4013
Epoch [5/6], Batch [404/428], Loss: 1.9714
Epoch [5/6], Batch [405/428], Loss: 1.9551
Epoch [5/6], Batch [406/428], Loss: 2.0051
Epoch [5/6], Batch [407/428], Loss: 0.9604
Epoch [5/6], Batch [408/428], Loss: 0.9459
Epoch [5/6], Batch [409/428], Loss: 0.9556
Epoch [5/6], Batch [410/428], Loss: 2.6290
Epoch [5/6], Batch [411/428], Loss: 2.6231
Epoch [5/6], Batch [412/428], Loss: 2.0424
Epoch [5/6], Batch [413/428], Loss: 2.6126
Epoch [5/6], Batch [414/428], Loss: 1.9023
Epoch [5/6], Batch [415/428], Loss: 2.4477
Epoch [5/6], Batch [416/428], Loss: 2.0395
Epoch [5/6], Batch [417/428], Loss: 2.5733
Epoch [5/6], Batch [418/428], Loss: 2.6445
Epoch [5/6], Batch [419/428], Loss: 2.4607
Epoch [5/6], Batch [420/428], Loss: 0.9489
Epoch [5/6], Batch [421/428], Loss: 2.4811
Epoch [5/6], Batch [422/428], Loss: 2.4549
Epoch [5/6], Batch [423/428], Loss: 2.4414
Epoch [5/6], Batch [424/428], Loss: 2.4088
Epoch [5/6], Batch [425/428], Loss: 1.0011
Epoch [5/6], Batch [426/428], Loss: 2.3418
Epoch [5/6], Batch [427/428], Loss: 1.9224
Epoch [5/6], Batch [428/428], Loss: 2.6084
Epoch [5] Training Time: 391.42 seconds
Epoch [5/6], Average Loss: 1.9251, Training Accuracy: 0.2547
Epoch [5], Validation Loss: 2.0694, Validation Accuracy: 0.1429
Epoch [5] Validation Time: 17.07 seconds
--------------------------------------------------
Epoch [6/6], Batch [1/428], Loss: 2.2063
Epoch [6/6], Batch [2/428], Loss: 2.6011
Epoch [6/6], Batch [3/428], Loss: 1.0103
Epoch [6/6], Batch [4/428], Loss: 1.0167
Epoch [6/6], Batch [5/428], Loss: 2.3863
Epoch [6/6], Batch [6/428], Loss: 1.0221
Epoch [6/6], Batch [7/428], Loss: 2.3958
Epoch [6/6], Batch [8/428], Loss: 2.5700
Epoch [6/6], Batch [9/428], Loss: 2.5884
Epoch [6/6], Batch [10/428], Loss: 1.0244
Epoch [6/6], Batch [11/428], Loss: 2.1790
Epoch [6/6], Batch [12/428], Loss: 2.3886
Epoch [6/6], Batch [13/428], Loss: 2.3887
Epoch [6/6], Batch [14/428], Loss: 1.0040[INFO 06-13 21:05:18] ax.service.ax_client: Completed trial 12 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 1
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 21:05:21] ax.service.ax_client: Generated new trial 13 with parameters {'lr': 1.4e-05, 'num_epochs': 1, 'unfreeze_epoch': 0, 'max_length': 64000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [6/6], Batch [15/428], Loss: 2.3757
Epoch [6/6], Batch [16/428], Loss: 2.1020
Epoch [6/6], Batch [17/428], Loss: 1.9923
Epoch [6/6], Batch [18/428], Loss: 1.9776
Epoch [6/6], Batch [19/428], Loss: 2.4078
Epoch [6/6], Batch [20/428], Loss: 2.3488
Epoch [6/6], Batch [21/428], Loss: 2.3868
Epoch [6/6], Batch [22/428], Loss: 2.1054
Epoch [6/6], Batch [23/428], Loss: 2.1504
Epoch [6/6], Batch [24/428], Loss: 1.0405
Epoch [6/6], Batch [25/428], Loss: 1.9567
Epoch [6/6], Batch [26/428], Loss: 2.3306
Epoch [6/6], Batch [27/428], Loss: 2.3237
Epoch [6/6], Batch [28/428], Loss: 1.0533
Epoch [6/6], Batch [29/428], Loss: 2.1618
Epoch [6/6], Batch [30/428], Loss: 1.0340
Epoch [6/6], Batch [31/428], Loss: 1.0393
Epoch [6/6], Batch [32/428], Loss: 2.2998
Epoch [6/6], Batch [33/428], Loss: 2.1468
Epoch [6/6], Batch [34/428], Loss: 2.2875
Epoch [6/6], Batch [35/428], Loss: 1.0455
Epoch [6/6], Batch [36/428], Loss: 2.5425
Epoch [6/6], Batch [37/428], Loss: 2.5404
Epoch [6/6], Batch [38/428], Loss: 1.0437
Epoch [6/6], Batch [39/428], Loss: 2.1276
Epoch [6/6], Batch [40/428], Loss: 1.0354
Epoch [6/6], Batch [41/428], Loss: 1.0348
Epoch [6/6], Batch [42/428], Loss: 2.0175
Epoch [6/6], Batch [43/428], Loss: 2.4247
Epoch [6/6], Batch [44/428], Loss: 2.2674
Epoch [6/6], Batch [45/428], Loss: 2.5289
Epoch [6/6], Batch [46/428], Loss: 2.4389
Epoch [6/6], Batch [47/428], Loss: 1.0375
Epoch [6/6], Batch [48/428], Loss: 2.0124
Epoch [6/6], Batch [49/428], Loss: 2.0113
Epoch [6/6], Batch [50/428], Loss: 1.0243
Epoch [6/6], Batch [51/428], Loss: 2.5179
Epoch [6/6], Batch [52/428], Loss: 2.5051
Epoch [6/6], Batch [53/428], Loss: 2.0137
Epoch [6/6], Batch [54/428], Loss: 2.1836
Epoch [6/6], Batch [55/428], Loss: 1.9889
Epoch [6/6], Batch [56/428], Loss: 2.4124
Epoch [6/6], Batch [57/428], Loss: 1.9839
Epoch [6/6], Batch [58/428], Loss: 1.0305
Epoch [6/6], Batch [59/428], Loss: 1.9751
Epoch [6/6], Batch [60/428], Loss: 2.4772
Epoch [6/6], Batch [61/428], Loss: 2.2625
Epoch [6/6], Batch [62/428], Loss: 2.1981
Epoch [6/6], Batch [63/428], Loss: 2.4066
Epoch [6/6], Batch [64/428], Loss: 2.4555
Epoch [6/6], Batch [65/428], Loss: 2.4480
Epoch [6/6], Batch [66/428], Loss: 1.0535
Epoch [6/6], Batch [67/428], Loss: 1.0515
Epoch [6/6], Batch [68/428], Loss: 2.2070
Epoch [6/6], Batch [69/428], Loss: 2.1784
Epoch [6/6], Batch [70/428], Loss: 1.0758
Epoch [6/6], Batch [71/428], Loss: 1.0492
Epoch [6/6], Batch [72/428], Loss: 2.2747
Epoch [6/6], Batch [73/428], Loss: 2.2040
Epoch [6/6], Batch [74/428], Loss: 1.9580
Epoch [6/6], Batch [75/428], Loss: 1.0637
Epoch [6/6], Batch [76/428], Loss: 1.9481
Epoch [6/6], Batch [77/428], Loss: 2.2625
Epoch [6/6], Batch [78/428], Loss: 1.0453
Epoch [6/6], Batch [79/428], Loss: 2.2683
Epoch [6/6], Batch [80/428], Loss: 2.4061
Epoch [6/6], Batch [81/428], Loss: 2.2145
Epoch [6/6], Batch [82/428], Loss: 2.1987
Epoch [6/6], Batch [83/428], Loss: 2.2052
Epoch [6/6], Batch [84/428], Loss: 2.3955
Epoch [6/6], Batch [85/428], Loss: 1.0501
Epoch [6/6], Batch [86/428], Loss: 2.4021
Epoch [6/6], Batch [87/428], Loss: 1.0405
Epoch [6/6], Batch [88/428], Loss: 2.1928
Epoch [6/6], Batch [89/428], Loss: 2.4479
Epoch [6/6], Batch [90/428], Loss: 2.1818
Epoch [6/6], Batch [91/428], Loss: 2.1838
Epoch [6/6], Batch [92/428], Loss: 2.1948
Epoch [6/6], Batch [93/428], Loss: 2.2476
Epoch [6/6], Batch [94/428], Loss: 2.1936
Epoch [6/6], Batch [95/428], Loss: 2.1526
Epoch [6/6], Batch [96/428], Loss: 2.1399
Epoch [6/6], Batch [97/428], Loss: 1.0667
Epoch [6/6], Batch [98/428], Loss: 1.0752
Epoch [6/6], Batch [99/428], Loss: 2.1788
Epoch [6/6], Batch [100/428], Loss: 2.4697
Epoch [6/6], Batch [101/428], Loss: 2.3855
Epoch [6/6], Batch [102/428], Loss: 1.0507
Epoch [6/6], Batch [103/428], Loss: 2.2435
Epoch [6/6], Batch [104/428], Loss: 1.9956
Epoch [6/6], Batch [105/428], Loss: 1.9944
Epoch [6/6], Batch [106/428], Loss: 2.2468
Epoch [6/6], Batch [107/428], Loss: 2.2427
Epoch [6/6], Batch [108/428], Loss: 2.1702
Epoch [6/6], Batch [109/428], Loss: 2.1062
Epoch [6/6], Batch [110/428], Loss: 2.1184
Epoch [6/6], Batch [111/428], Loss: 1.0796
Epoch [6/6], Batch [112/428], Loss: 2.3823
Epoch [6/6], Batch [113/428], Loss: 2.1567
Epoch [6/6], Batch [114/428], Loss: 2.0737
Epoch [6/6], Batch [115/428], Loss: 2.2221
Epoch [6/6], Batch [116/428], Loss: 2.2079
Epoch [6/6], Batch [117/428], Loss: 1.0935
Epoch [6/6], Batch [118/428], Loss: 2.0637
Epoch [6/6], Batch [119/428], Loss: 2.1498
Epoch [6/6], Batch [120/428], Loss: 2.1544
Epoch [6/6], Batch [121/428], Loss: 2.0591
Epoch [6/6], Batch [122/428], Loss: 2.1811
Epoch [6/6], Batch [123/428], Loss: 2.1737
Epoch [6/6], Batch [124/428], Loss: 2.1271
Epoch [6/6], Batch [125/428], Loss: 1.1216
Epoch [6/6], Batch [126/428], Loss: 2.1496
Epoch [6/6], Batch [127/428], Loss: 2.3920
Epoch [6/6], Batch [128/428], Loss: 1.1021
Epoch [6/6], Batch [129/428], Loss: 2.3827
Epoch [6/6], Batch [130/428], Loss: 2.5122
Epoch [6/6], Batch [131/428], Loss: 2.0566
Epoch [6/6], Batch [132/428], Loss: 2.0432
Epoch [6/6], Batch [133/428], Loss: 1.1297
Epoch [6/6], Batch [134/428], Loss: 2.0188
Epoch [6/6], Batch [135/428], Loss: 2.1026
Epoch [6/6], Batch [136/428], Loss: 2.3862
Epoch [6/6], Batch [137/428], Loss: 2.1261
Epoch [6/6], Batch [138/428], Loss: 1.1261
Epoch [6/6], Batch [139/428], Loss: 2.0225
Epoch [6/6], Batch [140/428], Loss: 2.0010
Epoch [6/6], Batch [141/428], Loss: 2.5006
Epoch [6/6], Batch [142/428], Loss: 2.5318
Epoch [6/6], Batch [143/428], Loss: 1.1377
Epoch [6/6], Batch [144/428], Loss: 2.3461
Epoch [6/6], Batch [145/428], Loss: 1.9814
Epoch [6/6], Batch [146/428], Loss: 2.3543
Epoch [6/6], Batch [147/428], Loss: 2.3263
Epoch [6/6], Batch [148/428], Loss: 2.1095
Epoch [6/6], Batch [149/428], Loss: 2.1148
Epoch [6/6], Batch [150/428], Loss: 1.1585
Epoch [6/6], Batch [151/428], Loss: 2.1071
Epoch [6/6], Batch [152/428], Loss: 2.0992
Epoch [6/6], Batch [153/428], Loss: 2.3103
Epoch [6/6], Batch [154/428], Loss: 2.5036
Epoch [6/6], Batch [155/428], Loss: 1.1536
Epoch [6/6], Batch [156/428], Loss: 2.1003
Epoch [6/6], Batch [157/428], Loss: 1.1547
Epoch [6/6], Batch [158/428], Loss: 2.2889
Epoch [6/6], Batch [159/428], Loss: 2.1400
Epoch [6/6], Batch [160/428], Loss: 2.0650
Epoch [6/6], Batch [161/428], Loss: 2.2765
Epoch [6/6], Batch [162/428], Loss: 1.1609
Epoch [6/6], Batch [163/428], Loss: 2.2698
Epoch [6/6], Batch [164/428], Loss: 2.2583
Epoch [6/6], Batch [165/428], Loss: 1.1743
Epoch [6/6], Batch [166/428], Loss: 2.1253
Epoch [6/6], Batch [167/428], Loss: 2.0211
Epoch [6/6], Batch [168/428], Loss: 2.0367
Epoch [6/6], Batch [169/428], Loss: 1.1651
Epoch [6/6], Batch [170/428], Loss: 2.1530
Epoch [6/6], Batch [171/428], Loss: 2.5015
Epoch [6/6], Batch [172/428], Loss: 2.1258
Epoch [6/6], Batch [173/428], Loss: 2.1516
Epoch [6/6], Batch [174/428], Loss: 2.0222
Epoch [6/6], Batch [175/428], Loss: 2.0763
Epoch [6/6], Batch [176/428], Loss: 2.1366
Epoch [6/6], Batch [177/428], Loss: 2.0666
Epoch [6/6], Batch [178/428], Loss: 2.1918
Epoch [6/6], Batch [179/428], Loss: 2.0669
Epoch [6/6], Batch [180/428], Loss: 2.1320
Epoch [6/6], Batch [181/428], Loss: 1.1880
Epoch [6/6], Batch [182/428], Loss: 1.1929
Epoch [6/6], Batch [183/428], Loss: 1.1871
Epoch [6/6], Batch [184/428], Loss: 2.0084
Epoch [6/6], Batch [185/428], Loss: 1.1883
Epoch [6/6], Batch [186/428], Loss: 2.0448
Epoch [6/6], Batch [187/428], Loss: 2.1336
Epoch [6/6], Batch [188/428], Loss: 2.1283
Epoch [6/6], Batch [189/428], Loss: 2.0244
Epoch [6/6], Batch [190/428], Loss: 2.0207
Epoch [6/6], Batch [191/428], Loss: 2.0364
Epoch [6/6], Batch [192/428], Loss: 2.5294
Epoch [6/6], Batch [193/428], Loss: 2.2261
Epoch [6/6], Batch [194/428], Loss: 1.9925
Epoch [6/6], Batch [195/428], Loss: 2.1369
Epoch [6/6], Batch [196/428], Loss: 1.1735
Epoch [6/6], Batch [197/428], Loss: 2.2215
Epoch [6/6], Batch [198/428], Loss: 1.1952
Epoch [6/6], Batch [199/428], Loss: 1.1891
Epoch [6/6], Batch [200/428], Loss: 1.1810
Epoch [6/6], Batch [201/428], Loss: 1.1782
Epoch [6/6], Batch [202/428], Loss: 2.1470
Epoch [6/6], Batch [203/428], Loss: 2.1983
Epoch [6/6], Batch [204/428], Loss: 2.0320
Epoch [6/6], Batch [205/428], Loss: 2.0372
Epoch [6/6], Batch [206/428], Loss: 2.1474
Epoch [6/6], Batch [207/428], Loss: 1.1792
Epoch [6/6], Batch [208/428], Loss: 1.9896
Epoch [6/6], Batch [209/428], Loss: 2.5398
Epoch [6/6], Batch [210/428], Loss: 1.1651
Epoch [6/6], Batch [211/428], Loss: 1.1499
Epoch [6/6], Batch [212/428], Loss: 2.1561
Epoch [6/6], Batch [213/428], Loss: 1.9952
Epoch [6/6], Batch [214/428], Loss: 2.0356
Epoch [6/6], Batch [215/428], Loss: 2.0382
Epoch [6/6], Batch [216/428], Loss: 2.5392
Epoch [6/6], Batch [217/428], Loss: 1.1577
Epoch [6/6], Batch [218/428], Loss: 2.0209
Epoch [6/6], Batch [219/428], Loss: 2.1621
Epoch [6/6], Batch [220/428], Loss: 2.5416
Epoch [6/6], Batch [221/428], Loss: 2.1725
Epoch [6/6], Batch [222/428], Loss: 1.1485
Epoch [6/6], Batch [223/428], Loss: 1.1470
Epoch [6/6], Batch [224/428], Loss: 2.1700
Epoch [6/6], Batch [225/428], Loss: 2.2462
Epoch [6/6], Batch [226/428], Loss: 2.0121
Epoch [6/6], Batch [227/428], Loss: 1.1485
Epoch [6/6], Batch [228/428], Loss: 1.1523
Epoch [6/6], Batch [229/428], Loss: 1.1436
Epoch [6/6], Batch [230/428], Loss: 2.1693
Epoch [6/6], Batch [231/428], Loss: 1.1402
Epoch [6/6], Batch [232/428], Loss: 2.1901
Epoch [6/6], Batch [233/428], Loss: 2.1549
Epoch [6/6], Batch [234/428], Loss: 1.1243
Epoch [6/6], Batch [235/428], Loss: 2.1552
Epoch [6/6], Batch [236/428], Loss: 2.0018
Epoch [6/6], Batch [237/428], Loss: 2.0803
Epoch [6/6], Batch [238/428], Loss: 1.9993
Epoch [6/6], Batch [239/428], Loss: 2.1950
Epoch [6/6], Batch [240/428], Loss: 2.0023
Epoch [6/6], Batch [241/428], Loss: 2.0623
Epoch [6/6], Batch [242/428], Loss: 1.1189
Epoch [6/6], Batch [243/428], Loss: 1.1108
Epoch [6/6], Batch [244/428], Loss: 1.1062
Epoch [6/6], Batch [245/428], Loss: 1.1110
Epoch [6/6], Batch [246/428], Loss: 2.3018
Epoch [6/6], Batch [247/428], Loss: 2.1127
Epoch [6/6], Batch [248/428], Loss: 2.3092
Epoch [6/6], Batch [249/428], Loss: 2.0672
Epoch [6/6], Batch [250/428], Loss: 1.9827
Epoch [6/6], Batch [251/428], Loss: 2.2986
Epoch [6/6], Batch [252/428], Loss: 1.9862
Epoch [6/6], Batch [253/428], Loss: 2.2847
Epoch [6/6], Batch [254/428], Loss: 1.1009
Epoch [6/6], Batch [255/428], Loss: 2.0777
Epoch [6/6], Batch [256/428], Loss: 2.1303
Epoch [6/6], Batch [257/428], Loss: 2.2239
Epoch [6/6], Batch [258/428], Loss: 2.0808
Epoch [6/6], Batch [259/428], Loss: 1.1034
Epoch [6/6], Batch [260/428], Loss: 1.1019
Epoch [6/6], Batch [261/428], Loss: 1.0875
Epoch [6/6], Batch [262/428], Loss: 2.0823
Epoch [6/6], Batch [263/428], Loss: 1.0939
Epoch [6/6], Batch [264/428], Loss: 1.9951
Epoch [6/6], Batch [265/428], Loss: 2.1425
Epoch [6/6], Batch [266/428], Loss: 1.0822
Epoch [6/6], Batch [267/428], Loss: 1.0863
Epoch [6/6], Batch [268/428], Loss: 2.0603
Epoch [6/6], Batch [269/428], Loss: 1.9858
Epoch [6/6], Batch [270/428], Loss: 2.6781
Epoch [6/6], Batch [271/428], Loss: 1.0626
Epoch [6/6], Batch [272/428], Loss: 2.0583
Epoch [6/6], Batch [273/428], Loss: 2.2787
Epoch [6/6], Batch [274/428], Loss: 2.2957
Epoch [6/6], Batch [275/428], Loss: 2.1627
Epoch [6/6], Batch [276/428], Loss: 1.0737
Epoch [6/6], Batch [277/428], Loss: 1.0656
Epoch [6/6], Batch [278/428], Loss: 2.7046
Epoch [6/6], Batch [279/428], Loss: 2.6722
Epoch [6/6], Batch [280/428], Loss: 2.2733
Epoch [6/6], Batch [281/428], Loss: 2.2754
Epoch [6/6], Batch [282/428], Loss: 1.9999
Epoch [6/6], Batch [283/428], Loss: 1.9985
Epoch [6/6], Batch [284/428], Loss: 2.1350
Epoch [6/6], Batch [285/428], Loss: 2.1482
Epoch [6/6], Batch [286/428], Loss: 1.0512
Epoch [6/6], Batch [287/428], Loss: 2.1509
Epoch [6/6], Batch [288/428], Loss: 2.3309
Epoch [6/6], Batch [289/428], Loss: 2.2406
Epoch [6/6], Batch [290/428], Loss: 2.1220
Epoch [6/6], Batch [291/428], Loss: 2.2963
Epoch [6/6], Batch [292/428], Loss: 2.1310
Epoch [6/6], Batch [293/428], Loss: 2.2466
Epoch [6/6], Batch [294/428], Loss: 2.0788
Epoch [6/6], Batch [295/428], Loss: 2.6848
Epoch [6/6], Batch [296/428], Loss: 2.3150
Epoch [6/6], Batch [297/428], Loss: 2.2971
Epoch [6/6], Batch [298/428], Loss: 2.0057
Epoch [6/6], Batch [299/428], Loss: 2.6585
Epoch [6/6], Batch [300/428], Loss: 2.2735
Epoch [6/6], Batch [301/428], Loss: 2.0711
Epoch [6/6], Batch [302/428], Loss: 1.1199
Epoch [6/6], Batch [303/428], Loss: 2.0020
Epoch [6/6], Batch [304/428], Loss: 1.1075
Epoch [6/6], Batch [305/428], Loss: 2.6099
Epoch [6/6], Batch [306/428], Loss: 1.1215
Epoch [6/6], Batch [307/428], Loss: 2.2277
Epoch [6/6], Batch [308/428], Loss: 2.0044
Epoch [6/6], Batch [309/428], Loss: 2.1019
Epoch [6/6], Batch [310/428], Loss: 1.1160
Epoch [6/6], Batch [311/428], Loss: 2.2325
Epoch [6/6], Batch [312/428], Loss: 1.1151
Epoch [6/6], Batch [313/428], Loss: 2.5967
Epoch [6/6], Batch [314/428], Loss: 1.1248
Epoch [6/6], Batch [315/428], Loss: 2.2208
Epoch [6/6], Batch [316/428], Loss: 2.2179
Epoch [6/6], Batch [317/428], Loss: 1.1202
Epoch [6/6], Batch [318/428], Loss: 2.2023
Epoch [6/6], Batch [319/428], Loss: 2.0012
Epoch [6/6], Batch [320/428], Loss: 1.0997
Epoch [6/6], Batch [321/428], Loss: 1.1062
Epoch [6/6], Batch [322/428], Loss: 1.0960
Epoch [6/6], Batch [323/428], Loss: 2.1153
Epoch [6/6], Batch [324/428], Loss: 1.1076
Epoch [6/6], Batch [325/428], Loss: 2.5929
Epoch [6/6], Batch [326/428], Loss: 1.0769
Epoch [6/6], Batch [327/428], Loss: 2.1653
Epoch [6/6], Batch [328/428], Loss: 2.1790
Epoch [6/6], Batch [329/428], Loss: 1.0805
Epoch [6/6], Batch [330/428], Loss: 2.1774
Epoch [6/6], Batch [331/428], Loss: 2.0364
Epoch [6/6], Batch [332/428], Loss: 1.0589
Epoch [6/6], Batch [333/428], Loss: 2.5886
Epoch [6/6], Batch [334/428], Loss: 2.3115
Epoch [6/6], Batch [335/428], Loss: 2.1706
Epoch [6/6], Batch [336/428], Loss: 2.0309
Epoch [6/6], Batch [337/428], Loss: 1.0663
Epoch [6/6], Batch [338/428], Loss: 2.1589
Epoch [6/6], Batch [339/428], Loss: 2.1797
Epoch [6/6], Batch [340/428], Loss: 1.0572
Epoch [6/6], Batch [341/428], Loss: 2.0279
Epoch [6/6], Batch [342/428], Loss: 2.1841
Epoch [6/6], Batch [343/428], Loss: 1.0425
Epoch [6/6], Batch [344/428], Loss: 2.0232
Epoch [6/6], Batch [345/428], Loss: 2.1874
Epoch [6/6], Batch [346/428], Loss: 2.1723
Epoch [6/6], Batch [347/428], Loss: 2.1830
Epoch [6/6], Batch [348/428], Loss: 1.0391
Epoch [6/6], Batch [349/428], Loss: 2.5880
Epoch [6/6], Batch [350/428], Loss: 2.0086
Epoch [6/6], Batch [351/428], Loss: 2.3630
Epoch [6/6], Batch [352/428], Loss: 2.1523
Epoch [6/6], Batch [353/428], Loss: 2.1710
Epoch [6/6], Batch [354/428], Loss: 2.3446
Epoch [6/6], Batch [355/428], Loss: 2.1553
Epoch [6/6], Batch [356/428], Loss: 2.1731
Epoch [6/6], Batch [357/428], Loss: 2.1637
Epoch [6/6], Batch [358/428], Loss: 2.0043
Epoch [6/6], Batch [359/428], Loss: 2.5860
Epoch [6/6], Batch [360/428], Loss: 2.3303
Epoch [6/6], Batch [361/428], Loss: 1.9995
Epoch [6/6], Batch [362/428], Loss: 2.1437
Epoch [6/6], Batch [363/428], Loss: 1.0759
Epoch [6/6], Batch [364/428], Loss: 2.1159
Epoch [6/6], Batch [365/428], Loss: 1.0863
Epoch [6/6], Batch [366/428], Loss: 2.1976
Epoch [6/6], Batch [367/428], Loss: 1.0926
Epoch [6/6], Batch [368/428], Loss: 2.1263
Epoch [6/6], Batch [369/428], Loss: 1.9952
Epoch [6/6], Batch [370/428], Loss: 2.3226
Epoch [6/6], Batch [371/428], Loss: 2.1986
Epoch [6/6], Batch [372/428], Loss: 2.0923
Epoch [6/6], Batch [373/428], Loss: 1.1058
Epoch [6/6], Batch [374/428], Loss: 1.9897
Epoch [6/6], Batch [375/428], Loss: 1.1161
Epoch [6/6], Batch [376/428], Loss: 2.3131
Epoch [6/6], Batch [377/428], Loss: 1.1047
Epoch [6/6], Batch [378/428], Loss: 1.9850
Epoch [6/6], Batch [379/428], Loss: 2.1119
Epoch [6/6], Batch [380/428], Loss: 1.0981
Epoch [6/6], Batch [381/428], Loss: 1.0906
Epoch [6/6], Batch [382/428], Loss: 2.1037
Epoch [6/6], Batch [383/428], Loss: 2.6059
Epoch [6/6], Batch [384/428], Loss: 1.0918
Epoch [6/6], Batch [385/428], Loss: 2.2962
Epoch [6/6], Batch [386/428], Loss: 2.1086
Epoch [6/6], Batch [387/428], Loss: 2.1139
Epoch [6/6], Batch [388/428], Loss: 2.2963
Epoch [6/6], Batch [389/428], Loss: 1.0851
Epoch [6/6], Batch [390/428], Loss: 2.0983
Epoch [6/6], Batch [391/428], Loss: 1.1008
Epoch [6/6], Batch [392/428], Loss: 2.0897
Epoch [6/6], Batch [393/428], Loss: 2.0843
Epoch [6/6], Batch [394/428], Loss: 2.2507
Epoch [6/6], Batch [395/428], Loss: 2.1602
Epoch [6/6], Batch [396/428], Loss: 1.0657
Epoch [6/6], Batch [397/428], Loss: 2.0508
Epoch [6/6], Batch [398/428], Loss: 2.2828
Epoch [6/6], Batch [399/428], Loss: 2.1160
Epoch [6/6], Batch [400/428], Loss: 2.0197
Epoch [6/6], Batch [401/428], Loss: 2.1353
Epoch [6/6], Batch [402/428], Loss: 2.0177
Epoch [6/6], Batch [403/428], Loss: 2.6532
Epoch [6/6], Batch [404/428], Loss: 1.0889
Epoch [6/6], Batch [405/428], Loss: 2.1207
Epoch [6/6], Batch [406/428], Loss: 2.2630
Epoch [6/6], Batch [407/428], Loss: 1.0953
Epoch [6/6], Batch [408/428], Loss: 2.2825
Epoch [6/6], Batch [409/428], Loss: 2.6393
Epoch [6/6], Batch [410/428], Loss: 1.0902
Epoch [6/6], Batch [411/428], Loss: 2.2576
Epoch [6/6], Batch [412/428], Loss: 2.0120
Epoch [6/6], Batch [413/428], Loss: 2.2664
Epoch [6/6], Batch [414/428], Loss: 2.0776
Epoch [6/6], Batch [415/428], Loss: 2.0200
Epoch [6/6], Batch [416/428], Loss: 2.6171
Epoch [6/6], Batch [417/428], Loss: 2.0993
Epoch [6/6], Batch [418/428], Loss: 2.0086
Epoch [6/6], Batch [419/428], Loss: 1.1143
Epoch [6/6], Batch [420/428], Loss: 2.0732
Epoch [6/6], Batch [421/428], Loss: 1.9956
Epoch [6/6], Batch [422/428], Loss: 2.0600
Epoch [6/6], Batch [423/428], Loss: 2.0615
Epoch [6/6], Batch [424/428], Loss: 2.2273
Epoch [6/6], Batch [425/428], Loss: 2.6261
Epoch [6/6], Batch [426/428], Loss: 2.3071
Epoch [6/6], Batch [427/428], Loss: 2.0500
Epoch [6/6], Batch [428/428], Loss: 2.0518
Epoch [6] Training Time: 391.26 seconds
Epoch [6/6], Average Loss: 1.9227, Training Accuracy: 0.2547
Epoch [6], Validation Loss: 2.0065, Validation Accuracy: 0.1429
Epoch [6] Validation Time: 17.17 seconds
--------------------------------------------------

Running trial 13 with config: {'batch_size': 1, 'lr': 1.3827608255373683e-05, 'num_epochs': 1, 'unfreeze_epoch': 0, 'max_length': 64000, 'device': device(type='cpu')}
Epoch 1: Unfreezing feature extractor layers...
Epoch [1/1], Batch [1/428], Loss: 2.2114
Epoch [1/1], Batch [2/428], Loss: 2.3289
Epoch [1/1], Batch [3/428], Loss: 4.6267
Epoch [1/1], Batch [4/428], Loss: 3.3689
Epoch [1/1], Batch [5/428], Loss: 2.7206
Epoch [1/1], Batch [6/428], Loss: 3.9422
Epoch [1/1], Batch [7/428], Loss: 2.4522
Epoch [1/1], Batch [8/428], Loss: 3.2650
Epoch [1/1], Batch [9/428], Loss: 0.3855
Epoch [1/1], Batch [10/428], Loss: 4.1336
Epoch [1/1], Batch [11/428], Loss: 1.2813
Epoch [1/1], Batch [12/428], Loss: 2.5925
Epoch [1/1], Batch [13/428], Loss: 0.6797
Epoch [1/1], Batch [14/428], Loss: 1.0745
Epoch [1/1], Batch [15/428], Loss: 2.0409
Epoch [1/1], Batch [16/428], Loss: 3.6879
Epoch [1/1], Batch [17/428], Loss: 1.1746
Epoch [1/1], Batch [18/428], Loss: 0.7600
Epoch [1/1], Batch [19/428], Loss: 0.8878
Epoch [1/1], Batch [20/428], Loss: 0.8939
Epoch [1/1], Batch [21/428], Loss: 3.6683
Epoch [1/1], Batch [22/428], Loss: 5.9796
Epoch [1/1], Batch [23/428], Loss: 3.8393
Epoch [1/1], Batch [24/428], Loss: 0.9856
Epoch [1/1], Batch [25/428], Loss: 0.4525
Epoch [1/1], Batch [26/428], Loss: 0.3310
Epoch [1/1], Batch [27/428], Loss: 0.4343
Epoch [1/1], Batch [28/428], Loss: 0.9110
Epoch [1/1], Batch [29/428], Loss: 2.6166
Epoch [1/1], Batch [30/428], Loss: 0.0617
Epoch [1/1], Batch [31/428], Loss: 0.0354
Epoch [1/1], Batch [32/428], Loss: 0.0253
Epoch [1/1], Batch [33/428], Loss: 0.0081
Epoch [1/1], Batch [34/428], Loss: 0.6115
Epoch [1/1], Batch [35/428], Loss: 3.2222
Epoch [1/1], Batch [36/428], Loss: 0.1875
Epoch [1/1], Batch [37/428], Loss: 0.5574
Epoch [1/1], Batch [38/428], Loss: 0.9780
Epoch [1/1], Batch [39/428], Loss: 0.0002
Epoch [1/1], Batch [40/428], Loss: 0.0001
Epoch [1/1], Batch [41/428], Loss: 1.2555
Epoch [1/1], Batch [42/428], Loss: 1.8993
Epoch [1/1], Batch [43/428], Loss: 0.0000
Epoch [1/1], Batch [44/428], Loss: 13.2170
Epoch [1/1], Batch [45/428], Loss: 7.0791
Epoch [1/1], Batch [46/428], Loss: 11.5006
Epoch [1/1], Batch [47/428], Loss: 3.6000
Epoch [1/1], Batch [48/428], Loss: 1.3794
Epoch [1/1], Batch [49/428], Loss: 0.7756
Epoch [1/1], Batch [50/428], Loss: 2.4655
Epoch [1/1], Batch [51/428], Loss: 0.0001
Epoch [1/1], Batch [52/428], Loss: 4.0612
Epoch [1/1], Batch [53/428], Loss: 3.2115
Epoch [1/1], Batch [54/428], Loss: 2.3782
Epoch [1/1], Batch [55/428], Loss: 3.5095
Epoch [1/1], Batch [56/428], Loss: 2.2124
Epoch [1/1], Batch [57/428], Loss: 1.2964
Epoch [1/1], Batch [58/428], Loss: 2.8039
Epoch [1/1], Batch [59/428], Loss: 1.6311
Epoch [1/1], Batch [60/428], Loss: 1.3109
Epoch [1/1], Batch [61/428], Loss: 0.0002
Epoch [1/1], Batch [62/428], Loss: 1.4387
Epoch [1/1], Batch [63/428], Loss: 1.6476
Epoch [1/1], Batch [64/428], Loss: 1.9838
Epoch [1/1], Batch [65/428], Loss: 1.8184
Epoch [1/1], Batch [66/428], Loss: 1.1726
Epoch [1/1], Batch [67/428], Loss: 0.0022
Epoch [1/1], Batch [68/428], Loss: 0.0007
Epoch [1/1], Batch [69/428], Loss: 0.0007
Epoch [1/1], Batch [70/428], Loss: 0.5390
Epoch [1/1], Batch [71/428], Loss: 1.7471
Epoch [1/1], Batch [72/428], Loss: 3.8511
Epoch [1/1], Batch [73/428], Loss: 0.5468
Epoch [1/1], Batch [74/428], Loss: 0.1423
Epoch [1/1], Batch [75/428], Loss: 3.8234
Epoch [1/1], Batch [76/428], Loss: 1.1737
Epoch [1/1], Batch [77/428], Loss: 1.4347
Epoch [1/1], Batch [78/428], Loss: 0.0000
Epoch [1/1], Batch [79/428], Loss: 1.7682
Epoch [1/1], Batch [80/428], Loss: 0.8614
Epoch [1/1], Batch [81/428], Loss: 1.2972
Epoch [1/1], Batch [82/428], Loss: 0.5189
Epoch [1/1], Batch [83/428], Loss: 10.8128
Epoch [1/1], Batch [84/428], Loss: 0.0000
Epoch [1/1], Batch [85/428], Loss: 0.0000
Epoch [1/1], Batch [86/428], Loss: 0.2214
Epoch [1/1], Batch [87/428], Loss: 0.9376
Epoch [1/1], Batch [88/428], Loss: 4.4349
Epoch [1/1], Batch [89/428], Loss: 0.0009
Epoch [1/1], Batch [90/428], Loss: 0.0000
Epoch [1/1], Batch [91/428], Loss: 0.0000
Epoch [1/1], Batch [92/428], Loss: 5.4994
Epoch [1/1], Batch [93/428], Loss: 1.8746
Epoch [1/1], Batch [94/428], Loss: 0.0392
Epoch [1/1], Batch [95/428], Loss: 3.2146
Epoch [1/1], Batch [96/428], Loss: 2.9585
Epoch [1/1], Batch [97/428], Loss: 0.0001
Epoch [1/1], Batch [98/428], Loss: 0.6575
Epoch [1/1], Batch [99/428], Loss: 2.0804
Epoch [1/1], Batch [100/428], Loss: 2.9483
Epoch [1/1], Batch [101/428], Loss: 0.0010
Epoch [1/1], Batch [102/428], Loss: 0.0000
Epoch [1/1], Batch [103/428], Loss: 0.3941
Epoch [1/1], Batch [104/428], Loss: 4.3748
Epoch [1/1], Batch [105/428], Loss: 0.6953
Epoch [1/1], Batch [106/428], Loss: 0.1016
Epoch [1/1], Batch [107/428], Loss: 1.3598
Epoch [1/1], Batch [108/428], Loss: 1.1427
Epoch [1/1], Batch [109/428], Loss: 0.8013
Epoch [1/1], Batch [110/428], Loss: 1.2758
Epoch [1/1], Batch [111/428], Loss: 1.1662
Epoch [1/1], Batch [112/428], Loss: 1.2327
Epoch [1/1], Batch [113/428], Loss: 8.9676
Epoch [1/1], Batch [114/428], Loss: 2.7247
Epoch [1/1], Batch [115/428], Loss: 0.1349
Epoch [1/1], Batch [116/428], Loss: 0.2083
Epoch [1/1], Batch [117/428], Loss: 2.2872
Epoch [1/1], Batch [118/428], Loss: 8.6395
Epoch [1/1], Batch [119/428], Loss: 0.0000
Epoch [1/1], Batch [120/428], Loss: 2.9287
Epoch [1/1], Batch [121/428], Loss: 2.1231
Epoch [1/1], Batch [122/428], Loss: 1.2465
Epoch [1/1], Batch [123/428], Loss: 1.3476
Epoch [1/1], Batch [124/428], Loss: 0.1012
Epoch [1/1], Batch [125/428], Loss: 0.1674
Epoch [1/1], Batch [126/428], Loss: 0.0004
Epoch [1/1], Batch [127/428], Loss: 0.5299
Epoch [1/1], Batch [128/428], Loss: 1.7974
Epoch [1/1], Batch [129/428], Loss: 0.3365
Epoch [1/1], Batch [130/428], Loss: 0.9857
Epoch [1/1], Batch [131/428], Loss: 0.1645
Epoch [1/1], Batch [132/428], Loss: 0.5531
Epoch [1/1], Batch [133/428], Loss: 0.0003
Epoch [1/1], Batch [134/428], Loss: 0.7803
Epoch [1/1], Batch [135/428], Loss: 0.2436
Epoch [1/1], Batch [136/428], Loss: 0.2504
Epoch [1/1], Batch [137/428], Loss: 1.0402
Epoch [1/1], Batch [138/428], Loss: 0.2471
Epoch [1/1], Batch [139/428], Loss: 0.1437
Epoch [1/1], Batch [140/428], Loss: 0.0002
Epoch [1/1], Batch [141/428], Loss: 0.0651
Epoch [1/1], Batch [142/428], Loss: 0.0387
Epoch [1/1], Batch [143/428], Loss: 0.3152
Epoch [1/1], Batch [144/428], Loss: 0.0097
Epoch [1/1], Batch [145/428], Loss: 4.5390
Epoch [1/1], Batch [146/428], Loss: 2.6011
Epoch [1/1], Batch [147/428], Loss: 0.1237
Epoch [1/1], Batch [148/428], Loss: 0.3946
Epoch [1/1], Batch [149/428], Loss: 1.3861
Epoch [1/1], Batch [150/428], Loss: 0.9401
Epoch [1/1], Batch [151/428], Loss: 0.0000
Epoch [1/1], Batch [152/428], Loss: 0.2548[INFO 06-13 21:10:10] ax.service.ax_client: Completed trial 13 with data: {'objective': (np.float64(-0.77979), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 4
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 21:10:13] ax.service.ax_client: Generated new trial 14 with parameters {'lr': 0.000593, 'num_epochs': 6, 'unfreeze_epoch': 2, 'max_length': 160000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [1/1], Batch [153/428], Loss: 0.0995
Epoch [1/1], Batch [154/428], Loss: 5.7107
Epoch [1/1], Batch [155/428], Loss: 4.7343
Epoch [1/1], Batch [156/428], Loss: 0.6231
Epoch [1/1], Batch [157/428], Loss: 7.2568
Epoch [1/1], Batch [158/428], Loss: 3.2315
Epoch [1/1], Batch [159/428], Loss: 0.0037
Epoch [1/1], Batch [160/428], Loss: 1.3071
Epoch [1/1], Batch [161/428], Loss: 0.3207
Epoch [1/1], Batch [162/428], Loss: 10.9368
Epoch [1/1], Batch [163/428], Loss: 0.0367
Epoch [1/1], Batch [164/428], Loss: 0.0000
Epoch [1/1], Batch [165/428], Loss: 0.8179
Epoch [1/1], Batch [166/428], Loss: 0.0000
Epoch [1/1], Batch [167/428], Loss: 0.0000
Epoch [1/1], Batch [168/428], Loss: 0.0107
Epoch [1/1], Batch [169/428], Loss: 10.1552
Epoch [1/1], Batch [170/428], Loss: 5.4759
Epoch [1/1], Batch [171/428], Loss: 3.3430
Epoch [1/1], Batch [172/428], Loss: 0.0166
Epoch [1/1], Batch [173/428], Loss: 2.6086
Epoch [1/1], Batch [174/428], Loss: 6.2803
Epoch [1/1], Batch [175/428], Loss: 0.0008
Epoch [1/1], Batch [176/428], Loss: 0.2327
Epoch [1/1], Batch [177/428], Loss: 0.0245
Epoch [1/1], Batch [178/428], Loss: 0.8198
Epoch [1/1], Batch [179/428], Loss: 0.0004
Epoch [1/1], Batch [180/428], Loss: 0.0029
Epoch [1/1], Batch [181/428], Loss: 0.0143
Epoch [1/1], Batch [182/428], Loss: 0.0002
Epoch [1/1], Batch [183/428], Loss: 0.0004
Epoch [1/1], Batch [184/428], Loss: 2.2926
Epoch [1/1], Batch [185/428], Loss: 0.0216
Epoch [1/1], Batch [186/428], Loss: 0.0169
Epoch [1/1], Batch [187/428], Loss: 0.0419
Epoch [1/1], Batch [188/428], Loss: 0.0003
Epoch [1/1], Batch [189/428], Loss: 0.0486
Epoch [1/1], Batch [190/428], Loss: 0.0069
Epoch [1/1], Batch [191/428], Loss: 0.0363
Epoch [1/1], Batch [192/428], Loss: 0.0053
Epoch [1/1], Batch [193/428], Loss: 4.8547
Epoch [1/1], Batch [194/428], Loss: 2.2389
Epoch [1/1], Batch [195/428], Loss: 2.7208
Epoch [1/1], Batch [196/428], Loss: 0.2651
Epoch [1/1], Batch [197/428], Loss: 0.0002
Epoch [1/1], Batch [198/428], Loss: 5.0249
Epoch [1/1], Batch [199/428], Loss: 1.9248
Epoch [1/1], Batch [200/428], Loss: 0.0002
Epoch [1/1], Batch [201/428], Loss: 0.0020
Epoch [1/1], Batch [202/428], Loss: 0.0226
Epoch [1/1], Batch [203/428], Loss: 3.6639
Epoch [1/1], Batch [204/428], Loss: 1.2042
Epoch [1/1], Batch [205/428], Loss: 0.4282
Epoch [1/1], Batch [206/428], Loss: 0.0003
Epoch [1/1], Batch [207/428], Loss: 4.6942
Epoch [1/1], Batch [208/428], Loss: 2.9803
Epoch [1/1], Batch [209/428], Loss: 5.7679
Epoch [1/1], Batch [210/428], Loss: 0.2050
Epoch [1/1], Batch [211/428], Loss: 0.0110
Epoch [1/1], Batch [212/428], Loss: 0.0064
Epoch [1/1], Batch [213/428], Loss: 4.6866
Epoch [1/1], Batch [214/428], Loss: 5.6720
Epoch [1/1], Batch [215/428], Loss: 0.3199
Epoch [1/1], Batch [216/428], Loss: 1.2229
Epoch [1/1], Batch [217/428], Loss: 3.2691
Epoch [1/1], Batch [218/428], Loss: 2.1704
Epoch [1/1], Batch [219/428], Loss: 3.4821
Epoch [1/1], Batch [220/428], Loss: 0.0353
Epoch [1/1], Batch [221/428], Loss: 0.1026
Epoch [1/1], Batch [222/428], Loss: 0.0812
Epoch [1/1], Batch [223/428], Loss: 1.9849
Epoch [1/1], Batch [224/428], Loss: 0.4221
Epoch [1/1], Batch [225/428], Loss: 0.0513
Epoch [1/1], Batch [226/428], Loss: 0.5945
Epoch [1/1], Batch [227/428], Loss: 0.1320
Epoch [1/1], Batch [228/428], Loss: 0.0363
Epoch [1/1], Batch [229/428], Loss: 1.8963
Epoch [1/1], Batch [230/428], Loss: 2.0881
Epoch [1/1], Batch [231/428], Loss: 0.2085
Epoch [1/1], Batch [232/428], Loss: 1.6463
Epoch [1/1], Batch [233/428], Loss: 0.1673
Epoch [1/1], Batch [234/428], Loss: 0.0037
Epoch [1/1], Batch [235/428], Loss: 4.3577
Epoch [1/1], Batch [236/428], Loss: 5.2285
Epoch [1/1], Batch [237/428], Loss: 1.5014
Epoch [1/1], Batch [238/428], Loss: 6.1426
Epoch [1/1], Batch [239/428], Loss: 4.0307
Epoch [1/1], Batch [240/428], Loss: 1.1974
Epoch [1/1], Batch [241/428], Loss: 2.7723
Epoch [1/1], Batch [242/428], Loss: 0.0535
Epoch [1/1], Batch [243/428], Loss: 2.7989
Epoch [1/1], Batch [244/428], Loss: 0.9075
Epoch [1/1], Batch [245/428], Loss: 0.0363
Epoch [1/1], Batch [246/428], Loss: 0.0251
Epoch [1/1], Batch [247/428], Loss: 6.5797
Epoch [1/1], Batch [248/428], Loss: 0.3243
Epoch [1/1], Batch [249/428], Loss: 5.6733
Epoch [1/1], Batch [250/428], Loss: 0.7369
Epoch [1/1], Batch [251/428], Loss: 0.3633
Epoch [1/1], Batch [252/428], Loss: 2.2540
Epoch [1/1], Batch [253/428], Loss: 6.2332
Epoch [1/1], Batch [254/428], Loss: 2.9103
Epoch [1/1], Batch [255/428], Loss: 0.0005
Epoch [1/1], Batch [256/428], Loss: 0.0014
Epoch [1/1], Batch [257/428], Loss: 1.2175
Epoch [1/1], Batch [258/428], Loss: 3.0056
Epoch [1/1], Batch [259/428], Loss: 0.4753
Epoch [1/1], Batch [260/428], Loss: 0.3894
Epoch [1/1], Batch [261/428], Loss: 4.0519
Epoch [1/1], Batch [262/428], Loss: 1.2921
Epoch [1/1], Batch [263/428], Loss: 0.7023
Epoch [1/1], Batch [264/428], Loss: 3.6159
Epoch [1/1], Batch [265/428], Loss: 2.4384
Epoch [1/1], Batch [266/428], Loss: 2.7804
Epoch [1/1], Batch [267/428], Loss: 0.6608
Epoch [1/1], Batch [268/428], Loss: 0.0008
Epoch [1/1], Batch [269/428], Loss: 0.0034
Epoch [1/1], Batch [270/428], Loss: 0.3439
Epoch [1/1], Batch [271/428], Loss: 0.0019
Epoch [1/1], Batch [272/428], Loss: 0.0022
Epoch [1/1], Batch [273/428], Loss: 6.7252
Epoch [1/1], Batch [274/428], Loss: 0.0209
Epoch [1/1], Batch [275/428], Loss: 1.8612
Epoch [1/1], Batch [276/428], Loss: 0.0082
Epoch [1/1], Batch [277/428], Loss: 0.4101
Epoch [1/1], Batch [278/428], Loss: 0.3627
Epoch [1/1], Batch [279/428], Loss: 0.0201
Epoch [1/1], Batch [280/428], Loss: 1.2994
Epoch [1/1], Batch [281/428], Loss: 0.0058
Epoch [1/1], Batch [282/428], Loss: 1.4562
Epoch [1/1], Batch [283/428], Loss: 5.1032
Epoch [1/1], Batch [284/428], Loss: 0.1374
Epoch [1/1], Batch [285/428], Loss: 8.8055
Epoch [1/1], Batch [286/428], Loss: 0.0042
Epoch [1/1], Batch [287/428], Loss: 0.0001
Epoch [1/1], Batch [288/428], Loss: 0.6355
Epoch [1/1], Batch [289/428], Loss: 6.1118
Epoch [1/1], Batch [290/428], Loss: 0.4258
Epoch [1/1], Batch [291/428], Loss: 0.0194
Epoch [1/1], Batch [292/428], Loss: 0.0010
Epoch [1/1], Batch [293/428], Loss: 5.2466
Epoch [1/1], Batch [294/428], Loss: 1.2731
Epoch [1/1], Batch [295/428], Loss: 0.0056
Epoch [1/1], Batch [296/428], Loss: 0.0597
Epoch [1/1], Batch [297/428], Loss: 0.2856
Epoch [1/1], Batch [298/428], Loss: 0.3236
Epoch [1/1], Batch [299/428], Loss: 0.0063
Epoch [1/1], Batch [300/428], Loss: 7.9074
Epoch [1/1], Batch [301/428], Loss: 0.5596
Epoch [1/1], Batch [302/428], Loss: 0.1705
Epoch [1/1], Batch [303/428], Loss: 7.0026
Epoch [1/1], Batch [304/428], Loss: 5.1466
Epoch [1/1], Batch [305/428], Loss: 0.0169
Epoch [1/1], Batch [306/428], Loss: 0.0027
Epoch [1/1], Batch [307/428], Loss: 0.0033
Epoch [1/1], Batch [308/428], Loss: 2.4292
Epoch [1/1], Batch [309/428], Loss: 0.7087
Epoch [1/1], Batch [310/428], Loss: 3.5343
Epoch [1/1], Batch [311/428], Loss: 5.7910
Epoch [1/1], Batch [312/428], Loss: 4.8498
Epoch [1/1], Batch [313/428], Loss: 5.6916
Epoch [1/1], Batch [314/428], Loss: 0.0103
Epoch [1/1], Batch [315/428], Loss: 2.5635
Epoch [1/1], Batch [316/428], Loss: 0.0022
Epoch [1/1], Batch [317/428], Loss: 0.0495
Epoch [1/1], Batch [318/428], Loss: 0.0037
Epoch [1/1], Batch [319/428], Loss: 0.0084
Epoch [1/1], Batch [320/428], Loss: 1.1569
Epoch [1/1], Batch [321/428], Loss: 0.0193
Epoch [1/1], Batch [322/428], Loss: 4.0400
Epoch [1/1], Batch [323/428], Loss: 0.0020
Epoch [1/1], Batch [324/428], Loss: 0.0009
Epoch [1/1], Batch [325/428], Loss: 0.0713
Epoch [1/1], Batch [326/428], Loss: 0.0035
Epoch [1/1], Batch [327/428], Loss: 4.8750
Epoch [1/1], Batch [328/428], Loss: 1.9462
Epoch [1/1], Batch [329/428], Loss: 0.5999
Epoch [1/1], Batch [330/428], Loss: 0.0749
Epoch [1/1], Batch [331/428], Loss: 0.0219
Epoch [1/1], Batch [332/428], Loss: 0.0048
Epoch [1/1], Batch [333/428], Loss: 0.0207
Epoch [1/1], Batch [334/428], Loss: 0.0654
Epoch [1/1], Batch [335/428], Loss: 0.0079
Epoch [1/1], Batch [336/428], Loss: 0.0009
Epoch [1/1], Batch [337/428], Loss: 0.0098
Epoch [1/1], Batch [338/428], Loss: 0.0016
Epoch [1/1], Batch [339/428], Loss: 0.0003
Epoch [1/1], Batch [340/428], Loss: 7.9714
Epoch [1/1], Batch [341/428], Loss: 0.0099
Epoch [1/1], Batch [342/428], Loss: 0.0012
Epoch [1/1], Batch [343/428], Loss: 5.7431
Epoch [1/1], Batch [344/428], Loss: 3.8446
Epoch [1/1], Batch [345/428], Loss: 1.5710
Epoch [1/1], Batch [346/428], Loss: 1.2882
Epoch [1/1], Batch [347/428], Loss: 6.1957
Epoch [1/1], Batch [348/428], Loss: 7.6219
Epoch [1/1], Batch [349/428], Loss: 0.0149
Epoch [1/1], Batch [350/428], Loss: 0.0005
Epoch [1/1], Batch [351/428], Loss: 0.0933
Epoch [1/1], Batch [352/428], Loss: 6.4892
Epoch [1/1], Batch [353/428], Loss: 0.0230
Epoch [1/1], Batch [354/428], Loss: 0.0000
Epoch [1/1], Batch [355/428], Loss: 2.3624
Epoch [1/1], Batch [356/428], Loss: 0.7649
Epoch [1/1], Batch [357/428], Loss: 3.3951
Epoch [1/1], Batch [358/428], Loss: 2.9628
Epoch [1/1], Batch [359/428], Loss: 3.5189
Epoch [1/1], Batch [360/428], Loss: 0.0012
Epoch [1/1], Batch [361/428], Loss: 0.0042
Epoch [1/1], Batch [362/428], Loss: 0.1642
Epoch [1/1], Batch [363/428], Loss: 3.6103
Epoch [1/1], Batch [364/428], Loss: 0.1047
Epoch [1/1], Batch [365/428], Loss: 0.9711
Epoch [1/1], Batch [366/428], Loss: 0.5842
Epoch [1/1], Batch [367/428], Loss: 0.0421
Epoch [1/1], Batch [368/428], Loss: 0.9072
Epoch [1/1], Batch [369/428], Loss: 0.0181
Epoch [1/1], Batch [370/428], Loss: 5.8560
Epoch [1/1], Batch [371/428], Loss: 3.8521
Epoch [1/1], Batch [372/428], Loss: 5.2065
Epoch [1/1], Batch [373/428], Loss: 0.0024
Epoch [1/1], Batch [374/428], Loss: 0.0006
Epoch [1/1], Batch [375/428], Loss: 0.0003
Epoch [1/1], Batch [376/428], Loss: 0.0018
Epoch [1/1], Batch [377/428], Loss: 0.0057
Epoch [1/1], Batch [378/428], Loss: 0.0000
Epoch [1/1], Batch [379/428], Loss: 0.0001
Epoch [1/1], Batch [380/428], Loss: 0.0001
Epoch [1/1], Batch [381/428], Loss: 0.0000
Epoch [1/1], Batch [382/428], Loss: 0.0001
Epoch [1/1], Batch [383/428], Loss: 0.0001
Epoch [1/1], Batch [384/428], Loss: 0.0004
Epoch [1/1], Batch [385/428], Loss: 0.0000
Epoch [1/1], Batch [386/428], Loss: 0.0001
Epoch [1/1], Batch [387/428], Loss: 0.0001
Epoch [1/1], Batch [388/428], Loss: 0.0117
Epoch [1/1], Batch [389/428], Loss: 10.1896
Epoch [1/1], Batch [390/428], Loss: 0.0513
Epoch [1/1], Batch [391/428], Loss: 0.0226
Epoch [1/1], Batch [392/428], Loss: 3.6740
Epoch [1/1], Batch [393/428], Loss: 0.0002
Epoch [1/1], Batch [394/428], Loss: 9.2629
Epoch [1/1], Batch [395/428], Loss: 0.5549
Epoch [1/1], Batch [396/428], Loss: 0.0012
Epoch [1/1], Batch [397/428], Loss: 0.0824
Epoch [1/1], Batch [398/428], Loss: 1.5011
Epoch [1/1], Batch [399/428], Loss: 5.9869
Epoch [1/1], Batch [400/428], Loss: 0.0610
Epoch [1/1], Batch [401/428], Loss: 4.1408
Epoch [1/1], Batch [402/428], Loss: 0.0014
Epoch [1/1], Batch [403/428], Loss: 0.0032
Epoch [1/1], Batch [404/428], Loss: 0.0057
Epoch [1/1], Batch [405/428], Loss: 0.0024
Epoch [1/1], Batch [406/428], Loss: 4.7211
Epoch [1/1], Batch [407/428], Loss: 0.6507
Epoch [1/1], Batch [408/428], Loss: 0.0001
Epoch [1/1], Batch [409/428], Loss: 0.0048
Epoch [1/1], Batch [410/428], Loss: 0.0066
Epoch [1/1], Batch [411/428], Loss: 7.5993
Epoch [1/1], Batch [412/428], Loss: 0.0062
Epoch [1/1], Batch [413/428], Loss: 1.5274
Epoch [1/1], Batch [414/428], Loss: 0.0024
Epoch [1/1], Batch [415/428], Loss: 0.0117
Epoch [1/1], Batch [416/428], Loss: 0.0001
Epoch [1/1], Batch [417/428], Loss: 0.2996
Epoch [1/1], Batch [418/428], Loss: 0.0007
Epoch [1/1], Batch [419/428], Loss: 0.0009
Epoch [1/1], Batch [420/428], Loss: 0.0020
Epoch [1/1], Batch [421/428], Loss: 1.8041
Epoch [1/1], Batch [422/428], Loss: 0.0005
Epoch [1/1], Batch [423/428], Loss: 0.0078
Epoch [1/1], Batch [424/428], Loss: 0.0012
Epoch [1/1], Batch [425/428], Loss: 0.0036
Epoch [1/1], Batch [426/428], Loss: 0.0002
Epoch [1/1], Batch [427/428], Loss: 0.0002
Epoch [1/1], Batch [428/428], Loss: 1.9940
Epoch [1] Training Time: 278.85 seconds
Epoch [1/1], Average Loss: 1.6237, Training Accuracy: 0.5748
Epoch [1], Validation Loss: 1.3520, Validation Accuracy: 0.7798
Epoch [1] Validation Time: 8.96 seconds
--------------------------------------------------

Running trial 14 with config: {'batch_size': 1, 'lr': 0.0005932270795956993, 'num_epochs': 6, 'unfreeze_epoch': 2, 'max_length': 160000, 'device': device(type='cpu')}
Epoch [1/6], Batch [1/428], Loss: 3.3857
Epoch [1/6], Batch [2/428], Loss: 3.2816
Epoch [1/6], Batch [3/428], Loss: 2.7547
Epoch [1/6], Batch [4/428], Loss: 3.7229
Epoch [1/6], Batch [5/428], Loss: 1.5089
Epoch [1/6], Batch [6/428], Loss: 1.6753
Epoch [1/6], Batch [7/428], Loss: 2.0043
Epoch [1/6], Batch [8/428], Loss: 2.5942
Epoch [1/6], Batch [9/428], Loss: 0.9568
Epoch [1/6], Batch [10/428], Loss: 2.4936
Epoch [1/6], Batch [11/428], Loss: 0.7716
Epoch [1/6], Batch [12/428], Loss: 0.6709
Epoch [1/6], Batch [13/428], Loss: 2.0755
Epoch [1/6], Batch [14/428], Loss: 1.9730
Epoch [1/6], Batch [15/428], Loss: 2.1044
Epoch [1/6], Batch [16/428], Loss: 1.3082
Epoch [1/6], Batch [17/428], Loss: 2.8390
Epoch [1/6], Batch [18/428], Loss: 3.6041
Epoch [1/6], Batch [19/428], Loss: 0.4035
Epoch [1/6], Batch [20/428], Loss: 1.3647
Epoch [1/6], Batch [21/428], Loss: 3.9928
Epoch [1/6], Batch [22/428], Loss: 1.0370
Epoch [1/6], Batch [23/428], Loss: 0.9891
Epoch [1/6], Batch [24/428], Loss: 1.7629
Epoch [1/6], Batch [25/428], Loss: 2.4362
Epoch [1/6], Batch [26/428], Loss: 2.4217
Epoch [1/6], Batch [27/428], Loss: 0.9439
Epoch [1/6], Batch [28/428], Loss: 1.1043
Epoch [1/6], Batch [29/428], Loss: 2.3128
Epoch [1/6], Batch [30/428], Loss: 0.7660
Epoch [1/6], Batch [31/428], Loss: 3.4387
Epoch [1/6], Batch [32/428], Loss: 1.8341
Epoch [1/6], Batch [33/428], Loss: 0.5128
Epoch [1/6], Batch [34/428], Loss: 1.4237
Epoch [1/6], Batch [35/428], Loss: 1.5062
Epoch [1/6], Batch [36/428], Loss: 1.5979
Epoch [1/6], Batch [37/428], Loss: 4.1142
Epoch [1/6], Batch [38/428], Loss: 1.0431
Epoch [1/6], Batch [39/428], Loss: 0.2885
Epoch [1/6], Batch [40/428], Loss: 0.0789
Epoch [1/6], Batch [41/428], Loss: 0.3679
Epoch [1/6], Batch [42/428], Loss: 1.3889
Epoch [1/6], Batch [43/428], Loss: 1.5646
Epoch [1/6], Batch [44/428], Loss: 1.2683
Epoch [1/6], Batch [45/428], Loss: 1.3137
Epoch [1/6], Batch [46/428], Loss: 2.5931
Epoch [1/6], Batch [47/428], Loss: 1.5250
Epoch [1/6], Batch [48/428], Loss: 2.4034
Epoch [1/6], Batch [49/428], Loss: 1.8635
Epoch [1/6], Batch [50/428], Loss: 2.7072
Epoch [1/6], Batch [51/428], Loss: 1.7472
Epoch [1/6], Batch [52/428], Loss: 2.4964
Epoch [1/6], Batch [53/428], Loss: 1.8546
Epoch [1/6], Batch [54/428], Loss: 0.0085
Epoch [1/6], Batch [55/428], Loss: 0.1127
Epoch [1/6], Batch [56/428], Loss: 2.9188
Epoch [1/6], Batch [57/428], Loss: 1.7681
Epoch [1/6], Batch [58/428], Loss: 2.1129
Epoch [1/6], Batch [59/428], Loss: 0.4865
Epoch [1/6], Batch [60/428], Loss: 0.1410
Epoch [1/6], Batch [61/428], Loss: 0.3495
Epoch [1/6], Batch [62/428], Loss: 6.6728
Epoch [1/6], Batch [63/428], Loss: 4.6444
Epoch [1/6], Batch [64/428], Loss: 0.0083
Epoch [1/6], Batch [65/428], Loss: 2.3513
Epoch [1/6], Batch [66/428], Loss: 0.0486
Epoch [1/6], Batch [67/428], Loss: 0.0569
Epoch [1/6], Batch [68/428], Loss: 2.3874
Epoch [1/6], Batch [69/428], Loss: 0.0489
Epoch [1/6], Batch [70/428], Loss: 1.3053
Epoch [1/6], Batch [71/428], Loss: 3.4756
Epoch [1/6], Batch [72/428], Loss: 0.0065
Epoch [1/6], Batch [73/428], Loss: 2.6847
Epoch [1/6], Batch [74/428], Loss: 0.1268
Epoch [1/6], Batch [75/428], Loss: 1.5775
Epoch [1/6], Batch [76/428], Loss: 2.1660
Epoch [1/6], Batch [77/428], Loss: 3.2349
Epoch [1/6], Batch [78/428], Loss: 2.6067
Epoch [1/6], Batch [79/428], Loss: 0.0186
Epoch [1/6], Batch [80/428], Loss: 3.5166
Epoch [1/6], Batch [81/428], Loss: 0.9575
Epoch [1/6], Batch [82/428], Loss: 1.2326
Epoch [1/6], Batch [83/428], Loss: 0.8179
Epoch [1/6], Batch [84/428], Loss: 2.3483
Epoch [1/6], Batch [85/428], Loss: 1.1958
Epoch [1/6], Batch [86/428], Loss: 0.0110
Epoch [1/6], Batch [87/428], Loss: 1.4699
Epoch [1/6], Batch [88/428], Loss: 1.6878
Epoch [1/6], Batch [89/428], Loss: 0.0064
Epoch [1/6], Batch [90/428], Loss: 0.8139
Epoch [1/6], Batch [91/428], Loss: 0.0718
Epoch [1/6], Batch [92/428], Loss: 1.3953
Epoch [1/6], Batch [93/428], Loss: 0.2265
Epoch [1/6], Batch [94/428], Loss: 1.7274
Epoch [1/6], Batch [95/428], Loss: 0.7196
Epoch [1/6], Batch [96/428], Loss: 2.1164
Epoch [1/6], Batch [97/428], Loss: 0.1562
Epoch [1/6], Batch [98/428], Loss: 3.2728
Epoch [1/6], Batch [99/428], Loss: 3.6233
Epoch [1/6], Batch [100/428], Loss: 1.0719
Epoch [1/6], Batch [101/428], Loss: 1.4850
Epoch [1/6], Batch [102/428], Loss: 0.6367
Epoch [1/6], Batch [103/428], Loss: 0.0253
Epoch [1/6], Batch [104/428], Loss: 1.6473
Epoch [1/6], Batch [105/428], Loss: 4.2308
Epoch [1/6], Batch [106/428], Loss: 0.2721
Epoch [1/6], Batch [107/428], Loss: 2.5734
Epoch [1/6], Batch [108/428], Loss: 0.0067
Epoch [1/6], Batch [109/428], Loss: 2.1719
Epoch [1/6], Batch [110/428], Loss: 1.4829
Epoch [1/6], Batch [111/428], Loss: 0.2478
Epoch [1/6], Batch [112/428], Loss: 2.7002
Epoch [1/6], Batch [113/428], Loss: 0.2074
Epoch [1/6], Batch [114/428], Loss: 0.1205
Epoch [1/6], Batch [115/428], Loss: 0.3047
Epoch [1/6], Batch [116/428], Loss: 3.0970
Epoch [1/6], Batch [117/428], Loss: 1.0809
Epoch [1/6], Batch [118/428], Loss: 0.2826
Epoch [1/6], Batch [119/428], Loss: 1.8586
Epoch [1/6], Batch [120/428], Loss: 0.4854
Epoch [1/6], Batch [121/428], Loss: 1.2656
Epoch [1/6], Batch [122/428], Loss: 1.8148
Epoch [1/6], Batch [123/428], Loss: 0.0994
Epoch [1/6], Batch [124/428], Loss: 2.3739
Epoch [1/6], Batch [125/428], Loss: 2.2386
Epoch [1/6], Batch [126/428], Loss: 0.8407
Epoch [1/6], Batch [127/428], Loss: 2.1215
Epoch [1/6], Batch [128/428], Loss: 0.7702
Epoch [1/6], Batch [129/428], Loss: 1.3461
Epoch [1/6], Batch [130/428], Loss: 0.0015
Epoch [1/6], Batch [131/428], Loss: 2.4284
Epoch [1/6], Batch [132/428], Loss: 1.1394
Epoch [1/6], Batch [133/428], Loss: 0.4416
Epoch [1/6], Batch [134/428], Loss: 2.0809
Epoch [1/6], Batch [135/428], Loss: 0.0247
Epoch [1/6], Batch [136/428], Loss: 4.8657
Epoch [1/6], Batch [137/428], Loss: 1.8456
Epoch [1/6], Batch [138/428], Loss: 0.3179
Epoch [1/6], Batch [139/428], Loss: 1.9938
Epoch [1/6], Batch [140/428], Loss: 5.0876
Epoch [1/6], Batch [141/428], Loss: 4.0705
Epoch [1/6], Batch [142/428], Loss: 0.0002
Epoch [1/6], Batch [143/428], Loss: 3.1482
Epoch [1/6], Batch [144/428], Loss: 2.5280
Epoch [1/6], Batch [145/428], Loss: 0.0002
Epoch [1/6], Batch [146/428], Loss: 0.0267
Epoch [1/6], Batch [147/428], Loss: 0.2018
Epoch [1/6], Batch [148/428], Loss: 0.1611
Epoch [1/6], Batch [149/428], Loss: 0.5240
Epoch [1/6], Batch [150/428], Loss: 1.4389
Epoch [1/6], Batch [151/428], Loss: 2.6757
Epoch [1/6], Batch [152/428], Loss: 4.0550
Epoch [1/6], Batch [153/428], Loss: 0.0613
Epoch [1/6], Batch [154/428], Loss: 0.1740
Epoch [1/6], Batch [155/428], Loss: 0.0064
Epoch [1/6], Batch [156/428], Loss: 0.8704
Epoch [1/6], Batch [157/428], Loss: 1.8156
Epoch [1/6], Batch [158/428], Loss: 0.0002
Epoch [1/6], Batch [159/428], Loss: 2.2810
Epoch [1/6], Batch [160/428], Loss: 1.9664
Epoch [1/6], Batch [161/428], Loss: 0.6440
Epoch [1/6], Batch [162/428], Loss: 0.4322
Epoch [1/6], Batch [163/428], Loss: 0.7397
Epoch [1/6], Batch [164/428], Loss: 2.3312
Epoch [1/6], Batch [165/428], Loss: 0.0058
Epoch [1/6], Batch [166/428], Loss: 3.7677
Epoch [1/6], Batch [167/428], Loss: 1.0299
Epoch [1/6], Batch [168/428], Loss: 1.4618
Epoch [1/6], Batch [169/428], Loss: 0.5317
Epoch [1/6], Batch [170/428], Loss: 1.7310
Epoch [1/6], Batch [171/428], Loss: 0.0322
Epoch [1/6], Batch [172/428], Loss: 0.0029
Epoch [1/6], Batch [173/428], Loss: 2.6688
Epoch [1/6], Batch [174/428], Loss: 1.6187
Epoch [1/6], Batch [175/428], Loss: 3.3017
Epoch [1/6], Batch [176/428], Loss: 1.6193
Epoch [1/6], Batch [177/428], Loss: 1.3952
Epoch [1/6], Batch [178/428], Loss: 1.6532
Epoch [1/6], Batch [179/428], Loss: 1.8268
Epoch [1/6], Batch [180/428], Loss: 0.0426
Epoch [1/6], Batch [181/428], Loss: 0.8791
Epoch [1/6], Batch [182/428], Loss: 0.8991
Epoch [1/6], Batch [183/428], Loss: 2.3737
Epoch [1/6], Batch [184/428], Loss: 0.3633
Epoch [1/6], Batch [185/428], Loss: 2.9588
Epoch [1/6], Batch [186/428], Loss: 0.0007
Epoch [1/6], Batch [187/428], Loss: 0.0335
Epoch [1/6], Batch [188/428], Loss: 0.4122
Epoch [1/6], Batch [189/428], Loss: 0.5122
Epoch [1/6], Batch [190/428], Loss: 0.0110
Epoch [1/6], Batch [191/428], Loss: 1.4427
Epoch [1/6], Batch [192/428], Loss: 1.8080
Epoch [1/6], Batch [193/428], Loss: 3.1155
Epoch [1/6], Batch [194/428], Loss: 1.1284
Epoch [1/6], Batch [195/428], Loss: 2.5954
Epoch [1/6], Batch [196/428], Loss: 1.2057
Epoch [1/6], Batch [197/428], Loss: 0.0001
Epoch [1/6], Batch [198/428], Loss: 0.0000
Epoch [1/6], Batch [199/428], Loss: 1.8464
Epoch [1/6], Batch [200/428], Loss: 0.9242
Epoch [1/6], Batch [201/428], Loss: 2.5060
Epoch [1/6], Batch [202/428], Loss: 0.0001
Epoch [1/6], Batch [203/428], Loss: 0.4277
Epoch [1/6], Batch [204/428], Loss: 2.9127
Epoch [1/6], Batch [205/428], Loss: 1.5846
Epoch [1/6], Batch [206/428], Loss: 0.0736
Epoch [1/6], Batch [207/428], Loss: 0.2114
Epoch [1/6], Batch [208/428], Loss: 1.9919
Epoch [1/6], Batch [209/428], Loss: 0.4624
Epoch [1/6], Batch [210/428], Loss: 0.0000
Epoch [1/6], Batch [211/428], Loss: 0.8028
Epoch [1/6], Batch [212/428], Loss: 3.8607
Epoch [1/6], Batch [213/428], Loss: 3.9752
Epoch [1/6], Batch [214/428], Loss: 2.8547
Epoch [1/6], Batch [215/428], Loss: 4.2070
Epoch [1/6], Batch [216/428], Loss: 6.3365
Epoch [1/6], Batch [217/428], Loss: 1.0563
Epoch [1/6], Batch [218/428], Loss: 0.5521
Epoch [1/6], Batch [219/428], Loss: 1.2519
Epoch [1/6], Batch [220/428], Loss: 0.0001
Epoch [1/6], Batch [221/428], Loss: 1.1774
Epoch [1/6], Batch [222/428], Loss: 2.0506
Epoch [1/6], Batch [223/428], Loss: 0.0007
Epoch [1/6], Batch [224/428], Loss: 0.8593
Epoch [1/6], Batch [225/428], Loss: 1.2416
Epoch [1/6], Batch [226/428], Loss: 2.4362
Epoch [1/6], Batch [227/428], Loss: 0.7912
Epoch [1/6], Batch [228/428], Loss: 0.1254
Epoch [1/6], Batch [229/428], Loss: 2.9114
Epoch [1/6], Batch [230/428], Loss: 0.7967
Epoch [1/6], Batch [231/428], Loss: 1.2139
Epoch [1/6], Batch [232/428], Loss: 1.1038
Epoch [1/6], Batch [233/428], Loss: 0.8070
Epoch [1/6], Batch [234/428], Loss: 0.0311
Epoch [1/6], Batch [235/428], Loss: 2.9351
Epoch [1/6], Batch [236/428], Loss: 0.0002
Epoch [1/6], Batch [237/428], Loss: 1.2238
Epoch [1/6], Batch [238/428], Loss: 1.7186
Epoch [1/6], Batch [239/428], Loss: 0.8446
Epoch [1/6], Batch [240/428], Loss: 0.1120
Epoch [1/6], Batch [241/428], Loss: 0.2560
Epoch [1/6], Batch [242/428], Loss: 0.2472
Epoch [1/6], Batch [243/428], Loss: 0.0400
Epoch [1/6], Batch [244/428], Loss: 0.0001
Epoch [1/6], Batch [245/428], Loss: 2.5610
Epoch [1/6], Batch [246/428], Loss: 2.1603
Epoch [1/6], Batch [247/428], Loss: 0.9341
Epoch [1/6], Batch [248/428], Loss: 0.0282
Epoch [1/6], Batch [249/428], Loss: 0.0002
Epoch [1/6], Batch [250/428], Loss: 1.8520
Epoch [1/6], Batch [251/428], Loss: 2.6137
Epoch [1/6], Batch [252/428], Loss: 2.0110
Epoch [1/6], Batch [253/428], Loss: 0.0220
Epoch [1/6], Batch [254/428], Loss: 2.1749
Epoch [1/6], Batch [255/428], Loss: 0.0297
Epoch [1/6], Batch [256/428], Loss: 0.0643
Epoch [1/6], Batch [257/428], Loss: 0.5943
Epoch [1/6], Batch [258/428], Loss: 1.1662
Epoch [1/6], Batch [259/428], Loss: 0.5063
Epoch [1/6], Batch [260/428], Loss: 1.0451
Epoch [1/6], Batch [261/428], Loss: 0.4768
Epoch [1/6], Batch [262/428], Loss: 0.0004
Epoch [1/6], Batch [263/428], Loss: 0.6283
Epoch [1/6], Batch [264/428], Loss: 0.0006
Epoch [1/6], Batch [265/428], Loss: 0.1962
Epoch [1/6], Batch [266/428], Loss: 7.5766
Epoch [1/6], Batch [267/428], Loss: 7.1057
Epoch [1/6], Batch [268/428], Loss: 0.9143
Epoch [1/6], Batch [269/428], Loss: 0.0019
Epoch [1/6], Batch [270/428], Loss: 2.9701
Epoch [1/6], Batch [271/428], Loss: 5.6807
Epoch [1/6], Batch [272/428], Loss: 5.4788
Epoch [1/6], Batch [273/428], Loss: 3.0975
Epoch [1/6], Batch [274/428], Loss: 4.5562
Epoch [1/6], Batch [275/428], Loss: 1.0593
Epoch [1/6], Batch [276/428], Loss: 0.9501
Epoch [1/6], Batch [277/428], Loss: 0.2826
Epoch [1/6], Batch [278/428], Loss: 1.1029
Epoch [1/6], Batch [279/428], Loss: 0.5423
Epoch [1/6], Batch [280/428], Loss: 1.5379
Epoch [1/6], Batch [281/428], Loss: 2.5199
Epoch [1/6], Batch [282/428], Loss: 0.3109
Epoch [1/6], Batch [283/428], Loss: 0.0009
Epoch [1/6], Batch [284/428], Loss: 0.7719
Epoch [1/6], Batch [285/428], Loss: 0.0006
Epoch [1/6], Batch [286/428], Loss: 0.5702
Epoch [1/6], Batch [287/428], Loss: 0.0001
Epoch [1/6], Batch [288/428], Loss: 0.1217
Epoch [1/6], Batch [289/428], Loss: 0.0102
Epoch [1/6], Batch [290/428], Loss: 0.1445
Epoch [1/6], Batch [291/428], Loss: 0.0470
Epoch [1/6], Batch [292/428], Loss: 0.2478
Epoch [1/6], Batch [293/428], Loss: 5.0801
Epoch [1/6], Batch [294/428], Loss: 0.6214
Epoch [1/6], Batch [295/428], Loss: 0.1055
Epoch [1/6], Batch [296/428], Loss: 0.8500
Epoch [1/6], Batch [297/428], Loss: 2.6611
Epoch [1/6], Batch [298/428], Loss: 0.0451
Epoch [1/6], Batch [299/428], Loss: 0.1115
Epoch [1/6], Batch [300/428], Loss: 2.3866
Epoch [1/6], Batch [301/428], Loss: 0.0660
Epoch [1/6], Batch [302/428], Loss: 0.0001
Epoch [1/6], Batch [303/428], Loss: 7.9416
Epoch [1/6], Batch [304/428], Loss: 0.4920
Epoch [1/6], Batch [305/428], Loss: 0.0162
Epoch [1/6], Batch [306/428], Loss: 0.5916
Epoch [1/6], Batch [307/428], Loss: 0.1407
Epoch [1/6], Batch [308/428], Loss: 1.2327
Epoch [1/6], Batch [309/428], Loss: 1.1378
Epoch [1/6], Batch [310/428], Loss: 2.5945
Epoch [1/6], Batch [311/428], Loss: 3.1522
Epoch [1/6], Batch [312/428], Loss: 0.0204
Epoch [1/6], Batch [313/428], Loss: 7.3051
Epoch [1/6], Batch [314/428], Loss: 2.4327
Epoch [1/6], Batch [315/428], Loss: 0.3038
Epoch [1/6], Batch [316/428], Loss: 0.0129
Epoch [1/6], Batch [317/428], Loss: 3.6587
Epoch [1/6], Batch [318/428], Loss: 0.0138
Epoch [1/6], Batch [319/428], Loss: 0.5208
Epoch [1/6], Batch [320/428], Loss: 0.0000
Epoch [1/6], Batch [321/428], Loss: 0.0157
Epoch [1/6], Batch [322/428], Loss: 0.0220
Epoch [1/6], Batch [323/428], Loss: 1.9183
Epoch [1/6], Batch [324/428], Loss: 0.6203
Epoch [1/6], Batch [325/428], Loss: 1.5382
Epoch [1/6], Batch [326/428], Loss: 0.5162
Epoch [1/6], Batch [327/428], Loss: 0.0000
Epoch [1/6], Batch [328/428], Loss: 2.2629
Epoch [1/6], Batch [329/428], Loss: 0.0004
Epoch [1/6], Batch [330/428], Loss: 0.1514
Epoch [1/6], Batch [331/428], Loss: 1.1166
Epoch [1/6], Batch [332/428], Loss: 1.9614
Epoch [1/6], Batch [333/428], Loss: 0.9576
Epoch [1/6], Batch [334/428], Loss: 3.4468
Epoch [1/6], Batch [335/428], Loss: 0.7754
Epoch [1/6], Batch [336/428], Loss: 0.3265
Epoch [1/6], Batch [337/428], Loss: 0.0366
Epoch [1/6], Batch [338/428], Loss: 0.7851
Epoch [1/6], Batch [339/428], Loss: 0.0001
Epoch [1/6], Batch [340/428], Loss: 4.1663
Epoch [1/6], Batch [341/428], Loss: 1.9052
Epoch [1/6], Batch [342/428], Loss: 0.5512
Epoch [1/6], Batch [343/428], Loss: 2.9566
Epoch [1/6], Batch [344/428], Loss: 2.5293
Epoch [1/6], Batch [345/428], Loss: 0.0007
Epoch [1/6], Batch [346/428], Loss: 0.0060
Epoch [1/6], Batch [347/428], Loss: 0.0050
Epoch [1/6], Batch [348/428], Loss: 5.9363
Epoch [1/6], Batch [349/428], Loss: 7.8355
Epoch [1/6], Batch [350/428], Loss: 2.9214
Epoch [1/6], Batch [351/428], Loss: 0.8491
Epoch [1/6], Batch [352/428], Loss: 0.6632
Epoch [1/6], Batch [353/428], Loss: 0.9630
Epoch [1/6], Batch [354/428], Loss: 0.1157
Epoch [1/6], Batch [355/428], Loss: 0.0062
Epoch [1/6], Batch [356/428], Loss: 1.3553
Epoch [1/6], Batch [357/428], Loss: 1.4086
Epoch [1/6], Batch [358/428], Loss: 0.2969
Epoch [1/6], Batch [359/428], Loss: 0.0022
Epoch [1/6], Batch [360/428], Loss: 1.8609
Epoch [1/6], Batch [361/428], Loss: 3.8102
Epoch [1/6], Batch [362/428], Loss: 0.3197
Epoch [1/6], Batch [363/428], Loss: 1.5314
Epoch [1/6], Batch [364/428], Loss: 0.0001
Epoch [1/6], Batch [365/428], Loss: 2.9575
Epoch [1/6], Batch [366/428], Loss: 0.6536
Epoch [1/6], Batch [367/428], Loss: 0.7401
Epoch [1/6], Batch [368/428], Loss: 0.4674
Epoch [1/6], Batch [369/428], Loss: 1.0144
Epoch [1/6], Batch [370/428], Loss: 0.0009
Epoch [1/6], Batch [371/428], Loss: 0.0130
Epoch [1/6], Batch [372/428], Loss: 0.0000
Epoch [1/6], Batch [373/428], Loss: 2.9772
Epoch [1/6], Batch [374/428], Loss: 1.5689
Epoch [1/6], Batch [375/428], Loss: 1.6964
Epoch [1/6], Batch [376/428], Loss: 0.9510
Epoch [1/6], Batch [377/428], Loss: 0.5090
Epoch [1/6], Batch [378/428], Loss: 0.5269
Epoch [1/6], Batch [379/428], Loss: 0.0223
Epoch [1/6], Batch [380/428], Loss: 2.1529
Epoch [1/6], Batch [381/428], Loss: 2.2354
Epoch [1/6], Batch [382/428], Loss: 1.7802
Epoch [1/6], Batch [383/428], Loss: 0.0119
Epoch [1/6], Batch [384/428], Loss: 3.3062
Epoch [1/6], Batch [385/428], Loss: 1.1786
Epoch [1/6], Batch [386/428], Loss: 3.8753
Epoch [1/6], Batch [387/428], Loss: 0.1962
Epoch [1/6], Batch [388/428], Loss: 0.1321
Epoch [1/6], Batch [389/428], Loss: 1.0030
Epoch [1/6], Batch [390/428], Loss: 0.8903
Epoch [1/6], Batch [391/428], Loss: 0.0014
Epoch [1/6], Batch [392/428], Loss: 0.0019
Epoch [1/6], Batch [393/428], Loss: 1.3584
Epoch [1/6], Batch [394/428], Loss: 1.4764
Epoch [1/6], Batch [395/428], Loss: 0.2310
Epoch [1/6], Batch [396/428], Loss: 0.5407
Epoch [1/6], Batch [397/428], Loss: 2.5433
Epoch [1/6], Batch [398/428], Loss: 0.0014
Epoch [1/6], Batch [399/428], Loss: 0.5977
Epoch [1/6], Batch [400/428], Loss: 0.0000
Epoch [1/6], Batch [401/428], Loss: 0.7460
Epoch [1/6], Batch [402/428], Loss: 1.9850
Epoch [1/6], Batch [403/428], Loss: 0.0074
Epoch [1/6], Batch [404/428], Loss: 0.2251
Epoch [1/6], Batch [405/428], Loss: 0.3107
Epoch [1/6], Batch [406/428], Loss: 0.1147
Epoch [1/6], Batch [407/428], Loss: 0.0177
Epoch [1/6], Batch [408/428], Loss: 2.6581
Epoch [1/6], Batch [409/428], Loss: 2.6533
Epoch [1/6], Batch [410/428], Loss: 0.0000
Epoch [1/6], Batch [411/428], Loss: 0.1320
Epoch [1/6], Batch [412/428], Loss: 0.8075
Epoch [1/6], Batch [413/428], Loss: 4.1039
Epoch [1/6], Batch [414/428], Loss: 0.0193
Epoch [1/6], Batch [415/428], Loss: 0.0017
Epoch [1/6], Batch [416/428], Loss: 0.0119
Epoch [1/6], Batch [417/428], Loss: 4.8824
Epoch [1/6], Batch [418/428], Loss: 0.0091
Epoch [1/6], Batch [419/428], Loss: 3.5566
Epoch [1/6], Batch [420/428], Loss: 0.7611
Epoch [1/6], Batch [421/428], Loss: 5.9261
Epoch [1/6], Batch [422/428], Loss: 0.2459
Epoch [1/6], Batch [423/428], Loss: 0.6973
Epoch [1/6], Batch [424/428], Loss: 0.0585
Epoch [1/6], Batch [425/428], Loss: 0.0002
Epoch [1/6], Batch [426/428], Loss: 5.3449
Epoch [1/6], Batch [427/428], Loss: 0.0000
Epoch [1/6], Batch [428/428], Loss: 0.4267
Epoch [1] Training Time: 350.02 seconds
Epoch [1/6], Average Loss: 1.4048, Training Accuracy: 0.5280
Epoch [1], Validation Loss: 1.5666, Validation Accuracy: 0.5500
Epoch [1] Validation Time: 19.31 seconds
--------------------------------------------------
Epoch [2/6], Batch [1/428], Loss: 1.8743
Epoch [2/6], Batch [2/428], Loss: 0.4615
Epoch [2/6], Batch [3/428], Loss: 0.0685
Epoch [2/6], Batch [4/428], Loss: 1.7428
Epoch [2/6], Batch [5/428], Loss: 0.0011
Epoch [2/6], Batch [6/428], Loss: 2.3456
Epoch [2/6], Batch [7/428], Loss: 0.0614
Epoch [2/6], Batch [8/428], Loss: 0.6195
Epoch [2/6], Batch [9/428], Loss: 0.2336
Epoch [2/6], Batch [10/428], Loss: 0.1327
Epoch [2/6], Batch [11/428], Loss: 0.0747
Epoch [2/6], Batch [12/428], Loss: 0.0026
Epoch [2/6], Batch [13/428], Loss: 2.6066
Epoch [2/6], Batch [14/428], Loss: 1.8163
Epoch [2/6], Batch [15/428], Loss: 0.0336
Epoch [2/6], Batch [16/428], Loss: 0.0001
Epoch [2/6], Batch [17/428], Loss: 2.3418
Epoch [2/6], Batch [18/428], Loss: 0.0677
Epoch [2/6], Batch [19/428], Loss: 0.0000
Epoch [2/6], Batch [20/428], Loss: 0.0118
Epoch [2/6], Batch [21/428], Loss: 1.9932
Epoch [2/6], Batch [22/428], Loss: 1.8273
Epoch [2/6], Batch [23/428], Loss: 0.0504
Epoch [2/6], Batch [24/428], Loss: 0.0012
Epoch [2/6], Batch [25/428], Loss: 0.0000
Epoch [2/6], Batch [26/428], Loss: 2.0200
Epoch [2/6], Batch [27/428], Loss: 3.2179
Epoch [2/6], Batch [28/428], Loss: 1.1703
Epoch [2/6], Batch [29/428], Loss: 1.1317
Epoch [2/6], Batch [30/428], Loss: 1.9338
Epoch [2/6], Batch [31/428], Loss: 6.1080
Epoch [2/6], Batch [32/428], Loss: 0.0004
Epoch [2/6], Batch [33/428], Loss: 0.5465
Epoch [2/6], Batch [34/428], Loss: 2.1549
Epoch [2/6], Batch [35/428], Loss: 1.9302
Epoch [2/6], Batch [36/428], Loss: 0.0093
Epoch [2/6], Batch [37/428], Loss: 3.0324
Epoch [2/6], Batch [38/428], Loss: 1.3682
Epoch [2/6], Batch [39/428], Loss: 0.4897
Epoch [2/6], Batch [40/428], Loss: 0.3137
Epoch [2/6], Batch [41/428], Loss: 3.5279
Epoch [2/6], Batch [42/428], Loss: 0.0000
Epoch [2/6], Batch [43/428], Loss: 0.0299
Epoch [2/6], Batch [44/428], Loss: 0.0415
Epoch [2/6], Batch [45/428], Loss: 1.3509
Epoch [2/6], Batch [46/428], Loss: 1.2384
Epoch [2/6], Batch [47/428], Loss: 2.4755
Epoch [2/6], Batch [48/428], Loss: 0.4378
Epoch [2/6], Batch [49/428], Loss: 0.8164
Epoch [2/6], Batch [50/428], Loss: 1.4783
Epoch [2/6], Batch [51/428], Loss: 1.1074
Epoch [2/6], Batch [52/428], Loss: 1.3778
Epoch [2/6], Batch [53/428], Loss: 4.8788
Epoch [2/6], Batch [54/428], Loss: 0.0197
Epoch [2/6], Batch [55/428], Loss: 0.1990
Epoch [2/6], Batch [56/428], Loss: 0.0007
Epoch [2/6], Batch [57/428], Loss: 0.8623
Epoch [2/6], Batch [58/428], Loss: 0.9910
Epoch [2/6], Batch [59/428], Loss: 0.2261
Epoch [2/6], Batch [60/428], Loss: 0.7022
Epoch [2/6], Batch [61/428], Loss: 4.7112
Epoch [2/6], Batch [62/428], Loss: 0.0001
Epoch [2/6], Batch [63/428], Loss: 3.4855
Epoch [2/6], Batch [64/428], Loss: 0.0859
Epoch [2/6], Batch [65/428], Loss: 1.1639
Epoch [2/6], Batch [66/428], Loss: 0.4339
Epoch [2/6], Batch [67/428], Loss: 0.0012
Epoch [2/6], Batch [68/428], Loss: 0.2197
Epoch [2/6], Batch [69/428], Loss: 0.6008
Epoch [2/6], Batch [70/428], Loss: 1.3251
Epoch [2/6], Batch [71/428], Loss: 0.0000
Epoch [2/6], Batch [72/428], Loss: 0.0006
Epoch [2/6], Batch [73/428], Loss: 5.0278
Epoch [2/6], Batch [74/428], Loss: 1.8820
Epoch [2/6], Batch [75/428], Loss: 0.0879
Epoch [2/6], Batch [76/428], Loss: 1.7792
Epoch [2/6], Batch [77/428], Loss: 1.9160
Epoch [2/6], Batch [78/428], Loss: 0.0000
Epoch [2/6], Batch [79/428], Loss: 0.0970
Epoch [2/6], Batch [80/428], Loss: 0.1757
Epoch [2/6], Batch [81/428], Loss: 2.3415
Epoch [2/6], Batch [82/428], Loss: 1.8482
Epoch [2/6], Batch [83/428], Loss: 0.2816
Epoch [2/6], Batch [84/428], Loss: 0.0081
Epoch [2/6], Batch [85/428], Loss: 0.0001
Epoch [2/6], Batch [86/428], Loss: 0.0040
Epoch [2/6], Batch [87/428], Loss: 2.9638
Epoch [2/6], Batch [88/428], Loss: 1.3638
Epoch [2/6], Batch [89/428], Loss: 4.9496
Epoch [2/6], Batch [90/428], Loss: 1.1934
Epoch [2/6], Batch [91/428], Loss: 1.2434
Epoch [2/6], Batch [92/428], Loss: 1.5603
Epoch [2/6], Batch [93/428], Loss: 0.8680
Epoch [2/6], Batch [94/428], Loss: 0.0049
Epoch [2/6], Batch [95/428], Loss: 1.4893
Epoch [2/6], Batch [96/428], Loss: 0.0014
Epoch [2/6], Batch [97/428], Loss: 1.1241
Epoch [2/6], Batch [98/428], Loss: 0.0803
Epoch [2/6], Batch [99/428], Loss: 2.1426
Epoch [2/6], Batch [100/428], Loss: 0.0414
Epoch [2/6], Batch [101/428], Loss: 0.0351
Epoch [2/6], Batch [102/428], Loss: 2.1730
Epoch [2/6], Batch [103/428], Loss: 2.4902
Epoch [2/6], Batch [104/428], Loss: 2.2752
Epoch [2/6], Batch [105/428], Loss: 0.0000
Epoch [2/6], Batch [106/428], Loss: 0.1087
Epoch [2/6], Batch [107/428], Loss: 0.0000
Epoch [2/6], Batch [108/428], Loss: 5.1376
Epoch [2/6], Batch [109/428], Loss: 1.5451
Epoch [2/6], Batch [110/428], Loss: 0.0794
Epoch [2/6], Batch [111/428], Loss: 0.0000
Epoch [2/6], Batch [112/428], Loss: 0.3209
Epoch [2/6], Batch [113/428], Loss: 1.1583
Epoch [2/6], Batch [114/428], Loss: 0.4739
Epoch [2/6], Batch [115/428], Loss: 0.0503
Epoch [2/6], Batch [116/428], Loss: 0.2024
Epoch [2/6], Batch [117/428], Loss: 0.9265
Epoch [2/6], Batch [118/428], Loss: 0.1626
Epoch [2/6], Batch [119/428], Loss: 0.1360
Epoch [2/6], Batch [120/428], Loss: 0.0431
Epoch [2/6], Batch [121/428], Loss: 1.5858
Epoch [2/6], Batch [122/428], Loss: 0.0000
Epoch [2/6], Batch [123/428], Loss: 2.8211
Epoch [2/6], Batch [124/428], Loss: 1.3161
Epoch [2/6], Batch [125/428], Loss: 0.0876
Epoch [2/6], Batch [126/428], Loss: 1.5618
Epoch [2/6], Batch [127/428], Loss: 3.5083
Epoch [2/6], Batch [128/428], Loss: 2.1662
Epoch [2/6], Batch [129/428], Loss: 0.9676
Epoch [2/6], Batch [130/428], Loss: 0.0004
Epoch [2/6], Batch [131/428], Loss: 0.5306
Epoch [2/6], Batch [132/428], Loss: 0.0130
Epoch [2/6], Batch [133/428], Loss: 5.7544
Epoch [2/6], Batch [134/428], Loss: 1.5673
Epoch [2/6], Batch [135/428], Loss: 0.0063
Epoch [2/6], Batch [136/428], Loss: 0.0000
Epoch [2/6], Batch [137/428], Loss: 0.4792
Epoch [2/6], Batch [138/428], Loss: 1.9431
Epoch [2/6], Batch [139/428], Loss: 0.8079
Epoch [2/6], Batch [140/428], Loss: 0.3528
Epoch [2/6], Batch [141/428], Loss: 0.0106
Epoch [2/6], Batch [142/428], Loss: 0.0570
Epoch [2/6], Batch [143/428], Loss: 0.5195
Epoch [2/6], Batch [144/428], Loss: 0.0729
Epoch [2/6], Batch [145/428], Loss: 0.0307
Epoch [2/6], Batch [146/428], Loss: 0.0550
Epoch [2/6], Batch [147/428], Loss: 5.1075
Epoch [2/6], Batch [148/428], Loss: 0.1744
Epoch [2/6], Batch [149/428], Loss: 3.0643
Epoch [2/6], Batch [150/428], Loss: 3.4406
Epoch [2/6], Batch [151/428], Loss: 2.7897
Epoch [2/6], Batch [152/428], Loss: 0.8198
Epoch [2/6], Batch [153/428], Loss: 0.0031
Epoch [2/6], Batch [154/428], Loss: 0.0256
Epoch [2/6], Batch [155/428], Loss: 3.2656
Epoch [2/6], Batch [156/428], Loss: 3.1899
Epoch [2/6], Batch [157/428], Loss: 0.1747
Epoch [2/6], Batch [158/428], Loss: 0.1794
Epoch [2/6], Batch [159/428], Loss: 0.0143
Epoch [2/6], Batch [160/428], Loss: 0.0000
Epoch [2/6], Batch [161/428], Loss: 0.0000
Epoch [2/6], Batch [162/428], Loss: 0.9186
Epoch [2/6], Batch [163/428], Loss: 0.0000
Epoch [2/6], Batch [164/428], Loss: 0.2497
Epoch [2/6], Batch [165/428], Loss: 2.5159
Epoch [2/6], Batch [166/428], Loss: 0.0000
Epoch [2/6], Batch [167/428], Loss: 0.3997
Epoch [2/6], Batch [168/428], Loss: 0.3813
Epoch [2/6], Batch [169/428], Loss: 3.5245
Epoch [2/6], Batch [170/428], Loss: 2.5775
Epoch [2/6], Batch [171/428], Loss: 3.7453
Epoch [2/6], Batch [172/428], Loss: 0.0008
Epoch [2/6], Batch [173/428], Loss: 0.0663
Epoch [2/6], Batch [174/428], Loss: 1.2342
Epoch [2/6], Batch [175/428], Loss: 3.5123
Epoch [2/6], Batch [176/428], Loss: 0.4193
Epoch [2/6], Batch [177/428], Loss: 1.6906
Epoch [2/6], Batch [178/428], Loss: 0.0080
Epoch [2/6], Batch [179/428], Loss: 0.0000
Epoch [2/6], Batch [180/428], Loss: 2.8431
Epoch [2/6], Batch [181/428], Loss: 0.0271
Epoch [2/6], Batch [182/428], Loss: 0.0439
Epoch [2/6], Batch [183/428], Loss: 0.4133
Epoch [2/6], Batch [184/428], Loss: 0.1062
Epoch [2/6], Batch [185/428], Loss: 0.0393
Epoch [2/6], Batch [186/428], Loss: 2.3376
Epoch [2/6], Batch [187/428], Loss: 0.0853
Epoch [2/6], Batch [188/428], Loss: 0.2510
Epoch [2/6], Batch [189/428], Loss: 0.9353
Epoch [2/6], Batch [190/428], Loss: 2.0946
Epoch [2/6], Batch [191/428], Loss: 0.0129
Epoch [2/6], Batch [192/428], Loss: 1.4306
Epoch [2/6], Batch [193/428], Loss: 0.0000
Epoch [2/6], Batch [194/428], Loss: 0.0609
Epoch [2/6], Batch [195/428], Loss: 0.0243
Epoch [2/6], Batch [196/428], Loss: 0.0000
Epoch [2/6], Batch [197/428], Loss: 0.0132
Epoch [2/6], Batch [198/428], Loss: 1.6097
Epoch [2/6], Batch [199/428], Loss: 1.2195
Epoch [2/6], Batch [200/428], Loss: 2.9498
Epoch [2/6], Batch [201/428], Loss: 0.1198
Epoch [2/6], Batch [202/428], Loss: 1.2914
Epoch [2/6], Batch [203/428], Loss: 0.0207
Epoch [2/6], Batch [204/428], Loss: 1.0469
Epoch [2/6], Batch [205/428], Loss: 0.4057
Epoch [2/6], Batch [206/428], Loss: 0.0605
Epoch [2/6], Batch [207/428], Loss: 0.0442
Epoch [2/6], Batch [208/428], Loss: 0.6857
Epoch [2/6], Batch [209/428], Loss: 1.4325
Epoch [2/6], Batch [210/428], Loss: 0.1309
Epoch [2/6], Batch [211/428], Loss: 0.0092
Epoch [2/6], Batch [212/428], Loss: 0.0022
Epoch [2/6], Batch [213/428], Loss: 1.7250
Epoch [2/6], Batch [214/428], Loss: 0.3183
Epoch [2/6], Batch [215/428], Loss: 6.1773
Epoch [2/6], Batch [216/428], Loss: 1.4286
Epoch [2/6], Batch [217/428], Loss: 3.5650
Epoch [2/6], Batch [218/428], Loss: 0.0106
Epoch [2/6], Batch [219/428], Loss: 0.6863
Epoch [2/6], Batch [220/428], Loss: 0.0000
Epoch [2/6], Batch [221/428], Loss: 1.4738
Epoch [2/6], Batch [222/428], Loss: 3.2284
Epoch [2/6], Batch [223/428], Loss: 0.1747
Epoch [2/6], Batch [224/428], Loss: 1.2645
Epoch [2/6], Batch [225/428], Loss: 0.1305
Epoch [2/6], Batch [226/428], Loss: 6.1456
Epoch [2/6], Batch [227/428], Loss: 5.2374
Epoch [2/6], Batch [228/428], Loss: 3.6490
Epoch [2/6], Batch [229/428], Loss: 2.8533
Epoch [2/6], Batch [230/428], Loss: 3.2110
Epoch [2/6], Batch [231/428], Loss: 0.3252
Epoch [2/6], Batch [232/428], Loss: 0.1733
Epoch [2/6], Batch [233/428], Loss: 0.0100
Epoch [2/6], Batch [234/428], Loss: 3.8036
Epoch [2/6], Batch [235/428], Loss: 7.5410
Epoch [2/6], Batch [236/428], Loss: 0.0055
Epoch [2/6], Batch [237/428], Loss: 2.2901
Epoch [2/6], Batch [238/428], Loss: 4.2463
Epoch [2/6], Batch [239/428], Loss: 0.0354
Epoch [2/6], Batch [240/428], Loss: 2.6919
Epoch [2/6], Batch [241/428], Loss: 2.5687
Epoch [2/6], Batch [242/428], Loss: 0.9864
Epoch [2/6], Batch [243/428], Loss: 3.4104
Epoch [2/6], Batch [244/428], Loss: 0.0246
Epoch [2/6], Batch [245/428], Loss: 2.6087
Epoch [2/6], Batch [246/428], Loss: 0.0002
Epoch [2/6], Batch [247/428], Loss: 1.1191
Epoch [2/6], Batch [248/428], Loss: 2.9329
Epoch [2/6], Batch [249/428], Loss: 0.1208
Epoch [2/6], Batch [250/428], Loss: 0.6664
Epoch [2/6], Batch [251/428], Loss: 0.0094
Epoch [2/6], Batch [252/428], Loss: 2.1576
Epoch [2/6], Batch [253/428], Loss: 0.0015
Epoch [2/6], Batch [254/428], Loss: 0.0048
Epoch [2/6], Batch [255/428], Loss: 3.9600
Epoch [2/6], Batch [256/428], Loss: 0.0145
Epoch [2/6], Batch [257/428], Loss: 0.0026
Epoch [2/6], Batch [258/428], Loss: 0.0901
Epoch [2/6], Batch [259/428], Loss: 0.0584
Epoch [2/6], Batch [260/428], Loss: 1.3384
Epoch [2/6], Batch [261/428], Loss: 0.0638
Epoch [2/6], Batch [262/428], Loss: 0.0385
Epoch [2/6], Batch [263/428], Loss: 3.7396
Epoch [2/6], Batch [264/428], Loss: 0.0669
Epoch [2/6], Batch [265/428], Loss: 3.2465
Epoch [2/6], Batch [266/428], Loss: 1.1339
Epoch [2/6], Batch [267/428], Loss: 5.3442
Epoch [2/6], Batch [268/428], Loss: 0.0229
Epoch [2/6], Batch [269/428], Loss: 2.5763
Epoch [2/6], Batch [270/428], Loss: 0.9064
Epoch [2/6], Batch [271/428], Loss: 0.6035
Epoch [2/6], Batch [272/428], Loss: 0.0233
Epoch [2/6], Batch [273/428], Loss: 2.3107
Epoch [2/6], Batch [274/428], Loss: 0.0000
Epoch [2/6], Batch [275/428], Loss: 1.7739
Epoch [2/6], Batch [276/428], Loss: 0.4074
Epoch [2/6], Batch [277/428], Loss: 2.0043
Epoch [2/6], Batch [278/428], Loss: 0.0608
Epoch [2/6], Batch [279/428], Loss: 3.9715
Epoch [2/6], Batch [280/428], Loss: 0.3384
Epoch [2/6], Batch [281/428], Loss: 0.4112
Epoch [2/6], Batch [282/428], Loss: 1.0383
Epoch [2/6], Batch [283/428], Loss: 0.0000
Epoch [2/6], Batch [284/428], Loss: 0.0162
Epoch [2/6], Batch [285/428], Loss: 0.0000
Epoch [2/6], Batch [286/428], Loss: 1.9348
Epoch [2/6], Batch [287/428], Loss: 2.6215
Epoch [2/6], Batch [288/428], Loss: 2.6408
Epoch [2/6], Batch [289/428], Loss: 0.0687
Epoch [2/6], Batch [290/428], Loss: 2.7029
Epoch [2/6], Batch [291/428], Loss: 0.0649
Epoch [2/6], Batch [292/428], Loss: 0.0113
Epoch [2/6], Batch [293/428], Loss: 2.7529
Epoch [2/6], Batch [294/428], Loss: 1.8540
Epoch [2/6], Batch [295/428], Loss: 1.3891
Epoch [2/6], Batch [296/428], Loss: 5.5449
Epoch [2/6], Batch [297/428], Loss: 0.0691
Epoch [2/6], Batch [298/428], Loss: 0.0001
Epoch [2/6], Batch [299/428], Loss: 0.1373
Epoch [2/6], Batch [300/428], Loss: 0.0141
Epoch [2/6], Batch [301/428], Loss: 0.0016
Epoch [2/6], Batch [302/428], Loss: 1.0495
Epoch [2/6], Batch [303/428], Loss: 2.5600
Epoch [2/6], Batch [304/428], Loss: 0.0153
Epoch [2/6], Batch [305/428], Loss: 1.4750
Epoch [2/6], Batch [306/428], Loss: 0.2799
Epoch [2/6], Batch [307/428], Loss: 3.3767
Epoch [2/6], Batch [308/428], Loss: 0.4526
Epoch [2/6], Batch [309/428], Loss: 0.0001
Epoch [2/6], Batch [310/428], Loss: 2.9665
Epoch [2/6], Batch [311/428], Loss: 0.5953
Epoch [2/6], Batch [312/428], Loss: 0.0447
Epoch [2/6], Batch [313/428], Loss: 1.9791
Epoch [2/6], Batch [314/428], Loss: 0.6280
Epoch [2/6], Batch [315/428], Loss: 0.2682
Epoch [2/6], Batch [316/428], Loss: 1.0454
Epoch [2/6], Batch [317/428], Loss: 1.1117
Epoch [2/6], Batch [318/428], Loss: 0.0085
Epoch [2/6], Batch [319/428], Loss: 0.0000
Epoch [2/6], Batch [320/428], Loss: 1.9618
Epoch [2/6], Batch [321/428], Loss: 0.0152
Epoch [2/6], Batch [322/428], Loss: 1.3444
Epoch [2/6], Batch [323/428], Loss: 0.5369
Epoch [2/6], Batch [324/428], Loss: 0.1034
Epoch [2/6], Batch [325/428], Loss: 1.6804
Epoch [2/6], Batch [326/428], Loss: 0.0136
Epoch [2/6], Batch [327/428], Loss: 0.3356
Epoch [2/6], Batch [328/428], Loss: 5.0095
Epoch [2/6], Batch [329/428], Loss: 2.8071
Epoch [2/6], Batch [330/428], Loss: 2.1514
Epoch [2/6], Batch [331/428], Loss: 3.9259
Epoch [2/6], Batch [332/428], Loss: 0.3270
Epoch [2/6], Batch [333/428], Loss: 1.0956
Epoch [2/6], Batch [334/428], Loss: 0.0155
Epoch [2/6], Batch [335/428], Loss: 0.0476
Epoch [2/6], Batch [336/428], Loss: 0.1390
Epoch [2/6], Batch [337/428], Loss: 1.1980
Epoch [2/6], Batch [338/428], Loss: 1.6881
Epoch [2/6], Batch [339/428], Loss: 2.0539
Epoch [2/6], Batch [340/428], Loss: 0.3308
Epoch [2/6], Batch [341/428], Loss: 2.6071
Epoch [2/6], Batch [342/428], Loss: 0.0000
Epoch [2/6], Batch [343/428], Loss: 0.8243
Epoch [2/6], Batch [344/428], Loss: 0.1072
Epoch [2/6], Batch [345/428], Loss: 0.2805
Epoch [2/6], Batch [346/428], Loss: 0.0129
Epoch [2/6], Batch [347/428], Loss: 1.6506
Epoch [2/6], Batch [348/428], Loss: 0.8518
Epoch [2/6], Batch [349/428], Loss: 1.8924
Epoch [2/6], Batch [350/428], Loss: 0.1563
Epoch [2/6], Batch [351/428], Loss: 0.1322
Epoch [2/6], Batch [352/428], Loss: 3.1172
Epoch [2/6], Batch [353/428], Loss: 0.4284
Epoch [2/6], Batch [354/428], Loss: 2.0755
Epoch [2/6], Batch [355/428], Loss: 0.9795
Epoch [2/6], Batch [356/428], Loss: 0.0000
Epoch [2/6], Batch [357/428], Loss: 0.0010
Epoch [2/6], Batch [358/428], Loss: 0.0939
Epoch [2/6], Batch [359/428], Loss: 3.6071
Epoch [2/6], Batch [360/428], Loss: 0.0455
Epoch [2/6], Batch [361/428], Loss: 0.0001
Epoch [2/6], Batch [362/428], Loss: 0.2049
Epoch [2/6], Batch [363/428], Loss: 0.2540
Epoch [2/6], Batch [364/428], Loss: 0.3588
Epoch [2/6], Batch [365/428], Loss: 0.5495
Epoch [2/6], Batch [366/428], Loss: 5.5075
Epoch [2/6], Batch [367/428], Loss: 0.0005
Epoch [2/6], Batch [368/428], Loss: 0.0000
Epoch [2/6], Batch [369/428], Loss: 1.2255
Epoch [2/6], Batch [370/428], Loss: 0.2045
Epoch [2/6], Batch [371/428], Loss: 0.6583
Epoch [2/6], Batch [372/428], Loss: 1.0719
Epoch [2/6], Batch [373/428], Loss: 0.0205
Epoch [2/6], Batch [374/428], Loss: 0.5399
Epoch [2/6], Batch [375/428], Loss: 0.0000
Epoch [2/6], Batch [376/428], Loss: 0.1266
Epoch [2/6], Batch [377/428], Loss: 0.0800
Epoch [2/6], Batch [378/428], Loss: 0.0070
Epoch [2/6], Batch [379/428], Loss: 1.9588
Epoch [2/6], Batch [380/428], Loss: 0.1733
Epoch [2/6], Batch [381/428], Loss: 1.4402
Epoch [2/6], Batch [382/428], Loss: 0.5991
Epoch [2/6], Batch [383/428], Loss: 3.5145
Epoch [2/6], Batch [384/428], Loss: 0.4808
Epoch [2/6], Batch [385/428], Loss: 1.2439
Epoch [2/6], Batch [386/428], Loss: 0.4767
Epoch [2/6], Batch [387/428], Loss: 0.7786
Epoch [2/6], Batch [388/428], Loss: 0.5133
Epoch [2/6], Batch [389/428], Loss: 0.7309
Epoch [2/6], Batch [390/428], Loss: 0.2225
Epoch [2/6], Batch [391/428], Loss: 0.0093
Epoch [2/6], Batch [392/428], Loss: 1.2194
Epoch [2/6], Batch [393/428], Loss: 2.7836
Epoch [2/6], Batch [394/428], Loss: 0.0000
Epoch [2/6], Batch [395/428], Loss: 0.0757
Epoch [2/6], Batch [396/428], Loss: 0.2548
Epoch [2/6], Batch [397/428], Loss: 0.0002
Epoch [2/6], Batch [398/428], Loss: 0.0019
Epoch [2/6], Batch [399/428], Loss: 0.0135
Epoch [2/6], Batch [400/428], Loss: 1.0132
Epoch [2/6], Batch [401/428], Loss: 0.0694
Epoch [2/6], Batch [402/428], Loss: 0.0880
Epoch [2/6], Batch [403/428], Loss: 0.0821
Epoch [2/6], Batch [404/428], Loss: 0.0006
Epoch [2/6], Batch [405/428], Loss: 0.0002
Epoch [2/6], Batch [406/428], Loss: 1.9254
Epoch [2/6], Batch [407/428], Loss: 0.3026
Epoch [2/6], Batch [408/428], Loss: 0.4676
Epoch [2/6], Batch [409/428], Loss: 0.0819
Epoch [2/6], Batch [410/428], Loss: 0.0396
Epoch [2/6], Batch [411/428], Loss: 0.6350
Epoch [2/6], Batch [412/428], Loss: 0.0060
Epoch [2/6], Batch [413/428], Loss: 1.1398
Epoch [2/6], Batch [414/428], Loss: 0.0002
Epoch [2/6], Batch [415/428], Loss: 0.0000
Epoch [2/6], Batch [416/428], Loss: 0.0000
Epoch [2/6], Batch [417/428], Loss: 11.9026
Epoch [2/6], Batch [418/428], Loss: 5.3585
Epoch [2/6], Batch [419/428], Loss: 2.4218
Epoch [2/6], Batch [420/428], Loss: 1.0303
Epoch [2/6], Batch [421/428], Loss: 1.1047
Epoch [2/6], Batch [422/428], Loss: 0.0221
Epoch [2/6], Batch [423/428], Loss: 1.0135
Epoch [2/6], Batch [424/428], Loss: 0.0148
Epoch [2/6], Batch [425/428], Loss: 0.0001
Epoch [2/6], Batch [426/428], Loss: 0.9489
Epoch [2/6], Batch [427/428], Loss: 1.0561
Epoch [2/6], Batch [428/428], Loss: 0.0000
Epoch [2] Training Time: 348.14 seconds
Epoch [2/6], Average Loss: 1.1186, Training Accuracy: 0.6098
Epoch [2], Validation Loss: 1.7407, Validation Accuracy: 0.5279
Epoch [2] Validation Time: 19.43 seconds
--------------------------------------------------
Epoch 3: Unfreezing feature extractor layers...
Epoch [3/6], Batch [1/428], Loss: 0.1344
Epoch [3/6], Batch [2/428], Loss: 15.4006
Epoch [3/6], Batch [3/428], Loss: 11.5254
Epoch [3/6], Batch [4/428], Loss: 6.9950
Epoch [3/6], Batch [5/428], Loss: 25.8992
Epoch [3/6], Batch [6/428], Loss: 0.1055
Epoch [3/6], Batch [7/428], Loss: 16.7423
Epoch [3/6], Batch [8/428], Loss: 0.0001
Epoch [3/6], Batch [9/428], Loss: 9.1288
Epoch [3/6], Batch [10/428], Loss: 8.3347
Epoch [3/6], Batch [11/428], Loss: 9.5433
Epoch [3/6], Batch [12/428], Loss: 4.8115
Epoch [3/6], Batch [13/428], Loss: 5.1480
Epoch [3/6], Batch [14/428], Loss: 4.3727
Epoch [3/6], Batch [15/428], Loss: 11.5677
Epoch [3/6], Batch [16/428], Loss: 18.5106
Epoch [3/6], Batch [17/428], Loss: 3.1813
Epoch [3/6], Batch [18/428], Loss: 7.1466
Epoch [3/6], Batch [19/428], Loss: 4.0639
Epoch [3/6], Batch [20/428], Loss: 0.2973
Epoch [3/6], Batch [21/428], Loss: 2.5534
Epoch [3/6], Batch [22/428], Loss: 0.3793
Epoch [3/6], Batch [23/428], Loss: 0.2768
Epoch [3/6], Batch [24/428], Loss: 0.0572
Epoch [3/6], Batch [25/428], Loss: 11.6630
Epoch [3/6], Batch [26/428], Loss: 12.3972
Epoch [3/6], Batch [27/428], Loss: 8.9330
Epoch [3/6], Batch [28/428], Loss: 0.0009
Epoch [3/6], Batch [29/428], Loss: 0.0025
Epoch [3/6], Batch [30/428], Loss: 8.6781
Epoch [3/6], Batch [31/428], Loss: 6.5173
Epoch [3/6], Batch [32/428], Loss: 2.0942
Epoch [3/6], Batch [33/428], Loss: 1.2912
Epoch [3/6], Batch [34/428], Loss: 11.8320
Epoch [3/6], Batch [35/428], Loss: 8.9870
Epoch [3/6], Batch [36/428], Loss: 2.7975
Epoch [3/6], Batch [37/428], Loss: 5.9883
Epoch [3/6], Batch [38/428], Loss: 1.5611
Epoch [3/6], Batch [39/428], Loss: 2.7709
Epoch [3/6], Batch [40/428], Loss: 1.7148
Epoch [3/6], Batch [41/428], Loss: 5.2799
Epoch [3/6], Batch [42/428], Loss: 2.8504
Epoch [3/6], Batch [43/428], Loss: 1.0020
Epoch [3/6], Batch [44/428], Loss: 2.0569
Epoch [3/6], Batch [45/428], Loss: 1.0219
Epoch [3/6], Batch [46/428], Loss: 3.8247
Epoch [3/6], Batch [47/428], Loss: 4.1071
Epoch [3/6], Batch [48/428], Loss: 4.6327
Epoch [3/6], Batch [49/428], Loss: 0.0658
Epoch [3/6], Batch [50/428], Loss: 0.0414
Epoch [3/6], Batch [51/428], Loss: 8.5617
Epoch [3/6], Batch [52/428], Loss: 5.0823
Epoch [3/6], Batch [53/428], Loss: 8.5877
Epoch [3/6], Batch [54/428], Loss: 0.0301
Epoch [3/6], Batch [55/428], Loss: 5.6224
Epoch [3/6], Batch [56/428], Loss: 4.9831
Epoch [3/6], Batch [57/428], Loss: 5.5231
Epoch [3/6], Batch [58/428], Loss: 0.2471
Epoch [3/6], Batch [59/428], Loss: 5.9510
Epoch [3/6], Batch [60/428], Loss: 5.3773
Epoch [3/6], Batch [61/428], Loss: 4.3925
Epoch [3/6], Batch [62/428], Loss: 4.8768
Epoch [3/6], Batch [63/428], Loss: 4.2214
Epoch [3/6], Batch [64/428], Loss: 2.9183
Epoch [3/6], Batch [65/428], Loss: 6.8088
Epoch [3/6], Batch [66/428], Loss: 4.6012
Epoch [3/6], Batch [67/428], Loss: 1.5520
Epoch [3/6], Batch [68/428], Loss: 3.7148
Epoch [3/6], Batch [69/428], Loss: 5.1762
Epoch [3/6], Batch [70/428], Loss: 3.2398
Epoch [3/6], Batch [71/428], Loss: 3.4164
Epoch [3/6], Batch [72/428], Loss: 3.1547
Epoch [3/6], Batch [73/428], Loss: 4.2956
Epoch [3/6], Batch [74/428], Loss: 1.7994
Epoch [3/6], Batch [75/428], Loss: 3.0314
Epoch [3/6], Batch [76/428], Loss: 2.3732
Epoch [3/6], Batch [77/428], Loss: 2.7154
Epoch [3/6], Batch [78/428], Loss: 1.0050
Epoch [3/6], Batch [79/428], Loss: 4.1108
Epoch [3/6], Batch [80/428], Loss: 2.1516
Epoch [3/6], Batch [81/428], Loss: 4.4334
Epoch [3/6], Batch [82/428], Loss: 4.0990
Epoch [3/6], Batch [83/428], Loss: 0.2170
Epoch [3/6], Batch [84/428], Loss: 3.3456
Epoch [3/6], Batch [85/428], Loss: 2.7046
Epoch [3/6], Batch [86/428], Loss: 3.6899
Epoch [3/6], Batch [87/428], Loss: 0.7453
Epoch [3/6], Batch [88/428], Loss: 8.7190
Epoch [3/6], Batch [89/428], Loss: 7.7981
Epoch [3/6], Batch [90/428], Loss: 8.1756
Epoch [3/6], Batch [91/428], Loss: 2.0268
Epoch [3/6], Batch [92/428], Loss: 1.9604
Epoch [3/6], Batch [93/428], Loss: 1.8597
Epoch [3/6], Batch [94/428], Loss: 1.5329
Epoch [3/6], Batch [95/428], Loss: 5.7677
Epoch [3/6], Batch [96/428], Loss: 0.6843
Epoch [3/6], Batch [97/428], Loss: 1.7657
Epoch [3/6], Batch [98/428], Loss: 0.2369
Epoch [3/6], Batch [99/428], Loss: 4.6631
Epoch [3/6], Batch [100/428], Loss: 5.6607
Epoch [3/6], Batch [101/428], Loss: 3.3496
Epoch [3/6], Batch [102/428], Loss: 3.0588
Epoch [3/6], Batch [103/428], Loss: 2.4390
Epoch [3/6], Batch [104/428], Loss: 4.3331
Epoch [3/6], Batch [105/428], Loss: 3.7170
Epoch [3/6], Batch [106/428], Loss: 1.3857
Epoch [3/6], Batch [107/428], Loss: 1.7344
Epoch [3/6], Batch [108/428], Loss: 0.6286
Epoch [3/6], Batch [109/428], Loss: 2.0337
Epoch [3/6], Batch [110/428], Loss: 4.6587
Epoch [3/6], Batch [111/428], Loss: 1.8683
Epoch [3/6], Batch [112/428], Loss: 1.0241
Epoch [3/6], Batch [113/428], Loss: 4.1824
Epoch [3/6], Batch [114/428], Loss: 3.8475
Epoch [3/6], Batch [115/428], Loss: 3.7259
Epoch [3/6], Batch [116/428], Loss: 1.1189
Epoch [3/6], Batch [117/428], Loss: 0.9156
Epoch [3/6], Batch [118/428], Loss: 0.6064
Epoch [3/6], Batch [119/428], Loss: 2.8297
Epoch [3/6], Batch [120/428], Loss: 0.2288
Epoch [3/6], Batch [121/428], Loss: 0.1349
Epoch [3/6], Batch [122/428], Loss: 0.0637
Epoch [3/6], Batch [123/428], Loss: 4.5646
Epoch [3/6], Batch [124/428], Loss: 0.0121
Epoch [3/6], Batch [125/428], Loss: 0.0063
Epoch [3/6], Batch [126/428], Loss: 9.8696
Epoch [3/6], Batch [127/428], Loss: 0.0023
Epoch [3/6], Batch [128/428], Loss: 0.0016
Epoch [3/6], Batch [129/428], Loss: 10.7562
Epoch [3/6], Batch [130/428], Loss: 0.0010
Epoch [3/6], Batch [131/428], Loss: 10.5767
Epoch [3/6], Batch [132/428], Loss: 7.0592
Epoch [3/6], Batch [133/428], Loss: 11.6410
Epoch [3/6], Batch [134/428], Loss: 5.8070
Epoch [3/6], Batch [135/428], Loss: 7.6191
Epoch [3/6], Batch [136/428], Loss: 6.6948
Epoch [3/6], Batch [137/428], Loss: 5.5321
Epoch [3/6], Batch [138/428], Loss: 1.6289
Epoch [3/6], Batch [139/428], Loss: 7.3317
Epoch [3/6], Batch [140/428], Loss: 1.5977
Epoch [3/6], Batch [141/428], Loss: 6.5603
Epoch [3/6], Batch [142/428], Loss: 5.9685
Epoch [3/6], Batch [143/428], Loss: 1.5555
Epoch [3/6], Batch [144/428], Loss: 4.4937
Epoch [3/6], Batch [145/428], Loss: 6.0634
Epoch [3/6], Batch [146/428], Loss: 4.1499
Epoch [3/6], Batch [147/428], Loss: 0.3846
Epoch [3/6], Batch [148/428], Loss: 2.2785
Epoch [3/6], Batch [149/428], Loss: 1.7837
Epoch [3/6], Batch [150/428], Loss: 1.1470
Epoch [3/6], Batch [151/428], Loss: 4.3776
Epoch [3/6], Batch [152/428], Loss: 5.8254
Epoch [3/6], Batch [153/428], Loss: 5.7552
Epoch [3/6], Batch [154/428], Loss: 5.1597
Epoch [3/6], Batch [155/428], Loss: 4.6008
Epoch [3/6], Batch [156/428], Loss: 4.2623
Epoch [3/6], Batch [157/428], Loss: 3.8215
Epoch [3/6], Batch [158/428], Loss: 4.8855
Epoch [3/6], Batch [159/428], Loss: 3.2277
Epoch [3/6], Batch [160/428], Loss: 4.7972
Epoch [3/6], Batch [161/428], Loss: 0.7101
Epoch [3/6], Batch [162/428], Loss: 3.9490
Epoch [3/6], Batch [163/428], Loss: 2.7166
Epoch [3/6], Batch [164/428], Loss: 5.5997
Epoch [3/6], Batch [165/428], Loss: 2.4177
Epoch [3/6], Batch [166/428], Loss: 2.3096
Epoch [3/6], Batch [167/428], Loss: 1.7249
Epoch [3/6], Batch [168/428], Loss: 5.1724
Epoch [3/6], Batch [169/428], Loss: 2.2646
Epoch [3/6], Batch [170/428], Loss: 2.7168
Epoch [3/6], Batch [171/428], Loss: 3.7925
Epoch [3/6], Batch [172/428], Loss: 3.7755
Epoch [3/6], Batch [173/428], Loss: 4.4944
Epoch [3/6], Batch [174/428], Loss: 1.2268
Epoch [3/6], Batch [175/428], Loss: 3.6167
Epoch [3/6], Batch [176/428], Loss: 3.1490
Epoch [3/6], Batch [177/428], Loss: 2.3604
Epoch [3/6], Batch [178/428], Loss: 2.6600
Epoch [3/6], Batch [179/428], Loss: 1.9622
Epoch [3/6], Batch [180/428], Loss: 2.4855
Epoch [3/6], Batch [181/428], Loss: 3.2249
Epoch [3/6], Batch [182/428], Loss: 2.7851
Epoch [3/6], Batch [183/428], Loss: 1.1220
Epoch [3/6], Batch [184/428], Loss: 2.1600
Epoch [3/6], Batch [185/428], Loss: 2.2508
Epoch [3/6], Batch [186/428], Loss: 1.8153
Epoch [3/6], Batch [187/428], Loss: 2.4113
Epoch [3/6], Batch [188/428], Loss: 4.1192
Epoch [3/6], Batch [189/428], Loss: 2.0913
Epoch [3/6], Batch [190/428], Loss: 4.1437
Epoch [3/6], Batch [191/428], Loss: 1.0677
Epoch [3/6], Batch [192/428], Loss: 2.7472
Epoch [3/6], Batch [193/428], Loss: 0.8658
Epoch [3/6], Batch [194/428], Loss: 0.6847
Epoch [3/6], Batch [195/428], Loss: 2.3371
Epoch [3/6], Batch [196/428], Loss: 3.1906
Epoch [3/6], Batch [197/428], Loss: 3.9018
Epoch [3/6], Batch [198/428], Loss: 2.9980
Epoch [3/6], Batch [199/428], Loss: 2.6399
Epoch [3/6], Batch [200/428], Loss: 2.1887
Epoch [3/6], Batch [201/428], Loss: 2.7981
Epoch [3/6], Batch [202/428], Loss: 2.8889
Epoch [3/6], Batch [203/428], Loss: 1.6293
Epoch [3/6], Batch [204/428], Loss: 4.6367
Epoch [3/6], Batch [205/428], Loss: 3.0627
Epoch [3/6], Batch [206/428], Loss: 2.8463
Epoch [3/6], Batch [207/428], Loss: 1.2032
Epoch [3/6], Batch [208/428], Loss: 2.3770
Epoch [3/6], Batch [209/428], Loss: 3.7319
Epoch [3/6], Batch [210/428], Loss: 1.0107
Epoch [3/6], Batch [211/428], Loss: 2.4078
Epoch [3/6], Batch [212/428], Loss: 0.8420
Epoch [3/6], Batch [213/428], Loss: 0.6783
Epoch [3/6], Batch [214/428], Loss: 2.0246
Epoch [3/6], Batch [215/428], Loss: 2.1472
Epoch [3/6], Batch [216/428], Loss: 2.6678
Epoch [3/6], Batch [217/428], Loss: 4.9768
Epoch [3/6], Batch [218/428], Loss: 0.4991
Epoch [3/6], Batch [219/428], Loss: 4.2341
Epoch [3/6], Batch [220/428], Loss: 4.2351
Epoch [3/6], Batch [221/428], Loss: 3.1773
Epoch [3/6], Batch [222/428], Loss: 1.5396
Epoch [3/6], Batch [223/428], Loss: 0.8080
Epoch [3/6], Batch [224/428], Loss: 3.4025
Epoch [3/6], Batch [225/428], Loss: 4.0222
Epoch [3/6], Batch [226/428], Loss: 1.0105
Epoch [3/6], Batch [227/428], Loss: 0.9179
Epoch [3/6], Batch [228/428], Loss: 3.3409
Epoch [3/6], Batch [229/428], Loss: 2.1582
Epoch [3/6], Batch [230/428], Loss: 4.1857
Epoch [3/6], Batch [231/428], Loss: 2.1221
Epoch [3/6], Batch [232/428], Loss: 0.7991
Epoch [3/6], Batch [233/428], Loss: 2.0649
Epoch [3/6], Batch [234/428], Loss: 1.6428
Epoch [3/6], Batch [235/428], Loss: 1.8919
Epoch [3/6], Batch [236/428], Loss: 1.9058
Epoch [3/6], Batch [237/428], Loss: 3.4373
Epoch [3/6], Batch [238/428], Loss: 3.5832
Epoch [3/6], Batch [239/428], Loss: 3.3380
Epoch [3/6], Batch [240/428], Loss: 1.4789
Epoch [3/6], Batch [241/428], Loss: 2.3738
Epoch [3/6], Batch [242/428], Loss: 1.5196
Epoch [3/6], Batch [243/428], Loss: 1.4870
Epoch [3/6], Batch [244/428], Loss: 2.6436
Epoch [3/6], Batch [245/428], Loss: 2.5645
Epoch [3/6], Batch [246/428], Loss: 1.1355
Epoch [3/6], Batch [247/428], Loss: 5.2376
Epoch [3/6], Batch [248/428], Loss: 0.7997
Epoch [3/6], Batch [249/428], Loss: 5.1317
Epoch [3/6], Batch [250/428], Loss: 2.3225
Epoch [3/6], Batch [251/428], Loss: 3.4431
Epoch [3/6], Batch [252/428], Loss: 2.3998
Epoch [3/6], Batch [253/428], Loss: 2.1890
Epoch [3/6], Batch [254/428], Loss: 3.7803
Epoch [3/6], Batch [255/428], Loss: 3.6513
Epoch [3/6], Batch [256/428], Loss: 1.9347
Epoch [3/6], Batch [257/428], Loss: 3.4305
Epoch [3/6], Batch [258/428], Loss: 1.7120
Epoch [3/6], Batch [259/428], Loss: 1.8846
Epoch [3/6], Batch [260/428], Loss: 1.6108
Epoch [3/6], Batch [261/428], Loss: 1.8625
Epoch [3/6], Batch [262/428], Loss: 1.4166
Epoch [3/6], Batch [263/428], Loss: 1.8697
Epoch [3/6], Batch [264/428], Loss: 2.6150
Epoch [3/6], Batch [265/428], Loss: 1.0709
Epoch [3/6], Batch [266/428], Loss: 1.6918
Epoch [3/6], Batch [267/428], Loss: 3.0994
Epoch [3/6], Batch [268/428], Loss: 0.8790
Epoch [3/6], Batch [269/428], Loss: 2.5900
Epoch [3/6], Batch [270/428], Loss: 0.7261
Epoch [3/6], Batch [271/428], Loss: 0.5959
Epoch [3/6], Batch [272/428], Loss: 2.8236
Epoch [3/6], Batch [273/428], Loss: 3.4262
Epoch [3/6], Batch [274/428], Loss: 3.3557
Epoch [3/6], Batch [275/428], Loss: 2.6809
Epoch [3/6], Batch [276/428], Loss: 4.7320
Epoch [3/6], Batch [277/428], Loss: 4.5983
Epoch [3/6], Batch [278/428], Loss: 2.1117
Epoch [3/6], Batch [279/428], Loss: 1.6713
Epoch [3/6], Batch [280/428], Loss: 1.3501
Epoch [3/6], Batch [281/428], Loss: 4.6004
Epoch [3/6], Batch [282/428], Loss: 1.8509
Epoch [3/6], Batch [283/428], Loss: 3.6793
Epoch [3/6], Batch [284/428], Loss: 1.3056
Epoch [3/6], Batch [285/428], Loss: 4.3598
Epoch [3/6], Batch [286/428], Loss: 1.0789
Epoch [3/6], Batch [287/428], Loss: 2.7736
Epoch [3/6], Batch [288/428], Loss: 0.6939
Epoch [3/6], Batch [289/428], Loss: 2.8814
Epoch [3/6], Batch [290/428], Loss: 1.9856
Epoch [3/6], Batch [291/428], Loss: 3.2879
Epoch [3/6], Batch [292/428], Loss: 2.6680
Epoch [3/6], Batch [293/428], Loss: 2.2612
Epoch [3/6], Batch [294/428], Loss: 2.3300
Epoch [3/6], Batch [295/428], Loss: 4.2147
Epoch [3/6], Batch [296/428], Loss: 1.7840
Epoch [3/6], Batch [297/428], Loss: 1.5455
Epoch [3/6], Batch [298/428], Loss: 1.2939
Epoch [3/6], Batch [299/428], Loss: 2.2830
Epoch [3/6], Batch [300/428], Loss: 3.7157
Epoch [3/6], Batch [301/428], Loss: 1.0826
Epoch [3/6], Batch [302/428], Loss: 3.6041
Epoch [3/6], Batch [303/428], Loss: 3.4269
Epoch [3/6], Batch [304/428], Loss: 0.7756
Epoch [3/6], Batch [305/428], Loss: 4.0714
Epoch [3/6], Batch [306/428], Loss: 3.8865
Epoch [3/6], Batch [307/428], Loss: 4.9003
Epoch [3/6], Batch [308/428], Loss: 4.8198
Epoch [3/6], Batch [309/428], Loss: 0.6401
Epoch [3/6], Batch [310/428], Loss: 4.4051
Epoch [3/6], Batch [311/428], Loss: 2.3281
Epoch [3/6], Batch [312/428], Loss: 2.4706
Epoch [3/6], Batch [313/428], Loss: 1.5707
Epoch [3/6], Batch [314/428], Loss: 1.8691
Epoch [3/6], Batch [315/428], Loss: 1.5003
Epoch [3/6], Batch [316/428], Loss: 1.6663
Epoch [3/6], Batch [317/428], Loss: 3.1047
Epoch [3/6], Batch [318/428], Loss: 1.8430
Epoch [3/6], Batch [319/428], Loss: 1.6387
Epoch [3/6], Batch [320/428], Loss: 1.4863
Epoch [3/6], Batch [321/428], Loss: 4.5360
Epoch [3/6], Batch [322/428], Loss: 4.4218
Epoch [3/6], Batch [323/428], Loss: 1.5120
Epoch [3/6], Batch [324/428], Loss: 0.8478
Epoch [3/6], Batch [325/428], Loss: 0.7427
Epoch [3/6], Batch [326/428], Loss: 0.5724
Epoch [3/6], Batch [327/428], Loss: 3.5746
Epoch [3/6], Batch [328/428], Loss: 3.8593
Epoch [3/6], Batch [329/428], Loss: 4.0566
Epoch [3/6], Batch [330/428], Loss: 4.0099
Epoch [3/6], Batch [331/428], Loss: 0.2561
Epoch [3/6], Batch [332/428], Loss: 4.0425
Epoch [3/6], Batch [333/428], Loss: 3.9351
Epoch [3/6], Batch [334/428], Loss: 3.2216
Epoch [3/6], Batch [335/428], Loss: 5.3798
Epoch [3/6], Batch [336/428], Loss: 2.4289
Epoch [3/6], Batch [337/428], Loss: 0.5732
Epoch [3/6], Batch [338/428], Loss: 0.6838
Epoch [3/6], Batch [339/428], Loss: 4.7327
Epoch [3/6], Batch [340/428], Loss: 1.7558
Epoch [3/6], Batch [341/428], Loss: 1.5410
Epoch [3/6], Batch [342/428], Loss: 3.1528
Epoch [3/6], Batch [343/428], Loss: 4.0243
Epoch [3/6], Batch [344/428], Loss: 1.4901
Epoch [3/6], Batch [345/428], Loss: 3.4733
Epoch [3/6], Batch [346/428], Loss: 1.9711
Epoch [3/6], Batch [347/428], Loss: 0.8318
Epoch [3/6], Batch [348/428], Loss: 2.9179
Epoch [3/6], Batch [349/428], Loss: 2.7723
Epoch [3/6], Batch [350/428], Loss: 2.5077
Epoch [3/6], Batch [351/428], Loss: 2.1822
Epoch [3/6], Batch [352/428], Loss: 1.8236
Epoch [3/6], Batch [353/428], Loss: 1.4491
Epoch [3/6], Batch [354/428], Loss: 2.2845
Epoch [3/6], Batch [355/428], Loss: 3.3536
Epoch [3/6], Batch [356/428], Loss: 0.8966
Epoch [3/6], Batch [357/428], Loss: 2.6443
Epoch [3/6], Batch [358/428], Loss: 2.6887
Epoch [3/6], Batch [359/428], Loss: 2.5811
Epoch [3/6], Batch [360/428], Loss: 0.5519
Epoch [3/6], Batch [361/428], Loss: 2.3733
Epoch [3/6], Batch [362/428], Loss: 2.5858
Epoch [3/6], Batch [363/428], Loss: 0.5292
Epoch [3/6], Batch [364/428], Loss: 3.3744
Epoch [3/6], Batch [365/428], Loss: 1.8929
Epoch [3/6], Batch [366/428], Loss: 2.2316
Epoch [3/6], Batch [367/428], Loss: 2.7471
Epoch [3/6], Batch [368/428], Loss: 1.9299
Epoch [3/6], Batch [369/428], Loss: 1.3064
Epoch [3/6], Batch [370/428], Loss: 5.0161
Epoch [3/6], Batch [371/428], Loss: 1.4310
Epoch [3/6], Batch [372/428], Loss: 4.7239
Epoch [3/6], Batch [373/428], Loss: 1.0911
Epoch [3/6], Batch [374/428], Loss: 2.6998
Epoch [3/6], Batch [375/428], Loss: 0.7375
Epoch [3/6], Batch [376/428], Loss: 2.5789
Epoch [3/6], Batch [377/428], Loss: 2.9262
Epoch [3/6], Batch [378/428], Loss: 0.4287
Epoch [3/6], Batch [379/428], Loss: 2.2681
Epoch [3/6], Batch [380/428], Loss: 3.5743
Epoch [3/6], Batch [381/428], Loss: 3.0928
Epoch [3/6], Batch [382/428], Loss: 1.7737
Epoch [3/6], Batch [383/428], Loss: 5.1076
Epoch [3/6], Batch [384/428], Loss: 1.2470
Epoch [3/6], Batch [385/428], Loss: 0.9425
Epoch [3/6], Batch [386/428], Loss: 4.6787
Epoch [3/6], Batch [387/428], Loss: 4.5273
Epoch [3/6], Batch [388/428], Loss: 2.0613
Epoch [3/6], Batch [389/428], Loss: 3.9462
Epoch [3/6], Batch [390/428], Loss: 2.5088
Epoch [3/6], Batch [391/428], Loss: 5.2700
Epoch [3/6], Batch [392/428], Loss: 4.4464
Epoch [3/6], Batch [393/428], Loss: 2.6185
Epoch [3/6], Batch [394/428], Loss: 1.6888
Epoch [3/6], Batch [395/428], Loss: 4.7296
Epoch [3/6], Batch [396/428], Loss: 1.3459
Epoch [3/6], Batch [397/428], Loss: 1.5095
Epoch [3/6], Batch [398/428], Loss: 1.5831
Epoch [3/6], Batch [399/428], Loss: 4.1653
Epoch [3/6], Batch [400/428], Loss: 3.9483
Epoch [3/6], Batch [401/428], Loss: 3.8619
Epoch [3/6], Batch [402/428], Loss: 1.4556
Epoch [3/6], Batch [403/428], Loss: 3.4971
Epoch [3/6], Batch [404/428], Loss: 3.2230
Epoch [3/6], Batch [405/428], Loss: 2.4968
Epoch [3/6], Batch [406/428], Loss: 1.4365
Epoch [3/6], Batch [407/428], Loss: 2.9258
Epoch [3/6], Batch [408/428], Loss: 1.6251
Epoch [3/6], Batch [409/428], Loss: 1.6249
Epoch [3/6], Batch [410/428], Loss: 1.5416
Epoch [3/6], Batch [411/428], Loss: 2.5686
Epoch [3/6], Batch [412/428], Loss: 1.4236
Epoch [3/6], Batch [413/428], Loss: 2.2580
Epoch [3/6], Batch [414/428], Loss: 3.0073
Epoch [3/6], Batch [415/428], Loss: 2.1997
Epoch [3/6], Batch [416/428], Loss: 2.0177
Epoch [3/6], Batch [417/428], Loss: 1.8872
Epoch [3/6], Batch [418/428], Loss: 3.0084
Epoch [3/6], Batch [419/428], Loss: 1.3479
Epoch [3/6], Batch [420/428], Loss: 1.9650
Epoch [3/6], Batch [421/428], Loss: 1.8947
Epoch [3/6], Batch [422/428], Loss: 1.7423
Epoch [3/6], Batch [423/428], Loss: 2.1849
Epoch [3/6], Batch [424/428], Loss: 2.5472
Epoch [3/6], Batch [425/428], Loss: 4.7951
Epoch [3/6], Batch [426/428], Loss: 3.0554
Epoch [3/6], Batch [427/428], Loss: 1.1177
Epoch [3/6], Batch [428/428], Loss: 2.6898
Epoch [3] Training Time: 553.22 seconds
Epoch [3/6], Average Loss: 3.1883, Training Accuracy: 0.1729
Epoch [3], Validation Loss: 2.3388, Validation Accuracy: 0.1429
Epoch [3] Validation Time: 23.12 seconds
--------------------------------------------------
Epoch [4/6], Batch [1/428], Loss: 1.1315
Epoch [4/6], Batch [2/428], Loss: 2.4895
Epoch [4/6], Batch [3/428], Loss: 1.1280
Epoch [4/6], Batch [4/428], Loss: 1.0613
Epoch [4/6], Batch [5/428], Loss: 0.9950
Epoch [4/6], Batch [6/428], Loss: 2.0403
Epoch [4/6], Batch [7/428], Loss: 0.8364
Epoch [4/6], Batch [8/428], Loss: 1.5761
Epoch [4/6], Batch [9/428], Loss: 1.8061
Epoch [4/6], Batch [10/428], Loss: 3.3331
Epoch [4/6], Batch [11/428], Loss: 1.8029
Epoch [4/6], Batch [12/428], Loss: 0.7822
Epoch [4/6], Batch [13/428], Loss: 3.5496
Epoch [4/6], Batch [14/428], Loss: 4.3407
Epoch [4/6], Batch [15/428], Loss: 0.7913
Epoch [4/6], Batch [16/428], Loss: 3.3398
Epoch [4/6], Batch [17/428], Loss: 3.0519
Epoch [4/6], Batch [18/428], Loss: 3.4008
Epoch [4/6], Batch [19/428], Loss: 0.7200
Epoch [4/6], Batch [20/428], Loss: 2.7172
Epoch [4/6], Batch [21/428], Loss: 2.5422
Epoch [4/6], Batch [22/428], Loss: 2.2782
Epoch [4/6], Batch [23/428], Loss: 0.7583
Epoch [4/6], Batch [24/428], Loss: 2.4694
Epoch [4/6], Batch [25/428], Loss: 2.2519
Epoch [4/6], Batch [26/428], Loss: 2.1386
Epoch [4/6], Batch [27/428], Loss: 2.5119
Epoch [4/6], Batch [28/428], Loss: 3.1319
Epoch [4/6], Batch [29/428], Loss: 1.1675
Epoch [4/6], Batch [30/428], Loss: 1.4453
Epoch [4/6], Batch [31/428], Loss: 1.5249
Epoch [4/6], Batch [32/428], Loss: 2.4272
Epoch [4/6], Batch [33/428], Loss: 1.7422
Epoch [4/6], Batch [34/428], Loss: 3.6598
Epoch [4/6], Batch [35/428], Loss: 3.5275
Epoch [4/6], Batch [36/428], Loss: 1.2334
Epoch [4/6], Batch [37/428], Loss: 2.0880
Epoch [4/6], Batch [38/428], Loss: 1.3333
Epoch [4/6], Batch [39/428], Loss: 1.3112
Epoch [4/6], Batch [40/428], Loss: 1.1782
Epoch [4/6], Batch [41/428], Loss: 1.0580
Epoch [4/6], Batch [42/428], Loss: 2.2604
Epoch [4/6], Batch [43/428], Loss: 2.3433
Epoch [4/6], Batch [44/428], Loss: 4.4383
Epoch [4/6], Batch [45/428], Loss: 2.2472
Epoch [4/6], Batch [46/428], Loss: 0.5646
Epoch [4/6], Batch [47/428], Loss: 2.3800
Epoch [4/6], Batch [48/428], Loss: 0.4762
Epoch [4/6], Batch [49/428], Loss: 2.4284
Epoch [4/6], Batch [50/428], Loss: 2.7004
Epoch [4/6], Batch [51/428], Loss: 2.9587
Epoch [4/6], Batch [52/428], Loss: 2.2900
Epoch [4/6], Batch [53/428], Loss: 4.2910
Epoch [4/6], Batch [54/428], Loss: 0.6098
Epoch [4/6], Batch [55/428], Loss: 3.5541
Epoch [4/6], Batch [56/428], Loss: 3.4508
Epoch [4/6], Batch [57/428], Loss: 1.6913
Epoch [4/6], Batch [58/428], Loss: 3.0931
Epoch [4/6], Batch [59/428], Loss: 1.4038
Epoch [4/6], Batch [60/428], Loss: 2.2369
Epoch [4/6], Batch [61/428], Loss: 2.4538
Epoch [4/6], Batch [62/428], Loss: 3.2419
Epoch [4/6], Batch [63/428], Loss: 2.3852
Epoch [4/6], Batch [64/428], Loss: 0.9919
Epoch [4/6], Batch [65/428], Loss: 2.0522
Epoch [4/6], Batch [66/428], Loss: 1.9142
Epoch [4/6], Batch [67/428], Loss: 0.9484
Epoch [4/6], Batch [68/428], Loss: 2.1084
Epoch [4/6], Batch [69/428], Loss: 2.9202
Epoch [4/6], Batch [70/428], Loss: 2.7462
Epoch [4/6], Batch [71/428], Loss: 1.3847
Epoch [4/6], Batch [72/428], Loss: 2.8984
Epoch [4/6], Batch [73/428], Loss: 1.2006
Epoch [4/6], Batch [74/428], Loss: 2.1440
Epoch [4/6], Batch [75/428], Loss: 1.2438
Epoch [4/6], Batch [76/428], Loss: 1.2301
Epoch [4/6], Batch [77/428], Loss: 2.3124
Epoch [4/6], Batch [78/428], Loss: 2.2172
Epoch [4/6], Batch [79/428], Loss: 2.0260
Epoch [4/6], Batch [80/428], Loss: 1.0595
Epoch [4/6], Batch [81/428], Loss: 2.4579
Epoch [4/6], Batch [82/428], Loss: 1.3732
Epoch [4/6], Batch [83/428], Loss: 3.1188
Epoch [4/6], Batch [84/428], Loss: 2.3832
Epoch [4/6], Batch [85/428], Loss: 0.8607
Epoch [4/6], Batch [86/428], Loss: 1.5061
Epoch [4/6], Batch [87/428], Loss: 0.6333
Epoch [4/6], Batch [88/428], Loss: 3.3081
Epoch [4/6], Batch [89/428], Loss: 3.4184
Epoch [4/6], Batch [90/428], Loss: 2.0142
Epoch [4/6], Batch [91/428], Loss: 2.7319
Epoch [4/6], Batch [92/428], Loss: 2.6616
Epoch [4/6], Batch [93/428], Loss: 2.7417
Epoch [4/6], Batch [94/428], Loss: 2.9906
Epoch [4/6], Batch [95/428], Loss: 0.7244
Epoch [4/6], Batch [96/428], Loss: 3.2791
Epoch [4/6], Batch [97/428], Loss: 3.1816
Epoch [4/6], Batch [98/428], Loss: 2.4235
Epoch [4/6], Batch [99/428], Loss: 5.3346
Epoch [4/6], Batch [100/428], Loss: 1.2436
Epoch [4/6], Batch [101/428], Loss: 1.6946
Epoch [4/6], Batch [102/428], Loss: 1.7733
Epoch [4/6], Batch [103/428], Loss: 4.8452
Epoch [4/6], Batch [104/428], Loss: 2.3134
Epoch [4/6], Batch [105/428], Loss: 2.1519
Epoch [4/6], Batch [106/428], Loss: 1.7013
Epoch [4/6], Batch [107/428], Loss: 1.2381
Epoch [4/6], Batch [108/428], Loss: 4.0249
Epoch [4/6], Batch [109/428], Loss: 1.8442
Epoch [4/6], Batch [110/428], Loss: 1.7159
Epoch [4/6], Batch [111/428], Loss: 2.6492
Epoch [4/6], Batch [112/428], Loss: 2.6685
Epoch [4/6], Batch [113/428], Loss: 1.8513
Epoch [4/6], Batch [114/428], Loss: 2.4897
Epoch [4/6], Batch [115/428], Loss: 1.8196
Epoch [4/6], Batch [116/428], Loss: 1.7244
Epoch [4/6], Batch [117/428], Loss: 2.6469
Epoch [4/6], Batch [118/428], Loss: 1.4004
Epoch [4/6], Batch [119/428], Loss: 2.9880
Epoch [4/6], Batch [120/428], Loss: 1.1112
Epoch [4/6], Batch [121/428], Loss: 1.5203
Epoch [4/6], Batch [122/428], Loss: 2.8084
Epoch [4/6], Batch [123/428], Loss: 2.0931
Epoch [4/6], Batch [124/428], Loss: 1.7450
Epoch [4/6], Batch [125/428], Loss: 0.7660
Epoch [4/6], Batch [126/428], Loss: 0.7261
Epoch [4/6], Batch [127/428], Loss: 3.2375
Epoch [4/6], Batch [128/428], Loss: 2.3962
Epoch [4/6], Batch [129/428], Loss: 3.0606
Epoch [4/6], Batch [130/428], Loss: 4.7593
Epoch [4/6], Batch [131/428], Loss: 0.5984
Epoch [4/6], Batch [132/428], Loss: 2.3159
Epoch [4/6], Batch [133/428], Loss: 0.5952
Epoch [4/6], Batch [134/428], Loss: 4.5495
Epoch [4/6], Batch [135/428], Loss: 2.0245
Epoch [4/6], Batch [136/428], Loss: 2.4707
Epoch [4/6], Batch [137/428], Loss: 4.1186
Epoch [4/6], Batch [138/428], Loss: 0.6874
Epoch [4/6], Batch [139/428], Loss: 1.6862
Epoch [4/6], Batch [140/428], Loss: 3.4645
Epoch [4/6], Batch [141/428], Loss: 2.7397
Epoch [4/6], Batch [142/428], Loss: 2.2645
Epoch [4/6], Batch [143/428], Loss: 1.0091
Epoch [4/6], Batch [144/428], Loss: 1.0546
Epoch [4/6], Batch [145/428], Loss: 3.4994
Epoch [4/6], Batch [146/428], Loss: 1.0296
Epoch [4/6], Batch [147/428], Loss: 3.4147
Epoch [4/6], Batch [148/428], Loss: 3.2635
Epoch [4/6], Batch [149/428], Loss: 2.1238
Epoch [4/6], Batch [150/428], Loss: 1.9342
Epoch [4/6], Batch [151/428], Loss: 0.9637
Epoch [4/6], Batch [152/428], Loss: 2.2831
Epoch [4/6], Batch [153/428], Loss: 2.4427
Epoch [4/6], Batch [154/428], Loss: 2.2479
Epoch [4/6], Batch [155/428], Loss: 1.0603
Epoch [4/6], Batch [156/428], Loss: 2.2137
Epoch [4/6], Batch [157/428], Loss: 2.2485
Epoch [4/6], Batch [158/428], Loss: 1.5121
Epoch [4/6], Batch [159/428], Loss: 1.1998
Epoch [4/6], Batch [160/428], Loss: 3.4776
Epoch [4/6], Batch [161/428], Loss: 2.1264
Epoch [4/6], Batch [162/428], Loss: 2.0517
Epoch [4/6], Batch [163/428], Loss: 2.4313
Epoch [4/6], Batch [164/428], Loss: 1.0609
Epoch [4/6], Batch [165/428], Loss: 1.5176
Epoch [4/6], Batch [166/428], Loss: 0.9763
Epoch [4/6], Batch [167/428], Loss: 3.8085
Epoch [4/6], Batch [168/428], Loss: 3.0125
Epoch [4/6], Batch [169/428], Loss: 1.6110
Epoch [4/6], Batch [170/428], Loss: 3.6404
Epoch [4/6], Batch [171/428], Loss: 3.4828
Epoch [4/6], Batch [172/428], Loss: 0.9733
Epoch [4/6], Batch [173/428], Loss: 3.2095
Epoch [4/6], Batch [174/428], Loss: 2.4718
Epoch [4/6], Batch [175/428], Loss: 2.0173
Epoch [4/6], Batch [176/428], Loss: 1.4694
Epoch [4/6], Batch [177/428], Loss: 2.7680
Epoch [4/6], Batch [178/428], Loss: 1.3585
Epoch [4/6], Batch [179/428], Loss: 1.3875
Epoch [4/6], Batch [180/428], Loss: 2.2468
Epoch [4/6], Batch [181/428], Loss: 2.1005
Epoch [4/6], Batch [182/428], Loss: 1.2440
Epoch [4/6], Batch [183/428], Loss: 1.7668
Epoch [4/6], Batch [184/428], Loss: 1.1487
Epoch [4/6], Batch [185/428], Loss: 2.4989
Epoch [4/6], Batch [186/428], Loss: 3.0446
Epoch [4/6], Batch [187/428], Loss: 3.0028
Epoch [4/6], Batch [188/428], Loss: 2.0002
Epoch [4/6], Batch [189/428], Loss: 2.2924
Epoch [4/6], Batch [190/428], Loss: 2.2177
Epoch [4/6], Batch [191/428], Loss: 1.1392
Epoch [4/6], Batch [192/428], Loss: 2.9382
Epoch [4/6], Batch [193/428], Loss: 2.9563
Epoch [4/6], Batch [194/428], Loss: 2.8263
Epoch [4/6], Batch [195/428], Loss: 1.2430
Epoch [4/6], Batch [196/428], Loss: 2.5064
Epoch [4/6], Batch [197/428], Loss: 1.8979
Epoch [4/6], Batch [198/428], Loss: 1.2389
Epoch [4/6], Batch [199/428], Loss: 2.0111
Epoch [4/6], Batch [200/428], Loss: 1.8075
Epoch [4/6], Batch [201/428], Loss: 2.3389
Epoch [4/6], Batch [202/428], Loss: 1.6641
Epoch [4/6], Batch [203/428], Loss: 1.3265
Epoch [4/6], Batch [204/428], Loss: 1.4799
Epoch [4/6], Batch [205/428], Loss: 1.4090
Epoch [4/6], Batch [206/428], Loss: 1.4191
Epoch [4/6], Batch [207/428], Loss: 3.0869
Epoch [4/6], Batch [208/428], Loss: 1.6080
Epoch [4/6], Batch [209/428], Loss: 3.6240
Epoch [4/6], Batch [210/428], Loss: 2.5768
Epoch [4/6], Batch [211/428], Loss: 1.6674
Epoch [4/6], Batch [212/428], Loss: 1.3021
Epoch [4/6], Batch [213/428], Loss: 1.2508
Epoch [4/6], Batch [214/428], Loss: 1.2584
Epoch [4/6], Batch [215/428], Loss: 1.6146
Epoch [4/6], Batch [216/428], Loss: 1.3440
Epoch [4/6], Batch [217/428], Loss: 3.5677
Epoch [4/6], Batch [218/428], Loss: 1.0663
Epoch [4/6], Batch [219/428], Loss: 1.5358
Epoch [4/6], Batch [220/428], Loss: 1.3692
Epoch [4/6], Batch [221/428], Loss: 1.4291
Epoch [4/6], Batch [222/428], Loss: 4.1129
Epoch [4/6], Batch [223/428], Loss: 2.7611
Epoch [4/6], Batch [224/428], Loss: 1.1649
Epoch [4/6], Batch [225/428], Loss: 1.4674
Epoch [4/6], Batch [226/428], Loss: 3.9244
Epoch [4/6], Batch [227/428], Loss: 0.9154
Epoch [4/6], Batch [228/428], Loss: 2.6327
Epoch [4/6], Batch [229/428], Loss: 2.5839
Epoch [4/6], Batch [230/428], Loss: 3.5548
Epoch [4/6], Batch [231/428], Loss: 3.1536
Epoch [4/6], Batch [232/428], Loss: 1.8986
Epoch [4/6], Batch [233/428], Loss: 3.5827
Epoch [4/6], Batch [234/428], Loss: 2.0250
Epoch [4/6], Batch [235/428], Loss: 2.7622
Epoch [4/6], Batch [236/428], Loss: 2.5757
Epoch [4/6], Batch [237/428], Loss: 1.8119
Epoch [4/6], Batch [238/428], Loss: 1.7419
Epoch [4/6], Batch [239/428], Loss: 2.0588
Epoch [4/6], Batch [240/428], Loss: 2.0309
Epoch [4/6], Batch [241/428], Loss: 1.7475
Epoch [4/6], Batch [242/428], Loss: 2.2157
Epoch [4/6], Batch [243/428], Loss: 1.5370
Epoch [4/6], Batch [244/428], Loss: 2.8550
Epoch [4/6], Batch [245/428], Loss: 1.7830
Epoch [4/6], Batch [246/428], Loss: 1.7217
Epoch [4/6], Batch [247/428], Loss: 2.6728
Epoch [4/6], Batch [248/428], Loss: 2.8726
Epoch [4/6], Batch [249/428], Loss: 2.4089
Epoch [4/6], Batch [250/428], Loss: 1.7147
Epoch [4/6], Batch [251/428], Loss: 1.6212
Epoch [4/6], Batch [252/428], Loss: 3.1507
Epoch [4/6], Batch [253/428], Loss: 3.1613
Epoch [4/6], Batch [254/428], Loss: 2.2972
Epoch [4/6], Batch [255/428], Loss: 1.7766
Epoch [4/6], Batch [256/428], Loss: 1.6962
Epoch [4/6], Batch [257/428], Loss: 1.3018
Epoch [4/6], Batch [258/428], Loss: 2.1375
Epoch [4/6], Batch [259/428], Loss: 2.7582
Epoch [4/6], Batch [260/428], Loss: 2.1676
Epoch [4/6], Batch [261/428], Loss: 2.3777
Epoch [4/6], Batch [262/428], Loss: 1.5031
Epoch [4/6], Batch [263/428], Loss: 1.9974
Epoch [4/6], Batch [264/428], Loss: 2.2242
Epoch [4/6], Batch [265/428], Loss: 1.7914
Epoch [4/6], Batch [266/428], Loss: 2.4894
Epoch [4/6], Batch [267/428], Loss: 1.9192
Epoch [4/6], Batch [268/428], Loss: 3.1398
Epoch [4/6], Batch [269/428], Loss: 2.5460
Epoch [4/6], Batch [270/428], Loss: 2.1337
Epoch [4/6], Batch [271/428], Loss: 1.7813
Epoch [4/6], Batch [272/428], Loss: 2.3935
Epoch [4/6], Batch [273/428], Loss: 1.7880
Epoch [4/6], Batch [274/428], Loss: 2.9898
Epoch [4/6], Batch [275/428], Loss: 2.4247
Epoch [4/6], Batch [276/428], Loss: 2.0067
Epoch [4/6], Batch [277/428], Loss: 2.3897
Epoch [4/6], Batch [278/428], Loss: 1.6929
Epoch [4/6], Batch [279/428], Loss: 2.2998
Epoch [4/6], Batch [280/428], Loss: 2.5018
Epoch [4/6], Batch [281/428], Loss: 1.7275
Epoch [4/6], Batch [282/428], Loss: 1.6811
Epoch [4/6], Batch [283/428], Loss: 2.0537
Epoch [4/6], Batch [284/428], Loss: 1.9671
Epoch [4/6], Batch [285/428], Loss: 2.5619
Epoch [4/6], Batch [286/428], Loss: 1.6856
Epoch [4/6], Batch [287/428], Loss: 1.5243
Epoch [4/6], Batch [288/428], Loss: 2.6533
Epoch [4/6], Batch [289/428], Loss: 2.6801
Epoch [4/6], Batch [290/428], Loss: 2.1788
Epoch [4/6], Batch [291/428], Loss: 2.6268
Epoch [4/6], Batch [292/428], Loss: 2.5855
Epoch [4/6], Batch [293/428], Loss: 0.8145
Epoch [4/6], Batch [294/428], Loss: 2.1071
Epoch [4/6], Batch [295/428], Loss: 0.7344
Epoch [4/6], Batch [296/428], Loss: 2.4156
Epoch [4/6], Batch [297/428], Loss: 0.6323
Epoch [4/6], Batch [298/428], Loss: 0.5709
Epoch [4/6], Batch [299/428], Loss: 2.7536
Epoch [4/6], Batch [300/428], Loss: 4.1170
Epoch [4/6], Batch [301/428], Loss: 0.4130
Epoch [4/6], Batch [302/428], Loss: 0.3537
Epoch [4/6], Batch [303/428], Loss: 3.9102
Epoch [4/6], Batch [304/428], Loss: 3.6161
Epoch [4/6], Batch [305/428], Loss: 4.3903
Epoch [4/6], Batch [306/428], Loss: 3.2313
Epoch [4/6], Batch [307/428], Loss: 2.9084
Epoch [4/6], Batch [308/428], Loss: 4.0764
Epoch [4/6], Batch [309/428], Loss: 2.6785
Epoch [4/6], Batch [310/428], Loss: 3.2102
Epoch [4/6], Batch [311/428], Loss: 3.4027
Epoch [4/6], Batch [312/428], Loss: 3.1198
Epoch [4/6], Batch [313/428], Loss: 3.3729
Epoch [4/6], Batch [314/428], Loss: 2.4975
Epoch [4/6], Batch [315/428], Loss: 0.9588
Epoch [4/6], Batch [316/428], Loss: 2.7838
Epoch [4/6], Batch [317/428], Loss: 1.8887
Epoch [4/6], Batch [318/428], Loss: 1.6653
Epoch [4/6], Batch [319/428], Loss: 1.9309
Epoch [4/6], Batch [320/428], Loss: 1.9466
Epoch [4/6], Batch [321/428], Loss: 2.8618
Epoch [4/6], Batch [322/428], Loss: 1.7841
Epoch [4/6], Batch [323/428], Loss: 2.2664
Epoch [4/6], Batch [324/428], Loss: 2.3656
Epoch [4/6], Batch [325/428], Loss: 2.5522
Epoch [4/6], Batch [326/428], Loss: 1.4210
Epoch [4/6], Batch [327/428], Loss: 2.3836
Epoch [4/6], Batch [328/428], Loss: 2.2873
Epoch [4/6], Batch [329/428], Loss: 2.2895
Epoch [4/6], Batch [330/428], Loss: 1.4973
Epoch [4/6], Batch [331/428], Loss: 2.5896
Epoch [4/6], Batch [332/428], Loss: 2.5094
Epoch [4/6], Batch [333/428], Loss: 1.1128
Epoch [4/6], Batch [334/428], Loss: 2.2612
Epoch [4/6], Batch [335/428], Loss: 1.0857
Epoch [4/6], Batch [336/428], Loss: 1.8884
Epoch [4/6], Batch [337/428], Loss: 1.8169
Epoch [4/6], Batch [338/428], Loss: 2.0990
Epoch [4/6], Batch [339/428], Loss: 1.6062
Epoch [4/6], Batch [340/428], Loss: 2.1956
Epoch [4/6], Batch [341/428], Loss: 2.1451
Epoch [4/6], Batch [342/428], Loss: 2.1699
Epoch [4/6], Batch [343/428], Loss: 2.1551
Epoch [4/6], Batch [344/428], Loss: 1.8148
Epoch [4/6], Batch [345/428], Loss: 1.6941
Epoch [4/6], Batch [346/428], Loss: 1.4803
Epoch [4/6], Batch [347/428], Loss: 3.5579
Epoch [4/6], Batch [348/428], Loss: 3.5549
Epoch [4/6], Batch [349/428], Loss: 1.4868
Epoch [4/6], Batch [350/428], Loss: 1.8421
Epoch [4/6], Batch [351/428], Loss: 2.6735
Epoch [4/6], Batch [352/428], Loss: 3.2419
Epoch [4/6], Batch [353/428], Loss: 2.6489
Epoch [4/6], Batch [354/428], Loss: 0.8394
Epoch [4/6], Batch [355/428], Loss: 4.1552
Epoch [4/6], Batch [356/428], Loss: 2.6448
Epoch [4/6], Batch [357/428], Loss: 1.6893
Epoch [4/6], Batch [358/428], Loss: 1.6114
Epoch [4/6], Batch [359/428], Loss: 2.0898
Epoch [4/6], Batch [360/428], Loss: 2.0926
Epoch [4/6], Batch [361/428], Loss: 2.2666
Epoch [4/6], Batch [362/428], Loss: 1.3352
Epoch [4/6], Batch [363/428], Loss: 1.9474
Epoch [4/6], Batch [364/428], Loss: 1.4635
Epoch [4/6], Batch [365/428], Loss: 1.7740
Epoch [4/6], Batch [366/428], Loss: 1.6091
Epoch [4/6], Batch [367/428], Loss: 3.5664
Epoch [4/6], Batch [368/428], Loss: 1.5617
Epoch [4/6], Batch [369/428], Loss: 1.1896
Epoch [4/6], Batch [370/428], Loss: 1.5493
Epoch [4/6], Batch [371/428], Loss: 0.9607
Epoch [4/6], Batch [372/428], Loss: 0.8268
Epoch [4/6], Batch [373/428], Loss: 0.6808
Epoch [4/6], Batch [374/428], Loss: 1.7476
Epoch [4/6], Batch [375/428], Loss: 1.8067
Epoch [4/6], Batch [376/428], Loss: 1.8123
Epoch [4/6], Batch [377/428], Loss: 0.4023
Epoch [4/6], Batch [378/428], Loss: 1.6979
Epoch [4/6], Batch [379/428], Loss: 3.6316
Epoch [4/6], Batch [380/428], Loss: 3.9495
Epoch [4/6], Batch [381/428], Loss: 0.4088
Epoch [4/6], Batch [382/428], Loss: 0.4028
Epoch [4/6], Batch [383/428], Loss: 3.9189
Epoch [4/6], Batch [384/428], Loss: 3.9183
Epoch [4/6], Batch [385/428], Loss: 5.1040
Epoch [4/6], Batch [386/428], Loss: 0.3613
Epoch [4/6], Batch [387/428], Loss: 0.3380
Epoch [4/6], Batch [388/428], Loss: 0.3031
Epoch [4/6], Batch [389/428], Loss: 4.1629
Epoch [4/6], Batch [390/428], Loss: 2.2064
Epoch [4/6], Batch [391/428], Loss: 4.1324
Epoch [4/6], Batch [392/428], Loss: 4.2318
Epoch [4/6], Batch [393/428], Loss: 3.8879
Epoch [4/6], Batch [394/428], Loss: 3.9333
Epoch [4/6], Batch [395/428], Loss: 0.2900
Epoch [4/6], Batch [396/428], Loss: 3.7584
Epoch [4/6], Batch [397/428], Loss: 3.4771
Epoch [4/6], Batch [398/428], Loss: 4.2389
Epoch [4/6], Batch [399/428], Loss: 0.4195
Epoch [4/6], Batch [400/428], Loss: 2.3065
Epoch [4/6], Batch [401/428], Loss: 0.5043
Epoch [4/6], Batch [402/428], Loss: 2.9765
Epoch [4/6], Batch [403/428], Loss: 2.8622
Epoch [4/6], Batch [404/428], Loss: 2.2882
Epoch [4/6], Batch [405/428], Loss: 2.5988
Epoch [4/6], Batch [406/428], Loss: 0.7346
Epoch [4/6], Batch [407/428], Loss: 2.4832
Epoch [4/6], Batch [408/428], Loss: 2.0651
Epoch [4/6], Batch [409/428], Loss: 2.0737
Epoch [4/6], Batch [410/428], Loss: 2.3604
Epoch [4/6], Batch [411/428], Loss: 1.1395
Epoch [4/6], Batch [412/428], Loss: 1.1825
Epoch [4/6], Batch [413/428], Loss: 1.1719
Epoch [4/6], Batch [414/428], Loss: 2.2443
Epoch [4/6], Batch [415/428], Loss: 2.0037
Epoch [4/6], Batch [416/428], Loss: 1.9559
Epoch [4/6], Batch [417/428], Loss: 3.4340
Epoch [4/6], Batch [418/428], Loss: 2.0177
Epoch [4/6], Batch [419/428], Loss: 1.7247
Epoch [4/6], Batch [420/428], Loss: 1.2045
Epoch [4/6], Batch [421/428], Loss: 1.2181
Epoch [4/6], Batch [422/428], Loss: 1.1479
Epoch [4/6], Batch [423/428], Loss: 3.1874
Epoch [4/6], Batch [424/428], Loss: 1.0070
Epoch [4/6], Batch [425/428], Loss: 3.0749
Epoch [4/6], Batch [426/428], Loss: 1.9303
Epoch [4/6], Batch [427/428], Loss: 3.0560
Epoch [4/6], Batch [428/428], Loss: 3.0655
Epoch [4] Training Time: 549.23 seconds
Epoch [4/6], Average Loss: 2.1719, Training Accuracy: 0.1846
Epoch [4], Validation Loss: 2.2287, Validation Accuracy: 0.1429
Epoch [4] Validation Time: 23.05 seconds
--------------------------------------------------
Epoch [5/6], Batch [1/428], Loss: 2.9417
Epoch [5/6], Batch [2/428], Loss: 1.8439
Epoch [5/6], Batch [3/428], Loss: 2.7032
Epoch [5/6], Batch [4/428], Loss: 2.4215
Epoch [5/6], Batch [5/428], Loss: 2.9972
Epoch [5/6], Batch [6/428], Loss: 2.2291
Epoch [5/6], Batch [7/428], Loss: 1.7239
Epoch [5/6], Batch [8/428], Loss: 1.0668
Epoch [5/6], Batch [9/428], Loss: 2.0256
Epoch [5/6], Batch [10/428], Loss: 1.1441
Epoch [5/6], Batch [11/428], Loss: 1.8959
Epoch [5/6], Batch [12/428], Loss: 1.1909
Epoch [5/6], Batch [13/428], Loss: 1.9915
Epoch [5/6], Batch [14/428], Loss: 3.0622
Epoch [5/6], Batch [15/428], Loss: 1.8716
Epoch [5/6], Batch [16/428], Loss: 3.7562
Epoch [5/6], Batch [17/428], Loss: 1.2296
Epoch [5/6], Batch [18/428], Loss: 1.6816
Epoch [5/6], Batch [19/428], Loss: 1.6354
Epoch [5/6], Batch [20/428], Loss: 1.5581
Epoch [5/6], Batch [21/428], Loss: 2.0432
Epoch [5/6], Batch [22/428], Loss: 1.3579
Epoch [5/6], Batch [23/428], Loss: 1.6755
Epoch [5/6], Batch [24/428], Loss: 1.1810
Epoch [5/6], Batch [25/428], Loss: 1.5581
Epoch [5/6], Batch [26/428], Loss: 1.6221
Epoch [5/6], Batch [27/428], Loss: 0.9355
Epoch [5/6], Batch [28/428], Loss: 0.8520
Epoch [5/6], Batch [29/428], Loss: 0.7678
Epoch [5/6], Batch [30/428], Loss: 1.7861
Epoch [5/6], Batch [31/428], Loss: 1.8329
Epoch [5/6], Batch [32/428], Loss: 2.7365
Epoch [5/6], Batch [33/428], Loss: 3.2334
Epoch [5/6], Batch [34/428], Loss: 1.8182
Epoch [5/6], Batch [35/428], Loss: 3.7090
Epoch [5/6], Batch [36/428], Loss: 3.2436
Epoch [5/6], Batch [37/428], Loss: 2.7276
Epoch [5/6], Batch [38/428], Loss: 1.5747
Epoch [5/6], Batch [39/428], Loss: 3.4569
Epoch [5/6], Batch [40/428], Loss: 1.3975
Epoch [5/6], Batch [41/428], Loss: 2.4834
Epoch [5/6], Batch [42/428], Loss: 1.1899
Epoch [5/6], Batch [43/428], Loss: 3.8333
Epoch [5/6], Batch [44/428], Loss: 2.7956
Epoch [5/6], Batch [45/428], Loss: 0.9560
Epoch [5/6], Batch [46/428], Loss: 2.6938
Epoch [5/6], Batch [47/428], Loss: 2.1398
Epoch [5/6], Batch [48/428], Loss: 0.7809
Epoch [5/6], Batch [49/428], Loss: 2.8504
Epoch [5/6], Batch [50/428], Loss: 2.7712
Epoch [5/6], Batch [51/428], Loss: 3.7270
Epoch [5/6], Batch [52/428], Loss: 3.6455
Epoch [5/6], Batch [53/428], Loss: 0.7030
Epoch [5/6], Batch [54/428], Loss: 2.5648
Epoch [5/6], Batch [55/428], Loss: 0.6916
Epoch [5/6], Batch [56/428], Loss: 2.3638
Epoch [5/6], Batch [57/428], Loss: 2.4065
Epoch [5/6], Batch [58/428], Loss: 2.2761
Epoch [5/6], Batch [59/428], Loss: 2.8458
Epoch [5/6], Batch [60/428], Loss: 0.7171
Epoch [5/6], Batch [61/428], Loss: 2.0979
Epoch [5/6], Batch [62/428], Loss: 2.1633
Epoch [5/6], Batch [63/428], Loss: 0.7819
Epoch [5/6], Batch [64/428], Loss: 2.9931
Epoch [5/6], Batch [65/428], Loss: 0.7851
Epoch [5/6], Batch [66/428], Loss: 0.7738
Epoch [5/6], Batch [67/428], Loss: 3.0132
Epoch [5/6], Batch [68/428], Loss: 3.0548
Epoch [5/6], Batch [69/428], Loss: 0.7142
Epoch [5/6], Batch [70/428], Loss: 2.2317
Epoch [5/6], Batch [71/428], Loss: 2.9721
Epoch [5/6], Batch [72/428], Loss: 2.4515
Epoch [5/6], Batch [73/428], Loss: 2.4450
Epoch [5/6], Batch [74/428], Loss: 2.7362
Epoch [5/6], Batch [75/428], Loss: 2.6075
Epoch [5/6], Batch [76/428], Loss: 0.7715
Epoch [5/6], Batch [77/428], Loss: 0.7934
Epoch [5/6], Batch [78/428], Loss: 0.7846
Epoch [5/6], Batch [79/428], Loss: 0.7624
Epoch [5/6], Batch [80/428], Loss: 2.2920
Epoch [5/6], Batch [81/428], Loss: 3.1090
Epoch [5/6], Batch [82/428], Loss: 0.6675
Epoch [5/6], Batch [83/428], Loss: 0.6266
Epoch [5/6], Batch [84/428], Loss: 3.1333
Epoch [5/6], Batch [85/428], Loss: 0.5449
Epoch [5/6], Batch [86/428], Loss: 0.5003
Epoch [5/6], Batch [87/428], Loss: 0.4352
Epoch [5/6], Batch [88/428], Loss: 2.8321
Epoch [5/6], Batch [89/428], Loss: 3.6086
Epoch [5/6], Batch [90/428], Loss: 0.3104
Epoch [5/6], Batch [91/428], Loss: 0.2791
Epoch [5/6], Batch [92/428], Loss: 3.2645
Epoch [5/6], Batch [93/428], Loss: 3.2209
Epoch [5/6], Batch [94/428], Loss: 3.2567
Epoch [5/6], Batch [95/428], Loss: 3.9349
Epoch [5/6], Batch [96/428], Loss: 3.1907
Epoch [5/6], Batch [97/428], Loss: 0.2015
Epoch [5/6], Batch [98/428], Loss: 3.8488
Epoch [5/6], Batch [99/428], Loss: 0.2049
Epoch [5/6], Batch [100/428], Loss: 3.7221
Epoch [5/6], Batch [101/428], Loss: 3.6009
Epoch [5/6], Batch [102/428], Loss: 3.5951
Epoch [5/6], Batch [103/428], Loss: 0.2222
Epoch [5/6], Batch [104/428], Loss: 0.2226
Epoch [5/6], Batch [105/428], Loss: 0.2164
Epoch [5/6], Batch [106/428], Loss: 3.6570
Epoch [5/6], Batch [107/428], Loss: 3.5996
Epoch [5/6], Batch [108/428], Loss: 0.1980
Epoch [5/6], Batch [109/428], Loss: 0.1910
Epoch [5/6], Batch [110/428], Loss: 3.7691
Epoch [5/6], Batch [111/428], Loss: 3.2341
Epoch [5/6], Batch [112/428], Loss: 4.4426
Epoch [5/6], Batch [113/428], Loss: 3.3937
Epoch [5/6], Batch [114/428], Loss: 3.5758
Epoch [5/6], Batch [115/428], Loss: 3.2950
Epoch [5/6], Batch [116/428], Loss: 4.2570
Epoch [5/6], Batch [117/428], Loss: 0.2311
Epoch [5/6], Batch [118/428], Loss: 0.2471
Epoch [5/6], Batch [119/428], Loss: 3.0186
Epoch [5/6], Batch [120/428], Loss: 3.6885
Epoch [5/6], Batch [121/428], Loss: 3.3029
Epoch [5/6], Batch [122/428], Loss: 0.3012
Epoch [5/6], Batch [123/428], Loss: 3.0524
Epoch [5/6], Batch [124/428], Loss: 2.7845
Epoch [5/6], Batch [125/428], Loss: 3.4107
Epoch [5/6], Batch [126/428], Loss: 3.0326
Epoch [5/6], Batch [127/428], Loss: 2.5519
Epoch [5/6], Batch [128/428], Loss: 3.0753
Epoch [5/6], Batch [129/428], Loss: 2.8688
Epoch [5/6], Batch [130/428], Loss: 3.3442
Epoch [5/6], Batch [131/428], Loss: 3.2608
Epoch [5/6], Batch [132/428], Loss: 2.3931
Epoch [5/6], Batch [133/428], Loss: 2.2174
Epoch [5/6], Batch [134/428], Loss: 2.9227
Epoch [5/6], Batch [135/428], Loss: 2.8033
Epoch [5/6], Batch [136/428], Loss: 2.6594
Epoch [5/6], Batch [137/428], Loss: 2.4528
Epoch [5/6], Batch [138/428], Loss: 1.6368
Epoch [5/6], Batch [139/428], Loss: 2.3446
Epoch [5/6], Batch [140/428], Loss: 1.9708
Epoch [5/6], Batch [141/428], Loss: 2.1834
Epoch [5/6], Batch [142/428], Loss: 1.6988
Epoch [5/6], Batch [143/428], Loss: 2.1941
Epoch [5/6], Batch [144/428], Loss: 2.1558
Epoch [5/6], Batch [145/428], Loss: 1.3205
Epoch [5/6], Batch [146/428], Loss: 2.3669
Epoch [5/6], Batch [147/428], Loss: 2.5550
Epoch [5/6], Batch [148/428], Loss: 2.5902
Epoch [5/6], Batch [149/428], Loss: 2.3110
Epoch [5/6], Batch [150/428], Loss: 2.4596
Epoch [5/6], Batch [151/428], Loss: 2.4635
Epoch [5/6], Batch [152/428], Loss: 1.9435
Epoch [5/6], Batch [153/428], Loss: 3.2189
Epoch [5/6], Batch [154/428], Loss: 2.0148
Epoch [5/6], Batch [155/428], Loss: 2.3196
Epoch [5/6], Batch [156/428], Loss: 1.0517
Epoch [5/6], Batch [157/428], Loss: 2.2035
Epoch [5/6], Batch [158/428], Loss: 2.1395
Epoch [5/6], Batch [159/428], Loss: 2.0148
Epoch [5/6], Batch [160/428], Loss: 1.8503
Epoch [5/6], Batch [161/428], Loss: 2.1077
Epoch [5/6], Batch [162/428], Loss: 2.1644
Epoch [5/6], Batch [163/428], Loss: 2.1079
Epoch [5/6], Batch [164/428], Loss: 2.0470
Epoch [5/6], Batch [165/428], Loss: 2.1595
Epoch [5/6], Batch [166/428], Loss: 3.1616
Epoch [5/6], Batch [167/428], Loss: 2.8670
Epoch [5/6], Batch [168/428], Loss: 1.2325
Epoch [5/6], Batch [169/428], Loss: 3.0639
Epoch [5/6], Batch [170/428], Loss: 1.9548
Epoch [5/6], Batch [171/428], Loss: 2.8433
Epoch [5/6], Batch [172/428], Loss: 1.1214
Epoch [5/6], Batch [173/428], Loss: 2.0609
Epoch [5/6], Batch [174/428], Loss: 2.0467
Epoch [5/6], Batch [175/428], Loss: 1.0331
Epoch [5/6], Batch [176/428], Loss: 1.9236
Epoch [5/6], Batch [177/428], Loss: 1.8389
Epoch [5/6], Batch [178/428], Loss: 2.2523
Epoch [5/6], Batch [179/428], Loss: 2.2411
Epoch [5/6], Batch [180/428], Loss: 1.5450
Epoch [5/6], Batch [181/428], Loss: 2.6891
Epoch [5/6], Batch [182/428], Loss: 2.2486
Epoch [5/6], Batch [183/428], Loss: 2.8356
Epoch [5/6], Batch [184/428], Loss: 1.2781
Epoch [5/6], Batch [185/428], Loss: 1.2983
Epoch [5/6], Batch [186/428], Loss: 2.1356
Epoch [5/6], Batch [187/428], Loss: 2.3443
Epoch [5/6], Batch [188/428], Loss: 2.8272
Epoch [5/6], Batch [189/428], Loss: 2.7938
Epoch [5/6], Batch [190/428], Loss: 2.2330
Epoch [5/6], Batch [191/428], Loss: 2.5391
Epoch [5/6], Batch [192/428], Loss: 2.5945
Epoch [5/6], Batch [193/428], Loss: 2.4616
Epoch [5/6], Batch [194/428], Loss: 2.3320
Epoch [5/6], Batch [195/428], Loss: 2.3217
Epoch [5/6], Batch [196/428], Loss: 2.0923
Epoch [5/6], Batch [197/428], Loss: 1.9192
Epoch [5/6], Batch [198/428], Loss: 2.0897
Epoch [5/6], Batch [199/428], Loss: 1.7340
Epoch [5/6], Batch [200/428], Loss: 2.9651
Epoch [5/6], Batch [201/428], Loss: 1.7918
Epoch [5/6], Batch [202/428], Loss: 1.8784
Epoch [5/6], Batch [203/428], Loss: 2.0876
Epoch [5/6], Batch [204/428], Loss: 1.9265
Epoch [5/6], Batch [205/428], Loss: 1.6826
Epoch [5/6], Batch [206/428], Loss: 1.7879
Epoch [5/6], Batch [207/428], Loss: 1.9966
Epoch [5/6], Batch [208/428], Loss: 1.9293
Epoch [5/6], Batch [209/428], Loss: 1.7184
Epoch [5/6], Batch [210/428], Loss: 1.9076
Epoch [5/6], Batch [211/428], Loss: 1.9070
Epoch [5/6], Batch [212/428], Loss: 1.6163
Epoch [5/6], Batch [213/428], Loss: 2.0939
Epoch [5/6], Batch [214/428], Loss: 1.5251
Epoch [5/6], Batch [215/428], Loss: 1.4376
Epoch [5/6], Batch [216/428], Loss: 2.1606
Epoch [5/6], Batch [217/428], Loss: 1.2703
Epoch [5/6], Batch [218/428], Loss: 2.6968
Epoch [5/6], Batch [219/428], Loss: 1.8747
Epoch [5/6], Batch [220/428], Loss: 1.8782
Epoch [5/6], Batch [221/428], Loss: 1.8661
Epoch [5/6], Batch [222/428], Loss: 3.1977
Epoch [5/6], Batch [223/428], Loss: 2.1989
Epoch [5/6], Batch [224/428], Loss: 0.9776
Epoch [5/6], Batch [225/428], Loss: 3.1302
Epoch [5/6], Batch [226/428], Loss: 0.9613
Epoch [5/6], Batch [227/428], Loss: 0.9096
Epoch [5/6], Batch [228/428], Loss: 1.8104
Epoch [5/6], Batch [229/428], Loss: 2.2118
Epoch [5/6], Batch [230/428], Loss: 0.8021
Epoch [5/6], Batch [231/428], Loss: 2.1931
Epoch [5/6], Batch [232/428], Loss: 1.8530
Epoch [5/6], Batch [233/428], Loss: 1.8522
Epoch [5/6], Batch [234/428], Loss: 2.9674
Epoch [5/6], Batch [235/428], Loss: 2.4291
Epoch [5/6], Batch [236/428], Loss: 2.0067
Epoch [5/6], Batch [237/428], Loss: 3.2263
Epoch [5/6], Batch [238/428], Loss: 2.4275
Epoch [5/6], Batch [239/428], Loss: 2.3613
Epoch [5/6], Batch [240/428], Loss: 1.6020
Epoch [5/6], Batch [241/428], Loss: 1.0368
Epoch [5/6], Batch [242/428], Loss: 3.2345
Epoch [5/6], Batch [243/428], Loss: 3.0658
Epoch [5/6], Batch [244/428], Loss: 1.1643
Epoch [5/6], Batch [245/428], Loss: 2.9766
Epoch [5/6], Batch [246/428], Loss: 2.8462
Epoch [5/6], Batch [247/428], Loss: 3.1257
Epoch [5/6], Batch [248/428], Loss: 2.5913
Epoch [5/6], Batch [249/428], Loss: 1.9971
Epoch [5/6], Batch [250/428], Loss: 1.8570
Epoch [5/6], Batch [251/428], Loss: 1.8412
Epoch [5/6], Batch [252/428], Loss: 1.9327
Epoch [5/6], Batch [253/428], Loss: 2.4139
Epoch [5/6], Batch [254/428], Loss: 1.5361
Epoch [5/6], Batch [255/428], Loss: 1.7808
Epoch [5/6], Batch [256/428], Loss: 1.7253
Epoch [5/6], Batch [257/428], Loss: 2.2520
Epoch [5/6], Batch [258/428], Loss: 2.0051
Epoch [5/6], Batch [259/428], Loss: 1.8274
Epoch [5/6], Batch [260/428], Loss: 2.8494
Epoch [5/6], Batch [261/428], Loss: 1.8002
Epoch [5/6], Batch [262/428], Loss: 1.8597
Epoch [5/6], Batch [263/428], Loss: 2.1258
Epoch [5/6], Batch [264/428], Loss: 1.8788
Epoch [5/6], Batch [265/428], Loss: 1.8572
Epoch [5/6], Batch [266/428], Loss: 2.7149
Epoch [5/6], Batch [267/428], Loss: 1.7645
Epoch [5/6], Batch [268/428], Loss: 2.3704
Epoch [5/6], Batch [269/428], Loss: 1.6151
Epoch [5/6], Batch [270/428], Loss: 2.3846
Epoch [5/6], Batch [271/428], Loss: 1.4719
Epoch [5/6], Batch [272/428], Loss: 1.7911
Epoch [5/6], Batch [273/428], Loss: 1.3134
Epoch [5/6], Batch [274/428], Loss: 2.2797
Epoch [5/6], Batch [275/428], Loss: 2.3286
Epoch [5/6], Batch [276/428], Loss: 1.1263
Epoch [5/6], Batch [277/428], Loss: 1.0527
Epoch [5/6], Batch [278/428], Loss: 0.9622
Epoch [5/6], Batch [279/428], Loss: 0.8704
Epoch [5/6], Batch [280/428], Loss: 2.4521
Epoch [5/6], Batch [281/428], Loss: 2.7680
Epoch [5/6], Batch [282/428], Loss: 2.5639[INFO 06-13 22:00:46] ax.service.ax_client: Completed trial 14 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 22:00:49] ax.service.ax_client: Generated new trial 15 with parameters {'lr': 0.00034, 'num_epochs': 5, 'unfreeze_epoch': 0, 'max_length': 80000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [5/6], Batch [283/428], Loss: 2.4518
Epoch [5/6], Batch [284/428], Loss: 2.5126
Epoch [5/6], Batch [285/428], Loss: 2.8738
Epoch [5/6], Batch [286/428], Loss: 2.8385
Epoch [5/6], Batch [287/428], Loss: 2.7428
Epoch [5/6], Batch [288/428], Loss: 2.5599
Epoch [5/6], Batch [289/428], Loss: 2.3356
Epoch [5/6], Batch [290/428], Loss: 0.6604
Epoch [5/6], Batch [291/428], Loss: 2.8351
Epoch [5/6], Batch [292/428], Loss: 2.5183
Epoch [5/6], Batch [293/428], Loss: 2.2894
Epoch [5/6], Batch [294/428], Loss: 2.2123
Epoch [5/6], Batch [295/428], Loss: 2.1458
Epoch [5/6], Batch [296/428], Loss: 2.3564
Epoch [5/6], Batch [297/428], Loss: 2.6678
Epoch [5/6], Batch [298/428], Loss: 2.6125
Epoch [5/6], Batch [299/428], Loss: 1.9162
Epoch [5/6], Batch [300/428], Loss: 1.8362
Epoch [5/6], Batch [301/428], Loss: 1.3199
Epoch [5/6], Batch [302/428], Loss: 1.7544
Epoch [5/6], Batch [303/428], Loss: 2.2501
Epoch [5/6], Batch [304/428], Loss: 2.1772
Epoch [5/6], Batch [305/428], Loss: 1.6036
Epoch [5/6], Batch [306/428], Loss: 2.1389
Epoch [5/6], Batch [307/428], Loss: 2.3133
Epoch [5/6], Batch [308/428], Loss: 3.3416
Epoch [5/6], Batch [309/428], Loss: 2.0925
Epoch [5/6], Batch [310/428], Loss: 1.7206
Epoch [5/6], Batch [311/428], Loss: 1.9813
Epoch [5/6], Batch [312/428], Loss: 3.2473
Epoch [5/6], Batch [313/428], Loss: 1.6986
Epoch [5/6], Batch [314/428], Loss: 1.7928
Epoch [5/6], Batch [315/428], Loss: 1.9738
Epoch [5/6], Batch [316/428], Loss: 1.7468
Epoch [5/6], Batch [317/428], Loss: 1.9865
Epoch [5/6], Batch [318/428], Loss: 1.9722
Epoch [5/6], Batch [319/428], Loss: 2.4903
Epoch [5/6], Batch [320/428], Loss: 3.0061
Epoch [5/6], Batch [321/428], Loss: 1.8169
Epoch [5/6], Batch [322/428], Loss: 1.7878
Epoch [5/6], Batch [323/428], Loss: 1.7495
Epoch [5/6], Batch [324/428], Loss: 2.4331
Epoch [5/6], Batch [325/428], Loss: 2.2153
Epoch [5/6], Batch [326/428], Loss: 1.6354
Epoch [5/6], Batch [327/428], Loss: 2.2803
Epoch [5/6], Batch [328/428], Loss: 2.2149
Epoch [5/6], Batch [329/428], Loss: 1.4880
Epoch [5/6], Batch [330/428], Loss: 1.6805
Epoch [5/6], Batch [331/428], Loss: 1.3814
Epoch [5/6], Batch [332/428], Loss: 2.6544
Epoch [5/6], Batch [333/428], Loss: 2.6095
Epoch [5/6], Batch [334/428], Loss: 1.8126
Epoch [5/6], Batch [335/428], Loss: 2.2329
Epoch [5/6], Batch [336/428], Loss: 2.4080
Epoch [5/6], Batch [337/428], Loss: 1.1913
Epoch [5/6], Batch [338/428], Loss: 1.8320
Epoch [5/6], Batch [339/428], Loss: 1.6391
Epoch [5/6], Batch [340/428], Loss: 2.4073
Epoch [5/6], Batch [341/428], Loss: 1.8485
Epoch [5/6], Batch [342/428], Loss: 1.5199
Epoch [5/6], Batch [343/428], Loss: 2.0697
Epoch [5/6], Batch [344/428], Loss: 2.0114
Epoch [5/6], Batch [345/428], Loss: 2.4105
Epoch [5/6], Batch [346/428], Loss: 1.3535
Epoch [5/6], Batch [347/428], Loss: 2.3728
Epoch [5/6], Batch [348/428], Loss: 1.8524
Epoch [5/6], Batch [349/428], Loss: 1.8245
Epoch [5/6], Batch [350/428], Loss: 1.4458
Epoch [5/6], Batch [351/428], Loss: 1.6763
Epoch [5/6], Batch [352/428], Loss: 1.5709
Epoch [5/6], Batch [353/428], Loss: 1.6290
Epoch [5/6], Batch [354/428], Loss: 1.6964
Epoch [5/6], Batch [355/428], Loss: 1.6600
Epoch [5/6], Batch [356/428], Loss: 3.4452
Epoch [5/6], Batch [357/428], Loss: 2.1719
Epoch [5/6], Batch [358/428], Loss: 1.6866
Epoch [5/6], Batch [359/428], Loss: 1.6937
Epoch [5/6], Batch [360/428], Loss: 3.3604
Epoch [5/6], Batch [361/428], Loss: 1.8799
Epoch [5/6], Batch [362/428], Loss: 1.4381
Epoch [5/6], Batch [363/428], Loss: 1.6407
Epoch [5/6], Batch [364/428], Loss: 2.0408
Epoch [5/6], Batch [365/428], Loss: 1.5993
Epoch [5/6], Batch [366/428], Loss: 1.9826
Epoch [5/6], Batch [367/428], Loss: 1.7690
Epoch [5/6], Batch [368/428], Loss: 1.4833
Epoch [5/6], Batch [369/428], Loss: 2.0828
Epoch [5/6], Batch [370/428], Loss: 1.3830
Epoch [5/6], Batch [371/428], Loss: 1.3195
Epoch [5/6], Batch [372/428], Loss: 1.9041
Epoch [5/6], Batch [373/428], Loss: 1.7863
Epoch [5/6], Batch [374/428], Loss: 3.9007
Epoch [5/6], Batch [375/428], Loss: 3.0629
Epoch [5/6], Batch [376/428], Loss: 1.9247
Epoch [5/6], Batch [377/428], Loss: 1.8754
Epoch [5/6], Batch [378/428], Loss: 2.9519
Epoch [5/6], Batch [379/428], Loss: 1.0722
Epoch [5/6], Batch [380/428], Loss: 3.7115
Epoch [5/6], Batch [381/428], Loss: 1.0473
Epoch [5/6], Batch [382/428], Loss: 1.0196
Epoch [5/6], Batch [383/428], Loss: 3.5541
Epoch [5/6], Batch [384/428], Loss: 2.3793
Epoch [5/6], Batch [385/428], Loss: 2.4076
Epoch [5/6], Batch [386/428], Loss: 2.6432
Epoch [5/6], Batch [387/428], Loss: 2.5583
Epoch [5/6], Batch [388/428], Loss: 2.5239
Epoch [5/6], Batch [389/428], Loss: 0.9285
Epoch [5/6], Batch [390/428], Loss: 2.3273
Epoch [5/6], Batch [391/428], Loss: 0.9262
Epoch [5/6], Batch [392/428], Loss: 2.3039
Epoch [5/6], Batch [393/428], Loss: 0.9142
Epoch [5/6], Batch [394/428], Loss: 1.9632
Epoch [5/6], Batch [395/428], Loss: 2.1306
Epoch [5/6], Batch [396/428], Loss: 2.4305
Epoch [5/6], Batch [397/428], Loss: 2.4546
Epoch [5/6], Batch [398/428], Loss: 2.1969
Epoch [5/6], Batch [399/428], Loss: 1.6456
Epoch [5/6], Batch [400/428], Loss: 2.1699
Epoch [5/6], Batch [401/428], Loss: 2.9255
Epoch [5/6], Batch [402/428], Loss: 1.1254
Epoch [5/6], Batch [403/428], Loss: 1.4014
Epoch [5/6], Batch [404/428], Loss: 1.3521
Epoch [5/6], Batch [405/428], Loss: 1.2513
Epoch [5/6], Batch [406/428], Loss: 2.9245
Epoch [5/6], Batch [407/428], Loss: 2.4253
Epoch [5/6], Batch [408/428], Loss: 2.9688
Epoch [5/6], Batch [409/428], Loss: 2.1540
Epoch [5/6], Batch [410/428], Loss: 1.6581
Epoch [5/6], Batch [411/428], Loss: 1.6756
Epoch [5/6], Batch [412/428], Loss: 2.3665
Epoch [5/6], Batch [413/428], Loss: 2.7983
Epoch [5/6], Batch [414/428], Loss: 0.9549
Epoch [5/6], Batch [415/428], Loss: 1.6325
Epoch [5/6], Batch [416/428], Loss: 2.0663
Epoch [5/6], Batch [417/428], Loss: 2.0330
Epoch [5/6], Batch [418/428], Loss: 2.2155
Epoch [5/6], Batch [419/428], Loss: 2.1978
Epoch [5/6], Batch [420/428], Loss: 2.8370
Epoch [5/6], Batch [421/428], Loss: 1.5459
Epoch [5/6], Batch [422/428], Loss: 1.5113
Epoch [5/6], Batch [423/428], Loss: 1.4463
Epoch [5/6], Batch [424/428], Loss: 1.7237
Epoch [5/6], Batch [425/428], Loss: 1.3922
Epoch [5/6], Batch [426/428], Loss: 1.3638
Epoch [5/6], Batch [427/428], Loss: 1.6556
Epoch [5/6], Batch [428/428], Loss: 1.7918
Epoch [5] Training Time: 554.04 seconds
Epoch [5/6], Average Loss: 2.0950, Training Accuracy: 0.1893
Epoch [5], Validation Loss: 2.1041, Validation Accuracy: 0.1429
Epoch [5] Validation Time: 22.60 seconds
--------------------------------------------------
Epoch [6/6], Batch [1/428], Loss: 1.1816
Epoch [6/6], Batch [2/428], Loss: 2.8425
Epoch [6/6], Batch [3/428], Loss: 1.9212
Epoch [6/6], Batch [4/428], Loss: 2.8144
Epoch [6/6], Batch [5/428], Loss: 2.8123
Epoch [6/6], Batch [6/428], Loss: 1.1285
Epoch [6/6], Batch [7/428], Loss: 3.2334
Epoch [6/6], Batch [8/428], Loss: 2.5649
Epoch [6/6], Batch [9/428], Loss: 1.1034
Epoch [6/6], Batch [10/428], Loss: 1.9534
Epoch [6/6], Batch [11/428], Loss: 1.0863
Epoch [6/6], Batch [12/428], Loss: 2.0034
Epoch [6/6], Batch [13/428], Loss: 1.6900
Epoch [6/6], Batch [14/428], Loss: 1.0576
Epoch [6/6], Batch [15/428], Loss: 1.9377
Epoch [6/6], Batch [16/428], Loss: 1.0399
Epoch [6/6], Batch [17/428], Loss: 1.0095
Epoch [6/6], Batch [18/428], Loss: 2.6806
Epoch [6/6], Batch [19/428], Loss: 0.9805
Epoch [6/6], Batch [20/428], Loss: 3.2258
Epoch [6/6], Batch [21/428], Loss: 2.6195
Epoch [6/6], Batch [22/428], Loss: 1.9532
Epoch [6/6], Batch [23/428], Loss: 1.8235
Epoch [6/6], Batch [24/428], Loss: 2.6366
Epoch [6/6], Batch [25/428], Loss: 1.9534
Epoch [6/6], Batch [26/428], Loss: 0.9003
Epoch [6/6], Batch [27/428], Loss: 2.2198
Epoch [6/6], Batch [28/428], Loss: 2.6467
Epoch [6/6], Batch [29/428], Loss: 1.9083
Epoch [6/6], Batch [30/428], Loss: 1.9237
Epoch [6/6], Batch [31/428], Loss: 0.9272
Epoch [6/6], Batch [32/428], Loss: 2.2310
Epoch [6/6], Batch [33/428], Loss: 2.2182
Epoch [6/6], Batch [34/428], Loss: 1.8198
Epoch [6/6], Batch [35/428], Loss: 2.1832
Epoch [6/6], Batch [36/428], Loss: 1.9376
Epoch [6/6], Batch [37/428], Loss: 0.9767
Epoch [6/6], Batch [38/428], Loss: 1.9882
Epoch [6/6], Batch [39/428], Loss: 2.0906
Epoch [6/6], Batch [40/428], Loss: 1.7403
Epoch [6/6], Batch [41/428], Loss: 1.0185
Epoch [6/6], Batch [42/428], Loss: 1.9854
Epoch [6/6], Batch [43/428], Loss: 3.1997
Epoch [6/6], Batch [44/428], Loss: 1.0468
Epoch [6/6], Batch [45/428], Loss: 1.6877
Epoch [6/6], Batch [46/428], Loss: 2.6279
Epoch [6/6], Batch [47/428], Loss: 1.0527
Epoch [6/6], Batch [48/428], Loss: 1.9559
Epoch [6/6], Batch [49/428], Loss: 2.6702
Epoch [6/6], Batch [50/428], Loss: 1.6854
Epoch [6/6], Batch [51/428], Loss: 1.9934
Epoch [6/6], Batch [52/428], Loss: 1.0709
Epoch [6/6], Batch [53/428], Loss: 1.6440
Epoch [6/6], Batch [54/428], Loss: 2.6672
Epoch [6/6], Batch [55/428], Loss: 1.9608
Epoch [6/6], Batch [56/428], Loss: 1.0935
Epoch [6/6], Batch [57/428], Loss: 1.1032
Epoch [6/6], Batch [58/428], Loss: 2.6278
Epoch [6/6], Batch [59/428], Loss: 3.2101
Epoch [6/6], Batch [60/428], Loss: 1.0853
Epoch [6/6], Batch [61/428], Loss: 1.0692
Epoch [6/6], Batch [62/428], Loss: 1.0586
Epoch [6/6], Batch [63/428], Loss: 1.0424
Epoch [6/6], Batch [64/428], Loss: 2.0447
Epoch [6/6], Batch [65/428], Loss: 3.1869
Epoch [6/6], Batch [66/428], Loss: 2.0718
Epoch [6/6], Batch [67/428], Loss: 2.0672
Epoch [6/6], Batch [68/428], Loss: 1.7632
Epoch [6/6], Batch [69/428], Loss: 3.1229
Epoch [6/6], Batch [70/428], Loss: 3.0978
Epoch [6/6], Batch [71/428], Loss: 2.0455
Epoch [6/6], Batch [72/428], Loss: 2.5977
Epoch [6/6], Batch [73/428], Loss: 1.7738
Epoch [6/6], Batch [74/428], Loss: 0.9655
Epoch [6/6], Batch [75/428], Loss: 2.0293
Epoch [6/6], Batch [76/428], Loss: 0.9689
Epoch [6/6], Batch [77/428], Loss: 2.0812
Epoch [6/6], Batch [78/428], Loss: 1.9755
Epoch [6/6], Batch [79/428], Loss: 2.5704
Epoch [6/6], Batch [80/428], Loss: 0.9833
Epoch [6/6], Batch [81/428], Loss: 0.9814
Epoch [6/6], Batch [82/428], Loss: 1.9227
Epoch [6/6], Batch [83/428], Loss: 2.8078
Epoch [6/6], Batch [84/428], Loss: 0.9739
Epoch [6/6], Batch [85/428], Loss: 0.9661
Epoch [6/6], Batch [86/428], Loss: 2.5312
Epoch [6/6], Batch [87/428], Loss: 0.9398
Epoch [6/6], Batch [88/428], Loss: 2.5281
Epoch [6/6], Batch [89/428], Loss: 2.9141
Epoch [6/6], Batch [90/428], Loss: 2.5027
Epoch [6/6], Batch [91/428], Loss: 2.1984
Epoch [6/6], Batch [92/428], Loss: 2.4525
Epoch [6/6], Batch [93/428], Loss: 2.4241
Epoch [6/6], Batch [94/428], Loss: 0.8931
Epoch [6/6], Batch [95/428], Loss: 2.0828
Epoch [6/6], Batch [96/428], Loss: 2.2013
Epoch [6/6], Batch [97/428], Loss: 0.8936
Epoch [6/6], Batch [98/428], Loss: 2.9145
Epoch [6/6], Batch [99/428], Loss: 2.2443
Epoch [6/6], Batch [100/428], Loss: 0.8902
Epoch [6/6], Batch [101/428], Loss: 2.8453
Epoch [6/6], Batch [102/428], Loss: 2.1990
Epoch [6/6], Batch [103/428], Loss: 0.8805
Epoch [6/6], Batch [104/428], Loss: 2.1869
Epoch [6/6], Batch [105/428], Loss: 2.1937
Epoch [6/6], Batch [106/428], Loss: 0.8630
Epoch [6/6], Batch [107/428], Loss: 2.7659
Epoch [6/6], Batch [108/428], Loss: 0.8603
Epoch [6/6], Batch [109/428], Loss: 2.1981
Epoch [6/6], Batch [110/428], Loss: 2.2251
Epoch [6/6], Batch [111/428], Loss: 0.8441
Epoch [6/6], Batch [112/428], Loss: 2.2253
Epoch [6/6], Batch [113/428], Loss: 2.3337
Epoch [6/6], Batch [114/428], Loss: 2.7295
Epoch [6/6], Batch [115/428], Loss: 2.2047
Epoch [6/6], Batch [116/428], Loss: 2.1615
Epoch [6/6], Batch [117/428], Loss: 2.3437
Epoch [6/6], Batch [118/428], Loss: 0.8610
Epoch [6/6], Batch [119/428], Loss: 2.6414
Epoch [6/6], Batch [120/428], Loss: 2.1225
Epoch [6/6], Batch [121/428], Loss: 2.1106
Epoch [6/6], Batch [122/428], Loss: 0.8768
Epoch [6/6], Batch [123/428], Loss: 2.1235
Epoch [6/6], Batch [124/428], Loss: 2.5792
Epoch [6/6], Batch [125/428], Loss: 2.9978
Epoch [6/6], Batch [126/428], Loss: 2.2908
Epoch [6/6], Batch [127/428], Loss: 2.0618
Epoch [6/6], Batch [128/428], Loss: 2.0725
Epoch [6/6], Batch [129/428], Loss: 2.1498
Epoch [6/6], Batch [130/428], Loss: 2.1400
Epoch [6/6], Batch [131/428], Loss: 0.9895
Epoch [6/6], Batch [132/428], Loss: 2.0087
Epoch [6/6], Batch [133/428], Loss: 1.0155
Epoch [6/6], Batch [134/428], Loss: 2.0111
Epoch [6/6], Batch [135/428], Loss: 1.0101
Epoch [6/6], Batch [136/428], Loss: 3.0170
Epoch [6/6], Batch [137/428], Loss: 1.9713
Epoch [6/6], Batch [138/428], Loss: 1.9607
Epoch [6/6], Batch [139/428], Loss: 2.2973
Epoch [6/6], Batch [140/428], Loss: 2.4923
Epoch [6/6], Batch [141/428], Loss: 2.4785
Epoch [6/6], Batch [142/428], Loss: 2.2672
Epoch [6/6], Batch [143/428], Loss: 1.9294
Epoch [6/6], Batch [144/428], Loss: 2.2189
Epoch [6/6], Batch [145/428], Loss: 2.2125
Epoch [6/6], Batch [146/428], Loss: 2.1620
Epoch [6/6], Batch [147/428], Loss: 2.3840
Epoch [6/6], Batch [148/428], Loss: 1.1816
Epoch [6/6], Batch [149/428], Loss: 2.1692
Epoch [6/6], Batch [150/428], Loss: 1.2209
Epoch [6/6], Batch [151/428], Loss: 2.3521
Epoch [6/6], Batch [152/428], Loss: 1.2216
Epoch [6/6], Batch [153/428], Loss: 2.9185
Epoch [6/6], Batch [154/428], Loss: 2.2655
Epoch [6/6], Batch [155/428], Loss: 1.2287
Epoch [6/6], Batch [156/428], Loss: 1.2100
Epoch [6/6], Batch [157/428], Loss: 2.0171
Epoch [6/6], Batch [158/428], Loss: 1.1895
Epoch [6/6], Batch [159/428], Loss: 1.9556
Epoch [6/6], Batch [160/428], Loss: 2.0203
Epoch [6/6], Batch [161/428], Loss: 2.2387
Epoch [6/6], Batch [162/428], Loss: 2.1789
Epoch [6/6], Batch [163/428], Loss: 2.0319
Epoch [6/6], Batch [164/428], Loss: 2.1132
Epoch [6/6], Batch [165/428], Loss: 2.1157
Epoch [6/6], Batch [166/428], Loss: 1.1560
Epoch [6/6], Batch [167/428], Loss: 2.9110
Epoch [6/6], Batch [168/428], Loss: 2.2372
Epoch [6/6], Batch [169/428], Loss: 2.0696
Epoch [6/6], Batch [170/428], Loss: 2.0811
Epoch [6/6], Batch [171/428], Loss: 2.8789
Epoch [6/6], Batch [172/428], Loss: 2.0600
Epoch [6/6], Batch [173/428], Loss: 2.0302
Epoch [6/6], Batch [174/428], Loss: 1.9889
Epoch [6/6], Batch [175/428], Loss: 1.2084
Epoch [6/6], Batch [176/428], Loss: 1.9490
Epoch [6/6], Batch [177/428], Loss: 1.2265
Epoch [6/6], Batch [178/428], Loss: 2.2532
Epoch [6/6], Batch [179/428], Loss: 2.2262
Epoch [6/6], Batch [180/428], Loss: 2.7848
Epoch [6/6], Batch [181/428], Loss: 1.2294
Epoch [6/6], Batch [182/428], Loss: 1.8300
Epoch [6/6], Batch [183/428], Loss: 2.2276
Epoch [6/6], Batch [184/428], Loss: 2.2134
Epoch [6/6], Batch [185/428], Loss: 2.2609
Epoch [6/6], Batch [186/428], Loss: 2.0396
Epoch [6/6], Batch [187/428], Loss: 2.0461
Epoch [6/6], Batch [188/428], Loss: 1.2670
Epoch [6/6], Batch [189/428], Loss: 2.1558
Epoch [6/6], Batch [190/428], Loss: 2.0284
Epoch [6/6], Batch [191/428], Loss: 2.1654
Epoch [6/6], Batch [192/428], Loss: 1.9759
Epoch [6/6], Batch [193/428], Loss: 2.0529
Epoch [6/6], Batch [194/428], Loss: 2.6990
Epoch [6/6], Batch [195/428], Loss: 1.3386
Epoch [6/6], Batch [196/428], Loss: 2.6919
Epoch [6/6], Batch [197/428], Loss: 2.2483
Epoch [6/6], Batch [198/428], Loss: 2.2547
Epoch [6/6], Batch [199/428], Loss: 1.3601
Epoch [6/6], Batch [200/428], Loss: 1.8375
Epoch [6/6], Batch [201/428], Loss: 1.3854
Epoch [6/6], Batch [202/428], Loss: 2.2138
Epoch [6/6], Batch [203/428], Loss: 2.5824
Epoch [6/6], Batch [204/428], Loss: 1.8951
Epoch [6/6], Batch [205/428], Loss: 1.3531
Epoch [6/6], Batch [206/428], Loss: 2.2438
Epoch [6/6], Batch [207/428], Loss: 1.8994
Epoch [6/6], Batch [208/428], Loss: 1.3382
Epoch [6/6], Batch [209/428], Loss: 1.3339
Epoch [6/6], Batch [210/428], Loss: 1.3069
Epoch [6/6], Batch [211/428], Loss: 2.1473
Epoch [6/6], Batch [212/428], Loss: 1.2496
Epoch [6/6], Batch [213/428], Loss: 2.1386
Epoch [6/6], Batch [214/428], Loss: 1.9568
Epoch [6/6], Batch [215/428], Loss: 2.0842
Epoch [6/6], Batch [216/428], Loss: 1.9616
Epoch [6/6], Batch [217/428], Loss: 2.2294
Epoch [6/6], Batch [218/428], Loss: 1.1758
Epoch [6/6], Batch [219/428], Loss: 1.9819
Epoch [6/6], Batch [220/428], Loss: 1.9824
Epoch [6/6], Batch [221/428], Loss: 2.2561
Epoch [6/6], Batch [222/428], Loss: 1.1432
Epoch [6/6], Batch [223/428], Loss: 1.1412
Epoch [6/6], Batch [224/428], Loss: 2.0167
Epoch [6/6], Batch [225/428], Loss: 2.6214
Epoch [6/6], Batch [226/428], Loss: 1.1174
Epoch [6/6], Batch [227/428], Loss: 1.9423
Epoch [6/6], Batch [228/428], Loss: 2.4663
Epoch [6/6], Batch [229/428], Loss: 2.0429
Epoch [6/6], Batch [230/428], Loss: 2.3157
Epoch [6/6], Batch [231/428], Loss: 1.9146
Epoch [6/6], Batch [232/428], Loss: 2.4693
Epoch [6/6], Batch [233/428], Loss: 1.0974
Epoch [6/6], Batch [234/428], Loss: 1.8820
Epoch [6/6], Batch [235/428], Loss: 2.2583
Epoch [6/6], Batch [236/428], Loss: 2.4448
Epoch [6/6], Batch [237/428], Loss: 1.8442
Epoch [6/6], Batch [238/428], Loss: 2.1684
Epoch [6/6], Batch [239/428], Loss: 1.1334
Epoch [6/6], Batch [240/428], Loss: 2.0539
Epoch [6/6], Batch [241/428], Loss: 1.1432
Epoch [6/6], Batch [242/428], Loss: 1.7813
Epoch [6/6], Batch [243/428], Loss: 2.1720
Epoch [6/6], Batch [244/428], Loss: 1.7697
Epoch [6/6], Batch [245/428], Loss: 1.1441
Epoch [6/6], Batch [246/428], Loss: 2.3663
Epoch [6/6], Batch [247/428], Loss: 1.1452
Epoch [6/6], Batch [248/428], Loss: 1.1305
Epoch [6/6], Batch [249/428], Loss: 2.1607
Epoch [6/6], Batch [250/428], Loss: 1.6923
Epoch [6/6], Batch [251/428], Loss: 2.3566
Epoch [6/6], Batch [252/428], Loss: 1.1089
Epoch [6/6], Batch [253/428], Loss: 2.3421
Epoch [6/6], Batch [254/428], Loss: 2.3529
Epoch [6/6], Batch [255/428], Loss: 2.2168
Epoch [6/6], Batch [256/428], Loss: 2.1543
Epoch [6/6], Batch [257/428], Loss: 2.2940
Epoch [6/6], Batch [258/428], Loss: 2.2930
Epoch [6/6], Batch [259/428], Loss: 2.2591
Epoch [6/6], Batch [260/428], Loss: 2.2061
Epoch [6/6], Batch [261/428], Loss: 1.1262
Epoch [6/6], Batch [262/428], Loss: 2.1283
Epoch [6/6], Batch [263/428], Loss: 2.3260
Epoch [6/6], Batch [264/428], Loss: 1.1516
Epoch [6/6], Batch [265/428], Loss: 2.1102
Epoch [6/6], Batch [266/428], Loss: 2.0341
Epoch [6/6], Batch [267/428], Loss: 1.1650
Epoch [6/6], Batch [268/428], Loss: 2.0009
Epoch [6/6], Batch [269/428], Loss: 2.3229
Epoch [6/6], Batch [270/428], Loss: 1.9315
Epoch [6/6], Batch [271/428], Loss: 2.3132
Epoch [6/6], Batch [272/428], Loss: 1.8778
Epoch [6/6], Batch [273/428], Loss: 2.0490
Epoch [6/6], Batch [274/428], Loss: 2.2210
Epoch [6/6], Batch [275/428], Loss: 1.9106
Epoch [6/6], Batch [276/428], Loss: 1.2529
Epoch [6/6], Batch [277/428], Loss: 1.7682
Epoch [6/6], Batch [278/428], Loss: 1.2694
Epoch [6/6], Batch [279/428], Loss: 1.2523
Epoch [6/6], Batch [280/428], Loss: 1.7455
Epoch [6/6], Batch [281/428], Loss: 1.2505
Epoch [6/6], Batch [282/428], Loss: 2.2704
Epoch [6/6], Batch [283/428], Loss: 2.2393
Epoch [6/6], Batch [284/428], Loss: 3.1530
Epoch [6/6], Batch [285/428], Loss: 2.0816
Epoch [6/6], Batch [286/428], Loss: 2.2274
Epoch [6/6], Batch [287/428], Loss: 2.2755
Epoch [6/6], Batch [288/428], Loss: 1.2354
Epoch [6/6], Batch [289/428], Loss: 3.1135
Epoch [6/6], Batch [290/428], Loss: 2.0425
Epoch [6/6], Batch [291/428], Loss: 2.0448
Epoch [6/6], Batch [292/428], Loss: 2.1055
Epoch [6/6], Batch [293/428], Loss: 2.0682
Epoch [6/6], Batch [294/428], Loss: 2.1712
Epoch [6/6], Batch [295/428], Loss: 2.0190
Epoch [6/6], Batch [296/428], Loss: 1.2478
Epoch [6/6], Batch [297/428], Loss: 2.2437
Epoch [6/6], Batch [298/428], Loss: 1.9794
Epoch [6/6], Batch [299/428], Loss: 2.2346
Epoch [6/6], Batch [300/428], Loss: 2.2072
Epoch [6/6], Batch [301/428], Loss: 1.9253
Epoch [6/6], Batch [302/428], Loss: 3.0109
Epoch [6/6], Batch [303/428], Loss: 1.3003
Epoch [6/6], Batch [304/428], Loss: 1.2993
Epoch [6/6], Batch [305/428], Loss: 2.1037
Epoch [6/6], Batch [306/428], Loss: 1.2994
Epoch [6/6], Batch [307/428], Loss: 1.9835
Epoch [6/6], Batch [308/428], Loss: 2.9630
Epoch [6/6], Batch [309/428], Loss: 1.9788
Epoch [6/6], Batch [310/428], Loss: 1.2631
Epoch [6/6], Batch [311/428], Loss: 1.2444
Epoch [6/6], Batch [312/428], Loss: 2.2216
Epoch [6/6], Batch [313/428], Loss: 1.9092
Epoch [6/6], Batch [314/428], Loss: 1.9231
Epoch [6/6], Batch [315/428], Loss: 2.2180
Epoch [6/6], Batch [316/428], Loss: 2.2089
Epoch [6/6], Batch [317/428], Loss: 1.1893
Epoch [6/6], Batch [318/428], Loss: 2.2210
Epoch [6/6], Batch [319/428], Loss: 2.8809
Epoch [6/6], Batch [320/428], Loss: 1.1818
Epoch [6/6], Batch [321/428], Loss: 2.0680
Epoch [6/6], Batch [322/428], Loss: 2.0750
Epoch [6/6], Batch [323/428], Loss: 2.0374
Epoch [6/6], Batch [324/428], Loss: 2.8328
Epoch [6/6], Batch [325/428], Loss: 1.8962
Epoch [6/6], Batch [326/428], Loss: 2.0393
Epoch [6/6], Batch [327/428], Loss: 1.1821
Epoch [6/6], Batch [328/428], Loss: 2.2291
Epoch [6/6], Batch [329/428], Loss: 2.0410
Epoch [6/6], Batch [330/428], Loss: 1.9423
Epoch [6/6], Batch [331/428], Loss: 2.0287
Epoch [6/6], Batch [332/428], Loss: 2.2714
Epoch [6/6], Batch [333/428], Loss: 2.6898
Epoch [6/6], Batch [334/428], Loss: 1.9021
Epoch [6/6], Batch [335/428], Loss: 1.9480
Epoch [6/6], Batch [336/428], Loss: 1.2706
Epoch [6/6], Batch [337/428], Loss: 2.2370
Epoch [6/6], Batch [338/428], Loss: 2.2670
Epoch [6/6], Batch [339/428], Loss: 1.9507
Epoch [6/6], Batch [340/428], Loss: 2.2333
Epoch [6/6], Batch [341/428], Loss: 1.8215
Epoch [6/6], Batch [342/428], Loss: 1.7996
Epoch [6/6], Batch [343/428], Loss: 1.9413
Epoch [6/6], Batch [344/428], Loss: 2.2237
Epoch [6/6], Batch [345/428], Loss: 2.1762
Epoch [6/6], Batch [346/428], Loss: 2.1348
Epoch [6/6], Batch [347/428], Loss: 1.4349
Epoch [6/6], Batch [348/428], Loss: 1.4471
Epoch [6/6], Batch [349/428], Loss: 1.4455
Epoch [6/6], Batch [350/428], Loss: 1.8749
Epoch [6/6], Batch [351/428], Loss: 1.4214
Epoch [6/6], Batch [352/428], Loss: 1.4038
Epoch [6/6], Batch [353/428], Loss: 2.6975
Epoch [6/6], Batch [354/428], Loss: 1.3565
Epoch [6/6], Batch [355/428], Loss: 1.3224
Epoch [6/6], Batch [356/428], Loss: 2.1522
Epoch [6/6], Batch [357/428], Loss: 1.2735
Epoch [6/6], Batch [358/428], Loss: 2.1610
Epoch [6/6], Batch [359/428], Loss: 1.8961
Epoch [6/6], Batch [360/428], Loss: 1.9211
Epoch [6/6], Batch [361/428], Loss: 2.7169
Epoch [6/6], Batch [362/428], Loss: 2.7075
Epoch [6/6], Batch [363/428], Loss: 1.1627
Epoch [6/6], Batch [364/428], Loss: 1.1369
Epoch [6/6], Batch [365/428], Loss: 2.5411
Epoch [6/6], Batch [366/428], Loss: 1.9662
Epoch [6/6], Batch [367/428], Loss: 2.0904
Epoch [6/6], Batch [368/428], Loss: 1.0782
Epoch [6/6], Batch [369/428], Loss: 2.0929
Epoch [6/6], Batch [370/428], Loss: 2.0726
Epoch [6/6], Batch [371/428], Loss: 2.0647
Epoch [6/6], Batch [372/428], Loss: 2.2392
Epoch [6/6], Batch [373/428], Loss: 2.1223
Epoch [6/6], Batch [374/428], Loss: 2.2389
Epoch [6/6], Batch [375/428], Loss: 2.1621
Epoch [6/6], Batch [376/428], Loss: 2.1177
Epoch [6/6], Batch [377/428], Loss: 2.6374
Epoch [6/6], Batch [378/428], Loss: 2.5791
Epoch [6/6], Batch [379/428], Loss: 2.1661
Epoch [6/6], Batch [380/428], Loss: 2.5908
Epoch [6/6], Batch [381/428], Loss: 1.8756
Epoch [6/6], Batch [382/428], Loss: 2.1539
Epoch [6/6], Batch [383/428], Loss: 2.1288
Epoch [6/6], Batch [384/428], Loss: 1.9783
Epoch [6/6], Batch [385/428], Loss: 2.0580
Epoch [6/6], Batch [386/428], Loss: 1.8467
Epoch [6/6], Batch [387/428], Loss: 2.1260
Epoch [6/6], Batch [388/428], Loss: 1.8101
Epoch [6/6], Batch [389/428], Loss: 2.5427
Epoch [6/6], Batch [390/428], Loss: 1.3623
Epoch [6/6], Batch [391/428], Loss: 2.4568
Epoch [6/6], Batch [392/428], Loss: 1.3920
Epoch [6/6], Batch [393/428], Loss: 1.9832
Epoch [6/6], Batch [394/428], Loss: 1.8649
Epoch [6/6], Batch [395/428], Loss: 1.4312
Epoch [6/6], Batch [396/428], Loss: 2.4971
Epoch [6/6], Batch [397/428], Loss: 2.4911
Epoch [6/6], Batch [398/428], Loss: 1.7255
Epoch [6/6], Batch [399/428], Loss: 2.4260
Epoch [6/6], Batch [400/428], Loss: 1.4364
Epoch [6/6], Batch [401/428], Loss: 1.8167
Epoch [6/6], Batch [402/428], Loss: 2.3995
Epoch [6/6], Batch [403/428], Loss: 2.3646
Epoch [6/6], Batch [404/428], Loss: 1.8157
Epoch [6/6], Batch [405/428], Loss: 1.7663
Epoch [6/6], Batch [406/428], Loss: 2.3222
Epoch [6/6], Batch [407/428], Loss: 1.4734
Epoch [6/6], Batch [408/428], Loss: 2.3648
Epoch [6/6], Batch [409/428], Loss: 2.3266
Epoch [6/6], Batch [410/428], Loss: 2.2113
Epoch [6/6], Batch [411/428], Loss: 1.4954
Epoch [6/6], Batch [412/428], Loss: 1.5088
Epoch [6/6], Batch [413/428], Loss: 2.1106
Epoch [6/6], Batch [414/428], Loss: 1.4661
Epoch [6/6], Batch [415/428], Loss: 1.8192
Epoch [6/6], Batch [416/428], Loss: 1.4559
Epoch [6/6], Batch [417/428], Loss: 2.3054
Epoch [6/6], Batch [418/428], Loss: 1.8324
Epoch [6/6], Batch [419/428], Loss: 2.2680
Epoch [6/6], Batch [420/428], Loss: 1.8104
Epoch [6/6], Batch [421/428], Loss: 2.1326
Epoch [6/6], Batch [422/428], Loss: 1.7509
Epoch [6/6], Batch [423/428], Loss: 1.3872
Epoch [6/6], Batch [424/428], Loss: 1.7460
Epoch [6/6], Batch [425/428], Loss: 1.9629
Epoch [6/6], Batch [426/428], Loss: 2.3802
Epoch [6/6], Batch [427/428], Loss: 1.6497
Epoch [6/6], Batch [428/428], Loss: 2.2939
Epoch [6] Training Time: 545.46 seconds
Epoch [6/6], Average Loss: 1.9486, Training Accuracy: 0.2547
Epoch [6], Validation Loss: 2.0020, Validation Accuracy: 0.1429
Epoch [6] Validation Time: 23.01 seconds
--------------------------------------------------

Running trial 15 with config: {'batch_size': 1, 'lr': 0.0003397813292683491, 'num_epochs': 5, 'unfreeze_epoch': 0, 'max_length': 80000, 'device': device(type='cpu')}
Epoch 1: Unfreezing feature extractor layers...
Epoch [1/5], Batch [1/428], Loss: 5.8994
Epoch [1/5], Batch [2/428], Loss: 8.2423
Epoch [1/5], Batch [3/428], Loss: 5.8632
Epoch [1/5], Batch [4/428], Loss: 5.9202
Epoch [1/5], Batch [5/428], Loss: 7.7527
Epoch [1/5], Batch [6/428], Loss: 0.1188
Epoch [1/5], Batch [7/428], Loss: 7.7137
Epoch [1/5], Batch [8/428], Loss: 7.5856
Epoch [1/5], Batch [9/428], Loss: 7.6774
Epoch [1/5], Batch [10/428], Loss: 4.9968
Epoch [1/5], Batch [11/428], Loss: 1.4848
Epoch [1/5], Batch [12/428], Loss: 4.4110
Epoch [1/5], Batch [13/428], Loss: 4.9283
Epoch [1/5], Batch [14/428], Loss: 9.0016
Epoch [1/5], Batch [15/428], Loss: 7.8608
Epoch [1/5], Batch [16/428], Loss: 10.6463
Epoch [1/5], Batch [17/428], Loss: 0.3445
Epoch [1/5], Batch [18/428], Loss: 7.9025
Epoch [1/5], Batch [19/428], Loss: 12.8628
Epoch [1/5], Batch [20/428], Loss: 4.9126
Epoch [1/5], Batch [21/428], Loss: 3.1615
Epoch [1/5], Batch [22/428], Loss: 1.5629
Epoch [1/5], Batch [23/428], Loss: 10.1515
Epoch [1/5], Batch [24/428], Loss: 9.6387
Epoch [1/5], Batch [25/428], Loss: 3.0299
Epoch [1/5], Batch [26/428], Loss: 7.4968
Epoch [1/5], Batch [27/428], Loss: 0.9066
Epoch [1/5], Batch [28/428], Loss: 1.0423
Epoch [1/5], Batch [29/428], Loss: 1.4735
Epoch [1/5], Batch [30/428], Loss: 6.6118
Epoch [1/5], Batch [31/428], Loss: 2.8006
Epoch [1/5], Batch [32/428], Loss: 0.5970
Epoch [1/5], Batch [33/428], Loss: 4.7851
Epoch [1/5], Batch [34/428], Loss: 1.8155
Epoch [1/5], Batch [35/428], Loss: 7.8496
Epoch [1/5], Batch [36/428], Loss: 2.0115
Epoch [1/5], Batch [37/428], Loss: 7.0914
Epoch [1/5], Batch [38/428], Loss: 4.3705
Epoch [1/5], Batch [39/428], Loss: 1.3264
Epoch [1/5], Batch [40/428], Loss: 2.4113
Epoch [1/5], Batch [41/428], Loss: 2.6548
Epoch [1/5], Batch [42/428], Loss: 2.0938
Epoch [1/5], Batch [43/428], Loss: 2.1995
Epoch [1/5], Batch [44/428], Loss: 1.2190
Epoch [1/5], Batch [45/428], Loss: 4.1448
Epoch [1/5], Batch [46/428], Loss: 2.4567
Epoch [1/5], Batch [47/428], Loss: 0.4876
Epoch [1/5], Batch [48/428], Loss: 3.0073
Epoch [1/5], Batch [49/428], Loss: 3.2575
Epoch [1/5], Batch [50/428], Loss: 7.2206
Epoch [1/5], Batch [51/428], Loss: 2.1419
Epoch [1/5], Batch [52/428], Loss: 6.4287
Epoch [1/5], Batch [53/428], Loss: 1.2351
Epoch [1/5], Batch [54/428], Loss: 2.4022
Epoch [1/5], Batch [55/428], Loss: 5.9378
Epoch [1/5], Batch [56/428], Loss: 1.8748
Epoch [1/5], Batch [57/428], Loss: 0.6890
Epoch [1/5], Batch [58/428], Loss: 4.9228
Epoch [1/5], Batch [59/428], Loss: 1.9439
Epoch [1/5], Batch [60/428], Loss: 0.7808
Epoch [1/5], Batch [61/428], Loss: 3.2928
Epoch [1/5], Batch [62/428], Loss: 2.5992
Epoch [1/5], Batch [63/428], Loss: 2.4913
Epoch [1/5], Batch [64/428], Loss: 1.7890
Epoch [1/5], Batch [65/428], Loss: 1.7887
Epoch [1/5], Batch [66/428], Loss: 2.0239
Epoch [1/5], Batch [67/428], Loss: 1.8262
Epoch [1/5], Batch [68/428], Loss: 1.9421
Epoch [1/5], Batch [69/428], Loss: 3.2729
Epoch [1/5], Batch [70/428], Loss: 3.0099
Epoch [1/5], Batch [71/428], Loss: 1.3448
Epoch [1/5], Batch [72/428], Loss: 2.2362
Epoch [1/5], Batch [73/428], Loss: 0.9742
Epoch [1/5], Batch [74/428], Loss: 4.7485
Epoch [1/5], Batch [75/428], Loss: 1.9885
Epoch [1/5], Batch [76/428], Loss: 1.6180
Epoch [1/5], Batch [77/428], Loss: 3.2212
Epoch [1/5], Batch [78/428], Loss: 0.7728
Epoch [1/5], Batch [79/428], Loss: 2.3720
Epoch [1/5], Batch [80/428], Loss: 2.2379
Epoch [1/5], Batch [81/428], Loss: 1.8115
Epoch [1/5], Batch [82/428], Loss: 1.1163
Epoch [1/5], Batch [83/428], Loss: 1.7816
Epoch [1/5], Batch [84/428], Loss: 1.3285
Epoch [1/5], Batch [85/428], Loss: 2.8985
Epoch [1/5], Batch [86/428], Loss: 2.6374
Epoch [1/5], Batch [87/428], Loss: 0.8916
Epoch [1/5], Batch [88/428], Loss: 1.3564
Epoch [1/5], Batch [89/428], Loss: 4.6490
Epoch [1/5], Batch [90/428], Loss: 1.2692
Epoch [1/5], Batch [91/428], Loss: 3.8992
Epoch [1/5], Batch [92/428], Loss: 3.6230
Epoch [1/5], Batch [93/428], Loss: 1.7732
Epoch [1/5], Batch [94/428], Loss: 3.5819
Epoch [1/5], Batch [95/428], Loss: 1.7454
Epoch [1/5], Batch [96/428], Loss: 2.7190
Epoch [1/5], Batch [97/428], Loss: 3.4597
Epoch [1/5], Batch [98/428], Loss: 2.2120
Epoch [1/5], Batch [99/428], Loss: 3.2290
Epoch [1/5], Batch [100/428], Loss: 1.0871
Epoch [1/5], Batch [101/428], Loss: 6.0588
Epoch [1/5], Batch [102/428], Loss: 2.1735
Epoch [1/5], Batch [103/428], Loss: 5.4455
Epoch [1/5], Batch [104/428], Loss: 2.7819
Epoch [1/5], Batch [105/428], Loss: 4.3100
Epoch [1/5], Batch [106/428], Loss: 3.3856
Epoch [1/5], Batch [107/428], Loss: 1.8406
Epoch [1/5], Batch [108/428], Loss: 1.6314
Epoch [1/5], Batch [109/428], Loss: 3.0500
Epoch [1/5], Batch [110/428], Loss: 2.2508
Epoch [1/5], Batch [111/428], Loss: 0.9884
Epoch [1/5], Batch [112/428], Loss: 4.5657
Epoch [1/5], Batch [113/428], Loss: 2.3051
Epoch [1/5], Batch [114/428], Loss: 1.5430
Epoch [1/5], Batch [115/428], Loss: 1.3383
Epoch [1/5], Batch [116/428], Loss: 1.0932
Epoch [1/5], Batch [117/428], Loss: 3.8846
Epoch [1/5], Batch [118/428], Loss: 0.8495
Epoch [1/5], Batch [119/428], Loss: 0.6406
Epoch [1/5], Batch [120/428], Loss: 2.1331
Epoch [1/5], Batch [121/428], Loss: 0.2757
Epoch [1/5], Batch [122/428], Loss: 6.9084
Epoch [1/5], Batch [123/428], Loss: 2.8829
Epoch [1/5], Batch [124/428], Loss: 0.1270
Epoch [1/5], Batch [125/428], Loss: 3.6342
Epoch [1/5], Batch [126/428], Loss: 5.6486
Epoch [1/5], Batch [127/428], Loss: 0.1130
Epoch [1/5], Batch [128/428], Loss: 3.0999
Epoch [1/5], Batch [129/428], Loss: 5.0432
Epoch [1/5], Batch [130/428], Loss: 3.1742
Epoch [1/5], Batch [131/428], Loss: 6.2391
Epoch [1/5], Batch [132/428], Loss: 5.5114
Epoch [1/5], Batch [133/428], Loss: 0.6998
Epoch [1/5], Batch [134/428], Loss: 1.1131
Epoch [1/5], Batch [135/428], Loss: 1.0874
Epoch [1/5], Batch [136/428], Loss: 4.4111
Epoch [1/5], Batch [137/428], Loss: 2.7218
Epoch [1/5], Batch [138/428], Loss: 2.3495
Epoch [1/5], Batch [139/428], Loss: 1.5362
Epoch [1/5], Batch [140/428], Loss: 2.1330
Epoch [1/5], Batch [141/428], Loss: 1.1331
Epoch [1/5], Batch [142/428], Loss: 1.8382
Epoch [1/5], Batch [143/428], Loss: 0.6542
Epoch [1/5], Batch [144/428], Loss: 2.7869
Epoch [1/5], Batch [145/428], Loss: 2.3285
Epoch [1/5], Batch [146/428], Loss: 2.9644
Epoch [1/5], Batch [147/428], Loss: 2.0700
Epoch [1/5], Batch [148/428], Loss: 4.6710
Epoch [1/5], Batch [149/428], Loss: 4.3550
Epoch [1/5], Batch [150/428], Loss: 2.1302
Epoch [1/5], Batch [151/428], Loss: 0.9038
Epoch [1/5], Batch [152/428], Loss: 3.6798
Epoch [1/5], Batch [153/428], Loss: 2.1488
Epoch [1/5], Batch [154/428], Loss: 4.4350
Epoch [1/5], Batch [155/428], Loss: 1.5578
Epoch [1/5], Batch [156/428], Loss: 3.0849
Epoch [1/5], Batch [157/428], Loss: 1.0093
Epoch [1/5], Batch [158/428], Loss: 2.4785
Epoch [1/5], Batch [159/428], Loss: 1.1220
Epoch [1/5], Batch [160/428], Loss: 1.6621
Epoch [1/5], Batch [161/428], Loss: 1.1308
Epoch [1/5], Batch [162/428], Loss: 3.7661
Epoch [1/5], Batch [163/428], Loss: 5.0197
Epoch [1/5], Batch [164/428], Loss: 3.5488
Epoch [1/5], Batch [165/428], Loss: 2.8961
Epoch [1/5], Batch [166/428], Loss: 1.1938
Epoch [1/5], Batch [167/428], Loss: 1.0407
Epoch [1/5], Batch [168/428], Loss: 2.8515
Epoch [1/5], Batch [169/428], Loss: 2.7308
Epoch [1/5], Batch [170/428], Loss: 0.6184
Epoch [1/5], Batch [171/428], Loss: 4.6681
Epoch [1/5], Batch [172/428], Loss: 0.5083
Epoch [1/5], Batch [173/428], Loss: 1.9396
Epoch [1/5], Batch [174/428], Loss: 1.9420
Epoch [1/5], Batch [175/428], Loss: 1.6776
Epoch [1/5], Batch [176/428], Loss: 4.3353
Epoch [1/5], Batch [177/428], Loss: 2.0863
Epoch [1/5], Batch [178/428], Loss: 4.4071
Epoch [1/5], Batch [179/428], Loss: 4.8263
Epoch [1/5], Batch [180/428], Loss: 1.6011
Epoch [1/5], Batch [181/428], Loss: 1.6264
Epoch [1/5], Batch [182/428], Loss: 3.4689
Epoch [1/5], Batch [183/428], Loss: 4.6264
Epoch [1/5], Batch [184/428], Loss: 1.3666
Epoch [1/5], Batch [185/428], Loss: 1.1541
Epoch [1/5], Batch [186/428], Loss: 3.9899
Epoch [1/5], Batch [187/428], Loss: 3.6694
Epoch [1/5], Batch [188/428], Loss: 3.1879
Epoch [1/5], Batch [189/428], Loss: 2.5096
Epoch [1/5], Batch [190/428], Loss: 2.9970
Epoch [1/5], Batch [191/428], Loss: 2.9375
Epoch [1/5], Batch [192/428], Loss: 2.7313
Epoch [1/5], Batch [193/428], Loss: 1.5317
Epoch [1/5], Batch [194/428], Loss: 3.6197
Epoch [1/5], Batch [195/428], Loss: 1.8653
Epoch [1/5], Batch [196/428], Loss: 1.8372
Epoch [1/5], Batch [197/428], Loss: 3.6396
Epoch [1/5], Batch [198/428], Loss: 1.0722
Epoch [1/5], Batch [199/428], Loss: 3.8107
Epoch [1/5], Batch [200/428], Loss: 3.4146
Epoch [1/5], Batch [201/428], Loss: 2.1105
Epoch [1/5], Batch [202/428], Loss: 1.5346
Epoch [1/5], Batch [203/428], Loss: 2.8690
Epoch [1/5], Batch [204/428], Loss: 1.2630
Epoch [1/5], Batch [205/428], Loss: 1.0593
Epoch [1/5], Batch [206/428], Loss: 1.1732
Epoch [1/5], Batch [207/428], Loss: 2.8490
Epoch [1/5], Batch [208/428], Loss: 1.0411
Epoch [1/5], Batch [209/428], Loss: 2.9963
Epoch [1/5], Batch [210/428], Loss: 0.9408
Epoch [1/5], Batch [211/428], Loss: 2.1503
Epoch [1/5], Batch [212/428], Loss: 2.1697
Epoch [1/5], Batch [213/428], Loss: 2.0222
Epoch [1/5], Batch [214/428], Loss: 1.8310
Epoch [1/5], Batch [215/428], Loss: 6.1800
Epoch [1/5], Batch [216/428], Loss: 1.1517
Epoch [1/5], Batch [217/428], Loss: 1.1502
Epoch [1/5], Batch [218/428], Loss: 1.0558
Epoch [1/5], Batch [219/428], Loss: 1.7600
Epoch [1/5], Batch [220/428], Loss: 2.6969
Epoch [1/5], Batch [221/428], Loss: 5.6259
Epoch [1/5], Batch [222/428], Loss: 3.7807
Epoch [1/5], Batch [223/428], Loss: 0.6515
Epoch [1/5], Batch [224/428], Loss: 1.8494
Epoch [1/5], Batch [225/428], Loss: 2.2811
Epoch [1/5], Batch [226/428], Loss: 2.2610
Epoch [1/5], Batch [227/428], Loss: 0.7183
Epoch [1/5], Batch [228/428], Loss: 2.9797
Epoch [1/5], Batch [229/428], Loss: 2.4834
Epoch [1/5], Batch [230/428], Loss: 2.4365
Epoch [1/5], Batch [231/428], Loss: 0.9392
Epoch [1/5], Batch [232/428], Loss: 3.5897
Epoch [1/5], Batch [233/428], Loss: 3.6529
Epoch [1/5], Batch [234/428], Loss: 2.0514
Epoch [1/5], Batch [235/428], Loss: 1.2839
Epoch [1/5], Batch [236/428], Loss: 2.8265
Epoch [1/5], Batch [237/428], Loss: 2.5010
Epoch [1/5], Batch [238/428], Loss: 1.7093
Epoch [1/5], Batch [239/428], Loss: 1.5976
Epoch [1/5], Batch [240/428], Loss: 1.6072
Epoch [1/5], Batch [241/428], Loss: 3.2356
Epoch [1/5], Batch [242/428], Loss: 3.1320
Epoch [1/5], Batch [243/428], Loss: 4.4019
Epoch [1/5], Batch [244/428], Loss: 1.8620
Epoch [1/5], Batch [245/428], Loss: 1.0684
Epoch [1/5], Batch [246/428], Loss: 2.7840
Epoch [1/5], Batch [247/428], Loss: 4.0989
Epoch [1/5], Batch [248/428], Loss: 2.8076
Epoch [1/5], Batch [249/428], Loss: 2.6026
Epoch [1/5], Batch [250/428], Loss: 2.3085
Epoch [1/5], Batch [251/428], Loss: 1.8975
Epoch [1/5], Batch [252/428], Loss: 1.6419
Epoch [1/5], Batch [253/428], Loss: 1.6964
Epoch [1/5], Batch [254/428], Loss: 1.7939
Epoch [1/5], Batch [255/428], Loss: 2.2196
Epoch [1/5], Batch [256/428], Loss: 2.8555
Epoch [1/5], Batch [257/428], Loss: 4.7045
Epoch [1/5], Batch [258/428], Loss: 1.8233
Epoch [1/5], Batch [259/428], Loss: 2.0014
Epoch [1/5], Batch [260/428], Loss: 1.8951
Epoch [1/5], Batch [261/428], Loss: 1.5099
Epoch [1/5], Batch [262/428], Loss: 1.2914
Epoch [1/5], Batch [263/428], Loss: 1.2825
Epoch [1/5], Batch [264/428], Loss: 1.5375
Epoch [1/5], Batch [265/428], Loss: 1.3664
Epoch [1/5], Batch [266/428], Loss: 3.5068
Epoch [1/5], Batch [267/428], Loss: 3.5511
Epoch [1/5], Batch [268/428], Loss: 3.2931
Epoch [1/5], Batch [269/428], Loss: 1.7379
Epoch [1/5], Batch [270/428], Loss: 3.1783
Epoch [1/5], Batch [271/428], Loss: 3.9322
Epoch [1/5], Batch [272/428], Loss: 1.4290
Epoch [1/5], Batch [273/428], Loss: 1.2968
Epoch [1/5], Batch [274/428], Loss: 1.0689
Epoch [1/5], Batch [275/428], Loss: 1.5573
Epoch [1/5], Batch [276/428], Loss: 3.9777
Epoch [1/5], Batch [277/428], Loss: 0.6403
Epoch [1/5], Batch [278/428], Loss: 1.5283
Epoch [1/5], Batch [279/428], Loss: 3.4912
Epoch [1/5], Batch [280/428], Loss: 3.7986
Epoch [1/5], Batch [281/428], Loss: 1.2877
Epoch [1/5], Batch [282/428], Loss: 4.1339
Epoch [1/5], Batch [283/428], Loss: 0.7730
Epoch [1/5], Batch [284/428], Loss: 0.8138
Epoch [1/5], Batch [285/428], Loss: 3.5353
Epoch [1/5], Batch [286/428], Loss: 0.6635
Epoch [1/5], Batch [287/428], Loss: 0.5508
Epoch [1/5], Batch [288/428], Loss: 2.7849
Epoch [1/5], Batch [289/428], Loss: 3.9157
Epoch [1/5], Batch [290/428], Loss: 4.3491
Epoch [1/5], Batch [291/428], Loss: 2.4627
Epoch [1/5], Batch [292/428], Loss: 2.5229
Epoch [1/5], Batch [293/428], Loss: 3.8505
Epoch [1/5], Batch [294/428], Loss: 0.5435
Epoch [1/5], Batch [295/428], Loss: 1.9731
Epoch [1/5], Batch [296/428], Loss: 2.7457
Epoch [1/5], Batch [297/428], Loss: 2.1046
Epoch [1/5], Batch [298/428], Loss: 1.9360
Epoch [1/5], Batch [299/428], Loss: 2.4506
Epoch [1/5], Batch [300/428], Loss: 2.0984
Epoch [1/5], Batch [301/428], Loss: 1.3201
Epoch [1/5], Batch [302/428], Loss: 1.7338
Epoch [1/5], Batch [303/428], Loss: 2.5024
Epoch [1/5], Batch [304/428], Loss: 2.6424
Epoch [1/5], Batch [305/428], Loss: 1.6959
Epoch [1/5], Batch [306/428], Loss: 2.9173
Epoch [1/5], Batch [307/428], Loss: 1.9385
Epoch [1/5], Batch [308/428], Loss: 1.8294
Epoch [1/5], Batch [309/428], Loss: 1.6160
Epoch [1/5], Batch [310/428], Loss: 4.4361
Epoch [1/5], Batch [311/428], Loss: 2.9823
Epoch [1/5], Batch [312/428], Loss: 2.9160
Epoch [1/5], Batch [313/428], Loss: 2.2150
Epoch [1/5], Batch [314/428], Loss: 2.3585
Epoch [1/5], Batch [315/428], Loss: 2.2129
Epoch [1/5], Batch [316/428], Loss: 2.0862
Epoch [1/5], Batch [317/428], Loss: 3.5559
Epoch [1/5], Batch [318/428], Loss: 1.1686
Epoch [1/5], Batch [319/428], Loss: 2.5616
Epoch [1/5], Batch [320/428], Loss: 1.3260
Epoch [1/5], Batch [321/428], Loss: 1.2889
Epoch [1/5], Batch [322/428], Loss: 1.1769
Epoch [1/5], Batch [323/428], Loss: 1.4741
Epoch [1/5], Batch [324/428], Loss: 1.9523
Epoch [1/5], Batch [325/428], Loss: 3.7206
Epoch [1/5], Batch [326/428], Loss: 1.5331
Epoch [1/5], Batch [327/428], Loss: 1.4402
Epoch [1/5], Batch [328/428], Loss: 2.7423
Epoch [1/5], Batch [329/428], Loss: 2.8849
Epoch [1/5], Batch [330/428], Loss: 0.9164
Epoch [1/5], Batch [331/428], Loss: 2.3664
Epoch [1/5], Batch [332/428], Loss: 3.6890
Epoch [1/5], Batch [333/428], Loss: 3.5957
Epoch [1/5], Batch [334/428], Loss: 3.3289
Epoch [1/5], Batch [335/428], Loss: 1.7515
Epoch [1/5], Batch [336/428], Loss: 0.7566
Epoch [1/5], Batch [337/428], Loss: 4.8355
Epoch [1/5], Batch [338/428], Loss: 2.6141
Epoch [1/5], Batch [339/428], Loss: 1.9160
Epoch [1/5], Batch [340/428], Loss: 1.2765
Epoch [1/5], Batch [341/428], Loss: 1.1849
Epoch [1/5], Batch [342/428], Loss: 1.5514
Epoch [1/5], Batch [343/428], Loss: 0.9277
Epoch [1/5], Batch [344/428], Loss: 0.7418
Epoch [1/5], Batch [345/428], Loss: 2.2035
Epoch [1/5], Batch [346/428], Loss: 3.1260
Epoch [1/5], Batch [347/428], Loss: 2.0715
Epoch [1/5], Batch [348/428], Loss: 2.5306
Epoch [1/5], Batch [349/428], Loss: 4.5325
Epoch [1/5], Batch [350/428], Loss: 0.4249
Epoch [1/5], Batch [351/428], Loss: 0.4392
Epoch [1/5], Batch [352/428], Loss: 2.8689
Epoch [1/5], Batch [353/428], Loss: 3.9306
Epoch [1/5], Batch [354/428], Loss: 4.6857
Epoch [1/5], Batch [355/428], Loss: 2.3484
Epoch [1/5], Batch [356/428], Loss: 2.1930
Epoch [1/5], Batch [357/428], Loss: 4.0109
Epoch [1/5], Batch [358/428], Loss: 1.9070
Epoch [1/5], Batch [359/428], Loss: 1.7898
Epoch [1/5], Batch [360/428], Loss: 1.5729
Epoch [1/5], Batch [361/428], Loss: 2.0182
Epoch [1/5], Batch [362/428], Loss: 1.8408
Epoch [1/5], Batch [363/428], Loss: 1.9781
Epoch [1/5], Batch [364/428], Loss: 2.0201
Epoch [1/5], Batch [365/428], Loss: 3.1459
Epoch [1/5], Batch [366/428], Loss: 1.8385
Epoch [1/5], Batch [367/428], Loss: 1.3398
Epoch [1/5], Batch [368/428], Loss: 5.6519
Epoch [1/5], Batch [369/428], Loss: 2.6961
Epoch [1/5], Batch [370/428], Loss: 1.3777
Epoch [1/5], Batch [371/428], Loss: 5.2575
Epoch [1/5], Batch [372/428], Loss: 1.2160
Epoch [1/5], Batch [373/428], Loss: 1.1232
Epoch [1/5], Batch [374/428], Loss: 2.9398
Epoch [1/5], Batch [375/428], Loss: 4.5199
Epoch [1/5], Batch [376/428], Loss: 4.2974
Epoch [1/5], Batch [377/428], Loss: 2.8067
Epoch [1/5], Batch [378/428], Loss: 0.6855
Epoch [1/5], Batch [379/428], Loss: 2.4069
Epoch [1/5], Batch [380/428], Loss: 2.4654
Epoch [1/5], Batch [381/428], Loss: 2.6466
Epoch [1/5], Batch [382/428], Loss: 5.5396
Epoch [1/5], Batch [383/428], Loss: 1.9966
Epoch [1/5], Batch [384/428], Loss: 1.7182
Epoch [1/5], Batch [385/428], Loss: 1.1971
Epoch [1/5], Batch [386/428], Loss: 3.4911
Epoch [1/5], Batch [387/428], Loss: 2.0419
Epoch [1/5], Batch [388/428], Loss: 2.7712
Epoch [1/5], Batch [389/428], Loss: 5.1071
Epoch [1/5], Batch [390/428], Loss: 1.7624
Epoch [1/5], Batch [391/428], Loss: 1.2627
Epoch [1/5], Batch [392/428], Loss: 1.7412
Epoch [1/5], Batch [393/428], Loss: 1.6560
Epoch [1/5], Batch [394/428], Loss: 1.4959
Epoch [1/5], Batch [395/428], Loss: 3.3026
Epoch [1/5], Batch [396/428], Loss: 1.4483
Epoch [1/5], Batch [397/428], Loss: 3.9513
Epoch [1/5], Batch [398/428], Loss: 2.1548
Epoch [1/5], Batch [399/428], Loss: 2.8949
Epoch [1/5], Batch [400/428], Loss: 3.3370
Epoch [1/5], Batch [401/428], Loss: 2.0802
Epoch [1/5], Batch [402/428], Loss: 1.9409
Epoch [1/5], Batch [403/428], Loss: 1.8302
Epoch [1/5], Batch [404/428], Loss: 1.5507
Epoch [1/5], Batch [405/428], Loss: 3.1368
Epoch [1/5], Batch [406/428], Loss: 1.1404
Epoch [1/5], Batch [407/428], Loss: 1.8850
Epoch [1/5], Batch [408/428], Loss: 2.1152
Epoch [1/5], Batch [409/428], Loss: 3.2682
Epoch [1/5], Batch [410/428], Loss: 4.0432
Epoch [1/5], Batch [411/428], Loss: 4.0111
Epoch [1/5], Batch [412/428], Loss: 2.8037
Epoch [1/5], Batch [413/428], Loss: 1.9601
Epoch [1/5], Batch [414/428], Loss: 2.5465
Epoch [1/5], Batch [415/428], Loss: 3.2614
Epoch [1/5], Batch [416/428], Loss: 1.8614
Epoch [1/5], Batch [417/428], Loss: 2.6680
Epoch [1/5], Batch [418/428], Loss: 2.6010
Epoch [1/5], Batch [419/428], Loss: 1.2450
Epoch [1/5], Batch [420/428], Loss: 1.7345
Epoch [1/5], Batch [421/428], Loss: 2.6022
Epoch [1/5], Batch [422/428], Loss: 2.6822
Epoch [1/5], Batch [423/428], Loss: 2.0402
Epoch [1/5], Batch [424/428], Loss: 1.8528
Epoch [1/5], Batch [425/428], Loss: 3.1478
Epoch [1/5], Batch [426/428], Loss: 1.0614
Epoch [1/5], Batch [427/428], Loss: 1.7287
Epoch [1/5], Batch [428/428], Loss: 1.5103
Epoch [1] Training Time: 269.66 seconds
Epoch [1/5], Average Loss: 2.6956, Training Accuracy: 0.1612
Epoch [1], Validation Loss: 2.2678, Validation Accuracy: 0.1429
Epoch [1] Validation Time: 10.79 seconds
--------------------------------------------------
Epoch [2/5], Batch [1/428], Loss: 3.0895
Epoch [2/5], Batch [2/428], Loss: 1.4656
Epoch [2/5], Batch [3/428], Loss: 1.3572
Epoch [2/5], Batch [4/428], Loss: 2.7340
Epoch [2/5], Batch [5/428], Loss: 3.6580
Epoch [2/5], Batch [6/428], Loss: 3.5941
Epoch [2/5], Batch [7/428], Loss: 3.4128
Epoch [2/5], Batch [8/428], Loss: 2.5468
Epoch [2/5], Batch [9/428], Loss: 2.3950
Epoch [2/5], Batch [10/428], Loss: 0.7916
Epoch [2/5], Batch [11/428], Loss: 2.0469
Epoch [2/5], Batch [12/428], Loss: 2.5227
Epoch [2/5], Batch [13/428], Loss: 2.8729
Epoch [2/5], Batch [14/428], Loss: 0.9838
Epoch [2/5], Batch [15/428], Loss: 2.2878
Epoch [2/5], Batch [16/428], Loss: 3.4574
Epoch [2/5], Batch [17/428], Loss: 1.2420
Epoch [2/5], Batch [18/428], Loss: 1.1454
Epoch [2/5], Batch [19/428], Loss: 1.4102
Epoch [2/5], Batch [20/428], Loss: 3.3952
Epoch [2/5], Batch [21/428], Loss: 2.2618
Epoch [2/5], Batch [22/428], Loss: 3.2518
Epoch [2/5], Batch [23/428], Loss: 2.1507
Epoch [2/5], Batch [24/428], Loss: 3.0517
Epoch [2/5], Batch [25/428], Loss: 2.8919
Epoch [2/5], Batch [26/428], Loss: 2.5460
Epoch [2/5], Batch [27/428], Loss: 1.9654
Epoch [2/5], Batch [28/428], Loss: 4.1595
Epoch [2/5], Batch [29/428], Loss: 1.7004
Epoch [2/5], Batch [30/428], Loss: 1.6471
Epoch [2/5], Batch [31/428], Loss: 1.6866
Epoch [2/5], Batch [32/428], Loss: 1.8338
Epoch [2/5], Batch [33/428], Loss: 2.1849
Epoch [2/5], Batch [34/428], Loss: 2.7938
Epoch [2/5], Batch [35/428], Loss: 2.7986
Epoch [2/5], Batch [36/428], Loss: 2.1263
Epoch [2/5], Batch [37/428], Loss: 1.7095
Epoch [2/5], Batch [38/428], Loss: 2.7311
Epoch [2/5], Batch [39/428], Loss: 2.0010
Epoch [2/5], Batch [40/428], Loss: 1.9105
Epoch [2/5], Batch [41/428], Loss: 2.4160
Epoch [2/5], Batch [42/428], Loss: 1.7150
Epoch [2/5], Batch [43/428], Loss: 1.5310
Epoch [2/5], Batch [44/428], Loss: 1.3049
Epoch [2/5], Batch [45/428], Loss: 1.9893
Epoch [2/5], Batch [46/428], Loss: 1.9926
Epoch [2/5], Batch [47/428], Loss: 2.2698
Epoch [2/5], Batch [48/428], Loss: 2.8099
Epoch [2/5], Batch [49/428], Loss: 2.8986
Epoch [2/5], Batch [50/428], Loss: 0.7096
Epoch [2/5], Batch [51/428], Loss: 2.8724
Epoch [2/5], Batch [52/428], Loss: 2.7608
Epoch [2/5], Batch [53/428], Loss: 2.8500
Epoch [2/5], Batch [54/428], Loss: 2.3831
Epoch [2/5], Batch [55/428], Loss: 3.0853
Epoch [2/5], Batch [56/428], Loss: 3.0330
Epoch [2/5], Batch [57/428], Loss: 0.9025
Epoch [2/5], Batch [58/428], Loss: 2.6746
Epoch [2/5], Batch [59/428], Loss: 1.4041
Epoch [2/5], Batch [60/428], Loss: 1.2657
Epoch [2/5], Batch [61/428], Loss: 1.0232
Epoch [2/5], Batch [62/428], Loss: 4.3039
Epoch [2/5], Batch [63/428], Loss: 0.6441
Epoch [2/5], Batch [64/428], Loss: 2.9533
Epoch [2/5], Batch [65/428], Loss: 4.3874
Epoch [2/5], Batch [66/428], Loss: 2.5189
Epoch [2/5], Batch [67/428], Loss: 2.6227
Epoch [2/5], Batch [68/428], Loss: 2.9250
Epoch [2/5], Batch [69/428], Loss: 3.7757
Epoch [2/5], Batch [70/428], Loss: 2.4683
Epoch [2/5], Batch [71/428], Loss: 3.4679
Epoch [2/5], Batch [72/428], Loss: 0.5532
Epoch [2/5], Batch [73/428], Loss: 0.6330
Epoch [2/5], Batch [74/428], Loss: 2.5633
Epoch [2/5], Batch [75/428], Loss: 3.4699
Epoch [2/5], Batch [76/428], Loss: 0.7165
Epoch [2/5], Batch [77/428], Loss: 2.1133
Epoch [2/5], Batch [78/428], Loss: 1.9059
Epoch [2/5], Batch [79/428], Loss: 3.3109
Epoch [2/5], Batch [80/428], Loss: 1.4814
Epoch [2/5], Batch [81/428], Loss: 3.0050
Epoch [2/5], Batch [82/428], Loss: 3.3655
Epoch [2/5], Batch [83/428], Loss: 3.2938
Epoch [2/5], Batch [84/428], Loss: 3.1333
Epoch [2/5], Batch [85/428], Loss: 2.8487
Epoch [2/5], Batch [86/428], Loss: 2.0396
Epoch [2/5], Batch [87/428], Loss: 2.7559
Epoch [2/5], Batch [88/428], Loss: 2.7922
Epoch [2/5], Batch [89/428], Loss: 2.7362
Epoch [2/5], Batch [90/428], Loss: 2.5721
Epoch [2/5], Batch [91/428], Loss: 2.3630
Epoch [2/5], Batch [92/428], Loss: 2.2034
Epoch [2/5], Batch [93/428], Loss: 1.9320
Epoch [2/5], Batch [94/428], Loss: 1.9713
Epoch [2/5], Batch [95/428], Loss: 1.9940
Epoch [2/5], Batch [96/428], Loss: 1.6402
Epoch [2/5], Batch [97/428], Loss: 2.3727
Epoch [2/5], Batch [98/428], Loss: 3.4466
Epoch [2/5], Batch [99/428], Loss: 1.4816
Epoch [2/5], Batch [100/428], Loss: 1.9645
Epoch [2/5], Batch [101/428], Loss: 2.2279
Epoch [2/5], Batch [102/428], Loss: 1.3278
Epoch [2/5], Batch [103/428], Loss: 2.1561
Epoch [2/5], Batch [104/428], Loss: 3.6450
Epoch [2/5], Batch [105/428], Loss: 1.0923
Epoch [2/5], Batch [106/428], Loss: 1.4213
Epoch [2/5], Batch [107/428], Loss: 2.3128
Epoch [2/5], Batch [108/428], Loss: 3.4164
Epoch [2/5], Batch [109/428], Loss: 3.2705
Epoch [2/5], Batch [110/428], Loss: 3.2602
Epoch [2/5], Batch [111/428], Loss: 1.0288
Epoch [2/5], Batch [112/428], Loss: 3.0945
Epoch [2/5], Batch [113/428], Loss: 3.0665
Epoch [2/5], Batch [114/428], Loss: 2.3223
Epoch [2/5], Batch [115/428], Loss: 2.6848
Epoch [2/5], Batch [116/428], Loss: 1.9314
Epoch [2/5], Batch [117/428], Loss: 1.7083
Epoch [2/5], Batch [118/428], Loss: 2.2775
Epoch [2/5], Batch [119/428], Loss: 1.5536
Epoch [2/5], Batch [120/428], Loss: 2.0675
Epoch [2/5], Batch [121/428], Loss: 2.0094
Epoch [2/5], Batch [122/428], Loss: 1.8309
Epoch [2/5], Batch [123/428], Loss: 1.6844
Epoch [2/5], Batch [124/428], Loss: 1.4535
Epoch [2/5], Batch [125/428], Loss: 3.0564
Epoch [2/5], Batch [126/428], Loss: 1.0115
Epoch [2/5], Batch [127/428], Loss: 2.4661
Epoch [2/5], Batch [128/428], Loss: 0.6672
Epoch [2/5], Batch [129/428], Loss: 2.0118
Epoch [2/5], Batch [130/428], Loss: 3.4700
Epoch [2/5], Batch [131/428], Loss: 2.3137
Epoch [2/5], Batch [132/428], Loss: 0.3533
Epoch [2/5], Batch [133/428], Loss: 2.3834
Epoch [2/5], Batch [134/428], Loss: 3.6679
Epoch [2/5], Batch [135/428], Loss: 3.2173
Epoch [2/5], Batch [136/428], Loss: 3.4652
Epoch [2/5], Batch [137/428], Loss: 4.2623
Epoch [2/5], Batch [138/428], Loss: 3.1927
Epoch [2/5], Batch [139/428], Loss: 1.9722
Epoch [2/5], Batch [140/428], Loss: 2.6126
Epoch [2/5], Batch [141/428], Loss: 2.3462
Epoch [2/5], Batch [142/428], Loss: 3.0622
Epoch [2/5], Batch [143/428], Loss: 3.6005
Epoch [2/5], Batch [144/428], Loss: 2.5987
Epoch [2/5], Batch [145/428], Loss: 1.4202
Epoch [2/5], Batch [146/428], Loss: 1.4426
Epoch [2/5], Batch [147/428], Loss: 2.6485
Epoch [2/5], Batch [148/428], Loss: 1.8797
Epoch [2/5], Batch [149/428], Loss: 2.3501
Epoch [2/5], Batch [150/428], Loss: 2.5285
Epoch [2/5], Batch [151/428], Loss: 2.1261
Epoch [2/5], Batch [152/428], Loss: 1.3939
Epoch [2/5], Batch [153/428], Loss: 2.3608
Epoch [2/5], Batch [154/428], Loss: 2.2065
Epoch [2/5], Batch [155/428], Loss: 2.2811
Epoch [2/5], Batch [156/428], Loss: 1.9254
Epoch [2/5], Batch [157/428], Loss: 2.2934
Epoch [2/5], Batch [158/428], Loss: 2.1447
Epoch [2/5], Batch [159/428], Loss: 1.5507
Epoch [2/5], Batch [160/428], Loss: 2.1417
Epoch [2/5], Batch [161/428], Loss: 2.0556
Epoch [2/5], Batch [162/428], Loss: 1.9499
Epoch [2/5], Batch [163/428], Loss: 2.3293
Epoch [2/5], Batch [164/428], Loss: 1.9136
Epoch [2/5], Batch [165/428], Loss: 1.2800
Epoch [2/5], Batch [166/428], Loss: 3.3315
Epoch [2/5], Batch [167/428], Loss: 3.2947
Epoch [2/5], Batch [168/428], Loss: 1.6296
Epoch [2/5], Batch [169/428], Loss: 1.5064
Epoch [2/5], Batch [170/428], Loss: 1.3306
Epoch [2/5], Batch [171/428], Loss: 2.6161
Epoch [2/5], Batch [172/428], Loss: 2.6200
Epoch [2/5], Batch [173/428], Loss: 2.1756
Epoch [2/5], Batch [174/428], Loss: 2.5679
Epoch [2/5], Batch [175/428], Loss: 3.0139
Epoch [2/5], Batch [176/428], Loss: 2.0936
Epoch [2/5], Batch [177/428], Loss: 2.5702
Epoch [2/5], Batch [178/428], Loss: 2.2066
Epoch [2/5], Batch [179/428], Loss: 2.2225
Epoch [2/5], Batch [180/428], Loss: 0.9692
Epoch [2/5], Batch [181/428], Loss: 2.0314
Epoch [2/5], Batch [182/428], Loss: 2.2763
Epoch [2/5], Batch [183/428], Loss: 2.1132
Epoch [2/5], Batch [184/428], Loss: 2.0299
Epoch [2/5], Batch [185/428], Loss: 1.7074
Epoch [2/5], Batch [186/428], Loss: 1.8992
Epoch [2/5], Batch [187/428], Loss: 1.5588
Epoch [2/5], Batch [188/428], Loss: 2.7306
Epoch [2/5], Batch [189/428], Loss: 1.6843
Epoch [2/5], Batch [190/428], Loss: 1.6661
Epoch [2/5], Batch [191/428], Loss: 3.1032
Epoch [2/5], Batch [192/428], Loss: 3.0193
Epoch [2/5], Batch [193/428], Loss: 2.2906
Epoch [2/5], Batch [194/428], Loss: 1.6004
Epoch [2/5], Batch [195/428], Loss: 2.5648
Epoch [2/5], Batch [196/428], Loss: 1.4891
Epoch [2/5], Batch [197/428], Loss: 2.3307
Epoch [2/5], Batch [198/428], Loss: 1.3557
Epoch [2/5], Batch [199/428], Loss: 1.2602
Epoch [2/5], Batch [200/428], Loss: 2.3309
Epoch [2/5], Batch [201/428], Loss: 2.4046
Epoch [2/5], Batch [202/428], Loss: 2.5178
Epoch [2/5], Batch [203/428], Loss: 2.0881
Epoch [2/5], Batch [204/428], Loss: 2.0262
Epoch [2/5], Batch [205/428], Loss: 0.9900
Epoch [2/5], Batch [206/428], Loss: 2.0968
Epoch [2/5], Batch [207/428], Loss: 1.7775
Epoch [2/5], Batch [208/428], Loss: 2.0166
Epoch [2/5], Batch [209/428], Loss: 1.9122
Epoch [2/5], Batch [210/428], Loss: 2.2041
Epoch [2/5], Batch [211/428], Loss: 2.1496
Epoch [2/5], Batch [212/428], Loss: 2.0363
Epoch [2/5], Batch [213/428], Loss: 1.4622
Epoch [2/5], Batch [214/428], Loss: 3.2328
Epoch [2/5], Batch [215/428], Loss: 3.1712
Epoch [2/5], Batch [216/428], Loss: 1.6654
Epoch [2/5], Batch [217/428], Loss: 3.4320
Epoch [2/5], Batch [218/428], Loss: 1.7829
Epoch [2/5], Batch [219/428], Loss: 1.6381
Epoch [2/5], Batch [220/428], Loss: 3.5454
Epoch [2/5], Batch [221/428], Loss: 1.7460
Epoch [2/5], Batch [222/428], Loss: 1.7775
Epoch [2/5], Batch [223/428], Loss: 3.3540
Epoch [2/5], Batch [224/428], Loss: 3.1601
Epoch [2/5], Batch [225/428], Loss: 3.1065
Epoch [2/5], Batch [226/428], Loss: 1.5631
Epoch [2/5], Batch [227/428], Loss: 2.2772
Epoch [2/5], Batch [228/428], Loss: 1.8527
Epoch [2/5], Batch [229/428], Loss: 1.8700
Epoch [2/5], Batch [230/428], Loss: 1.8336
Epoch [2/5], Batch [231/428], Loss: 2.0970
Epoch [2/5], Batch [232/428], Loss: 2.4445
Epoch [2/5], Batch [233/428], Loss: 2.4520
Epoch [2/5], Batch [234/428], Loss: 1.8376
Epoch [2/5], Batch [235/428], Loss: 2.3447
Epoch [2/5], Batch [236/428], Loss: 1.7935
Epoch [2/5], Batch [237/428], Loss: 2.5752
Epoch [2/5], Batch [238/428], Loss: 2.5345
Epoch [2/5], Batch [239/428], Loss: 1.8292
Epoch [2/5], Batch [240/428], Loss: 1.9551
Epoch [2/5], Batch [241/428], Loss: 2.4980
Epoch [2/5], Batch [242/428], Loss: 2.3499
Epoch [2/5], Batch [243/428], Loss: 2.4059
Epoch [2/5], Batch [244/428], Loss: 1.8554
Epoch [2/5], Batch [245/428], Loss: 1.9539
Epoch [2/5], Batch [246/428], Loss: 1.8625
Epoch [2/5], Batch [247/428], Loss: 2.2299
Epoch [2/5], Batch [248/428], Loss: 1.9785
Epoch [2/5], Batch [249/428], Loss: 2.0317
Epoch [2/5], Batch [250/428], Loss: 1.9707
Epoch [2/5], Batch [251/428], Loss: 1.7432
Epoch [2/5], Batch [252/428], Loss: 1.8051
Epoch [2/5], Batch [253/428], Loss: 1.6930
Epoch [2/5], Batch [254/428], Loss: 1.5598
Epoch [2/5], Batch [255/428], Loss: 2.7013
Epoch [2/5], Batch [256/428], Loss: 2.3033
Epoch [2/5], Batch [257/428], Loss: 2.9818
Epoch [2/5], Batch [258/428], Loss: 2.3522
Epoch [2/5], Batch [259/428], Loss: 0.9711
Epoch [2/5], Batch [260/428], Loss: 0.8762
Epoch [2/5], Batch [261/428], Loss: 0.7485
Epoch [2/5], Batch [262/428], Loss: 2.9315
Epoch [2/5], Batch [263/428], Loss: 0.5181
Epoch [2/5], Batch [264/428], Loss: 2.9517
Epoch [2/5], Batch [265/428], Loss: 3.4657
Epoch [2/5], Batch [266/428], Loss: 2.8538
Epoch [2/5], Batch [267/428], Loss: 2.8090
Epoch [2/5], Batch [268/428], Loss: 2.7861
Epoch [2/5], Batch [269/428], Loss: 0.3394
Epoch [2/5], Batch [270/428], Loss: 4.0237
Epoch [2/5], Batch [271/428], Loss: 3.2765
Epoch [2/5], Batch [272/428], Loss: 3.1563
Epoch [2/5], Batch [273/428], Loss: 3.8479
Epoch [2/5], Batch [274/428], Loss: 4.2613
Epoch [2/5], Batch [275/428], Loss: 0.5554
Epoch [2/5], Batch [276/428], Loss: 0.5930
Epoch [2/5], Batch [277/428], Loss: 1.9408
Epoch [2/5], Batch [278/428], Loss: 3.3083
Epoch [2/5], Batch [279/428], Loss: 1.7635
Epoch [2/5], Batch [280/428], Loss: 1.6625
Epoch [2/5], Batch [281/428], Loss: 3.7394
Epoch [2/5], Batch [282/428], Loss: 0.9220
Epoch [2/5], Batch [283/428], Loss: 1.2774
Epoch [2/5], Batch [284/428], Loss: 2.6632
Epoch [2/5], Batch [285/428], Loss: 1.1669
Epoch [2/5], Batch [286/428], Loss: 1.2081
Epoch [2/5], Batch [287/428], Loss: 1.1875
Epoch [2/5], Batch [288/428], Loss: 2.4464
Epoch [2/5], Batch [289/428], Loss: 3.0166
Epoch [2/5], Batch [290/428], Loss: 3.2108
Epoch [2/5], Batch [291/428], Loss: 1.0111
Epoch [2/5], Batch [292/428], Loss: 0.9301
Epoch [2/5], Batch [293/428], Loss: 2.9742
Epoch [2/5], Batch [294/428], Loss: 3.5675
Epoch [2/5], Batch [295/428], Loss: 2.2177
Epoch [2/5], Batch [296/428], Loss: 0.7140
Epoch [2/5], Batch [297/428], Loss: 0.6588
Epoch [2/5], Batch [298/428], Loss: 2.6934
Epoch [2/5], Batch [299/428], Loss: 0.5394
Epoch [2/5], Batch [300/428], Loss: 2.2722
Epoch [2/5], Batch [301/428], Loss: 2.8554
Epoch [2/5], Batch [302/428], Loss: 2.8347
Epoch [2/5], Batch [303/428], Loss: 0.4560
Epoch [2/5], Batch [304/428], Loss: 3.3748
Epoch [2/5], Batch [305/428], Loss: 3.4078
Epoch [2/5], Batch [306/428], Loss: 2.2897
Epoch [2/5], Batch [307/428], Loss: 3.6349
Epoch [2/5], Batch [308/428], Loss: 0.5305
Epoch [2/5], Batch [309/428], Loss: 0.5418
Epoch [2/5], Batch [310/428], Loss: 3.4913
Epoch [2/5], Batch [311/428], Loss: 3.4147
Epoch [2/5], Batch [312/428], Loss: 2.1590
Epoch [2/5], Batch [313/428], Loss: 0.5460
Epoch [2/5], Batch [314/428], Loss: 2.2161
Epoch [2/5], Batch [315/428], Loss: 2.0359
Epoch [2/5], Batch [316/428], Loss: 3.5668
Epoch [2/5], Batch [317/428], Loss: 2.0580
Epoch [2/5], Batch [318/428], Loss: 0.7632
Epoch [2/5], Batch [319/428], Loss: 3.1606
Epoch [2/5], Batch [320/428], Loss: 1.8644
Epoch [2/5], Batch [321/428], Loss: 2.9862
Epoch [2/5], Batch [322/428], Loss: 3.2548
Epoch [2/5], Batch [323/428], Loss: 1.0806
Epoch [2/5], Batch [324/428], Loss: 3.0053
Epoch [2/5], Batch [325/428], Loss: 1.1713
Epoch [2/5], Batch [326/428], Loss: 3.3007
Epoch [2/5], Batch [327/428], Loss: 2.6628
Epoch [2/5], Batch [328/428], Loss: 2.4422
Epoch [2/5], Batch [329/428], Loss: 3.1389
Epoch [2/5], Batch [330/428], Loss: 1.6064
Epoch [2/5], Batch [331/428], Loss: 2.1819
Epoch [2/5], Batch [332/428], Loss: 2.4618
Epoch [2/5], Batch [333/428], Loss: 2.3686
Epoch [2/5], Batch [334/428], Loss: 2.4557
Epoch [2/5], Batch [335/428], Loss: 1.9466
Epoch [2/5], Batch [336/428], Loss: 1.8228
Epoch [2/5], Batch [337/428], Loss: 2.2671
Epoch [2/5], Batch [338/428], Loss: 1.8984
Epoch [2/5], Batch [339/428], Loss: 1.4632
Epoch [2/5], Batch [340/428], Loss: 1.3809
Epoch [2/5], Batch [341/428], Loss: 1.9640
Epoch [2/5], Batch [342/428], Loss: 1.9111
Epoch [2/5], Batch [343/428], Loss: 1.8758
Epoch [2/5], Batch [344/428], Loss: 2.5978
Epoch [2/5], Batch [345/428], Loss: 2.5773
Epoch [2/5], Batch [346/428], Loss: 1.6517
Epoch [2/5], Batch [347/428], Loss: 2.8428
Epoch [2/5], Batch [348/428], Loss: 1.4284
Epoch [2/5], Batch [349/428], Loss: 1.5130
Epoch [2/5], Batch [350/428], Loss: 3.0129
Epoch [2/5], Batch [351/428], Loss: 1.7463
Epoch [2/5], Batch [352/428], Loss: 1.1268
Epoch [2/5], Batch [353/428], Loss: 1.0095
Epoch [2/5], Batch [354/428], Loss: 0.9040
Epoch [2/5], Batch [355/428], Loss: 1.8915
Epoch [2/5], Batch [356/428], Loss: 2.0451
Epoch [2/5], Batch [357/428], Loss: 3.2103
Epoch [2/5], Batch [358/428], Loss: 2.8441
Epoch [2/5], Batch [359/428], Loss: 3.2154
Epoch [2/5], Batch [360/428], Loss: 3.1168
Epoch [2/5], Batch [361/428], Loss: 3.1784
Epoch [2/5], Batch [362/428], Loss: 3.0462
Epoch [2/5], Batch [363/428], Loss: 0.6994
Epoch [2/5], Batch [364/428], Loss: 2.7421
Epoch [2/5], Batch [365/428], Loss: 2.5058
Epoch [2/5], Batch [366/428], Loss: 2.3509
Epoch [2/5], Batch [367/428], Loss: 2.0970
Epoch [2/5], Batch [368/428], Loss: 2.3363
Epoch [2/5], Batch [369/428], Loss: 2.3591
Epoch [2/5], Batch [370/428], Loss: 2.1841
Epoch [2/5], Batch [371/428], Loss: 2.0937
Epoch [2/5], Batch [372/428], Loss: 1.5140
Epoch [2/5], Batch [373/428], Loss: 2.5695
Epoch [2/5], Batch [374/428], Loss: 1.6854
Epoch [2/5], Batch [375/428], Loss: 1.1897
Epoch [2/5], Batch [376/428], Loss: 2.9497
Epoch [2/5], Batch [377/428], Loss: 1.6271
Epoch [2/5], Batch [378/428], Loss: 1.8730
Epoch [2/5], Batch [379/428], Loss: 2.2325
Epoch [2/5], Batch [380/428], Loss: 1.8494
Epoch [2/5], Batch [381/428], Loss: 2.4926
Epoch [2/5], Batch [382/428], Loss: 1.4022
Epoch [2/5], Batch [383/428], Loss: 1.7173
Epoch [2/5], Batch [384/428], Loss: 1.2931
Epoch [2/5], Batch [385/428], Loss: 2.3540
Epoch [2/5], Batch [386/428], Loss: 2.2483
Epoch [2/5], Batch [387/428], Loss: 1.5424
Epoch [2/5], Batch [388/428], Loss: 2.0421
Epoch [2/5], Batch [389/428], Loss: 2.2721
Epoch [2/5], Batch [390/428], Loss: 1.1966
Epoch [2/5], Batch [391/428], Loss: 1.2159
Epoch [2/5], Batch [392/428], Loss: 1.7314
Epoch [2/5], Batch [393/428], Loss: 1.5000
Epoch [2/5], Batch [394/428], Loss: 3.4847
Epoch [2/5], Batch [395/428], Loss: 2.5051
Epoch [2/5], Batch [396/428], Loss: 1.1246
Epoch [2/5], Batch [397/428], Loss: 2.5370
Epoch [2/5], Batch [398/428], Loss: 1.4931
Epoch [2/5], Batch [399/428], Loss: 1.4816
Epoch [2/5], Batch [400/428], Loss: 1.4038
Epoch [2/5], Batch [401/428], Loss: 1.7027
Epoch [2/5], Batch [402/428], Loss: 1.6754
Epoch [2/5], Batch [403/428], Loss: 2.2665
Epoch [2/5], Batch [404/428], Loss: 4.1890
Epoch [2/5], Batch [405/428], Loss: 2.7491
Epoch [2/5], Batch [406/428], Loss: 2.6953
Epoch [2/5], Batch [407/428], Loss: 2.5706
Epoch [2/5], Batch [408/428], Loss: 2.4075
Epoch [2/5], Batch [409/428], Loss: 1.4413
Epoch [2/5], Batch [410/428], Loss: 1.9966
Epoch [2/5], Batch [411/428], Loss: 1.7696
Epoch [2/5], Batch [412/428], Loss: 3.3085
Epoch [2/5], Batch [413/428], Loss: 1.5161
Epoch [2/5], Batch [414/428], Loss: 1.5586
Epoch [2/5], Batch [415/428], Loss: 1.5683
Epoch [2/5], Batch [416/428], Loss: 2.3386
Epoch [2/5], Batch [417/428], Loss: 0.9446
Epoch [2/5], Batch [418/428], Loss: 3.8604
Epoch [2/5], Batch [419/428], Loss: 1.4933
Epoch [2/5], Batch [420/428], Loss: 1.4183
Epoch [2/5], Batch [421/428], Loss: 1.3216
Epoch [2/5], Batch [422/428], Loss: 1.1572
Epoch [2/5], Batch [423/428], Loss: 0.9742
Epoch [2/5], Batch [424/428], Loss: 0.8931
Epoch [2/5], Batch [425/428], Loss: 3.8462
Epoch [2/5], Batch [426/428], Loss: 3.2781
Epoch [2/5], Batch [427/428], Loss: 1.3394
Epoch [2/5], Batch [428/428], Loss: 0.5766
Epoch [2] Training Time: 269.75 seconds
Epoch [2/5], Average Loss: 2.1983, Training Accuracy: 0.1402
Epoch [2], Validation Loss: 2.6149, Validation Accuracy: 0.1429
Epoch [2] Validation Time: 10.76 seconds
--------------------------------------------------
Epoch [3/5], Batch [1/428], Loss: 2.9608
Epoch [3/5], Batch [2/428], Loss: 0.4976
Epoch [3/5], Batch [3/428], Loss: 0.4530
Epoch [3/5], Batch [4/428], Loss: 1.7272
Epoch [3/5], Batch [5/428], Loss: 1.8257
Epoch [3/5], Batch [6/428], Loss: 3.7298
Epoch [3/5], Batch [7/428], Loss: 1.8255
Epoch [3/5], Batch [8/428], Loss: 3.8038
Epoch [3/5], Batch [9/428], Loss: 3.0978
Epoch [3/5], Batch [10/428], Loss: 4.0034
Epoch [3/5], Batch [11/428], Loss: 1.5796
Epoch [3/5], Batch [12/428], Loss: 3.8285
Epoch [3/5], Batch [13/428], Loss: 0.5874
Epoch [3/5], Batch [14/428], Loss: 2.7703
Epoch [3/5], Batch [15/428], Loss: 2.6252
Epoch [3/5], Batch [16/428], Loss: 1.2716
Epoch [3/5], Batch [17/428], Loss: 3.0756
Epoch [3/5], Batch [18/428], Loss: 2.9009
Epoch [3/5], Batch [19/428], Loss: 0.9721
Epoch [3/5], Batch [20/428], Loss: 3.0001
Epoch [3/5], Batch [21/428], Loss: 1.0546
Epoch [3/5], Batch [22/428], Loss: 3.2202
Epoch [3/5], Batch [23/428], Loss: 1.0854
Epoch [3/5], Batch [24/428], Loss: 1.3220
Epoch [3/5], Batch [25/428], Loss: 2.8636
Epoch [3/5], Batch [26/428], Loss: 1.1105
Epoch [3/5], Batch [27/428], Loss: 1.9613
Epoch [3/5], Batch [28/428], Loss: 1.4506
Epoch [3/5], Batch [29/428], Loss: 2.6635
Epoch [3/5], Batch [30/428], Loss: 1.1130
Epoch [3/5], Batch [31/428], Loss: 1.1047
Epoch [3/5], Batch [32/428], Loss: 2.6473
Epoch [3/5], Batch [33/428], Loss: 1.0416
Epoch [3/5], Batch [34/428], Loss: 1.6470
Epoch [3/5], Batch [35/428], Loss: 2.3885
Epoch [3/5], Batch [36/428], Loss: 2.5351
Epoch [3/5], Batch [37/428], Loss: 1.7197
Epoch [3/5], Batch [38/428], Loss: 0.9647
Epoch [3/5], Batch [39/428], Loss: 3.1531
Epoch [3/5], Batch [40/428], Loss: 2.2749
Epoch [3/5], Batch [41/428], Loss: 0.9214
Epoch [3/5], Batch [42/428], Loss: 0.9070
Epoch [3/5], Batch [43/428], Loss: 1.7743
Epoch [3/5], Batch [44/428], Loss: 2.3524
Epoch [3/5], Batch [45/428], Loss: 2.6405
Epoch [3/5], Batch [46/428], Loss: 3.0525
Epoch [3/5], Batch [47/428], Loss: 2.2788
Epoch [3/5], Batch [48/428], Loss: 0.8503
Epoch [3/5], Batch [49/428], Loss: 0.8544
Epoch [3/5], Batch [50/428], Loss: 2.8537
Epoch [3/5], Batch [51/428], Loss: 2.9894
Epoch [3/5], Batch [52/428], Loss: 2.2900
Epoch [3/5], Batch [53/428], Loss: 0.7996
Epoch [3/5], Batch [54/428], Loss: 2.6123
Epoch [3/5], Batch [55/428], Loss: 2.2967
Epoch [3/5], Batch [56/428], Loss: 2.6335
Epoch [3/5], Batch [57/428], Loss: 2.3652
Epoch [3/5], Batch [58/428], Loss: 0.8380
Epoch [3/5], Batch [59/428], Loss: 2.5488
Epoch [3/5], Batch [60/428], Loss: 0.8771
Epoch [3/5], Batch [61/428], Loss: 2.2231
Epoch [3/5], Batch [62/428], Loss: 2.4049
Epoch [3/5], Batch [63/428], Loss: 0.8593
Epoch [3/5], Batch [64/428], Loss: 2.1640
Epoch [3/5], Batch [65/428], Loss: 2.9727
Epoch [3/5], Batch [66/428], Loss: 0.8953
Epoch [3/5], Batch [67/428], Loss: 2.9475
Epoch [3/5], Batch [68/428], Loss: 2.0916
Epoch [3/5], Batch [69/428], Loss: 2.7468
Epoch [3/5], Batch [70/428], Loss: 0.8934
Epoch [3/5], Batch [71/428], Loss: 3.0016
Epoch [3/5], Batch [72/428], Loss: 2.4192
Epoch [3/5], Batch [73/428], Loss: 3.0111
Epoch [3/5], Batch [74/428], Loss: 2.0665
Epoch [3/5], Batch [75/428], Loss: 2.9558
Epoch [3/5], Batch [76/428], Loss: 2.8300
Epoch [3/5], Batch [77/428], Loss: 1.1022
Epoch [3/5], Batch [78/428], Loss: 1.8862
Epoch [3/5], Batch [79/428], Loss: 1.1296
Epoch [3/5], Batch [80/428], Loss: 2.6039
Epoch [3/5], Batch [81/428], Loss: 1.1643
Epoch [3/5], Batch [82/428], Loss: 1.1137
Epoch [3/5], Batch [83/428], Loss: 1.0417
Epoch [3/5], Batch [84/428], Loss: 2.6159
Epoch [3/5], Batch [85/428], Loss: 1.9854
Epoch [3/5], Batch [86/428], Loss: 2.5536
Epoch [3/5], Batch [87/428], Loss: 2.4173
Epoch [3/5], Batch [88/428], Loss: 0.8345
Epoch [3/5], Batch [89/428], Loss: 0.7992
Epoch [3/5], Batch [90/428], Loss: 2.3143
Epoch [3/5], Batch [91/428], Loss: 2.3403
Epoch [3/5], Batch [92/428], Loss: 2.4627
Epoch [3/5], Batch [93/428], Loss: 2.2604
Epoch [3/5], Batch [94/428], Loss: 3.5817
Epoch [3/5], Batch [95/428], Loss: 2.7013
Epoch [3/5], Batch [96/428], Loss: 2.4459
Epoch [3/5], Batch [97/428], Loss: 3.4975
Epoch [3/5], Batch [98/428], Loss: 2.0244
Epoch [3/5], Batch [99/428], Loss: 2.3565
Epoch [3/5], Batch [100/428], Loss: 2.2693
Epoch [3/5], Batch [101/428], Loss: 1.7502
Epoch [3/5], Batch [102/428], Loss: 2.6166
Epoch [3/5], Batch [103/428], Loss: 2.2990
Epoch [3/5], Batch [104/428], Loss: 1.9007
Epoch [3/5], Batch [105/428], Loss: 1.4603
Epoch [3/5], Batch [106/428], Loss: 3.0854
Epoch [3/5], Batch [107/428], Loss: 2.1973
Epoch [3/5], Batch [108/428], Loss: 1.6425
Epoch [3/5], Batch [109/428], Loss: 1.6797
Epoch [3/5], Batch [110/428], Loss: 1.5517
Epoch [3/5], Batch [111/428], Loss: 1.6198
Epoch [3/5], Batch [112/428], Loss: 2.4921
Epoch [3/5], Batch [113/428], Loss: 2.0315
Epoch [3/5], Batch [114/428], Loss: 1.5075
Epoch [3/5], Batch [115/428], Loss: 2.7241
Epoch [3/5], Batch [116/428], Loss: 1.9963
Epoch [3/5], Batch [117/428], Loss: 1.3614
Epoch [3/5], Batch [118/428], Loss: 1.7063
Epoch [3/5], Batch [119/428], Loss: 1.2572
Epoch [3/5], Batch [120/428], Loss: 1.9244
Epoch [3/5], Batch [121/428], Loss: 1.1488
Epoch [3/5], Batch [122/428], Loss: 2.5075
Epoch [3/5], Batch [123/428], Loss: 2.5244
Epoch [3/5], Batch [124/428], Loss: 1.8550
Epoch [3/5], Batch [125/428], Loss: 2.4016
Epoch [3/5], Batch [126/428], Loss: 2.6446
Epoch [3/5], Batch [127/428], Loss: 1.8908
Epoch [3/5], Batch [128/428], Loss: 3.0857
Epoch [3/5], Batch [129/428], Loss: 2.1636
Epoch [3/5], Batch [130/428], Loss: 1.7774
Epoch [3/5], Batch [131/428], Loss: 1.1172
Epoch [3/5], Batch [132/428], Loss: 1.1247
Epoch [3/5], Batch [133/428], Loss: 1.8540
Epoch [3/5], Batch [134/428], Loss: 1.1050
Epoch [3/5], Batch [135/428], Loss: 1.0878
Epoch [3/5], Batch [136/428], Loss: 1.0316
Epoch [3/5], Batch [137/428], Loss: 1.7618
Epoch [3/5], Batch [138/428], Loss: 1.7741
Epoch [3/5], Batch [139/428], Loss: 0.8510
Epoch [3/5], Batch [140/428], Loss: 2.9740
Epoch [3/5], Batch [141/428], Loss: 1.8808
Epoch [3/5], Batch [142/428], Loss: 1.7311
Epoch [3/5], Batch [143/428], Loss: 1.8618
Epoch [3/5], Batch [144/428], Loss: 2.9263
Epoch [3/5], Batch [145/428], Loss: 3.1157
Epoch [3/5], Batch [146/428], Loss: 3.0148
Epoch [3/5], Batch [147/428], Loss: 3.0604
Epoch [3/5], Batch [148/428], Loss: 1.6232
Epoch [3/5], Batch [149/428], Loss: 2.8271
Epoch [3/5], Batch [150/428], Loss: 1.5773
Epoch [3/5], Batch [151/428], Loss: 1.5327
Epoch [3/5], Batch [152/428], Loss: 2.7588
Epoch [3/5], Batch [153/428], Loss: 1.3779
Epoch [3/5], Batch [154/428], Loss: 1.3818
Epoch [3/5], Batch [155/428], Loss: 1.2352
Epoch [3/5], Batch [156/428], Loss: 1.5354
Epoch [3/5], Batch [157/428], Loss: 2.6500
Epoch [3/5], Batch [158/428], Loss: 1.6678
Epoch [3/5], Batch [159/428], Loss: 1.7138
Epoch [3/5], Batch [160/428], Loss: 1.7254
Epoch [3/5], Batch [161/428], Loss: 1.6733
Epoch [3/5], Batch [162/428], Loss: 1.6086
Epoch [3/5], Batch [163/428], Loss: 2.7712
Epoch [3/5], Batch [164/428], Loss: 1.4710
Epoch [3/5], Batch [165/428], Loss: 3.8463
Epoch [3/5], Batch [166/428], Loss: 2.4398
Epoch [3/5], Batch [167/428], Loss: 1.3705
Epoch [3/5], Batch [168/428], Loss: 1.1985
Epoch [3/5], Batch [169/428], Loss: 1.1417
Epoch [3/5], Batch [170/428], Loss: 2.5695
Epoch [3/5], Batch [171/428], Loss: 2.3041
Epoch [3/5], Batch [172/428], Loss: 2.5572
Epoch [3/5], Batch [173/428], Loss: 0.9156
Epoch [3/5], Batch [174/428], Loss: 2.0755
Epoch [3/5], Batch [175/428], Loss: 1.9614
Epoch [3/5], Batch [176/428], Loss: 2.1683
Epoch [3/5], Batch [177/428], Loss: 0.8147
Epoch [3/5], Batch [178/428], Loss: 2.0416
Epoch [3/5], Batch [179/428], Loss: 2.0531
Epoch [3/5], Batch [180/428], Loss: 2.3636
Epoch [3/5], Batch [181/428], Loss: 0.8046
Epoch [3/5], Batch [182/428], Loss: 2.0399
Epoch [3/5], Batch [183/428], Loss: 2.3865
Epoch [3/5], Batch [184/428], Loss: 2.2109
Epoch [3/5], Batch [185/428], Loss: 3.6008
Epoch [3/5], Batch [186/428], Loss: 3.1589
Epoch [3/5], Batch [187/428], Loss: 3.5221
Epoch [3/5], Batch [188/428], Loss: 1.9469
Epoch [3/5], Batch [189/428], Loss: 2.3710
Epoch [3/5], Batch [190/428], Loss: 3.1211
Epoch [3/5], Batch [191/428], Loss: 1.8125
Epoch [3/5], Batch [192/428], Loss: 1.2731
Epoch [3/5], Batch [193/428], Loss: 1.2946
Epoch [3/5], Batch [194/428], Loss: 1.2931
Epoch [3/5], Batch [195/428], Loss: 2.2092
Epoch [3/5], Batch [196/428], Loss: 1.8201
Epoch [3/5], Batch [197/428], Loss: 1.8857
Epoch [3/5], Batch [198/428], Loss: 1.2387
Epoch [3/5], Batch [199/428], Loss: 2.0953
Epoch [3/5], Batch [200/428], Loss: 2.3730
Epoch [3/5], Batch [201/428], Loss: 1.8542
Epoch [3/5], Batch [202/428], Loss: 1.8316
Epoch [3/5], Batch [203/428], Loss: 3.0667
Epoch [3/5], Batch [204/428], Loss: 1.9547
Epoch [3/5], Batch [205/428], Loss: 2.2079
Epoch [3/5], Batch [206/428], Loss: 1.6223
Epoch [3/5], Batch [207/428], Loss: 2.2370
Epoch [3/5], Batch [208/428], Loss: 1.9399
Epoch [3/5], Batch [209/428], Loss: 1.5286
Epoch [3/5], Batch [210/428], Loss: 2.1732
Epoch [3/5], Batch [211/428], Loss: 1.3904
Epoch [3/5], Batch [212/428], Loss: 1.6317
Epoch [3/5], Batch [213/428], Loss: 1.8213
Epoch [3/5], Batch [214/428], Loss: 2.3224
Epoch [3/5], Batch [215/428], Loss: 1.3253
Epoch [3/5], Batch [216/428], Loss: 2.3183
Epoch [3/5], Batch [217/428], Loss: 2.0818
Epoch [3/5], Batch [218/428], Loss: 2.3075
Epoch [3/5], Batch [219/428], Loss: 3.0433
Epoch [3/5], Batch [220/428], Loss: 2.9910
Epoch [3/5], Batch [221/428], Loss: 1.8529
Epoch [3/5], Batch [222/428], Loss: 2.1211
Epoch [3/5], Batch [223/428], Loss: 2.3749
Epoch [3/5], Batch [224/428], Loss: 1.8320
Epoch [3/5], Batch [225/428], Loss: 1.8116
Epoch [3/5], Batch [226/428], Loss: 2.2755
Epoch [3/5], Batch [227/428], Loss: 2.0582
Epoch [3/5], Batch [228/428], Loss: 2.0208
Epoch [3/5], Batch [229/428], Loss: 1.5876
Epoch [3/5], Batch [230/428], Loss: 2.4971
Epoch [3/5], Batch [231/428], Loss: 1.9550
Epoch [3/5], Batch [232/428], Loss: 2.2517
Epoch [3/5], Batch [233/428], Loss: 2.4032
Epoch [3/5], Batch [234/428], Loss: 2.2334
Epoch [3/5], Batch [235/428], Loss: 1.4470
Epoch [3/5], Batch [236/428], Loss: 2.1607
Epoch [3/5], Batch [237/428], Loss: 2.4461
Epoch [3/5], Batch [238/428], Loss: 2.4735
Epoch [3/5], Batch [239/428], Loss: 1.7371
Epoch [3/5], Batch [240/428], Loss: 2.2059
Epoch [3/5], Batch [241/428], Loss: 1.4190
Epoch [3/5], Batch [242/428], Loss: 2.3638
Epoch [3/5], Batch [243/428], Loss: 2.2782
Epoch [3/5], Batch [244/428], Loss: 2.0926
Epoch [3/5], Batch [245/428], Loss: 1.8944
Epoch [3/5], Batch [246/428], Loss: 1.8125
Epoch [3/5], Batch [247/428], Loss: 2.2944
Epoch [3/5], Batch [248/428], Loss: 1.8920
Epoch [3/5], Batch [249/428], Loss: 1.5864
Epoch [3/5], Batch [250/428], Loss: 1.5866
Epoch [3/5], Batch [251/428], Loss: 2.2523
Epoch [3/5], Batch [252/428], Loss: 1.6291
Epoch [3/5], Batch [253/428], Loss: 1.9983
Epoch [3/5], Batch [254/428], Loss: 1.9095
Epoch [3/5], Batch [255/428], Loss: 1.8449
Epoch [3/5], Batch [256/428], Loss: 1.6206
Epoch [3/5], Batch [257/428], Loss: 1.6207
Epoch [3/5], Batch [258/428], Loss: 2.2481
Epoch [3/5], Batch [259/428], Loss: 1.6147
Epoch [3/5], Batch [260/428], Loss: 1.5988
Epoch [3/5], Batch [261/428], Loss: 1.6092
Epoch [3/5], Batch [262/428], Loss: 2.3639
Epoch [3/5], Batch [263/428], Loss: 3.5642
Epoch [3/5], Batch [264/428], Loss: 2.3623
Epoch [3/5], Batch [265/428], Loss: 1.4046
Epoch [3/5], Batch [266/428], Loss: 1.3449
Epoch [3/5], Batch [267/428], Loss: 1.2590
Epoch [3/5], Batch [268/428], Loss: 2.8714
Epoch [3/5], Batch [269/428], Loss: 1.0646
Epoch [3/5], Batch [270/428], Loss: 1.5449
Epoch [3/5], Batch [271/428], Loss: 1.5822
Epoch [3/5], Batch [272/428], Loss: 0.8494
Epoch [3/5], Batch [273/428], Loss: 2.3910
Epoch [3/5], Batch [274/428], Loss: 2.4082
Epoch [3/5], Batch [275/428], Loss: 1.7111
Epoch [3/5], Batch [276/428], Loss: 2.6686
Epoch [3/5], Batch [277/428], Loss: 2.7074
Epoch [3/5], Batch [278/428], Loss: 3.6817
Epoch [3/5], Batch [279/428], Loss: 3.5823
Epoch [3/5], Batch [280/428], Loss: 2.1224
Epoch [3/5], Batch [281/428], Loss: 3.1434
Epoch [3/5], Batch [282/428], Loss: 0.8652
Epoch [3/5], Batch [283/428], Loss: 3.0353
Epoch [3/5], Batch [284/428], Loss: 2.9495
Epoch [3/5], Batch [285/428], Loss: 2.5086
Epoch [3/5], Batch [286/428], Loss: 2.7032
Epoch [3/5], Batch [287/428], Loss: 2.4851
Epoch [3/5], Batch [288/428], Loss: 1.7471
Epoch [3/5], Batch [289/428], Loss: 1.1781
Epoch [3/5], Batch [290/428], Loss: 2.7525
Epoch [3/5], Batch [291/428], Loss: 1.2693
Epoch [3/5], Batch [292/428], Loss: 2.7112
Epoch [3/5], Batch [293/428], Loss: 2.7019
Epoch [3/5], Batch [294/428], Loss: 1.6310
Epoch [3/5], Batch [295/428], Loss: 1.8867
Epoch [3/5], Batch [296/428], Loss: 2.2061
Epoch [3/5], Batch [297/428], Loss: 1.8877
Epoch [3/5], Batch [298/428], Loss: 1.5040
Epoch [3/5], Batch [299/428], Loss: 1.8486
Epoch [3/5], Batch [300/428], Loss: 1.4085
Epoch [3/5], Batch [301/428], Loss: 1.3077
Epoch [3/5], Batch [302/428], Loss: 2.5896
Epoch [3/5], Batch [303/428], Loss: 1.7075
Epoch [3/5], Batch [304/428], Loss: 1.7050
Epoch [3/5], Batch [305/428], Loss: 1.6853
Epoch [3/5], Batch [306/428], Loss: 1.1038
Epoch [3/5], Batch [307/428], Loss: 2.5878
Epoch [3/5], Batch [308/428], Loss: 1.7889
Epoch [3/5], Batch [309/428], Loss: 1.5522
Epoch [3/5], Batch [310/428], Loss: 2.6836
Epoch [3/5], Batch [311/428], Loss: 2.9011
Epoch [3/5], Batch [312/428], Loss: 1.7759
Epoch [3/5], Batch [313/428], Loss: 2.5262
Epoch [3/5], Batch [314/428], Loss: 1.3438
Epoch [3/5], Batch [315/428], Loss: 1.3029
Epoch [3/5], Batch [316/428], Loss: 2.5023
Epoch [3/5], Batch [317/428], Loss: 2.9315
Epoch [3/5], Batch [318/428], Loss: 1.1235
Epoch [3/5], Batch [319/428], Loss: 2.3372
Epoch [3/5], Batch [320/428], Loss: 1.7740
Epoch [3/5], Batch [321/428], Loss: 0.9750
Epoch [3/5], Batch [322/428], Loss: 2.9373
Epoch [3/5], Batch [323/428], Loss: 2.2009
Epoch [3/5], Batch [324/428], Loss: 2.1637
Epoch [3/5], Batch [325/428], Loss: 0.8564
Epoch [3/5], Batch [326/428], Loss: 2.4672
Epoch [3/5], Batch [327/428], Loss: 0.8333
Epoch [3/5], Batch [328/428], Loss: 2.0133
Epoch [3/5], Batch [329/428], Loss: 1.8441
Epoch [3/5], Batch [330/428], Loss: 3.0118
Epoch [3/5], Batch [331/428], Loss: 2.4476
Epoch [3/5], Batch [332/428], Loss: 1.6821
Epoch [3/5], Batch [333/428], Loss: 1.5694
Epoch [3/5], Batch [334/428], Loss: 0.9268
Epoch [3/5], Batch [335/428], Loss: 0.9597
Epoch [3/5], Batch [336/428], Loss: 2.9847
Epoch [3/5], Batch [337/428], Loss: 0.9542
Epoch [3/5], Batch [338/428], Loss: 2.9491
Epoch [3/5], Batch [339/428], Loss: 2.4148
Epoch [3/5], Batch [340/428], Loss: 3.5468
Epoch [3/5], Batch [341/428], Loss: 3.5002
Epoch [3/5], Batch [342/428], Loss: 2.4444
Epoch [3/5], Batch [343/428], Loss: 1.3324
Epoch [3/5], Batch [344/428], Loss: 2.8480
Epoch [3/5], Batch [345/428], Loss: 2.2506
Epoch [3/5], Batch [346/428], Loss: 2.6669
Epoch [3/5], Batch [347/428], Loss: 2.5715
Epoch [3/5], Batch [348/428], Loss: 1.3222
Epoch [3/5], Batch [349/428], Loss: 2.3237
Epoch [3/5], Batch [350/428], Loss: 1.3451
Epoch [3/5], Batch [351/428], Loss: 2.4302
Epoch [3/5], Batch [352/428], Loss: 3.0299
Epoch [3/5], Batch [353/428], Loss: 1.3852
Epoch [3/5], Batch [354/428], Loss: 2.5277
Epoch [3/5], Batch [355/428], Loss: 1.3674
Epoch [3/5], Batch [356/428], Loss: 1.3282
Epoch [3/5], Batch [357/428], Loss: 2.8363
Epoch [3/5], Batch [358/428], Loss: 1.8218
Epoch [3/5], Batch [359/428], Loss: 2.4941
Epoch [3/5], Batch [360/428], Loss: 1.9138
Epoch [3/5], Batch [361/428], Loss: 2.2692
Epoch [3/5], Batch [362/428], Loss: 2.3934
Epoch [3/5], Batch [363/428], Loss: 2.5476
Epoch [3/5], Batch [364/428], Loss: 1.8695
Epoch [3/5], Batch [365/428], Loss: 2.3429
Epoch [3/5], Batch [366/428], Loss: 1.7675
Epoch [3/5], Batch [367/428], Loss: 1.7155
Epoch [3/5], Batch [368/428], Loss: 1.6097
Epoch [3/5], Batch [369/428], Loss: 2.0376
Epoch [3/5], Batch [370/428], Loss: 1.4049
Epoch [3/5], Batch [371/428], Loss: 1.2819
Epoch [3/5], Batch [372/428], Loss: 1.9192
Epoch [3/5], Batch [373/428], Loss: 2.0239
Epoch [3/5], Batch [374/428], Loss: 2.4180
Epoch [3/5], Batch [375/428], Loss: 2.8585
Epoch [3/5], Batch [376/428], Loss: 1.9872
Epoch [3/5], Batch [377/428], Loss: 2.0164
Epoch [3/5], Batch [378/428], Loss: 2.4797
Epoch [3/5], Batch [379/428], Loss: 1.8513
Epoch [3/5], Batch [380/428], Loss: 0.9365
Epoch [3/5], Batch [381/428], Loss: 3.3078
Epoch [3/5], Batch [382/428], Loss: 1.7584
Epoch [3/5], Batch [383/428], Loss: 1.6830
Epoch [3/5], Batch [384/428], Loss: 1.5571
Epoch [3/5], Batch [385/428], Loss: 2.3645
Epoch [3/5], Batch [386/428], Loss: 1.1059
Epoch [3/5], Batch [387/428], Loss: 1.2924
Epoch [3/5], Batch [388/428], Loss: 3.1343
Epoch [3/5], Batch [389/428], Loss: 1.1007
Epoch [3/5], Batch [390/428], Loss: 2.0251
Epoch [3/5], Batch [391/428], Loss: 1.4147
Epoch [3/5], Batch [392/428], Loss: 2.3833
Epoch [3/5], Batch [393/428], Loss: 1.4601
Epoch [3/5], Batch [394/428], Loss: 0.8337
Epoch [3/5], Batch [395/428], Loss: 3.5778
Epoch [3/5], Batch [396/428], Loss: 3.3326
Epoch [3/5], Batch [397/428], Loss: 3.4539
Epoch [3/5], Batch [398/428], Loss: 1.5166
Epoch [3/5], Batch [399/428], Loss: 2.2585
Epoch [3/5], Batch [400/428], Loss: 3.0039
Epoch [3/5], Batch [401/428], Loss: 3.0128
Epoch [3/5], Batch [402/428], Loss: 2.0909
Epoch [3/5], Batch [403/428], Loss: 2.7373
Epoch [3/5], Batch [404/428], Loss: 3.0960
Epoch [3/5], Batch [405/428], Loss: 2.4227
Epoch [3/5], Batch [406/428], Loss: 1.3785
Epoch [3/5], Batch [407/428], Loss: 1.4395
Epoch [3/5], Batch [408/428], Loss: 2.8835
Epoch [3/5], Batch [409/428], Loss: 1.7512
Epoch [3/5], Batch [410/428], Loss: 1.4488
Epoch [3/5], Batch [411/428], Loss: 1.7095
Epoch [3/5], Batch [412/428], Loss: 1.4276
Epoch [3/5], Batch [413/428], Loss: 1.8950
Epoch [3/5], Batch [414/428], Loss: 1.6696
Epoch [3/5], Batch [415/428], Loss: 1.6571
Epoch [3/5], Batch [416/428], Loss: 2.8359
Epoch [3/5], Batch [417/428], Loss: 2.0718
Epoch [3/5], Batch [418/428], Loss: 1.3811
Epoch [3/5], Batch [419/428], Loss: 2.8232
Epoch [3/5], Batch [420/428], Loss: 1.2409
Epoch [3/5], Batch [421/428], Loss: 1.7471
Epoch [3/5], Batch [422/428], Loss: 2.7935
Epoch [3/5], Batch [423/428], Loss: 1.0274
Epoch [3/5], Batch [424/428], Loss: 0.9392
Epoch [3/5], Batch [425/428], Loss: 2.3910
Epoch [3/5], Batch [426/428], Loss: 2.9080
Epoch [3/5], Batch [427/428], Loss: 2.0034
Epoch [3/5], Batch [428/428], Loss: 2.8888
Epoch [3] Training Time: 268.29 seconds
Epoch [3/5], Average Loss: 2.0472, Training Accuracy: 0.2103
Epoch [3], Validation Loss: 2.3881, Validation Accuracy: 0.1429
Epoch [3] Validation Time: 10.71 seconds
--------------------------------------------------
Epoch [4/5], Batch [1/428], Loss: 2.0366
Epoch [4/5], Batch [2/428], Loss: 2.2290
Epoch [4/5], Batch [3/428], Loss: 2.6219
Epoch [4/5], Batch [4/428], Loss: 2.5726
Epoch [4/5], Batch [5/428], Loss: 2.6793
Epoch [4/5], Batch [6/428], Loss: 0.8035
Epoch [4/5], Batch [7/428], Loss: 0.8155
Epoch [4/5], Batch [8/428], Loss: 2.2035
Epoch [4/5], Batch [9/428], Loss: 1.8473
Epoch [4/5], Batch [10/428], Loss: 2.3516
Epoch [4/5], Batch [11/428], Loss: 2.3065
Epoch [4/5], Batch [12/428], Loss: 2.1917
Epoch [4/5], Batch [13/428], Loss: 3.4368
Epoch [4/5], Batch [14/428], Loss: 2.4257
Epoch [4/5], Batch [15/428], Loss: 3.3634
Epoch [4/5], Batch [16/428], Loss: 2.3597
Epoch [4/5], Batch [17/428], Loss: 1.9332
Epoch [4/5], Batch [18/428], Loss: 2.3533
Epoch [4/5], Batch [19/428], Loss: 2.0518
Epoch [4/5], Batch [20/428], Loss: 1.2763
Epoch [4/5], Batch [21/428], Loss: 1.9838
Epoch [4/5], Batch [22/428], Loss: 2.2208
Epoch [4/5], Batch [23/428], Loss: 1.8785
Epoch [4/5], Batch [24/428], Loss: 1.8909
Epoch [4/5], Batch [25/428], Loss: 1.8585
Epoch [4/5], Batch [26/428], Loss: 1.7176
Epoch [4/5], Batch [27/428], Loss: 1.8186
Epoch [4/5], Batch [28/428], Loss: 1.6645
Epoch [4/5], Batch [29/428], Loss: 1.7296
Epoch [4/5], Batch [30/428], Loss: 1.6945
Epoch [4/5], Batch [31/428], Loss: 2.9460
Epoch [4/5], Batch [32/428], Loss: 2.1489
Epoch [4/5], Batch [33/428], Loss: 1.5346
Epoch [4/5], Batch [34/428], Loss: 1.4776
Epoch [4/5], Batch [35/428], Loss: 2.1364
Epoch [4/5], Batch [36/428], Loss: 1.9152
Epoch [4/5], Batch [37/428], Loss: 1.3351
Epoch [4/5], Batch [38/428], Loss: 2.3835
Epoch [4/5], Batch [39/428], Loss: 2.9043
Epoch [4/5], Batch [40/428], Loss: 2.0747
Epoch [4/5], Batch [41/428], Loss: 2.4113
Epoch [4/5], Batch [42/428], Loss: 1.1524
Epoch [4/5], Batch [43/428], Loss: 1.9512
Epoch [4/5], Batch [44/428], Loss: 2.7542
Epoch [4/5], Batch [45/428], Loss: 2.7362
Epoch [4/5], Batch [46/428], Loss: 1.0806
Epoch [4/5], Batch [47/428], Loss: 2.0910
Epoch [4/5], Batch [48/428], Loss: 2.3784
Epoch [4/5], Batch [49/428], Loss: 2.4397
Epoch [4/5], Batch [50/428], Loss: 2.2628
Epoch [4/5], Batch [51/428], Loss: 2.4230
Epoch [4/5], Batch [52/428], Loss: 1.8469
Epoch [4/5], Batch [53/428], Loss: 1.0724
Epoch [4/5], Batch [54/428], Loss: 1.0810
Epoch [4/5], Batch [55/428], Loss: 2.4089
Epoch [4/5], Batch [56/428], Loss: 2.3594
Epoch [4/5], Batch [57/428], Loss: 2.3063
Epoch [4/5], Batch [58/428], Loss: 1.0734
Epoch [4/5], Batch [59/428], Loss: 2.4116
Epoch [4/5], Batch [60/428], Loss: 1.9046
Epoch [4/5], Batch [61/428], Loss: 2.3948
Epoch [4/5], Batch [62/428], Loss: 2.3198
Epoch [4/5], Batch [63/428], Loss: 2.3297
Epoch [4/5], Batch [64/428], Loss: 2.4722
Epoch [4/5], Batch [65/428], Loss: 1.8636
Epoch [4/5], Batch [66/428], Loss: 1.8434
Epoch [4/5], Batch [67/428], Loss: 2.3188
Epoch [4/5], Batch [68/428], Loss: 2.2121
Epoch [4/5], Batch [69/428], Loss: 2.5193
Epoch [4/5], Batch [70/428], Loss: 2.5498
Epoch [4/5], Batch [71/428], Loss: 2.3838
Epoch [4/5], Batch [72/428], Loss: 2.1707
Epoch [4/5], Batch [73/428], Loss: 2.1307
Epoch [4/5], Batch [74/428], Loss: 2.1011
Epoch [4/5], Batch [75/428], Loss: 1.4666
Epoch [4/5], Batch [76/428], Loss: 1.9004
Epoch [4/5], Batch [77/428], Loss: 1.5100
Epoch [4/5], Batch [78/428], Loss: 2.3122
Epoch [4/5], Batch [79/428], Loss: 2.1081
Epoch [4/5], Batch [80/428], Loss: 1.6705
Epoch [4/5], Batch [81/428], Loss: 2.1385
Epoch [4/5], Batch [82/428], Loss: 2.3491
Epoch [4/5], Batch [83/428], Loss: 2.3322
Epoch [4/5], Batch [84/428], Loss: 1.6296
Epoch [4/5], Batch [85/428], Loss: 1.6473
Epoch [4/5], Batch [86/428], Loss: 2.1255
Epoch [4/5], Batch [87/428], Loss: 1.6099
Epoch [4/5], Batch [88/428], Loss: 1.5540
Epoch [4/5], Batch [89/428], Loss: 2.1013
Epoch [4/5], Batch [90/428], Loss: 2.2871
Epoch [4/5], Batch [91/428], Loss: 1.4826
Epoch [4/5], Batch [92/428], Loss: 1.4233
Epoch [4/5], Batch [93/428], Loss: 2.0058
Epoch [4/5], Batch [94/428], Loss: 2.3198
Epoch [4/5], Batch [95/428], Loss: 2.3982
Epoch [4/5], Batch [96/428], Loss: 1.6978
Epoch [4/5], Batch [97/428], Loss: 1.2418
Epoch [4/5], Batch [98/428], Loss: 2.2682
Epoch [4/5], Batch [99/428], Loss: 1.1926
Epoch [4/5], Batch [100/428], Loss: 2.4635
Epoch [4/5], Batch [101/428], Loss: 1.1194
Epoch [4/5], Batch [102/428], Loss: 1.0972
Epoch [4/5], Batch [103/428], Loss: 1.9817
Epoch [4/5], Batch [104/428], Loss: 1.9551
Epoch [4/5], Batch [105/428], Loss: 1.9405
Epoch [4/5], Batch [106/428], Loss: 0.9474
Epoch [4/5], Batch [107/428], Loss: 0.9311
Epoch [4/5], Batch [108/428], Loss: 2.6863
Epoch [4/5], Batch [109/428], Loss: 2.7184
Epoch [4/5], Batch [110/428], Loss: 2.7485
Epoch [4/5], Batch [111/428], Loss: 2.1246
Epoch [4/5], Batch [112/428], Loss: 0.8064
Epoch [4/5], Batch [113/428], Loss: 2.6070
Epoch [4/5], Batch [114/428], Loss: 2.6898
Epoch [4/5], Batch [115/428], Loss: 2.5838
Epoch [4/5], Batch [116/428], Loss: 2.1425
Epoch [4/5], Batch [117/428], Loss: 2.7527
Epoch [4/5], Batch [118/428], Loss: 2.1203
Epoch [4/5], Batch [119/428], Loss: 0.8395
Epoch [4/5], Batch [120/428], Loss: 2.4928
Epoch [4/5], Batch [121/428], Loss: 2.5615
Epoch [4/5], Batch [122/428], Loss: 2.1161
Epoch [4/5], Batch [123/428], Loss: 1.9369
Epoch [4/5], Batch [124/428], Loss: 2.1002
Epoch [4/5], Batch [125/428], Loss: 0.9300
Epoch [4/5], Batch [126/428], Loss: 2.0738
Epoch [4/5], Batch [127/428], Loss: 2.3178
Epoch [4/5], Batch [128/428], Loss: 2.2822
Epoch [4/5], Batch [129/428], Loss: 2.6008
Epoch [4/5], Batch [130/428], Loss: 1.9765
Epoch [4/5], Batch [131/428], Loss: 1.1056
Epoch [4/5], Batch [132/428], Loss: 2.5640
Epoch [4/5], Batch [133/428], Loss: 2.4814
Epoch [4/5], Batch [134/428], Loss: 1.8922
Epoch [4/5], Batch [135/428], Loss: 1.8517
Epoch [4/5], Batch [136/428], Loss: 1.1917
Epoch [4/5], Batch [137/428], Loss: 2.4696
Epoch [4/5], Batch [138/428], Loss: 2.7269
Epoch [4/5], Batch [139/428], Loss: 1.2343
Epoch [4/5], Batch [140/428], Loss: 2.4361
Epoch [4/5], Batch [141/428], Loss: 1.7193
Epoch [4/5], Batch [142/428], Loss: 1.9270
Epoch [4/5], Batch [143/428], Loss: 1.2693
Epoch [4/5], Batch [144/428], Loss: 2.3349
Epoch [4/5], Batch [145/428], Loss: 1.2560
Epoch [4/5], Batch [146/428], Loss: 1.9031
Epoch [4/5], Batch [147/428], Loss: 1.6844
Epoch [4/5], Batch [148/428], Loss: 1.2401
Epoch [4/5], Batch [149/428], Loss: 1.6716
Epoch [4/5], Batch [150/428], Loss: 2.2410
Epoch [4/5], Batch [151/428], Loss: 2.2782
Epoch [4/5], Batch [152/428], Loss: 2.1518
Epoch [4/5], Batch [153/428], Loss: 2.1474
Epoch [4/5], Batch [154/428], Loss: 1.9808
Epoch [4/5], Batch [155/428], Loss: 1.9953
Epoch [4/5], Batch [156/428], Loss: 1.9052
Epoch [4/5], Batch [157/428], Loss: 1.6485
Epoch [4/5], Batch [158/428], Loss: 1.5912
Epoch [4/5], Batch [159/428], Loss: 1.6033
Epoch [4/5], Batch [160/428], Loss: 1.3964
Epoch [4/5], Batch [161/428], Loss: 1.5729
Epoch [4/5], Batch [162/428], Loss: 1.4804
Epoch [4/5], Batch [163/428], Loss: 1.4725
Epoch [4/5], Batch [164/428], Loss: 2.1158
Epoch [4/5], Batch [165/428], Loss: 2.1589
Epoch [4/5], Batch [166/428], Loss: 1.6063
Epoch [4/5], Batch [167/428], Loss: 1.4007
Epoch [4/5], Batch [168/428], Loss: 3.2193
Epoch [4/5], Batch [169/428], Loss: 2.9007
Epoch [4/5], Batch [170/428], Loss: 2.7229
Epoch [4/5], Batch [171/428], Loss: 1.2967
Epoch [4/5], Batch [172/428], Loss: 1.7265
Epoch [4/5], Batch [173/428], Loss: 2.6994
Epoch [4/5], Batch [174/428], Loss: 1.7157
Epoch [4/5], Batch [175/428], Loss: 2.0955
Epoch [4/5], Batch [176/428], Loss: 2.5922
Epoch [4/5], Batch [177/428], Loss: 1.2624
Epoch [4/5], Batch [178/428], Loss: 1.4640
Epoch [4/5], Batch [179/428], Loss: 2.0815
Epoch [4/5], Batch [180/428], Loss: 1.6752
Epoch [4/5], Batch [181/428], Loss: 2.4393
Epoch [4/5], Batch [182/428], Loss: 1.6794
Epoch [4/5], Batch [183/428], Loss: 2.8940
Epoch [4/5], Batch [184/428], Loss: 1.5478
Epoch [4/5], Batch [185/428], Loss: 2.3082
Epoch [4/5], Batch [186/428], Loss: 1.5862
Epoch [4/5], Batch [187/428], Loss: 3.1505
Epoch [4/5], Batch [188/428], Loss: 1.5302
Epoch [4/5], Batch [189/428], Loss: 2.7644
Epoch [4/5], Batch [190/428], Loss: 1.6171
Epoch [4/5], Batch [191/428], Loss: 2.1001
Epoch [4/5], Batch [192/428], Loss: 1.6649
Epoch [4/5], Batch [193/428], Loss: 1.4276
Epoch [4/5], Batch [194/428], Loss: 1.4132
Epoch [4/5], Batch [195/428], Loss: 2.6780
Epoch [4/5], Batch [196/428], Loss: 1.7316
Epoch [4/5], Batch [197/428], Loss: 2.0919
Epoch [4/5], Batch [198/428], Loss: 2.6246
Epoch [4/5], Batch [199/428], Loss: 1.6542
Epoch [4/5], Batch [200/428], Loss: 1.6580
Epoch [4/5], Batch [201/428], Loss: 2.4568
Epoch [4/5], Batch [202/428], Loss: 1.5741
Epoch [4/5], Batch [203/428], Loss: 2.0329
Epoch [4/5], Batch [204/428], Loss: 2.1721
Epoch [4/5], Batch [205/428], Loss: 2.0207
Epoch [4/5], Batch [206/428], Loss: 1.4131
Epoch [4/5], Batch [207/428], Loss: 1.9786
Epoch [4/5], Batch [208/428], Loss: 1.9198
Epoch [4/5], Batch [209/428], Loss: 2.2233
Epoch [4/5], Batch [210/428], Loss: 3.2273
Epoch [4/5], Batch [211/428], Loss: 1.5878
Epoch [4/5], Batch [212/428], Loss: 2.2027
Epoch [4/5], Batch [213/428], Loss: 1.6609
Epoch [4/5], Batch [214/428], Loss: 1.6402
Epoch [4/5], Batch [215/428], Loss: 1.6450
Epoch [4/5], Batch [216/428], Loss: 2.1768
Epoch [4/5], Batch [217/428], Loss: 2.0818
Epoch [4/5], Batch [218/428], Loss: 1.4833
Epoch [4/5], Batch [219/428], Loss: 1.4404
Epoch [4/5], Batch [220/428], Loss: 2.7371
Epoch [4/5], Batch [221/428], Loss: 2.0423
Epoch [4/5], Batch [222/428], Loss: 2.7458
Epoch [4/5], Batch [223/428], Loss: 3.1568
Epoch [4/5], Batch [224/428], Loss: 1.6204
Epoch [4/5], Batch [225/428], Loss: 2.6411
Epoch [4/5], Batch [226/428], Loss: 1.9040
Epoch [4/5], Batch [227/428], Loss: 2.0684
Epoch [4/5], Batch [228/428], Loss: 1.5783
Epoch [4/5], Batch [229/428], Loss: 1.5460
Epoch [4/5], Batch [230/428], Loss: 1.8242
Epoch [4/5], Batch [231/428], Loss: 1.5577
Epoch [4/5], Batch [232/428], Loss: 1.8528
Epoch [4/5], Batch [233/428], Loss: 1.8503
Epoch [4/5], Batch [234/428], Loss: 2.1134
Epoch [4/5], Batch [235/428], Loss: 1.7330
Epoch [4/5], Batch [236/428], Loss: 2.4934
Epoch [4/5], Batch [237/428], Loss: 1.6419
Epoch [4/5], Batch [238/428], Loss: 1.8374
Epoch [4/5], Batch [239/428], Loss: 1.8014
Epoch [4/5], Batch [240/428], Loss: 2.4309
Epoch [4/5], Batch [241/428], Loss: 1.6912
Epoch [4/5], Batch [242/428], Loss: 3.1030
Epoch [4/5], Batch [243/428], Loss: 1.7114
Epoch [4/5], Batch [244/428], Loss: 2.1161
Epoch [4/5], Batch [245/428], Loss: 1.7014
Epoch [4/5], Batch [246/428], Loss: 1.5944
Epoch [4/5], Batch [247/428], Loss: 1.6654
Epoch [4/5], Batch [248/428], Loss: 3.0225
Epoch [4/5], Batch [249/428], Loss: 1.6183
Epoch [4/5], Batch [250/428], Loss: 1.5856
Epoch [4/5], Batch [251/428], Loss: 2.8951
Epoch [4/5], Batch [252/428], Loss: 2.2859
Epoch [4/5], Batch [253/428], Loss: 2.1514
Epoch [4/5], Batch [254/428], Loss: 2.2895
Epoch [4/5], Batch [255/428], Loss: 1.4602
Epoch [4/5], Batch [256/428], Loss: 2.1371
Epoch [4/5], Batch [257/428], Loss: 2.1173
Epoch [4/5], Batch [258/428], Loss: 1.4004
Epoch [4/5], Batch [259/428], Loss: 1.7234
Epoch [4/5], Batch [260/428], Loss: 1.7285
Epoch [4/5], Batch [261/428], Loss: 1.3374
Epoch [4/5], Batch [262/428], Loss: 2.4530
Epoch [4/5], Batch [263/428], Loss: 1.2829
Epoch [4/5], Batch [264/428], Loss: 1.2637
Epoch [4/5], Batch [265/428], Loss: 2.1063
Epoch [4/5], Batch [266/428], Loss: 2.0838
Epoch [4/5], Batch [267/428], Loss: 1.1413
Epoch [4/5], Batch [268/428], Loss: 2.4459
Epoch [4/5], Batch [269/428], Loss: 2.4594
Epoch [4/5], Batch [270/428], Loss: 1.8240
Epoch [4/5], Batch [271/428], Loss: 2.4746
Epoch [4/5], Batch [272/428], Loss: 1.0316
Epoch [4/5], Batch [273/428], Loss: 1.0372
Epoch [4/5], Batch [274/428], Loss: 2.3771
Epoch [4/5], Batch [275/428], Loss: 1.8480
Epoch [4/5], Batch [276/428], Loss: 2.1840
Epoch [4/5], Batch [277/428], Loss: 0.9323
Epoch [4/5], Batch [278/428], Loss: 1.8823
Epoch [4/5], Batch [279/428], Loss: 1.8501
Epoch [4/5], Batch [280/428], Loss: 0.8989
Epoch [4/5], Batch [281/428], Loss: 2.5881
Epoch [4/5], Batch [282/428], Loss: 2.3982
Epoch [4/5], Batch [283/428], Loss: 0.8790
Epoch [4/5], Batch [284/428], Loss: 2.4133
Epoch [4/5], Batch [285/428], Loss: 2.4129
Epoch [4/5], Batch [286/428], Loss: 0.8671
Epoch [4/5], Batch [287/428], Loss: 2.3547
Epoch [4/5], Batch [288/428], Loss: 3.2116
Epoch [4/5], Batch [289/428], Loss: 2.2984
Epoch [4/5], Batch [290/428], Loss: 0.8345
Epoch [4/5], Batch [291/428], Loss: 0.8440
Epoch [4/5], Batch [292/428], Loss: 2.6587
Epoch [4/5], Batch [293/428], Loss: 1.9263
Epoch [4/5], Batch [294/428], Loss: 2.3515
Epoch [4/5], Batch [295/428], Loss: 2.1191
Epoch [4/5], Batch [296/428], Loss: 0.8061
Epoch [4/5], Batch [297/428], Loss: 2.6013
Epoch [4/5], Batch [298/428], Loss: 2.0217
Epoch [4/5], Batch [299/428], Loss: 2.3165
Epoch [4/5], Batch [300/428], Loss: 1.9793
Epoch [4/5], Batch [301/428], Loss: 2.7267
Epoch [4/5], Batch [302/428], Loss: 1.9066
Epoch [4/5], Batch [303/428], Loss: 0.9011
Epoch [4/5], Batch [304/428], Loss: 0.9242
Epoch [4/5], Batch [305/428], Loss: 2.7464
Epoch [4/5], Batch [306/428], Loss: 1.8030
Epoch [4/5], Batch [307/428], Loss: 2.6525
Epoch [4/5], Batch [308/428], Loss: 3.2453
Epoch [4/5], Batch [309/428], Loss: 2.5830
Epoch [4/5], Batch [310/428], Loss: 3.2313
Epoch [4/5], Batch [311/428], Loss: 1.0197
Epoch [4/5], Batch [312/428], Loss: 2.4932
Epoch [4/5], Batch [313/428], Loss: 1.0306
Epoch [4/5], Batch [314/428], Loss: 1.6510
Epoch [4/5], Batch [315/428], Loss: 2.4650
Epoch [4/5], Batch [316/428], Loss: 1.0382
Epoch [4/5], Batch [317/428], Loss: 2.9534
Epoch [4/5], Batch [318/428], Loss: 1.0140
Epoch [4/5], Batch [319/428], Loss: 2.8409
Epoch [4/5], Batch [320/428], Loss: 2.4544
Epoch [4/5], Batch [321/428], Loss: 2.7512
Epoch [4/5], Batch [322/428], Loss: 2.4346
Epoch [4/5], Batch [323/428], Loss: 2.3430
Epoch [4/5], Batch [324/428], Loss: 2.3039
Epoch [4/5], Batch [325/428], Loss: 1.0222
Epoch [4/5], Batch [326/428], Loss: 2.3097
Epoch [4/5], Batch [327/428], Loss: 2.5010
Epoch [4/5], Batch [328/428], Loss: 1.0501
Epoch [4/5], Batch [329/428], Loss: 1.9438
Epoch [4/5], Batch [330/428], Loss: 2.2639
Epoch [4/5], Batch [331/428], Loss: 1.0607
Epoch [4/5], Batch [332/428], Loss: 1.0649
Epoch [4/5], Batch [333/428], Loss: 2.0096
Epoch [4/5], Batch [334/428], Loss: 2.0037
Epoch [4/5], Batch [335/428], Loss: 2.1774
Epoch [4/5], Batch [336/428], Loss: 1.0285
Epoch [4/5], Batch [337/428], Loss: 1.9652
Epoch [4/5], Batch [338/428], Loss: 2.1507
Epoch [4/5], Batch [339/428], Loss: 2.6351
Epoch [4/5], Batch [340/428], Loss: 1.0122
Epoch [4/5], Batch [341/428], Loss: 1.8479
Epoch [4/5], Batch [342/428], Loss: 2.4565
Epoch [4/5], Batch [343/428], Loss: 2.2997
Epoch [4/5], Batch [344/428], Loss: 2.5096
Epoch [4/5], Batch [345/428], Loss: 2.0363
Epoch [4/5], Batch [346/428], Loss: 2.0495
Epoch [4/5], Batch [347/428], Loss: 1.0917
Epoch [4/5], Batch [348/428], Loss: 2.5581
Epoch [4/5], Batch [349/428], Loss: 2.5125
Epoch [4/5], Batch [350/428], Loss: 2.2917
Epoch [4/5], Batch [351/428], Loss: 2.3136
Epoch [4/5], Batch [352/428], Loss: 1.1446
Epoch [4/5], Batch [353/428], Loss: 2.4868
Epoch [4/5], Batch [354/428], Loss: 2.4323
Epoch [4/5], Batch [355/428], Loss: 2.1446
Epoch [4/5], Batch [356/428], Loss: 1.2014
Epoch [4/5], Batch [357/428], Loss: 1.2012
Epoch [4/5], Batch [358/428], Loss: 1.1836
Epoch [4/5], Batch [359/428], Loss: 1.9975
Epoch [4/5], Batch [360/428], Loss: 2.2850
Epoch [4/5], Batch [361/428], Loss: 2.1014
Epoch [4/5], Batch [362/428], Loss: 2.3076
Epoch [4/5], Batch [363/428], Loss: 2.0235
Epoch [4/5], Batch [364/428], Loss: 1.1339
Epoch [4/5], Batch [365/428], Loss: 1.1063
Epoch [4/5], Batch [366/428], Loss: 2.3350
Epoch [4/5], Batch [367/428], Loss: 2.2859
Epoch [4/5], Batch [368/428], Loss: 2.2203
Epoch [4/5], Batch [369/428], Loss: 2.1722
Epoch [4/5], Batch [370/428], Loss: 2.2222
Epoch [4/5], Batch [371/428], Loss: 2.1353
Epoch [4/5], Batch [372/428], Loss: 1.0951
Epoch [4/5], Batch [373/428], Loss: 1.9755
Epoch [4/5], Batch [374/428], Loss: 2.0780
Epoch [4/5], Batch [375/428], Loss: 1.1078
Epoch [4/5], Batch [376/428], Loss: 1.9763
Epoch [4/5], Batch [377/428], Loss: 2.3745
Epoch [4/5], Batch [378/428], Loss: 1.1161
Epoch [4/5], Batch [379/428], Loss: 3.1319
Epoch [4/5], Batch [380/428], Loss: 2.1704
Epoch [4/5], Batch [381/428], Loss: 1.1001
Epoch [4/5], Batch [382/428], Loss: 1.8663
Epoch [4/5], Batch [383/428], Loss: 1.8290
Epoch [4/5], Batch [384/428], Loss: 2.1403
Epoch [4/5], Batch [385/428], Loss: 2.4295
Epoch [4/5], Batch [386/428], Loss: 3.1565
Epoch [4/5], Batch [387/428], Loss: 1.1115
Epoch [4/5], Batch [388/428], Loss: 1.1108
Epoch [4/5], Batch [389/428], Loss: 1.6475
Epoch [4/5], Batch [390/428], Loss: 2.2113
Epoch [4/5], Batch [391/428], Loss: 1.0695
Epoch [4/5], Batch [392/428], Loss: 2.2559
Epoch [4/5], Batch [393/428], Loss: 1.6024
Epoch [4/5], Batch [394/428], Loss: 2.2238
Epoch [4/5], Batch [395/428], Loss: 3.0385
Epoch [4/5], Batch [396/428], Loss: 2.5012
Epoch [4/5], Batch [397/428], Loss: 1.4947
Epoch [4/5], Batch [398/428], Loss: 1.1098
Epoch [4/5], Batch [399/428], Loss: 2.5864
Epoch [4/5], Batch [400/428], Loss: 1.4499
Epoch [4/5], Batch [401/428], Loss: 1.1330
Epoch [4/5], Batch [402/428], Loss: 2.4484
Epoch [4/5], Batch [403/428], Loss: 1.1282
Epoch [4/5], Batch [404/428], Loss: 1.1104
Epoch [4/5], Batch [405/428], Loss: 1.4503
Epoch [4/5], Batch [406/428], Loss: 2.9089
Epoch [4/5], Batch [407/428], Loss: 1.0559
Epoch [4/5], Batch [408/428], Loss: 2.4543
Epoch [4/5], Batch [409/428], Loss: 2.4881
Epoch [4/5], Batch [410/428], Loss: 2.4895
Epoch [4/5], Batch [411/428], Loss: 2.4587[INFO 06-13 22:24:13] ax.service.ax_client: Completed trial 15 with data: {'objective': (np.float64(-0.142857), None)}.
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3
  best_X, best_acq_val = generate_starting_points(
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
/users/ach21ag/.conda/envs/myspark/lib/python3.12/dataclasses.py:1588: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.
  return obj.__class__(**changes)
[INFO 06-13 22:24:16] ax.service.ax_client: Generated new trial 16 with parameters {'lr': 0.000656, 'num_epochs': 5, 'unfreeze_epoch': 2, 'max_length': 112000} using model BoTorch.
INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
/users/ach21ag/.conda/envs/myspark/lib/python3.12/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.
INFO:speechbrain.utils.fetching:Fetch wav2vec2.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch model.ckpt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/emotion-recognition-wav2vec2-IEMOCAP' if not cached
INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: wav2vec2, model, label_encoder

Epoch [4/5], Batch [412/428], Loss: 0.9970
Epoch [4/5], Batch [413/428], Loss: 2.8333
Epoch [4/5], Batch [414/428], Loss: 2.8161
Epoch [4/5], Batch [415/428], Loss: 0.9630
Epoch [4/5], Batch [416/428], Loss: 2.8491
Epoch [4/5], Batch [417/428], Loss: 2.4888
Epoch [4/5], Batch [418/428], Loss: 1.7281
Epoch [4/5], Batch [419/428], Loss: 2.4710
Epoch [4/5], Batch [420/428], Loss: 2.4632
Epoch [4/5], Batch [421/428], Loss: 1.7046
Epoch [4/5], Batch [422/428], Loss: 1.7097
Epoch [4/5], Batch [423/428], Loss: 2.1705
Epoch [4/5], Batch [424/428], Loss: 2.4939
Epoch [4/5], Batch [425/428], Loss: 1.0825
Epoch [4/5], Batch [426/428], Loss: 2.3984
Epoch [4/5], Batch [427/428], Loss: 2.1257
Epoch [4/5], Batch [428/428], Loss: 2.4010
Epoch [4] Training Time: 269.17 seconds
Epoch [4/5], Average Loss: 1.9826, Training Accuracy: 0.2103
Epoch [4], Validation Loss: 2.0376, Validation Accuracy: 0.1429
Epoch [4] Validation Time: 10.85 seconds
--------------------------------------------------
Epoch [5/5], Batch [1/428], Loss: 1.5958
Epoch [5/5], Batch [2/428], Loss: 2.1731
Epoch [5/5], Batch [3/428], Loss: 2.1565
Epoch [5/5], Batch [4/428], Loss: 1.2117
Epoch [5/5], Batch [5/428], Loss: 2.8318
Epoch [5/5], Batch [6/428], Loss: 2.3303
Epoch [5/5], Batch [7/428], Loss: 2.8114
Epoch [5/5], Batch [8/428], Loss: 2.0254
Epoch [5/5], Batch [9/428], Loss: 1.6529
Epoch [5/5], Batch [10/428], Loss: 1.2339
Epoch [5/5], Batch [11/428], Loss: 1.6031
Epoch [5/5], Batch [12/428], Loss: 1.9974
Epoch [5/5], Batch [13/428], Loss: 2.4022
Epoch [5/5], Batch [14/428], Loss: 1.5564
Epoch [5/5], Batch [15/428], Loss: 1.2748
Epoch [5/5], Batch [16/428], Loss: 1.2782
Epoch [5/5], Batch [17/428], Loss: 2.2661
Epoch [5/5], Batch [18/428], Loss: 2.0047
Epoch [5/5], Batch [19/428], Loss: 2.1193
Epoch [5/5], Batch [20/428], Loss: 1.5987
Epoch [5/5], Batch [21/428], Loss: 2.1084
Epoch [5/5], Batch [22/428], Loss: 1.2776
Epoch [5/5], Batch [23/428], Loss: 1.5425
Epoch [5/5], Batch [24/428], Loss: 2.1183
Epoch [5/5], Batch [25/428], Loss: 2.4436
Epoch [5/5], Batch [26/428], Loss: 2.0079
Epoch [5/5], Batch [27/428], Loss: 1.5286
Epoch [5/5], Batch [28/428], Loss: 2.4634
Epoch [5/5], Batch [29/428], Loss: 2.0016
Epoch [5/5], Batch [30/428], Loss: 1.5352
Epoch [5/5], Batch [31/428], Loss: 2.0350
Epoch [5/5], Batch [32/428], Loss: 1.3455
Epoch [5/5], Batch [33/428], Loss: 1.3627
Epoch [5/5], Batch [34/428], Loss: 1.4736
Epoch [5/5], Batch [35/428], Loss: 2.0348
Epoch [5/5], Batch [36/428], Loss: 1.5005
Epoch [5/5], Batch [37/428], Loss: 1.5051
Epoch [5/5], Batch [38/428], Loss: 2.4339
Epoch [5/5], Batch [39/428], Loss: 1.9656
Epoch [5/5], Batch [40/428], Loss: 1.3736
Epoch [5/5], Batch [41/428], Loss: 1.3810
Epoch [5/5], Batch [42/428], Loss: 2.4228
Epoch [5/5], Batch [43/428], Loss: 1.4531
Epoch [5/5], Batch [44/428], Loss: 1.4622
Epoch [5/5], Batch [45/428], Loss: 2.3996
Epoch [5/5], Batch [46/428], Loss: 1.4206
Epoch [5/5], Batch [47/428], Loss: 2.0540
Epoch [5/5], Batch [48/428], Loss: 1.9940
Epoch [5/5], Batch [49/428], Loss: 2.9530
Epoch [5/5], Batch [50/428], Loss: 2.4212
Epoch [5/5], Batch [51/428], Loss: 2.0525
Epoch [5/5], Batch [52/428], Loss: 1.4298
Epoch [5/5], Batch [53/428], Loss: 1.4178
Epoch [5/5], Batch [54/428], Loss: 1.3603
Epoch [5/5], Batch [55/428], Loss: 1.3935
Epoch [5/5], Batch [56/428], Loss: 2.0051
Epoch [5/5], Batch [57/428], Loss: 1.4293
Epoch [5/5], Batch [58/428], Loss: 2.0070
Epoch [5/5], Batch [59/428], Loss: 2.4419
Epoch [5/5], Batch [60/428], Loss: 2.3528
Epoch [5/5], Batch [61/428], Loss: 1.3755
Epoch [5/5], Batch [62/428], Loss: 2.4250
Epoch [5/5], Batch [63/428], Loss: 2.4065
Epoch [5/5], Batch [64/428], Loss: 1.3474
Epoch [5/5], Batch [65/428], Loss: 1.3858
Epoch [5/5], Batch [66/428], Loss: 2.0993
Epoch [5/5], Batch [67/428], Loss: 1.4087
Epoch [5/5], Batch [68/428], Loss: 2.3717
Epoch [5/5], Batch [69/428], Loss: 2.9679
Epoch [5/5], Batch [70/428], Loss: 2.0214
Epoch [5/5], Batch [71/428], Loss: 1.4137
Epoch [5/5], Batch [72/428], Loss: 1.3911
Epoch [5/5], Batch [73/428], Loss: 2.4503
Epoch [5/5], Batch [74/428], Loss: 2.8875
Epoch [5/5], Batch [75/428], Loss: 2.0216
Epoch [5/5], Batch [76/428], Loss: 1.9972
Epoch [5/5], Batch [77/428], Loss: 1.3705
Epoch [5/5], Batch [78/428], Loss: 2.3044
Epoch [5/5], Batch [79/428], Loss: 2.1204
Epoch [5/5], Batch [80/428], Loss: 1.3880
Epoch [5/5], Batch [81/428], Loss: 1.4362
Epoch [5/5], Batch [82/428], Loss: 2.3905
Epoch [5/5], Batch [83/428], Loss: 1.3669
Epoch [5/5], Batch [84/428], Loss: 1.4440
Epoch [5/5], Batch [85/428], Loss: 1.3521
Epoch [5/5], Batch [86/428], Loss: 2.1285
Epoch [5/5], Batch [87/428], Loss: 2.2281
Epoch [5/5], Batch [88/428], Loss: 2.8932
Epoch [5/5], Batch [89/428], Loss: 1.3198
Epoch [5/5], Batch [90/428], Loss: 2.1533
Epoch [5/5], Batch [91/428], Loss: 1.9690
Epoch [5/5], Batch [92/428], Loss: 1.9645
Epoch [5/5], Batch [93/428], Loss: 1.5256
Epoch [5/5], Batch [94/428], Loss: 1.5413
Epoch [5/5], Batch [95/428], Loss: 1.3142
Epoch [5/5], Batch [96/428], Loss: 1.3132
Epoch [5/5], Batch [97/428], Loss: 2.1194
Epoch [5/5], Batch [98/428], Loss: 2.8545
Epoch [5/5], Batch [99/428], Loss: 2.1246
Epoch [5/5], Batch [100/428], Loss: 2.4218
Epoch [5/5], Batch [101/428], Loss: 1.9765
Epoch [5/5], Batch [102/428], Loss: 2.2903
Epoch [5/5], Batch [103/428], Loss: 1.2737
Epoch [5/5], Batch [104/428], Loss: 1.5770
Epoch [5/5], Batch [105/428], Loss: 1.3003
Epoch [5/5], Batch [106/428], Loss: 1.9566
Epoch [5/5], Batch [107/428], Loss: 2.0619
Epoch [5/5], Batch [108/428], Loss: 1.2694
Epoch [5/5], Batch [109/428], Loss: 2.2994
Epoch [5/5], Batch [110/428], Loss: 2.8409
Epoch [5/5], Batch [111/428], Loss: 1.2566
Epoch [5/5], Batch [112/428], Loss: 1.2612
Epoch [5/5], Batch [113/428], Loss: 1.2470
Epoch [5/5], Batch [114/428], Loss: 2.4707
Epoch [5/5], Batch [115/428], Loss: 1.6235
Epoch [5/5], Batch [116/428], Loss: 1.2038
Epoch [5/5], Batch [117/428], Loss: 2.0676
Epoch [5/5], Batch [118/428], Loss: 1.6549
Epoch [5/5], Batch [119/428], Loss: 2.2746
Epoch [5/5], Batch [120/428], Loss: 1.6550
Epoch [5/5], Batch [121/428], Loss: 2.8257
Epoch [5/5], Batch [122/428], Loss: 1.6370
Epoch [5/5], Batch [123/428], Loss: 2.4535
Epoch [5/5], Batch [124/428], Loss: 1.1816
Epoch [5/5], Batch [125/428], Loss: 2.7681
Epoch [5/5], Batch [126/428], Loss: 2.3078
Epoch [5/5], Batch [127/428], Loss: 2.7637
Epoch [5/5], Batch [128/428], Loss: 2.1118
Epoch [5/5], Batch [129/428], Loss: 2.1338
Epoch [5/5], Batch [130/428], Loss: 2.1343
Epoch [5/5], Batch [131/428], Loss: 1.6292
Epoch [5/5], Batch [132/428], Loss: 1.1863
Epoch [5/5], Batch [133/428], Loss: 1.6333
Epoch [5/5], Batch [134/428], Loss: 2.0728
Epoch [5/5], Batch [135/428], Loss: 2.4996
Epoch [5/5], Batch [136/428], Loss: 1.2089
Epoch [5/5], Batch [137/428], Loss: 2.4722
Epoch [5/5], Batch [138/428], Loss: 2.0572
Epoch [5/5], Batch [139/428], Loss: 2.6792
Epoch [5/5], Batch [140/428], Loss: 2.4468
Epoch [5/5], Batch [141/428], Loss: 1.2448
Epoch [5/5], Batch [142/428], Loss: 2.4220
Epoch [5/5], Batch [143/428], Loss: 1.2268
Epoch [5/5], Batch [144/428], Loss: 2.3785
Epoch [5/5], Batch [145/428], Loss: 1.6223
Epoch [5/5], Batch [146/428], Loss: 1.2152
Epoch [5/5], Batch [147/428], Loss: 2.2065
Epoch [5/5], Batch [148/428], Loss: 1.2182
Epoch [5/5], Batch [149/428], Loss: 2.2037
Epoch [5/5], Batch [150/428], Loss: 2.3352
Epoch [5/5], Batch [151/428], Loss: 1.1918
Epoch [5/5], Batch [152/428], Loss: 1.2045
Epoch [5/5], Batch [153/428], Loss: 2.3131
Epoch [5/5], Batch [154/428], Loss: 1.1636
Epoch [5/5], Batch [155/428], Loss: 2.3075
Epoch [5/5], Batch [156/428], Loss: 1.1554
Epoch [5/5], Batch [157/428], Loss: 2.2750
Epoch [5/5], Batch [158/428], Loss: 2.3690
Epoch [5/5], Batch [159/428], Loss: 2.3780
Epoch [5/5], Batch [160/428], Loss: 2.2373
Epoch [5/5], Batch [161/428], Loss: 1.0806
Epoch [5/5], Batch [162/428], Loss: 2.1786
Epoch [5/5], Batch [163/428], Loss: 2.1815
Epoch [5/5], Batch [164/428], Loss: 2.3172
Epoch [5/5], Batch [165/428], Loss: 2.1170
Epoch [5/5], Batch [166/428], Loss: 1.9050
Epoch [5/5], Batch [167/428], Loss: 1.8348
Epoch [5/5], Batch [168/428], Loss: 2.0287
Epoch [5/5], Batch [169/428], Loss: 2.2831
Epoch [5/5], Batch [170/428], Loss: 1.8818
Epoch [5/5], Batch [171/428], Loss: 1.0967
Epoch [5/5], Batch [172/428], Loss: 1.8683
Epoch [5/5], Batch [173/428], Loss: 1.1255
Epoch [5/5], Batch [174/428], Loss: 2.2939
Epoch [5/5], Batch [175/428], Loss: 1.1077
Epoch [5/5], Batch [176/428], Loss: 1.8174
Epoch [5/5], Batch [177/428], Loss: 1.1077
Epoch [5/5], Batch [178/428], Loss: 1.1078
Epoch [5/5], Batch [179/428], Loss: 2.3590
Epoch [5/5], Batch [180/428], Loss: 2.3370
Epoch [5/5], Batch [181/428], Loss: 1.0974
Epoch [5/5], Batch [182/428], Loss: 1.0930
Epoch [5/5], Batch [183/428], Loss: 2.3629
Epoch [5/5], Batch [184/428], Loss: 1.0532
Epoch [5/5], Batch [185/428], Loss: 1.0554
Epoch [5/5], Batch [186/428], Loss: 1.0256
Epoch [5/5], Batch [187/428], Loss: 2.3809
Epoch [5/5], Batch [188/428], Loss: 2.9071
Epoch [5/5], Batch [189/428], Loss: 2.9138
Epoch [5/5], Batch [190/428], Loss: 2.0301
Epoch [5/5], Batch [191/428], Loss: 2.8958
Epoch [5/5], Batch [192/428], Loss: 2.8774
Epoch [5/5], Batch [193/428], Loss: 2.3443
Epoch [5/5], Batch [194/428], Loss: 2.4017
Epoch [5/5], Batch [195/428], Loss: 2.4164
Epoch [5/5], Batch [196/428], Loss: 0.9614
Epoch [5/5], Batch [197/428], Loss: 2.0474
Epoch [5/5], Batch [198/428], Loss: 1.9994
Epoch [5/5], Batch [199/428], Loss: 1.9835
Epoch [5/5], Batch [200/428], Loss: 0.9665
Epoch [5/5], Batch [201/428], Loss: 2.3499
Epoch [5/5], Batch [202/428], Loss: 2.3282
Epoch [5/5], Batch [203/428], Loss: 2.4263
Epoch [5/5], Batch [204/428], Loss: 2.4000
Epoch [5/5], Batch [205/428], Loss: 1.9825
Epoch [5/5], Batch [206/428], Loss: 0.9798
Epoch [5/5], Batch [207/428], Loss: 2.3797
Epoch [5/5], Batch [208/428], Loss: 2.3702
Epoch [5/5], Batch [209/428], Loss: 1.0014
Epoch [5/5], Batch [210/428], Loss: 2.3606
Epoch [5/5], Batch [211/428], Loss: 2.0163
Epoch [5/5], Batch [212/428], Loss: 1.9895
Epoch [5/5], Batch [213/428], Loss: 2.0128
Epoch [5/5], Batch [214/428], Loss: 2.3170
Epoch [5/5], Batch [215/428], Loss: 2.0101
Epoch [5/5], Batch [216/428], Loss: 2.2635
Epoch [5/5], Batch [217/428], Loss: 1.0446
Epoch [5/5], Batch [218/428], Loss: 2.2553
Epoch [5/5], Batch [219/428], Loss: 2.2319
Epoch [5/5], Batch [220/428], Loss: 2.2384
Epoch [5/5], Batch [221/428], Loss: 2.2180
Epoch [5/5], Batch [222/428], Loss: 2.3378
Epoch [5/5], Batch [223/428], Loss: 1.9320
Epoch [5/5], Batch [224/428], Loss: 2.1707
Epoch [5/5], Batch [225/428], Loss: 1.1061
Epoch [5/5], Batch [226/428], Loss: 1.8959
Epoch [5/5], Batch [227/428], Loss: 1.1126
Epoch [5/5], Batch [228/428], Loss: 2.3236
Epoch [5/5], Batch [229/428], Loss: 1.1300
Epoch [5/5], Batch [230/428], Loss: 1.1197
Epoch [5/5], Batch [231/428], Loss: 2.1455
Epoch [5/5], Batch [232/428], Loss: 2.1438
Epoch [5/5], Batch [233/428], Loss: 2.1052
Epoch [5/5], Batch [234/428], Loss: 2.1482
Epoch [5/5], Batch [235/428], Loss: 1.1080
Epoch [5/5], Batch [236/428], Loss: 2.1003
Epoch [5/5], Batch [237/428], Loss: 1.1036
Epoch [5/5], Batch [238/428], Loss: 2.8169
Epoch [5/5], Batch [239/428], Loss: 1.0735
Epoch [5/5], Batch [240/428], Loss: 2.0829
Epoch [5/5], Batch [241/428], Loss: 1.0809
Epoch [5/5], Batch [242/428], Loss: 2.1024
Epoch [5/5], Batch [243/428], Loss: 2.1826
Epoch [5/5], Batch [244/428], Loss: 2.0568
Epoch [5/5], Batch [245/428], Loss: 1.0644
Epoch [5/5], Batch [246/428], Loss: 1.0654
Epoch [5/5], Batch [247/428], Loss: 2.8644
Epoch [5/5], Batch [248/428], Loss: 2.1466
Epoch [5/5], Batch [249/428], Loss: 1.0376
Epoch [5/5], Batch [250/428], Loss: 2.1305
Epoch [5/5], Batch [251/428], Loss: 2.1508
Epoch [5/5], Batch [252/428], Loss: 2.0524
Epoch [5/5], Batch [253/428], Loss: 2.1076
Epoch [5/5], Batch [254/428], Loss: 2.0537
Epoch [5/5], Batch [255/428], Loss: 2.4239
Epoch [5/5], Batch [256/428], Loss: 2.1809
Epoch [5/5], Batch [257/428], Loss: 2.4392
Epoch [5/5], Batch [258/428], Loss: 2.1746
Epoch [5/5], Batch [259/428], Loss: 2.8614
Epoch [5/5], Batch [260/428], Loss: 2.3897
Epoch [5/5], Batch [261/428], Loss: 2.1397
Epoch [5/5], Batch [262/428], Loss: 1.0599
Epoch [5/5], Batch [263/428], Loss: 1.0728
Epoch [5/5], Batch [264/428], Loss: 2.3767
Epoch [5/5], Batch [265/428], Loss: 2.0954
Epoch [5/5], Batch [266/428], Loss: 2.1425
Epoch [5/5], Batch [267/428], Loss: 2.3576
Epoch [5/5], Batch [268/428], Loss: 2.0949
Epoch [5/5], Batch [269/428], Loss: 1.0710
Epoch [5/5], Batch [270/428], Loss: 2.0539
Epoch [5/5], Batch [271/428], Loss: 2.0312
Epoch [5/5], Batch [272/428], Loss: 1.0980
Epoch [5/5], Batch [273/428], Loss: 2.8642
Epoch [5/5], Batch [274/428], Loss: 2.8482
Epoch [5/5], Batch [275/428], Loss: 2.1650
Epoch [5/5], Batch [276/428], Loss: 2.2483
Epoch [5/5], Batch [277/428], Loss: 1.9842
Epoch [5/5], Batch [278/428], Loss: 1.1337
Epoch [5/5], Batch [279/428], Loss: 2.2600
Epoch [5/5], Batch [280/428], Loss: 1.1278
Epoch [5/5], Batch [281/428], Loss: 2.1411
Epoch [5/5], Batch [282/428], Loss: 2.1937
Epoch [5/5], Batch [283/428], Loss: 2.2458
Epoch [5/5], Batch [284/428], Loss: 1.9452
Epoch [5/5], Batch [285/428], Loss: 2.1857
Epoch [5/5], Batch [286/428], Loss: 2.1672
Epoch [5/5], Batch [287/428], Loss: 2.7386
Epoch [5/5], Batch [288/428], Loss: 1.1438
Epoch [5/5], Batch [289/428], Loss: 1.1595
Epoch [5/5], Batch [290/428], Loss: 2.0842
Epoch [5/5], Batch [291/428], Loss: 1.1524
Epoch [5/5], Batch [292/428], Loss: 2.1346
Epoch [5/5], Batch [293/428], Loss: 1.9298
Epoch [5/5], Batch [294/428], Loss: 2.1805
Epoch [5/5], Batch [295/428], Loss: 2.1730
Epoch [5/5], Batch [296/428], Loss: 1.1373
Epoch [5/5], Batch [297/428], Loss: 2.0902
Epoch [5/5], Batch [298/428], Loss: 2.1229
Epoch [5/5], Batch [299/428], Loss: 2.0740
Epoch [5/5], Batch [300/428], Loss: 2.0681
Epoch [5/5], Batch [301/428], Loss: 2.0766
Epoch [5/5], Batch [302/428], Loss: 2.0842
Epoch [5/5], Batch [303/428], Loss: 2.2905
Epoch [5/5], Batch [304/428], Loss: 2.1133
Epoch [5/5], Batch [305/428], Loss: 2.2785
Epoch [5/5], Batch [306/428], Loss: 2.1546
Epoch [5/5], Batch [307/428], Loss: 1.9668
Epoch [5/5], Batch [308/428], Loss: 2.1153
Epoch [5/5], Batch [309/428], Loss: 2.7557
Epoch [5/5], Batch [310/428], Loss: 2.7710
Epoch [5/5], Batch [311/428], Loss: 2.2596
Epoch [5/5], Batch [312/428], Loss: 1.2527
Epoch [5/5], Batch [313/428], Loss: 2.2490
Epoch [5/5], Batch [314/428], Loss: 2.0335
Epoch [5/5], Batch [315/428], Loss: 2.6975
Epoch [5/5], Batch [316/428], Loss: 2.0675
Epoch [5/5], Batch [317/428], Loss: 2.1564
Epoch [5/5], Batch [318/428], Loss: 1.9662
Epoch [5/5], Batch [319/428], Loss: 1.2795
Epoch [5/5], Batch [320/428], Loss: 2.0403
Epoch [5/5], Batch [321/428], Loss: 1.3106
Epoch [5/5], Batch [322/428], Loss: 1.9774
Epoch [5/5], Batch [323/428], Loss: 1.9595
Epoch [5/5], Batch [324/428], Loss: 2.5943
Epoch [5/5], Batch [325/428], Loss: 1.3323
Epoch [5/5], Batch [326/428], Loss: 2.5828
Epoch [5/5], Batch [327/428], Loss: 2.1264
Epoch [5/5], Batch [328/428], Loss: 2.0215
Epoch [5/5], Batch [329/428], Loss: 2.0173
Epoch [5/5], Batch [330/428], Loss: 1.3394
Epoch [5/5], Batch [331/428], Loss: 2.0774
Epoch [5/5], Batch [332/428], Loss: 1.3391
Epoch [5/5], Batch [333/428], Loss: 1.3282
Epoch [5/5], Batch [334/428], Loss: 2.0057
Epoch [5/5], Batch [335/428], Loss: 2.1150
Epoch [5/5], Batch [336/428], Loss: 2.1284
Epoch [5/5], Batch [337/428], Loss: 1.9789
Epoch [5/5], Batch [338/428], Loss: 2.5030
Epoch [5/5], Batch [339/428], Loss: 1.3021
Epoch [5/5], Batch [340/428], Loss: 1.9918
Epoch [5/5], Batch [341/428], Loss: 1.9834
Epoch [5/5], Batch [342/428], Loss: 2.1978
Epoch [5/5], Batch [343/428], Loss: 2.1037
Epoch [5/5], Batch [344/428], Loss: 1.3149
Epoch [5/5], Batch [345/428], Loss: 2.0475
Epoch [5/5], Batch [346/428], Loss: 2.1109
Epoch [5/5], Batch [347/428], Loss: 2.0399
Epoch [5/5], Batch [348/428], Loss: 1.2936
Epoch [5/5], Batch [349/428], Loss: 1.3004
Epoch [5/5], Batch [350/428], Loss: 1.2993
Epoch [5/5], Batch [351/428], Loss: 2.1584
Epoch [5/5], Batch [352/428], Loss: 1.9907
Epoch [5/5], Batch [353/428], Loss: 2.1754
Epoch [5/5], Batch [354/428], Loss: 1.9436
Epoch [5/5], Batch [355/428], Loss: 1.2518
Epoch [5/5], Batch [356/428], Loss: 1.9809
Epoch [5/5], Batch [357/428], Loss: 2.1448
Epoch [5/5], Batch [358/428], Loss: 1.2311
Epoch [5/5], Batch [359/428], Loss: 2.5161
Epoch [5/5], Batch [360/428], Loss: 1.9462
Epoch [5/5], Batch [361/428], Loss: 2.1330
Epoch [5/5], Batch [362/428], Loss: 2.2584
Epoch [5/5], Batch [363/428], Loss: 1.9265
Epoch [5/5], Batch [364/428], Loss: 2.0111
Epoch [5/5], Batch [365/428], Loss: 1.2423
Epoch [5/5], Batch [366/428], Loss: 2.5639
Epoch [5/5], Batch [367/428], Loss: 2.2791
Epoch [5/5], Batch [368/428], Loss: 2.1970
Epoch [5/5], Batch [369/428], Loss: 1.2290
Epoch [5/5], Batch [370/428], Loss: 2.1950
Epoch [5/5], Batch [371/428], Loss: 2.2582
Epoch [5/5], Batch [372/428], Loss: 2.4715
Epoch [5/5], Batch [373/428], Loss: 2.4753
Epoch [5/5], Batch [374/428], Loss: 2.2216
Epoch [5/5], Batch [375/428], Loss: 1.8978
Epoch [5/5], Batch [376/428], Loss: 1.9153
Epoch [5/5], Batch [377/428], Loss: 2.1638
Epoch [5/5], Batch [378/428], Loss: 1.8884
Epoch [5/5], Batch [379/428], Loss: 2.4611
Epoch [5/5], Batch [380/428], Loss: 2.0742
Epoch [5/5], Batch [381/428], Loss: 1.2741
Epoch [5/5], Batch [382/428], Loss: 2.1453
Epoch [5/5], Batch [383/428], Loss: 1.3012
Epoch [5/5], Batch [384/428], Loss: 1.3123
Epoch [5/5], Batch [385/428], Loss: 1.2842
Epoch [5/5], Batch [386/428], Loss: 2.2661
Epoch [5/5], Batch [387/428], Loss: 2.0443
Epoch [5/5], Batch [388/428], Loss: 2.3825
Epoch [5/5], Batch [389/428], Loss: 2.1284
Epoch [5/5], Batch [390/428], Loss: 1.8630
Epoch [5/5], Batch [391/428], Loss: 1.3005
Epoch [5/5], Batch [392/428], Loss: 1.8742
Epoch [5/5], Batch [393/428], Loss: 2.0724
Epoch [5/5], Batch [394/428], Loss: 1.8445
Epoch [5/5], Batch [395/428], Loss: 2.2887
Epoch [5/5], Batch [396/428], Loss: 2.1243
Epoch [5/5], Batch [397/428], Loss: 1.2527
Epoch [5/5], Batch [398/428], Loss: 1.7711
Epoch [5/5], Batch [399/428], Loss: 2.1220
Epoch [5/5], Batch [400/428], Loss: 2.2690
Epoch [5/5], Batch [401/428], Loss: 1.7657
Epoch [5/5], Batch [402/428], Loss: 2.2650
Epoch [5/5], Batch [403/428], Loss: 1.7209
Epoch [5/5], Batch [404/428], Loss: 1.7261
Epoch [5/5], Batch [405/428], Loss: 2.2555
Epoch [5/5], Batch [406/428], Loss: 2.1081
Epoch [5/5], Batch [407/428], Loss: 2.1823
Epoch [5/5], Batch [408/428], Loss: 1.6721
Epoch [5/5], Batch [409/428], Loss: 2.3052
Epoch [5/5], Batch [410/428], Loss: 2.1865
Epoch [5/5], Batch [411/428], Loss: 1.3701
Epoch [5/5], Batch [412/428], Loss: 1.3765
Epoch [5/5], Batch [413/428], Loss: 1.3659
Epoch [5/5], Batch [414/428], Loss: 1.3723
Epoch [5/5], Batch [415/428], Loss: 1.5848
Epoch [5/5], Batch [416/428], Loss: 1.5756
Epoch [5/5], Batch [417/428], Loss: 2.1561
Epoch [5/5], Batch [418/428], Loss: 2.1426
Epoch [5/5], Batch [419/428], Loss: 1.3396
Epoch [5/5], Batch [420/428], Loss: 2.3430
Epoch [5/5], Batch [421/428], Loss: 2.1743
Epoch [5/5], Batch [422/428], Loss: 1.3320
Epoch [5/5], Batch [423/428], Loss: 1.3377
Epoch [5/5], Batch [424/428], Loss: 2.1929
Epoch [5/5], Batch [425/428], Loss: 1.3334
Epoch [5/5], Batch [426/428], Loss: 2.3448
Epoch [5/5], Batch [427/428], Loss: 1.2882
Epoch [5/5], Batch [428/428], Loss: 2.2579
Epoch [5] Training Time: 270.64 seconds
Epoch [5/5], Average Loss: 1.9179, Training Accuracy: 0.2477
Epoch [5], Validation Loss: 1.9783, Validation Accuracy: 0.1429
Epoch [5] Validation Time: 10.84 seconds
--------------------------------------------------

Running trial 16 with config: {'batch_size': 1, 'lr': 0.0006559427542242146, 'num_epochs': 5, 'unfreeze_epoch': 2, 'max_length': 112000, 'device': device(type='cpu')}
Epoch [1/5], Batch [1/428], Loss: 2.4868
Epoch [1/5], Batch [2/428], Loss: 3.9197
Epoch [1/5], Batch [3/428], Loss: 0.6643
Epoch [1/5], Batch [4/428], Loss: 2.4247
Epoch [1/5], Batch [5/428], Loss: 3.5262
Epoch [1/5], Batch [6/428], Loss: 3.9369
Epoch [1/5], Batch [7/428], Loss: 0.7268
Epoch [1/5], Batch [8/428], Loss: 3.5523
Epoch [1/5], Batch [9/428], Loss: 1.3689
Epoch [1/5], Batch [10/428], Loss: 1.2354
Epoch [1/5], Batch [11/428], Loss: 4.7120
Epoch [1/5], Batch [12/428], Loss: 4.3549
Epoch [1/5], Batch [13/428], Loss: 3.7740
Epoch [1/5], Batch [14/428], Loss: 4.0130
Epoch [1/5], Batch [15/428], Loss: 0.6171
Epoch [1/5], Batch [16/428], Loss: 1.3844
Epoch [1/5], Batch [17/428], Loss: 3.1928
Epoch [1/5], Batch [18/428], Loss: 2.6556
Epoch [1/5], Batch [19/428], Loss: 0.6933
Epoch [1/5], Batch [20/428], Loss: 1.0860
Epoch [1/5], Batch [21/428], Loss: 4.0957
Epoch [1/5], Batch [22/428], Loss: 0.1470
Epoch [1/5], Batch [23/428], Loss: 0.9493
Epoch [1/5], Batch [24/428], Loss: 1.1419
Epoch [1/5], Batch [25/428], Loss: 0.1865
Epoch [1/5], Batch [26/428], Loss: 0.0167
Epoch [1/5], Batch [27/428], Loss: 2.4183
Epoch [1/5], Batch [28/428], Loss: 2.2460
Epoch [1/5], Batch [29/428], Loss: 0.0145
Epoch [1/5], Batch [30/428], Loss: 2.0657
Epoch [1/5], Batch [31/428], Loss: 1.5640
Epoch [1/5], Batch [32/428], Loss: 2.2519
Epoch [1/5], Batch [33/428], Loss: 1.7376
Epoch [1/5], Batch [34/428], Loss: 1.6202
Epoch [1/5], Batch [35/428], Loss: 6.0174
Epoch [1/5], Batch [36/428], Loss: 2.2037
Epoch [1/5], Batch [37/428], Loss: 3.7382
Epoch [1/5], Batch [38/428], Loss: 1.1115
Epoch [1/5], Batch [39/428], Loss: 2.3702
Epoch [1/5], Batch [40/428], Loss: 2.2089
Epoch [1/5], Batch [41/428], Loss: 0.8924
Epoch [1/5], Batch [42/428], Loss: 0.0027
Epoch [1/5], Batch [43/428], Loss: 0.7856
Epoch [1/5], Batch [44/428], Loss: 2.6885
Epoch [1/5], Batch [45/428], Loss: 0.4325
Epoch [1/5], Batch [46/428], Loss: 2.5229
Epoch [1/5], Batch [47/428], Loss: 0.0009
Epoch [1/5], Batch [48/428], Loss: 1.3774
Epoch [1/5], Batch [49/428], Loss: 0.0103
Epoch [1/5], Batch [50/428], Loss: 2.2248
Epoch [1/5], Batch [51/428], Loss: 6.0427
Epoch [1/5], Batch [52/428], Loss: 0.7017
Epoch [1/5], Batch [53/428], Loss: 1.6748
Epoch [1/5], Batch [54/428], Loss: 1.4183
Epoch [1/5], Batch [55/428], Loss: 3.1962
Epoch [1/5], Batch [56/428], Loss: 0.5407
Epoch [1/5], Batch [57/428], Loss: 2.2745
Epoch [1/5], Batch [58/428], Loss: 0.0208
Epoch [1/5], Batch [59/428], Loss: 0.3448
Epoch [1/5], Batch [60/428], Loss: 3.7012
Epoch [1/5], Batch [61/428], Loss: 2.6276
Epoch [1/5], Batch [62/428], Loss: 0.0579
Epoch [1/5], Batch [63/428], Loss: 2.3955
Epoch [1/5], Batch [64/428], Loss: 2.7100
Epoch [1/5], Batch [65/428], Loss: 1.5401
Epoch [1/5], Batch [66/428], Loss: 3.1714
Epoch [1/5], Batch [67/428], Loss: 0.0010
Epoch [1/5], Batch [68/428], Loss: 0.9264
Epoch [1/5], Batch [69/428], Loss: 3.1308
Epoch [1/5], Batch [70/428], Loss: 0.0203
Epoch [1/5], Batch [71/428], Loss: 2.6122
Epoch [1/5], Batch [72/428], Loss: 2.1071
Epoch [1/5], Batch [73/428], Loss: 0.0034
Epoch [1/5], Batch [74/428], Loss: 0.0070
Epoch [1/5], Batch [75/428], Loss: 3.1319
Epoch [1/5], Batch [76/428], Loss: 0.0041
Epoch [1/5], Batch [77/428], Loss: 3.4654
Epoch [1/5], Batch [78/428], Loss: 2.6555
Epoch [1/5], Batch [79/428], Loss: 2.1827
Epoch [1/5], Batch [80/428], Loss: 4.4650
Epoch [1/5], Batch [81/428], Loss: 0.0012
Epoch [1/5], Batch [82/428], Loss: 0.0336
Epoch [1/5], Batch [83/428], Loss: 2.0257
Epoch [1/5], Batch [84/428], Loss: 3.6239
Epoch [1/5], Batch [85/428], Loss: 4.7900
Epoch [1/5], Batch [86/428], Loss: 2.9273
Epoch [1/5], Batch [87/428], Loss: 0.0466
Epoch [1/5], Batch [88/428], Loss: 1.4977
Epoch [1/5], Batch [89/428], Loss: 2.2487
Epoch [1/5], Batch [90/428], Loss: 0.1344
Epoch [1/5], Batch [91/428], Loss: 0.0556
Epoch [1/5], Batch [92/428], Loss: 3.2607
Epoch [1/5], Batch [93/428], Loss: 1.6778
Epoch [1/5], Batch [94/428], Loss: 2.0988
Epoch [1/5], Batch [95/428], Loss: 0.4638
Epoch [1/5], Batch [96/428], Loss: 0.9598
Epoch [1/5], Batch [97/428], Loss: 0.1643
Epoch [1/5], Batch [98/428], Loss: 2.9488
Epoch [1/5], Batch [99/428], Loss: 0.0721
Epoch [1/5], Batch [100/428], Loss: 2.2958
Epoch [1/5], Batch [101/428], Loss: 2.9781
Epoch [1/5], Batch [102/428], Loss: 0.0801
Epoch [1/5], Batch [103/428], Loss: 2.9382
Epoch [1/5], Batch [104/428], Loss: 5.2997
Epoch [1/5], Batch [105/428], Loss: 2.1831
Epoch [1/5], Batch [106/428], Loss: 1.8872
Epoch [1/5], Batch [107/428], Loss: 2.5305
Epoch [1/5], Batch [108/428], Loss: 2.5451
Epoch [1/5], Batch [109/428], Loss: 1.8213
Epoch [1/5], Batch [110/428], Loss: 1.6261
Epoch [1/5], Batch [111/428], Loss: 1.2718
Epoch [1/5], Batch [112/428], Loss: 5.2173
Epoch [1/5], Batch [113/428], Loss: 1.8505
Epoch [1/5], Batch [114/428], Loss: 0.3106
Epoch [1/5], Batch [115/428], Loss: 0.3447
Epoch [1/5], Batch [116/428], Loss: 1.9934
Epoch [1/5], Batch [117/428], Loss: 0.8789
Epoch [1/5], Batch [118/428], Loss: 3.3215
Epoch [1/5], Batch [119/428], Loss: 1.3312
Epoch [1/5], Batch [120/428], Loss: 0.0265
Epoch [1/5], Batch [121/428], Loss: 1.3060
Epoch [1/5], Batch [122/428], Loss: 1.3993
Epoch [1/5], Batch [123/428], Loss: 0.2478
Epoch [1/5], Batch [124/428], Loss: 0.3944
Epoch [1/5], Batch [125/428], Loss: 1.3541
Epoch [1/5], Batch [126/428], Loss: 4.3733
Epoch [1/5], Batch [127/428], Loss: 1.3211
Epoch [1/5], Batch [128/428], Loss: 0.2509
Epoch [1/5], Batch [129/428], Loss: 1.7973
Epoch [1/5], Batch [130/428], Loss: 0.6183
Epoch [1/5], Batch [131/428], Loss: 2.0158
Epoch [1/5], Batch [132/428], Loss: 3.1577
Epoch [1/5], Batch [133/428], Loss: 3.0684
Epoch [1/5], Batch [134/428], Loss: 0.6917
Epoch [1/5], Batch [135/428], Loss: 2.7650
Epoch [1/5], Batch [136/428], Loss: 1.3713
Epoch [1/5], Batch [137/428], Loss: 0.0013
Epoch [1/5], Batch [138/428], Loss: 0.9868
Epoch [1/5], Batch [139/428], Loss: 2.2596
Epoch [1/5], Batch [140/428], Loss: 0.0008
Epoch [1/5], Batch [141/428], Loss: 1.5793
Epoch [1/5], Batch [142/428], Loss: 0.9644
Epoch [1/5], Batch [143/428], Loss: 0.4713
Epoch [1/5], Batch [144/428], Loss: 0.0016
Epoch [1/5], Batch [145/428], Loss: 1.5761
Epoch [1/5], Batch [146/428], Loss: 1.3344
Epoch [1/5], Batch [147/428], Loss: 0.0044
Epoch [1/5], Batch [148/428], Loss: 1.5185
Epoch [1/5], Batch [149/428], Loss: 0.0008
Epoch [1/5], Batch [150/428], Loss: 0.3693
Epoch [1/5], Batch [151/428], Loss: 0.0922
Epoch [1/5], Batch [152/428], Loss: 6.5996
Epoch [1/5], Batch [153/428], Loss: 0.0062
Epoch [1/5], Batch [154/428], Loss: 5.0438
Epoch [1/5], Batch [155/428], Loss: 0.0003
Epoch [1/5], Batch [156/428], Loss: 1.4151
Epoch [1/5], Batch [157/428], Loss: 5.6509
Epoch [1/5], Batch [158/428], Loss: 1.6988
Epoch [1/5], Batch [159/428], Loss: 3.7535
Epoch [1/5], Batch [160/428], Loss: 3.1336
Epoch [1/5], Batch [161/428], Loss: 2.6520
Epoch [1/5], Batch [162/428], Loss: 2.9897
Epoch [1/5], Batch [163/428], Loss: 2.6584
Epoch [1/5], Batch [164/428], Loss: 2.8139
Epoch [1/5], Batch [165/428], Loss: 0.1227
Epoch [1/5], Batch [166/428], Loss: 0.0352
Epoch [1/5], Batch [167/428], Loss: 0.0005
Epoch [1/5], Batch [168/428], Loss: 0.6416
Epoch [1/5], Batch [169/428], Loss: 2.0055
Epoch [1/5], Batch [170/428], Loss: 2.0755
Epoch [1/5], Batch [171/428], Loss: 1.1991
Epoch [1/5], Batch [172/428], Loss: 0.7343
Epoch [1/5], Batch [173/428], Loss: 0.1352
Epoch [1/5], Batch [174/428], Loss: 3.6191
Epoch [1/5], Batch [175/428], Loss: 0.0004
Epoch [1/5], Batch [176/428], Loss: 0.6923
Epoch [1/5], Batch [177/428], Loss: 2.3200
Epoch [1/5], Batch [178/428], Loss: 0.0050
Epoch [1/5], Batch [179/428], Loss: 1.8398
Epoch [1/5], Batch [180/428], Loss: 1.2000
Epoch [1/5], Batch [181/428], Loss: 6.0819
Epoch [1/5], Batch [182/428], Loss: 0.1058
Epoch [1/5], Batch [183/428], Loss: 1.5470
Epoch [1/5], Batch [184/428], Loss: 1.7450
Epoch [1/5], Batch [185/428], Loss: 0.0005
Epoch [1/5], Batch [186/428], Loss: 0.9891
Epoch [1/5], Batch [187/428], Loss: 1.1627
Epoch [1/5], Batch [188/428], Loss: 1.3257
Epoch [1/5], Batch [189/428], Loss: 0.7100
Epoch [1/5], Batch [190/428], Loss: 0.0313
Epoch [1/5], Batch [191/428], Loss: 1.7043
Epoch [1/5], Batch [192/428], Loss: 1.9844
Epoch [1/5], Batch [193/428], Loss: 1.2154
Epoch [1/5], Batch [194/428], Loss: 0.8784
Epoch [1/5], Batch [195/428], Loss: 0.0063
Epoch [1/5], Batch [196/428], Loss: 0.1328
Epoch [1/5], Batch [197/428], Loss: 2.2069
Epoch [1/5], Batch [198/428], Loss: 0.5200
Epoch [1/5], Batch [199/428], Loss: 2.2992
Epoch [1/5], Batch [200/428], Loss: 0.7139
Epoch [1/5], Batch [201/428], Loss: 0.0663
Epoch [1/5], Batch [202/428], Loss: 2.0210
Epoch [1/5], Batch [203/428], Loss: 0.0833
Epoch [1/5], Batch [204/428], Loss: 0.5507
Epoch [1/5], Batch [205/428], Loss: 1.5875
Epoch [1/5], Batch [206/428], Loss: 0.4841
Epoch [1/5], Batch [207/428], Loss: 2.4189
Epoch [1/5], Batch [208/428], Loss: 2.1970
Epoch [1/5], Batch [209/428], Loss: 0.0001
Epoch [1/5], Batch [210/428], Loss: 0.2057
Epoch [1/5], Batch [211/428], Loss: 1.8052
Epoch [1/5], Batch [212/428], Loss: 0.0048
Epoch [1/5], Batch [213/428], Loss: 1.8691
Epoch [1/5], Batch [214/428], Loss: 0.0001
Epoch [1/5], Batch [215/428], Loss: 0.8171
Epoch [1/5], Batch [216/428], Loss: 0.1795
Epoch [1/5], Batch [217/428], Loss: 1.0354
Epoch [1/5], Batch [218/428], Loss: 1.4125
Epoch [1/5], Batch [219/428], Loss: 1.7278
Epoch [1/5], Batch [220/428], Loss: 0.4163
Epoch [1/5], Batch [221/428], Loss: 0.8430
Epoch [1/5], Batch [222/428], Loss: 3.2502
Epoch [1/5], Batch [223/428], Loss: 1.7656
Epoch [1/5], Batch [224/428], Loss: 0.1030
Epoch [1/5], Batch [225/428], Loss: 0.0053
Epoch [1/5], Batch [226/428], Loss: 0.3287
Epoch [1/5], Batch [227/428], Loss: 0.0001
Epoch [1/5], Batch [228/428], Loss: 0.2908
Epoch [1/5], Batch [229/428], Loss: 0.0050
Epoch [1/5], Batch [230/428], Loss: 1.7998
Epoch [1/5], Batch [231/428], Loss: 0.0001
Epoch [1/5], Batch [232/428], Loss: 0.5166
Epoch [1/5], Batch [233/428], Loss: 3.2556
Epoch [1/5], Batch [234/428], Loss: 1.0325
Epoch [1/5], Batch [235/428], Loss: 2.2791
Epoch [1/5], Batch [236/428], Loss: 0.5793
Epoch [1/5], Batch [237/428], Loss: 3.6508
Epoch [1/5], Batch [238/428], Loss: 2.1591
Epoch [1/5], Batch [239/428], Loss: 3.2730
Epoch [1/5], Batch [240/428], Loss: 3.6403
Epoch [1/5], Batch [241/428], Loss: 0.0315
Epoch [1/5], Batch [242/428], Loss: 1.4158
Epoch [1/5], Batch [243/428], Loss: 0.3362
Epoch [1/5], Batch [244/428], Loss: 0.2411
Epoch [1/5], Batch [245/428], Loss: 0.0538
Epoch [1/5], Batch [246/428], Loss: 1.1683
Epoch [1/5], Batch [247/428], Loss: 5.2771
Epoch [1/5], Batch [248/428], Loss: 0.0083
Epoch [1/5], Batch [249/428], Loss: 0.0430
Epoch [1/5], Batch [250/428], Loss: 0.0042
Epoch [1/5], Batch [251/428], Loss: 4.0914
Epoch [1/5], Batch [252/428], Loss: 0.0043
Epoch [1/5], Batch [253/428], Loss: 0.0002
Epoch [1/5], Batch [254/428], Loss: 0.1845
Epoch [1/5], Batch [255/428], Loss: 4.6426
Epoch [1/5], Batch [256/428], Loss: 0.0755
Epoch [1/5], Batch [257/428], Loss: 1.1255
Epoch [1/5], Batch [258/428], Loss: 1.9400
Epoch [1/5], Batch [259/428], Loss: 2.2347
Epoch [1/5], Batch [260/428], Loss: 0.0324
Epoch [1/5], Batch [261/428], Loss: 2.0713
Epoch [1/5], Batch [262/428], Loss: 1.7084
Epoch [1/5], Batch [263/428], Loss: 0.0196
Epoch [1/5], Batch [264/428], Loss: 1.3721
Epoch [1/5], Batch [265/428], Loss: 0.9900
Epoch [1/5], Batch [266/428], Loss: 2.0603
Epoch [1/5], Batch [267/428], Loss: 3.1796
Epoch [1/5], Batch [268/428], Loss: 0.0002
Epoch [1/5], Batch [269/428], Loss: 1.5845
Epoch [1/5], Batch [270/428], Loss: 0.0001
Epoch [1/5], Batch [271/428], Loss: 0.0508
Epoch [1/5], Batch [272/428], Loss: 0.1257
Epoch [1/5], Batch [273/428], Loss: 0.0001
Epoch [1/5], Batch [274/428], Loss: 0.5491
Epoch [1/5], Batch [275/428], Loss: 1.8141
Epoch [1/5], Batch [276/428], Loss: 1.6664
Epoch [1/5], Batch [277/428], Loss: 0.8387
Epoch [1/5], Batch [278/428], Loss: 0.3499
Epoch [1/5], Batch [279/428], Loss: 2.7647
Epoch [1/5], Batch [280/428], Loss: 2.2322
Epoch [1/5], Batch [281/428], Loss: 2.4177
Epoch [1/5], Batch [282/428], Loss: 1.6365
Epoch [1/5], Batch [283/428], Loss: 1.8318
Epoch [1/5], Batch [284/428], Loss: 0.0127
Epoch [1/5], Batch [285/428], Loss: 0.0007
Epoch [1/5], Batch [286/428], Loss: 0.8202
Epoch [1/5], Batch [287/428], Loss: 0.8773
Epoch [1/5], Batch [288/428], Loss: 0.1665
Epoch [1/5], Batch [289/428], Loss: 2.8919
Epoch [1/5], Batch [290/428], Loss: 0.8419
Epoch [1/5], Batch [291/428], Loss: 1.4386
Epoch [1/5], Batch [292/428], Loss: 0.0009
Epoch [1/5], Batch [293/428], Loss: 0.9679
Epoch [1/5], Batch [294/428], Loss: 0.0001
Epoch [1/5], Batch [295/428], Loss: 3.8919
Epoch [1/5], Batch [296/428], Loss: 1.9109
Epoch [1/5], Batch [297/428], Loss: 1.9450
Epoch [1/5], Batch [298/428], Loss: 0.0259
Epoch [1/5], Batch [299/428], Loss: 0.2657
Epoch [1/5], Batch [300/428], Loss: 3.1121
Epoch [1/5], Batch [301/428], Loss: 0.0286
Epoch [1/5], Batch [302/428], Loss: 1.4281
Epoch [1/5], Batch [303/428], Loss: 0.0781
Epoch [1/5], Batch [304/428], Loss: 1.1775
Epoch [1/5], Batch [305/428], Loss: 2.7754
Epoch [1/5], Batch [306/428], Loss: 0.1000
Epoch [1/5], Batch [307/428], Loss: 2.1630
Epoch [1/5], Batch [308/428], Loss: 4.6439
Epoch [1/5], Batch [309/428], Loss: 6.2847
Epoch [1/5], Batch [310/428], Loss: 3.9701
Epoch [1/5], Batch [311/428], Loss: 0.7965
Epoch [1/5], Batch [312/428], Loss: 0.1685
Epoch [1/5], Batch [313/428], Loss: 1.7344
Epoch [1/5], Batch [314/428], Loss: 3.4384
Epoch [1/5], Batch [315/428], Loss: 1.3180
Epoch [1/5], Batch [316/428], Loss: 0.0228
Epoch [1/5], Batch [317/428], Loss: 4.0446
Epoch [1/5], Batch [318/428], Loss: 1.5434
Epoch [1/5], Batch [319/428], Loss: 0.6416
Epoch [1/5], Batch [320/428], Loss: 2.8728
Epoch [1/5], Batch [321/428], Loss: 0.4146
Epoch [1/5], Batch [322/428], Loss: 1.6956
Epoch [1/5], Batch [323/428], Loss: 0.0564
Epoch [1/5], Batch [324/428], Loss: 0.0029
Epoch [1/5], Batch [325/428], Loss: 4.0045
Epoch [1/5], Batch [326/428], Loss: 0.0000
Epoch [1/5], Batch [327/428], Loss: 0.9036
Epoch [1/5], Batch [328/428], Loss: 0.8020
Epoch [1/5], Batch [329/428], Loss: 1.3927
Epoch [1/5], Batch [330/428], Loss: 0.0606
Epoch [1/5], Batch [331/428], Loss: 2.2784
Epoch [1/5], Batch [332/428], Loss: 1.9921
Epoch [1/5], Batch [333/428], Loss: 0.0000
Epoch [1/5], Batch [334/428], Loss: 0.0504
Epoch [1/5], Batch [335/428], Loss: 0.0021
Epoch [1/5], Batch [336/428], Loss: 0.9558
Epoch [1/5], Batch [337/428], Loss: 0.0651
Epoch [1/5], Batch [338/428], Loss: 0.0197
Epoch [1/5], Batch [339/428], Loss: 2.0564
Epoch [1/5], Batch [340/428], Loss: 0.2369
Epoch [1/5], Batch [341/428], Loss: 0.0245
Epoch [1/5], Batch [342/428], Loss: 2.2310
Epoch [1/5], Batch [343/428], Loss: 0.0137
Epoch [1/5], Batch [344/428], Loss: 0.0242
Epoch [1/5], Batch [345/428], Loss: 1.5413
Epoch [1/5], Batch [346/428], Loss: 0.3255
Epoch [1/5], Batch [347/428], Loss: 0.0216
Epoch [1/5], Batch [348/428], Loss: 1.6638
Epoch [1/5], Batch [349/428], Loss: 0.8272
Epoch [1/5], Batch [350/428], Loss: 0.6079
Epoch [1/5], Batch [351/428], Loss: 0.2877
Epoch [1/5], Batch [352/428], Loss: 0.0017
Epoch [1/5], Batch [353/428], Loss: 3.4040
Epoch [1/5], Batch [354/428], Loss: 0.8628
Epoch [1/5], Batch [355/428], Loss: 0.2102
Epoch [1/5], Batch [356/428], Loss: 6.3213
Epoch [1/5], Batch [357/428], Loss: 6.6595
Epoch [1/5], Batch [358/428], Loss: 2.7802
Epoch [1/5], Batch [359/428], Loss: 5.1316
Epoch [1/5], Batch [360/428], Loss: 0.0055
Epoch [1/5], Batch [361/428], Loss: 0.0188
Epoch [1/5], Batch [362/428], Loss: 1.1598
Epoch [1/5], Batch [363/428], Loss: 4.0043
Epoch [1/5], Batch [364/428], Loss: 0.1006
Epoch [1/5], Batch [365/428], Loss: 3.5414
Epoch [1/5], Batch [366/428], Loss: 1.1198
Epoch [1/5], Batch [367/428], Loss: 2.4755
Epoch [1/5], Batch [368/428], Loss: 2.5088
Epoch [1/5], Batch [369/428], Loss: 0.0413
Epoch [1/5], Batch [370/428], Loss: 3.9070
Epoch [1/5], Batch [371/428], Loss: 0.4211
Epoch [1/5], Batch [372/428], Loss: 0.2759
Epoch [1/5], Batch [373/428], Loss: 2.3102
Epoch [1/5], Batch [374/428], Loss: 0.4558
Epoch [1/5], Batch [375/428], Loss: 2.2718
Epoch [1/5], Batch [376/428], Loss: 0.9165
Epoch [1/5], Batch [377/428], Loss: 0.1457
Epoch [1/5], Batch [378/428], Loss: 0.7242
Epoch [1/5], Batch [379/428], Loss: 1.4204
Epoch [1/5], Batch [380/428], Loss: 0.6596
Epoch [1/5], Batch [381/428], Loss: 0.9959
Epoch [1/5], Batch [382/428], Loss: 0.0014
Epoch [1/5], Batch [383/428], Loss: 0.0163
Epoch [1/5], Batch [384/428], Loss: 1.0425
Epoch [1/5], Batch [385/428], Loss: 0.0217
Epoch [1/5], Batch [386/428], Loss: 8.8785
Epoch [1/5], Batch [387/428], Loss: 0.4733
Epoch [1/5], Batch [388/428], Loss: 1.8431
Epoch [1/5], Batch [389/428], Loss: 0.4612
Epoch [1/5], Batch [390/428], Loss: 4.4446
Epoch [1/5], Batch [391/428], Loss: 0.4031
Epoch [1/5], Batch [392/428], Loss: 0.2183
Epoch [1/5], Batch [393/428], Loss: 0.0873
Epoch [1/5], Batch [394/428], Loss: 1.4725
Epoch [1/5], Batch [395/428], Loss: 0.0002
Epoch [1/5], Batch [396/428], Loss: 0.1381
Epoch [1/5], Batch [397/428], Loss: 0.0226
Epoch [1/5], Batch [398/428], Loss: 1.2541
Epoch [1/5], Batch [399/428], Loss: 0.0417
Epoch [1/5], Batch [400/428], Loss: 0.0101
Epoch [1/5], Batch [401/428], Loss: 1.0872
Epoch [1/5], Batch [402/428], Loss: 0.1486
Epoch [1/5], Batch [403/428], Loss: 0.0002
Epoch [1/5], Batch [404/428], Loss: 0.0442
Epoch [1/5], Batch [405/428], Loss: 0.4150
Epoch [1/5], Batch [406/428], Loss: 1.4300
Epoch [1/5], Batch [407/428], Loss: 3.3383
Epoch [1/5], Batch [408/428], Loss: 0.0001
Epoch [1/5], Batch [409/428], Loss: 1.5473
Epoch [1/5], Batch [410/428], Loss: 0.0023
Epoch [1/5], Batch [411/428], Loss: 1.9682
Epoch [1/5], Batch [412/428], Loss: 5.4310
Epoch [1/5], Batch [413/428], Loss: 0.2425
Epoch [1/5], Batch [414/428], Loss: 3.7518
Epoch [1/5], Batch [415/428], Loss: 0.2688
Epoch [1/5], Batch [416/428], Loss: 0.2117
Epoch [1/5], Batch [417/428], Loss: 0.0076
Epoch [1/5], Batch [418/428], Loss: 0.0008
Epoch [1/5], Batch [419/428], Loss: 0.0368
Epoch [1/5], Batch [420/428], Loss: 0.0929
Epoch [1/5], Batch [421/428], Loss: 3.5061
Epoch [1/5], Batch [422/428], Loss: 0.0936
Epoch [1/5], Batch [423/428], Loss: 0.4243
Epoch [1/5], Batch [424/428], Loss: 2.6260
Epoch [1/5], Batch [425/428], Loss: 0.0060
Epoch [1/5], Batch [426/428], Loss: 2.2569
Epoch [1/5], Batch [427/428], Loss: 0.7696
Epoch [1/5], Batch [428/428], Loss: 1.3951
Epoch [1] Training Time: 232.73 seconds
Epoch [1/5], Average Loss: 1.4849, Training Accuracy: 0.5000
Epoch [1], Validation Loss: 2.0810, Validation Accuracy: 0.4556
Epoch [1] Validation Time: 14.33 seconds
--------------------------------------------------
Epoch [2/5], Batch [1/428], Loss: 2.7748
Epoch [2/5], Batch [2/428], Loss: 0.1412
Epoch [2/5], Batch [3/428], Loss: 0.7851
Epoch [2/5], Batch [4/428], Loss: 1.1463
Epoch [2/5], Batch [5/428], Loss: 0.0134
Epoch [2/5], Batch [6/428], Loss: 0.3510
Epoch [2/5], Batch [7/428], Loss: 0.5611
Epoch [2/5], Batch [8/428], Loss: 1.4803
Epoch [2/5], Batch [9/428], Loss: 0.1130
Epoch [2/5], Batch [10/428], Loss: 0.0461
Epoch [2/5], Batch [11/428], Loss: 0.1566
Epoch [2/5], Batch [12/428], Loss: 0.0139
Epoch [2/5], Batch [13/428], Loss: 0.0067
Epoch [2/5], Batch [14/428], Loss: 1.0942
Epoch [2/5], Batch [15/428], Loss: 0.0000
Epoch [2/5], Batch [16/428], Loss: 0.0083
Epoch [2/5], Batch [17/428], Loss: 1.7761
Epoch [2/5], Batch [18/428], Loss: 0.2942
Epoch [2/5], Batch [19/428], Loss: 0.1868
Epoch [2/5], Batch [20/428], Loss: 2.4264
Epoch [2/5], Batch [21/428], Loss: 6.2855
Epoch [2/5], Batch [22/428], Loss: 2.3126
Epoch [2/5], Batch [23/428], Loss: 0.0480
Epoch [2/5], Batch [24/428], Loss: 3.7551
Epoch [2/5], Batch [25/428], Loss: 2.2839
Epoch [2/5], Batch [26/428], Loss: 2.8263
Epoch [2/5], Batch [27/428], Loss: 1.6866
Epoch [2/5], Batch [28/428], Loss: 0.1144
Epoch [2/5], Batch [29/428], Loss: 1.2277
Epoch [2/5], Batch [30/428], Loss: 0.7401
Epoch [2/5], Batch [31/428], Loss: 2.1912
Epoch [2/5], Batch [32/428], Loss: 0.0971
Epoch [2/5], Batch [33/428], Loss: 0.2579
Epoch [2/5], Batch [34/428], Loss: 1.2361
Epoch [2/5], Batch [35/428], Loss: 0.8678
Epoch [2/5], Batch [36/428], Loss: 0.0903
Epoch [2/5], Batch [37/428], Loss: 4.7072
Epoch [2/5], Batch [38/428], Loss: 2.0772
Epoch [2/5], Batch [39/428], Loss: 0.0777
Epoch [2/5], Batch [40/428], Loss: 0.1883
Epoch [2/5], Batch [41/428], Loss: 1.3779
Epoch [2/5], Batch [42/428], Loss: 0.0157
Epoch [2/5], Batch [43/428], Loss: 0.0069
Epoch [2/5], Batch [44/428], Loss: 4.6821
Epoch [2/5], Batch [45/428], Loss: 0.0010
Epoch [2/5], Batch [46/428], Loss: 2.1221
Epoch [2/5], Batch [47/428], Loss: 0.0000
Epoch [2/5], Batch [48/428], Loss: 2.8365
Epoch [2/5], Batch [49/428], Loss: 5.9426
Epoch [2/5], Batch [50/428], Loss: 4.1977
Epoch [2/5], Batch [51/428], Loss: 1.5886
Epoch [2/5], Batch [52/428], Loss: 0.1500
Epoch [2/5], Batch [53/428], Loss: 4.3118
Epoch [2/5], Batch [54/428], Loss: 2.9500
Epoch [2/5], Batch [55/428], Loss: 0.0000
Epoch [2/5], Batch [56/428], Loss: 0.0357
Epoch [2/5], Batch [57/428], Loss: 2.1912
Epoch [2/5], Batch [58/428], Loss: 0.0000
Epoch [2/5], Batch [59/428], Loss: 3.5045
Epoch [2/5], Batch [60/428], Loss: 0.0971
Epoch [2/5], Batch [61/428], Loss: 0.8748
Epoch [2/5], Batch [62/428], Loss: 0.1572
Epoch [2/5], Batch [63/428], Loss: 0.0037
Epoch [2/5], Batch [64/428], Loss: 0.8557
Epoch [2/5], Batch [65/428], Loss: 0.6489
Epoch [2/5], Batch [66/428], Loss: 0.0023
Epoch [2/5], Batch [67/428], Loss: 0.2565
Epoch [2/5], Batch [68/428], Loss: 2.2903
Epoch [2/5], Batch [69/428], Loss: 3.5623
Epoch [2/5], Batch [70/428], Loss: 1.4345
Epoch [2/5], Batch [71/428], Loss: 0.3732
Epoch [2/5], Batch [72/428], Loss: 0.4952
Epoch [2/5], Batch [73/428], Loss: 0.4102
Epoch [2/5], Batch [74/428], Loss: 3.4710
Epoch [2/5], Batch [75/428], Loss: 0.0026
Epoch [2/5], Batch [76/428], Loss: 3.8409
Epoch [2/5], Batch [77/428], Loss: 0.0001
Epoch [2/5], Batch [78/428], Loss: 0.7116
Epoch [2/5], Batch [79/428], Loss: 0.0000
Epoch [2/5], Batch [80/428], Loss: 0.0356
Epoch [2/5], Batch [81/428], Loss: 1.5827
Epoch [2/5], Batch [82/428], Loss: 2.5737
Epoch [2/5], Batch [83/428], Loss: 1.3447
Epoch [2/5], Batch [84/428], Loss: 1.2010
Epoch [2/5], Batch [85/428], Loss: 0.5788
Epoch [2/5], Batch [86/428], Loss: 0.4357
Epoch [2/5], Batch [87/428], Loss: 2.8239
Epoch [2/5], Batch [88/428], Loss: 1.3336
Epoch [2/5], Batch [89/428], Loss: 0.0000
Epoch [2/5], Batch [90/428], Loss: 0.5479
Epoch [2/5], Batch [91/428], Loss: 0.0440
Epoch [2/5], Batch [92/428], Loss: 1.3030
Epoch [2/5], Batch [93/428], Loss: 1.6236
Epoch [2/5], Batch [94/428], Loss: 1.4445
Epoch [2/5], Batch [95/428], Loss: 5.4045
Epoch [2/5], Batch [96/428], Loss: 0.1648
Epoch [2/5], Batch [97/428], Loss: 0.6766
Epoch [2/5], Batch [98/428], Loss: 0.2510
Epoch [2/5], Batch [99/428], Loss: 1.6087
Epoch [2/5], Batch [100/428], Loss: 0.3456
Epoch [2/5], Batch [101/428], Loss: 0.0008
Epoch [2/5], Batch [102/428], Loss: 0.2194
Epoch [2/5], Batch [103/428], Loss: 1.9131
Epoch [2/5], Batch [104/428], Loss: 1.7146
Epoch [2/5], Batch [105/428], Loss: 0.0442
Epoch [2/5], Batch [106/428], Loss: 2.2834
Epoch [2/5], Batch [107/428], Loss: 0.0962
Epoch [2/5], Batch [108/428], Loss: 0.0001
Epoch [2/5], Batch [109/428], Loss: 3.1761
Epoch [2/5], Batch [110/428], Loss: 1.0555
Epoch [2/5], Batch [111/428], Loss: 1.1557
Epoch [2/5], Batch [112/428], Loss: 0.0000
Epoch [2/5], Batch [113/428], Loss: 0.1465
Epoch [2/5], Batch [114/428], Loss: 1.6305
Epoch [2/5], Batch [115/428], Loss: 0.0824
Epoch [2/5], Batch [116/428], Loss: 7.7891
Epoch [2/5], Batch [117/428], Loss: 0.3545
Epoch [2/5], Batch [118/428], Loss: 0.1224
Epoch [2/5], Batch [119/428], Loss: 0.3020
Epoch [2/5], Batch [120/428], Loss: 0.0000
Epoch [2/5], Batch [121/428], Loss: 0.8906
Epoch [2/5], Batch [122/428], Loss: 0.0000
Epoch [2/5], Batch [123/428], Loss: 0.0098
Epoch [2/5], Batch [124/428], Loss: 0.2884
Epoch [2/5], Batch [125/428], Loss: 0.0001
Epoch [2/5], Batch [126/428], Loss: 0.0024
Epoch [2/5], Batch [127/428], Loss: 0.0406
Epoch [2/5], Batch [128/428], Loss: 2.1400
Epoch [2/5], Batch [129/428], Loss: 0.0000
Epoch [2/5], Batch [130/428], Loss: 1.7979
Epoch [2/5], Batch [131/428], Loss: 2.6075
Epoch [2/5], Batch [132/428], Loss: 1.6138
Epoch [2/5], Batch [133/428], Loss: 4.5400
Epoch [2/5], Batch [134/428], Loss: 3.0581
Epoch [2/5], Batch [135/428], Loss: 0.0016
Epoch [2/5], Batch [136/428], Loss: 0.0065
Epoch [2/5], Batch [137/428], Loss: 0.0531
Epoch [2/5], Batch [138/428], Loss: 2.0180
Epoch [2/5], Batch [139/428], Loss: 1.3498
Epoch [2/5], Batch [140/428], Loss: 1.1871
Epoch [2/5], Batch [141/428], Loss: 0.1651
Epoch [2/5], Batch [142/428], Loss: 0.0214
Epoch [2/5], Batch [143/428], Loss: 0.1408
Epoch [2/5], Batch [144/428], Loss: 0.0001
Epoch [2/5], Batch [145/428], Loss: 0.8508
Epoch [2/5], Batch [146/428], Loss: 2.2195
Epoch [2/5], Batch [147/428], Loss: 0.0043
Epoch [2/5], Batch [148/428], Loss: 3.1820
Epoch [2/5], Batch [149/428], Loss: 0.0659
Epoch [2/5], Batch [150/428], Loss: 1.3631
Epoch [2/5], Batch [151/428], Loss: 0.0000
Epoch [2/5], Batch [152/428], Loss: 0.1919
Epoch [2/5], Batch [153/428], Loss: 6.8505
Epoch [2/5], Batch [154/428], Loss: 2.8197
Epoch [2/5], Batch [155/428], Loss: 1.6401
Epoch [2/5], Batch [156/428], Loss: 0.0232
Epoch [2/5], Batch [157/428], Loss: 0.0360
Epoch [2/5], Batch [158/428], Loss: 0.0000
Epoch [2/5], Batch [159/428], Loss: 0.4587
Epoch [2/5], Batch [160/428], Loss: 1.1485
Epoch [2/5], Batch [161/428], Loss: 0.0013
Epoch [2/5], Batch [162/428], Loss: 0.7829
Epoch [2/5], Batch [163/428], Loss: 1.0770
Epoch [2/5], Batch [164/428], Loss: 1.4502
Epoch [2/5], Batch [165/428], Loss: 0.0030
Epoch [2/5], Batch [166/428], Loss: 0.2872
Epoch [2/5], Batch [167/428], Loss: 0.3912
Epoch [2/5], Batch [168/428], Loss: 0.4003
Epoch [2/5], Batch [169/428], Loss: 0.0634
Epoch [2/5], Batch [170/428], Loss: 0.0000
Epoch [2/5], Batch [171/428], Loss: 0.0116
Epoch [2/5], Batch [172/428], Loss: 2.6106
Epoch [2/5], Batch [173/428], Loss: 0.1880
Epoch [2/5], Batch [174/428], Loss: 0.0039
Epoch [2/5], Batch [175/428], Loss: 0.5238
Epoch [2/5], Batch [176/428], Loss: 0.0000
Epoch [2/5], Batch [177/428], Loss: 0.0064
Epoch [2/5], Batch [178/428], Loss: 0.7487
Epoch [2/5], Batch [179/428], Loss: 0.9266
Epoch [2/5], Batch [180/428], Loss: 0.8474
Epoch [2/5], Batch [181/428], Loss: 0.8749
Epoch [2/5], Batch [182/428], Loss: 0.3745
Epoch [2/5], Batch [183/428], Loss: 4.8262
Epoch [2/5], Batch [184/428], Loss: 0.1610
Epoch [2/5], Batch [185/428], Loss: 0.0186
Epoch [2/5], Batch [186/428], Loss: 0.7017
Epoch [2/5], Batch [187/428], Loss: 0.0000
Epoch [2/5], Batch [188/428], Loss: 1.9356
Epoch [2/5], Batch [189/428], Loss: 0.1934
Epoch [2/5], Batch [190/428], Loss: 2.8709
Epoch [2/5], Batch [191/428], Loss: 1.0463
Epoch [2/5], Batch [192/428], Loss: 0.0024
Epoch [2/5], Batch [193/428], Loss: 0.0004
Epoch [2/5], Batch [194/428], Loss: 1.5780
Epoch [2/5], Batch [195/428], Loss: 0.1720
Epoch [2/5], Batch [196/428], Loss: 0.1359
Epoch [2/5], Batch [197/428], Loss: 0.0002
Epoch [2/5], Batch [198/428], Loss: 0.1626
Epoch [2/5], Batch [199/428], Loss: 2.2771
Epoch [2/5], Batch [200/428], Loss: 0.0000
Epoch [2/5], Batch [201/428], Loss: 0.3870
Epoch [2/5], Batch [202/428], Loss: 0.0229
Epoch [2/5], Batch [203/428], Loss: 0.0315
Epoch [2/5], Batch [204/428], Loss: 0.8385
Epoch [2/5], Batch [205/428], Loss: 1.7217
Epoch [2/5], Batch [206/428], Loss: 0.8673
Epoch [2/5], Batch [207/428], Loss: 2.6166
Epoch [2/5], Batch [208/428], Loss: 3.7997
Epoch [2/5], Batch [209/428], Loss: 0.0000
Epoch [2/5], Batch [210/428], Loss: 6.1710
Epoch [2/5], Batch [211/428], Loss: 0.6190
Epoch [2/5], Batch [212/428], Loss: 1.3508
Epoch [2/5], Batch [213/428], Loss: 1.4666
Epoch [2/5], Batch [214/428], Loss: 2.5448
Epoch [2/5], Batch [215/428], Loss: 0.1026
Epoch [2/5], Batch [216/428], Loss: 3.0622
Epoch [2/5], Batch [217/428], Loss: 0.6097
Epoch [2/5], Batch [218/428], Loss: 0.2990
Epoch [2/5], Batch [219/428], Loss: 0.5963
Epoch [2/5], Batch [220/428], Loss: 1.6334
Epoch [2/5], Batch [221/428], Loss: 0.0807
Epoch [2/5], Batch [222/428], Loss: 0.0013
Epoch [2/5], Batch [223/428], Loss: 0.0944
Epoch [2/5], Batch [224/428], Loss: 0.4039
Epoch [2/5], Batch [225/428], Loss: 0.1176
Epoch [2/5], Batch [226/428], Loss: 2.0096
Epoch [2/5], Batch [227/428], Loss: 0.0103
Epoch [2/5], Batch [228/428], Loss: 2.0345
Epoch [2/5], Batch [229/428], Loss: 0.7122
Epoch [2/5], Batch [230/428], Loss: 2.2501
Epoch [2/5], Batch [231/428], Loss: 0.1693
Epoch [2/5], Batch [232/428], Loss: 0.0311
Epoch [2/5], Batch [233/428], Loss: 0.1413
Epoch [2/5], Batch [234/428], Loss: 0.1873
Epoch [2/5], Batch [235/428], Loss: 1.4561
Epoch [2/5], Batch [236/428], Loss: 0.8997
Epoch [2/5], Batch [237/428], Loss: 0.7119
Epoch [2/5], Batch [238/428], Loss: 0.1781
Epoch [2/5], Batch [239/428], Loss: 3.8257
Epoch [2/5], Batch [240/428], Loss: 1.6586
Epoch [2/5], Batch [241/428], Loss: 0.1314
Epoch [2/5], Batch [242/428], Loss: 0.9412
Epoch [2/5], Batch [243/428], Loss: 3.0441
Epoch [2/5], Batch [244/428], Loss: 0.0001
Epoch [2/5], Batch [245/428], Loss: 2.5521
Epoch [2/5], Batch [246/428], Loss: 0.0000
Epoch [2/5], Batch [247/428], Loss: 0.6800
Epoch [2/5], Batch [248/428], Loss: 1.3633
Epoch [2/5], Batch [249/428], Loss: 0.3082
Epoch [2/5], Batch [250/428], Loss: 0.0840
Epoch [2/5], Batch [251/428], Loss: 0.2476
Epoch [2/5], Batch [252/428], Loss: 1.1751
Epoch [2/5], Batch [253/428], Loss: 0.0621
Epoch [2/5], Batch [254/428], Loss: 1.4428
Epoch [2/5], Batch [255/428], Loss: 0.2563
Epoch [2/5], Batch [256/428], Loss: 0.1706
Epoch [2/5], Batch [257/428], Loss: 0.0805
Epoch [2/5], Batch [258/428], Loss: 0.9722
Epoch [2/5], Batch [259/428], Loss: 3.0112
Epoch [2/5], Batch [260/428], Loss: 3.4722
Epoch [2/5], Batch [261/428], Loss: 0.0007
Epoch [2/5], Batch [262/428], Loss: 0.0107
Epoch [2/5], Batch [263/428], Loss: 1.5963
Epoch [2/5], Batch [264/428], Loss: 0.0882
Epoch [2/5], Batch [265/428], Loss: 3.0378
Epoch [2/5], Batch [266/428], Loss: 4.9249
Epoch [2/5], Batch [267/428], Loss: 0.0000
Epoch [2/5], Batch [268/428], Loss: 0.0108
Epoch [2/5], Batch [269/428], Loss: 0.0000
Epoch [2/5], Batch [270/428], Loss: 3.3927
Epoch [2/5], Batch [271/428], Loss: 0.1449
Epoch [2/5], Batch [272/428], Loss: 0.3422
Epoch [2/5], Batch [273/428], Loss: 0.0277
Epoch [2/5], Batch [274/428], Loss: 0.1817
Epoch [2/5], Batch [275/428], Loss: 0.0000
Epoch [2/5], Batch [276/428], Loss: 0.0153
Epoch [2/5], Batch [277/428], Loss: 3.8503
Epoch [2/5], Batch [278/428], Loss: 0.0133
Epoch [2/5], Batch [279/428], Loss: 0.0067
Epoch [2/5], Batch [280/428], Loss: 0.0541
Epoch [2/5], Batch [281/428], Loss: 0.0136
Epoch [2/5], Batch [282/428], Loss: 1.4791
Epoch [2/5], Batch [283/428], Loss: 1.2924
Epoch [2/5], Batch [284/428], Loss: 3.1954
Epoch [2/5], Batch [285/428], Loss: 2.8369
Epoch [2/5], Batch [286/428], Loss: 4.5867
Epoch [2/5], Batch [287/428], Loss: 0.1725
Epoch [2/5], Batch [288/428], Loss: 1.5114
Epoch [2/5], Batch [289/428], Loss: 0.0076
Epoch [2/5], Batch [290/428], Loss: 3.1142
Epoch [2/5], Batch [291/428], Loss: 0.0007
Epoch [2/5], Batch [292/428], Loss: 0.0000
Epoch [2/5], Batch [293/428], Loss: 0.1262
Epoch [2/5], Batch [294/428], Loss: 0.3759
Epoch [2/5], Batch [295/428], Loss: 0.0053
Epoch [2/5], Batch [296/428], Loss: 0.0039
Epoch [2/5], Batch [297/428], Loss: 0.0693
Epoch [2/5], Batch [298/428], Loss: 0.0010
Epoch [2/5], Batch [299/428], Loss: 1.4755
Epoch [2/5], Batch [300/428], Loss: 0.0024
Epoch [2/5], Batch [301/428], Loss: 0.0016
Epoch [2/5], Batch [302/428], Loss: 0.2302
Epoch [2/5], Batch [303/428], Loss: 3.8118
Epoch [2/5], Batch [304/428], Loss: 1.6546
Epoch [2/5], Batch [305/428], Loss: 2.6885
Epoch [2/5], Batch [306/428], Loss: 0.3555
Epoch [2/5], Batch [307/428], Loss: 0.9689
Epoch [2/5], Batch [308/428], Loss: 1.0807
Epoch [2/5], Batch [309/428], Loss: 0.0006
Epoch [2/5], Batch [310/428], Loss: 1.5392
Epoch [2/5], Batch [311/428], Loss: 0.5773
Epoch [2/5], Batch [312/428], Loss: 0.0272
Epoch [2/5], Batch [313/428], Loss: 0.6037
Epoch [2/5], Batch [314/428], Loss: 1.1194
Epoch [2/5], Batch [315/428], Loss: 0.0013
Epoch [2/5], Batch [316/428], Loss: 0.1167
Epoch [2/5], Batch [317/428], Loss: 0.0143
Epoch [2/5], Batch [318/428], Loss: 0.2642
Epoch [2/5], Batch [319/428], Loss: 0.0000
Epoch [2/5], Batch [320/428], Loss: 0.5935
Epoch [2/5], Batch [321/428], Loss: 0.0000
Epoch [2/5], Batch [322/428], Loss: 2.6031
Epoch [2/5], Batch [323/428], Loss: 0.0228
Epoch [2/5], Batch [324/428], Loss: 0.0022
Epoch [2/5], Batch [325/428], Loss: 0.2881
Epoch [2/5], Batch [326/428], Loss: 1.5642
Epoch [2/5], Batch [327/428], Loss: 0.0738
Epoch [2/5], Batch [328/428], Loss: 0.9006
Epoch [2/5], Batch [329/428], Loss: 0.0012
Epoch [2/5], Batch [330/428], Loss: 2.4778
Epoch [2/5], Batch [331/428], Loss: 0.3536
Epoch [2/5], Batch [332/428], Loss: 0.8731
Epoch [2/5], Batch [333/428], Loss: 8.5241
Epoch [2/5], Batch [334/428], Loss: 0.0019
Epoch [2/5], Batch [335/428], Loss: 4.9197
Epoch [2/5], Batch [336/428], Loss: 1.5593
Epoch [2/5], Batch [337/428], Loss: 0.0003
Epoch [2/5], Batch [338/428], Loss: 0.4812
Epoch [2/5], Batch [339/428], Loss: 0.0126
Epoch [2/5], Batch [340/428], Loss: 2.9468
Epoch [2/5], Batch [341/428], Loss: 5.9871
Epoch [2/5], Batch [342/428], Loss: 0.0338
Epoch [2/5], Batch [343/428], Loss: 0.0004
Epoch [2/5], Batch [344/428], Loss: 3.1389
Epoch [2/5], Batch [345/428], Loss: 1.8447
Epoch [2/5], Batch [346/428], Loss: 0.0001
Epoch [2/5], Batch [347/428], Loss: 0.0065
Epoch [2/5], Batch [348/428], Loss: 0.2591
Epoch [2/5], Batch [349/428], Loss: 0.0230
Epoch [2/5], Batch [350/428], Loss: 2.0302
Epoch [2/5], Batch [351/428], Loss: 1.6428
Epoch [2/5], Batch [352/428], Loss: 1.4151
Epoch [2/5], Batch [353/428], Loss: 2.7825
Epoch [2/5], Batch [354/428], Loss: 2.1480
Epoch [2/5], Batch [355/428], Loss: 4.0678
Epoch [2/5], Batch [356/428], Loss: 1.8254
Epoch [2/5], Batch [357/428], Loss: 0.0001
Epoch [2/5], Batch [358/428], Loss: 0.0326
Epoch [2/5], Batch [359/428], Loss: 0.9830
Epoch [2/5], Batch [360/428], Loss: 11.5089
Epoch [2/5], Batch [361/428], Loss: 0.0551
Epoch [2/5], Batch [362/428], Loss: 2.3383
Epoch [2/5], Batch [363/428], Loss: 0.0099
Epoch [2/5], Batch [364/428], Loss: 0.9592
Epoch [2/5], Batch [365/428], Loss: 0.0306
Epoch [2/5], Batch [366/428], Loss: 0.1771
Epoch [2/5], Batch [367/428], Loss: 0.0002
Epoch [2/5], Batch [368/428], Loss: 0.0754
Epoch [2/5], Batch [369/428], Loss: 0.0001
Epoch [2/5], Batch [370/428], Loss: 4.1784
Epoch [2/5], Batch [371/428], Loss: 0.1125
Epoch [2/5], Batch [372/428], Loss: 1.1141
Epoch [2/5], Batch [373/428], Loss: 0.0767
Epoch [2/5], Batch [374/428], Loss: 4.3155
Epoch [2/5], Batch [375/428], Loss: 0.0072
Epoch [2/5], Batch [376/428], Loss: 5.7394
Epoch [2/5], Batch [377/428], Loss: 0.3925
Epoch [2/5], Batch [378/428], Loss: 0.0003
Epoch [2/5], Batch [379/428], Loss: 3.2004
Epoch [2/5], Batch [380/428], Loss: 1.5809
Epoch [2/5], Batch [381/428], Loss: 0.0001
Epoch [2/5], Batch [382/428], Loss: 0.0141
Epoch [2/5], Batch [383/428], Loss: 0.4742
Epoch [2/5], Batch [384/428], Loss: 0.6187
Epoch [2/5], Batch [385/428], Loss: 0.0592
Epoch [2/5], Batch [386/428], Loss: 0.9018
Epoch [2/5], Batch [387/428], Loss: 0.5844
Epoch [2/5], Batch [388/428], Loss: 0.0073
Epoch [2/5], Batch [389/428], Loss: 1.0281
Epoch [2/5], Batch [390/428], Loss: 1.0450
Epoch [2/5], Batch [391/428], Loss: 2.8323
Epoch [2/5], Batch [392/428], Loss: 1.0844
Epoch [2/5], Batch [393/428], Loss: 2.7003
Epoch [2/5], Batch [394/428], Loss: 1.7354
Epoch [2/5], Batch [395/428], Loss: 3.3268
Epoch [2/5], Batch [396/428], Loss: 0.0000
Epoch [2/5], Batch [397/428], Loss: 0.9767
Epoch [2/5], Batch [398/428], Loss: 0.0173
Epoch [2/5], Batch [399/428], Loss: 0.5100
Epoch [2/5], Batch [400/428], Loss: 0.2415
Epoch [2/5], Batch [401/428], Loss: 0.0000
Epoch [2/5], Batch [402/428], Loss: 0.0876
Epoch [2/5], Batch [403/428], Loss: 0.0000
Epoch [2/5], Batch [404/428], Loss: 0.0453
Epoch [2/5], Batch [405/428], Loss: 0.0766
Epoch [2/5], Batch [406/428], Loss: 0.2895
Epoch [2/5], Batch [407/428], Loss: 0.3819
Epoch [2/5], Batch [408/428], Loss: 4.5815
Epoch [2/5], Batch [409/428], Loss: 0.9860
Epoch [2/5], Batch [410/428], Loss: 0.0431
Epoch [2/5], Batch [411/428], Loss: 2.2815
Epoch [2/5], Batch [412/428], Loss: 0.0043
Epoch [2/5], Batch [413/428], Loss: 0.2308
Epoch [2/5], Batch [414/428], Loss: 0.0008
Epoch [2/5], Batch [415/428], Loss: 0.4621
Epoch [2/5], Batch [416/428], Loss: 1.4336
Epoch [2/5], Batch [417/428], Loss: 0.0771
Epoch [2/5], Batch [418/428], Loss: 0.0000
Epoch [2/5], Batch [419/428], Loss: 0.7831
Epoch [2/5], Batch [420/428], Loss: 4.7041
Epoch [2/5], Batch [421/428], Loss: 0.2899
Epoch [2/5], Batch [422/428], Loss: 1.0040
Epoch [2/5], Batch [423/428], Loss: 0.1273
Epoch [2/5], Batch [424/428], Loss: 0.0043
Epoch [2/5], Batch [425/428], Loss: 3.0055
Epoch [2/5], Batch [426/428], Loss: 4.3244
Epoch [2/5], Batch [427/428], Loss: 3.9407
Epoch [2/5], Batch [428/428], Loss: 2.0128
Epoch [2] Training Time: 230.88 seconds
Epoch [2/5], Average Loss: 1.1216, Training Accuracy: 0.6075
Epoch [2], Validation Loss: 1.7889, Validation Accuracy: 0.5078
Epoch [2] Validation Time: 14.28 seconds
--------------------------------------------------
Epoch 3: Unfreezing feature extractor layers...
Epoch [3/5], Batch [1/428], Loss: 1.4379
Epoch [3/5], Batch [2/428], Loss: 3.0661
Epoch [3/5], Batch [3/428], Loss: 20.9462
Epoch [3/5], Batch [4/428], Loss: 0.5090
Epoch [3/5], Batch [5/428], Loss: 17.6966
Epoch [3/5], Batch [6/428], Loss: 16.8553
Epoch [3/5], Batch [7/428], Loss: 33.1955
Epoch [3/5], Batch [8/428], Loss: 26.9207
Epoch [3/5], Batch [9/428], Loss: 35.4599
Epoch [3/5], Batch [10/428], Loss: 0.0081
Epoch [3/5], Batch [11/428], Loss: 26.2197
Epoch [3/5], Batch [12/428], Loss: 24.3877
Epoch [3/5], Batch [13/428], Loss: 17.6716
Epoch [3/5], Batch [14/428], Loss: 0.0775
Epoch [3/5], Batch [15/428], Loss: 0.0005
Epoch [3/5], Batch [16/428], Loss: 11.2348
Epoch [3/5], Batch [17/428], Loss: 9.1654
Epoch [3/5], Batch [18/428], Loss: 0.9756
Epoch [3/5], Batch [19/428], Loss: 3.7056
Epoch [3/5], Batch [20/428], Loss: 15.3000
Epoch [3/5], Batch [21/428], Loss: 14.6844
Epoch [3/5], Batch [22/428], Loss: 11.1357
Epoch [3/5], Batch [23/428], Loss: 0.1967
Epoch [3/5], Batch [24/428], Loss: 0.0998
Epoch [3/5], Batch [25/428], Loss: 0.0204
Epoch [3/5], Batch [26/428], Loss: 9.4375
Epoch [3/5], Batch [27/428], Loss: 9.2166
Epoch [3/5], Batch [28/428], Loss: 7.6458
Epoch [3/5], Batch [29/428], Loss: 6.6085
Epoch [3/5], Batch [30/428], Loss: 4.7351
Epoch [3/5], Batch [31/428], Loss: 1.5410
Epoch [3/5], Batch [32/428], Loss: 7.5217
Epoch [3/5], Batch [33/428], Loss: 4.8880
Epoch [3/5], Batch [34/428], Loss: 6.0046
Epoch [3/5], Batch [35/428], Loss: 0.7584
Epoch [3/5], Batch [36/428], Loss: 0.8459
Epoch [3/5], Batch [37/428], Loss: 6.5801
Epoch [3/5], Batch [38/428], Loss: 1.5416
Epoch [3/5], Batch [39/428], Loss: 1.9788
Epoch [3/5], Batch [40/428], Loss: 5.9895
Epoch [3/5], Batch [41/428], Loss: 5.2652
Epoch [3/5], Batch [42/428], Loss: 3.5388
Epoch [3/5], Batch [43/428], Loss: 1.5750
Epoch [3/5], Batch [44/428], Loss: 3.7675
Epoch [3/5], Batch [45/428], Loss: 7.9503
Epoch [3/5], Batch [46/428], Loss: 2.1681
Epoch [3/5], Batch [47/428], Loss: 9.2746
Epoch [3/5], Batch [48/428], Loss: 1.0396
Epoch [3/5], Batch [49/428], Loss: 2.4831
Epoch [3/5], Batch [50/428], Loss: 0.4617
Epoch [3/5], Batch [51/428], Loss: 2.7774
Epoch [3/5], Batch [52/428], Loss: 4.6554
Epoch [3/5], Batch [53/428], Loss: 4.8183
Epoch [3/5], Batch [54/428], Loss: 3.3824
Epoch [3/5], Batch [55/428], Loss: 6.2239
Epoch [3/5], Batch [56/428], Loss: 0.9904
Epoch [3/5], Batch [57/428], Loss: 3.5520
Epoch [3/5], Batch [58/428], Loss: 4.1686
Epoch [3/5], Batch [59/428], Loss: 3.1600
Epoch [3/5], Batch [60/428], Loss: 4.3645
Epoch [3/5], Batch [61/428], Loss: 1.4345
Epoch [3/5], Batch [62/428], Loss: 4.7730
Epoch [3/5], Batch [63/428], Loss: 1.1754
Epoch [3/5], Batch [64/428], Loss: 0.7854
Epoch [3/5], Batch [65/428], Loss: 4.8484
Epoch [3/5], Batch [66/428], Loss: 3.3913
Epoch [3/5], Batch [67/428], Loss: 3.5221
Epoch [3/5], Batch [68/428], Loss: 4.8581
Epoch [3/5], Batch [69/428], Loss: 0.2581
Epoch [3/5], Batch [70/428], Loss: 4.7608
Epoch [3/5], Batch [71/428], Loss: 2.8153
Epoch [3/5], Batch [72/428], Loss: 1.7673
Epoch [3/5], Batch [73/428], Loss: 1.1543
Epoch [3/5], Batch [74/428], Loss: 2.3826
Epoch [3/5], Batch [75/428], Loss: 0.3686
Epoch [3/5], Batch [76/428], Loss: 2.4772
Epoch [3/5], Batch [77/428], Loss: 0.1648
Epoch [3/5], Batch [78/428], Loss: 0.0988
Epoch [3/5], Batch [79/428], Loss: 3.4645
Epoch [3/5], Batch [80/428], Loss: 7.1238
Epoch [3/5], Batch [81/428], Loss: 6.6830
Epoch [3/5], Batch [82/428], Loss: 6.8144
Epoch [3/5], Batch [83/428], Loss: 0.0519
Epoch [3/5], Batch [84/428], Loss: 6.0791
Epoch [3/5], Batch [85/428], Loss: 5.2897
Epoch [3/5], Batch [86/428], Loss: 9.3376
Epoch [3/5], Batch [87/428], Loss: 8.7342
Epoch [3/5], Batch [88/428], Loss: 0.3621
Epoch [3/5], Batch [89/428], Loss: 7.1966
Epoch [3/5], Batch [90/428], Loss: 6.8964
Epoch [3/5], Batch [91/428], Loss: 1.5170
Epoch [3/5], Batch [92/428], Loss: 1.5809
Epoch [3/5], Batch [93/428], Loss: 0.8349
Epoch [3/5], Batch [94/428], Loss: 4.2763
Epoch [3/5], Batch [95/428], Loss: 3.1280
Epoch [3/5], Batch [96/428], Loss: 5.1616
Epoch [3/5], Batch [97/428], Loss: 2.6511
Epoch [3/5], Batch [98/428], Loss: 1.7979
Epoch [3/5], Batch [99/428], Loss: 3.3651
Epoch [3/5], Batch [100/428], Loss: 2.9996
Epoch [3/5], Batch [101/428], Loss: 4.2878
Epoch [3/5], Batch [102/428], Loss: 4.1205
Epoch [3/5], Batch [103/428], Loss: 3.6068
Epoch [3/5], Batch [104/428], Loss: 4.1090
Epoch [3/5], Batch [105/428], Loss: 3.7736
Epoch [3/5], Batch [106/428], Loss: 3.8176
Epoch [3/5], Batch [107/428], Loss: 1.4025
Epoch [3/5], Batch [108/428], Loss: 0.9222
Epoch [3/5], Batch [109/428], Loss: 4.1602
Epoch [3/5], Batch [110/428], Loss: 2.6172
Epoch [3/5], Batch [111/428], Loss: 2.1798
Epoch [3/5], Batch [112/428], Loss: 3.7242
Epoch [3/5], Batch [113/428], Loss: 3.3842
Epoch [3/5], Batch [114/428], Loss: 2.7291
Epoch [3/5], Batch [115/428], Loss: 1.7884
Epoch [3/5], Batch [116/428], Loss: 0.7031
Epoch [3/5], Batch [117/428], Loss: 0.5915
Epoch [3/5], Batch [118/428], Loss: 0.4158
Epoch [3/5], Batch [119/428], Loss: 2.4210
Epoch [3/5], Batch [120/428], Loss: 4.8248
Epoch [3/5], Batch [121/428], Loss: 0.1514
Epoch [3/5], Batch [122/428], Loss: 6.3333
Epoch [3/5], Batch [123/428], Loss: 0.0950
Epoch [3/5], Batch [124/428], Loss: 3.2136
Epoch [3/5], Batch [125/428], Loss: 7.4546
Epoch [3/5], Batch [126/428], Loss: 7.3803
Epoch [3/5], Batch [127/428], Loss: 5.4643
Epoch [3/5], Batch [128/428], Loss: 4.5071
Epoch [3/5], Batch [129/428], Loss: 4.9421
Epoch [3/5], Batch [130/428], Loss: 5.2017
Epoch [3/5], Batch [131/428], Loss: 1.2745
Epoch [3/5], Batch [132/428], Loss: 0.8416
Epoch [3/5], Batch [133/428], Loss: 2.9240
Epoch [3/5], Batch [134/428], Loss: 4.2966
Epoch [3/5], Batch [135/428], Loss: 3.7242
Epoch [3/5], Batch [136/428], Loss: 2.2314
Epoch [3/5], Batch [137/428], Loss: 4.2763
Epoch [3/5], Batch [138/428], Loss: 0.8651
Epoch [3/5], Batch [139/428], Loss: 4.6978
Epoch [3/5], Batch [140/428], Loss: 4.6619
Epoch [3/5], Batch [141/428], Loss: 1.2402
Epoch [3/5], Batch [142/428], Loss: 2.1445
Epoch [3/5], Batch [143/428], Loss: 1.8536
Epoch [3/5], Batch [144/428], Loss: 1.3688
Epoch [3/5], Batch [145/428], Loss: 2.3250
Epoch [3/5], Batch [146/428], Loss: 1.2664
Epoch [3/5], Batch [147/428], Loss: 3.6058
Epoch [3/5], Batch [148/428], Loss: 1.6430
Epoch [3/5], Batch [149/428], Loss: 3.1750
Epoch [3/5], Batch [150/428], Loss: 2.8635
Epoch [3/5], Batch [151/428], Loss: 3.1929
Epoch [3/5], Batch [152/428], Loss: 2.9500
Epoch [3/5], Batch [153/428], Loss: 1.4334
Epoch [3/5], Batch [154/428], Loss: 1.6130
Epoch [3/5], Batch [155/428], Loss: 1.8358
Epoch [3/5], Batch [156/428], Loss: 2.6510
Epoch [3/5], Batch [157/428], Loss: 0.9471
Epoch [3/5], Batch [158/428], Loss: 2.0991
Epoch [3/5], Batch [159/428], Loss: 2.2167
Epoch [3/5], Batch [160/428], Loss: 0.6205
Epoch [3/5], Batch [161/428], Loss: 4.6191
Epoch [3/5], Batch [162/428], Loss: 4.5895
Epoch [3/5], Batch [163/428], Loss: 0.4491
Epoch [3/5], Batch [164/428], Loss: 3.0527
Epoch [3/5], Batch [165/428], Loss: 2.6771
Epoch [3/5], Batch [166/428], Loss: 2.8642
Epoch [3/5], Batch [167/428], Loss: 2.4589
Epoch [3/5], Batch [168/428], Loss: 3.0171
Epoch [3/5], Batch [169/428], Loss: 2.8928
Epoch [3/5], Batch [170/428], Loss: 2.1879
Epoch [3/5], Batch [171/428], Loss: 2.6468
Epoch [3/5], Batch [172/428], Loss: 1.6694
Epoch [3/5], Batch [173/428], Loss: 1.9844
Epoch [3/5], Batch [174/428], Loss: 1.9378
Epoch [3/5], Batch [175/428], Loss: 1.6638
Epoch [3/5], Batch [176/428], Loss: 3.9735
Epoch [3/5], Batch [177/428], Loss: 1.4378
Epoch [3/5], Batch [178/428], Loss: 1.8951
Epoch [3/5], Batch [179/428], Loss: 4.6229
Epoch [3/5], Batch [180/428], Loss: 1.7403
Epoch [3/5], Batch [181/428], Loss: 3.7308
Epoch [3/5], Batch [182/428], Loss: 6.2242
Epoch [3/5], Batch [183/428], Loss: 4.0350
Epoch [3/5], Batch [184/428], Loss: 0.8382
Epoch [3/5], Batch [185/428], Loss: 1.8548
Epoch [3/5], Batch [186/428], Loss: 3.2278
Epoch [3/5], Batch [187/428], Loss: 0.4969
Epoch [3/5], Batch [188/428], Loss: 0.3959
Epoch [3/5], Batch [189/428], Loss: 2.6150
Epoch [3/5], Batch [190/428], Loss: 2.4562
Epoch [3/5], Batch [191/428], Loss: 3.7043
Epoch [3/5], Batch [192/428], Loss: 3.7184
Epoch [3/5], Batch [193/428], Loss: 4.0124
Epoch [3/5], Batch [194/428], Loss: 4.2533
Epoch [3/5], Batch [195/428], Loss: 3.7013
Epoch [3/5], Batch [196/428], Loss: 0.5207
Epoch [3/5], Batch [197/428], Loss: 4.0802
Epoch [3/5], Batch [198/428], Loss: 0.3221
Epoch [3/5], Batch [199/428], Loss: 0.2362
Epoch [3/5], Batch [200/428], Loss: 0.1635
Epoch [3/5], Batch [201/428], Loss: 3.7855
Epoch [3/5], Batch [202/428], Loss: 4.1300
Epoch [3/5], Batch [203/428], Loss: 0.0605
Epoch [3/5], Batch [204/428], Loss: 6.6289
Epoch [3/5], Batch [205/428], Loss: 4.6172
Epoch [3/5], Batch [206/428], Loss: 0.0400
Epoch [3/5], Batch [207/428], Loss: 4.5719
Epoch [3/5], Batch [208/428], Loss: 6.2706
Epoch [3/5], Batch [209/428], Loss: 0.0421
Epoch [3/5], Batch [210/428], Loss: 3.9772
Epoch [3/5], Batch [211/428], Loss: 0.0475
Epoch [3/5], Batch [212/428], Loss: 7.7797
Epoch [3/5], Batch [213/428], Loss: 3.5068
Epoch [3/5], Batch [214/428], Loss: 4.7890
Epoch [3/5], Batch [215/428], Loss: 5.1277
Epoch [3/5], Batch [216/428], Loss: 6.8489
Epoch [3/5], Batch [217/428], Loss: 4.3489
Epoch [3/5], Batch [218/428], Loss: 1.3727
Epoch [3/5], Batch [219/428], Loss: 4.7616
Epoch [3/5], Batch [220/428], Loss: 0.6510
Epoch [3/5], Batch [221/428], Loss: 4.3312
Epoch [3/5], Batch [222/428], Loss: 2.7878
Epoch [3/5], Batch [223/428], Loss: 4.9157
Epoch [3/5], Batch [224/428], Loss: 2.1160
Epoch [3/5], Batch [225/428], Loss: 2.9982
Epoch [3/5], Batch [226/428], Loss: 0.7480
Epoch [3/5], Batch [227/428], Loss: 4.2208
Epoch [3/5], Batch [228/428], Loss: 4.4336
Epoch [3/5], Batch [229/428], Loss: 3.4701
Epoch [3/5], Batch [230/428], Loss: 2.8204
Epoch [3/5], Batch [231/428], Loss: 2.9979
Epoch [3/5], Batch [232/428], Loss: 4.1695
Epoch [3/5], Batch [233/428], Loss: 1.3153
Epoch [3/5], Batch [234/428], Loss: 2.1383
Epoch [3/5], Batch [235/428], Loss: 1.4637
Epoch [3/5], Batch [236/428], Loss: 3.5799
Epoch [3/5], Batch [237/428], Loss: 2.4067
Epoch [3/5], Batch [238/428], Loss: 2.1925
Epoch [3/5], Batch [239/428], Loss: 1.4885
Epoch [3/5], Batch [240/428], Loss: 1.7329
Epoch [3/5], Batch [241/428], Loss: 1.6618
Epoch [3/5], Batch [242/428], Loss: 1.3119
Epoch [3/5], Batch [243/428], Loss: 2.8427
Epoch [3/5], Batch [244/428], Loss: 1.4450
Epoch [3/5], Batch [245/428], Loss: 1.3129
Epoch [3/5], Batch [246/428], Loss: 1.3005
Epoch [3/5], Batch [247/428], Loss: 1.4254
Epoch [3/5], Batch [248/428], Loss: 2.5249
Epoch [3/5], Batch [249/428], Loss: 2.4008
Epoch [3/5], Batch [250/428], Loss: 1.4370
Epoch [3/5], Batch [251/428], Loss: 1.5698
Epoch [3/5], Batch [252/428], Loss: 1.2366
Epoch [3/5], Batch [253/428], Loss: 4.6563
Epoch [3/5], Batch [254/428], Loss: 4.5523
Epoch [3/5], Batch [255/428], Loss: 4.2607
Epoch [3/5], Batch [256/428], Loss: 6.0156
Epoch [3/5], Batch [257/428], Loss: 1.7530
Epoch [3/5], Batch [258/428], Loss: 1.6308
Epoch [3/5], Batch [259/428], Loss: 1.5761
Epoch [3/5], Batch [260/428], Loss: 5.1916
Epoch [3/5], Batch [261/428], Loss: 1.5196
Epoch [3/5], Batch [262/428], Loss: 1.5203
Epoch [3/5], Batch [263/428], Loss: 1.2561
Epoch [3/5], Batch [264/428], Loss: 1.3643
Epoch [3/5], Batch [265/428], Loss: 1.6456
Epoch [3/5], Batch [266/428], Loss: 1.2120
Epoch [3/5], Batch [267/428], Loss: 3.5334
Epoch [3/5], Batch [268/428], Loss: 2.7683
Epoch [3/5], Batch [269/428], Loss: 1.2222
Epoch [3/5], Batch [270/428], Loss: 3.4921
Epoch [3/5], Batch [271/428], Loss: 2.7327
Epoch [3/5], Batch [272/428], Loss: 2.5618
Epoch [3/5], Batch [273/428], Loss: 0.9740
Epoch [3/5], Batch [274/428], Loss: 0.8869
Epoch [3/5], Batch [275/428], Loss: 5.5233
Epoch [3/5], Batch [276/428], Loss: 3.5284
Epoch [3/5], Batch [277/428], Loss: 0.5864
Epoch [3/5], Batch [278/428], Loss: 0.4915
Epoch [3/5], Batch [279/428], Loss: 0.3551
Epoch [3/5], Batch [280/428], Loss: 3.7746
Epoch [3/5], Batch [281/428], Loss: 3.7708
Epoch [3/5], Batch [282/428], Loss: 0.1472
Epoch [3/5], Batch [283/428], Loss: 4.5171
Epoch [3/5], Batch [284/428], Loss: 3.9391
Epoch [3/5], Batch [285/428], Loss: 3.8091
Epoch [3/5], Batch [286/428], Loss: 5.7539
Epoch [3/5], Batch [287/428], Loss: 5.2346
Epoch [3/5], Batch [288/428], Loss: 0.1622
Epoch [3/5], Batch [289/428], Loss: 4.6532
Epoch [3/5], Batch [290/428], Loss: 3.2415
Epoch [3/5], Batch [291/428], Loss: 3.4430
Epoch [3/5], Batch [292/428], Loss: 3.3420
Epoch [3/5], Batch [293/428], Loss: 2.4215
Epoch [3/5], Batch [294/428], Loss: 2.5914
Epoch [3/5], Batch [295/428], Loss: 0.9764
Epoch [3/5], Batch [296/428], Loss: 1.7195
Epoch [3/5], Batch [297/428], Loss: 1.6021
Epoch [3/5], Batch [298/428], Loss: 1.4459
Epoch [3/5], Batch [299/428], Loss: 2.1498
Epoch [3/5], Batch [300/428], Loss: 2.3377
Epoch [3/5], Batch [301/428], Loss: 2.5433
Epoch [3/5], Batch [302/428], Loss: 0.9038
Epoch [3/5], Batch [303/428], Loss: 1.3916
Epoch [3/5], Batch [304/428], Loss: 1.3726
Epoch [3/5], Batch [305/428], Loss: 2.7233
Epoch [3/5], Batch [306/428], Loss: 2.5186
Epoch [3/5], Batch [307/428], Loss: 2.5539
Epoch [3/5], Batch [308/428], Loss: 0.9512
Epoch [3/5], Batch [309/428], Loss: 2.2345
Epoch [3/5], Batch [310/428], Loss: 2.0277
Epoch [3/5], Batch [311/428], Loss: 1.8854
Epoch [3/5], Batch [312/428], Loss: 1.4226
Epoch [3/5], Batch [313/428], Loss: 4.1997
Epoch [3/5], Batch [314/428], Loss: 3.4959
Epoch [3/5], Batch [315/428], Loss: 3.9922
Epoch [3/5], Batch [316/428], Loss: 2.4985
Epoch [3/5], Batch [317/428], Loss: 3.1915
Epoch [3/5], Batch [318/428], Loss: 3.2569
Epoch [3/5], Batch [319/428], Loss: 2.3851
Epoch [3/5], Batch [320/428], Loss: 0.6045
Epoch [3/5], Batch [321/428], Loss: 2.2267
Epoch [3/5], Batch [322/428], Loss: 2.0207
Epoch [3/5], Batch [323/428], Loss: 1.7466
Epoch [3/5], Batch [324/428], Loss: 1.0428
Epoch [3/5], Batch [325/428], Loss: 1.0653
Epoch [3/5], Batch [326/428], Loss: 2.3271
Epoch [3/5], Batch [327/428], Loss: 5.2543
Epoch [3/5], Batch [328/428], Loss: 1.9314
Epoch [3/5], Batch [329/428], Loss: 0.4701
Epoch [3/5], Batch [330/428], Loss: 2.1861
Epoch [3/5], Batch [331/428], Loss: 3.8510
Epoch [3/5], Batch [332/428], Loss: 2.8621
Epoch [3/5], Batch [333/428], Loss: 0.3967
Epoch [3/5], Batch [334/428], Loss: 2.6527
Epoch [3/5], Batch [335/428], Loss: 0.4071
Epoch [3/5], Batch [336/428], Loss: 0.3663
Epoch [3/5], Batch [337/428], Loss: 2.5112
Epoch [3/5], Batch [338/428], Loss: 0.2672
Epoch [3/5], Batch [339/428], Loss: 2.4918
Epoch [3/5], Batch [340/428], Loss: 3.7176
Epoch [3/5], Batch [341/428], Loss: 5.0055
Epoch [3/5], Batch [342/428], Loss: 1.9795
Epoch [3/5], Batch [343/428], Loss: 3.2977
Epoch [3/5], Batch [344/428], Loss: 3.1920
Epoch [3/5], Batch [345/428], Loss: 2.9006
Epoch [3/5], Batch [346/428], Loss: 6.0121
Epoch [3/5], Batch [347/428], Loss: 2.2947
Epoch [3/5], Batch [348/428], Loss: 0.5981
Epoch [3/5], Batch [349/428], Loss: 1.7601
Epoch [3/5], Batch [350/428], Loss: 3.1710
Epoch [3/5], Batch [351/428], Loss: 5.1711
Epoch [3/5], Batch [352/428], Loss: 1.0106
Epoch [3/5], Batch [353/428], Loss: 2.8760
Epoch [3/5], Batch [354/428], Loss: 1.2690
Epoch [3/5], Batch [355/428], Loss: 4.2673
Epoch [3/5], Batch [356/428], Loss: 0.4927
Epoch [3/5], Batch [357/428], Loss: 3.9426
Epoch [3/5], Batch [358/428], Loss: 3.5876
Epoch [3/5], Batch [359/428], Loss: 2.1769
Epoch [3/5], Batch [360/428], Loss: 3.3939
Epoch [3/5], Batch [361/428], Loss: 4.9227
Epoch [3/5], Batch [362/428], Loss: 3.3562
Epoch [3/5], Batch [363/428], Loss: 0.7100
Epoch [3/5], Batch [364/428], Loss: 2.6528
Epoch [3/5], Batch [365/428], Loss: 2.0844
Epoch [3/5], Batch [366/428], Loss: 1.9480
Epoch [3/5], Batch [367/428], Loss: 4.5335
Epoch [3/5], Batch [368/428], Loss: 1.3912
Epoch [3/5], Batch [369/428], Loss: 2.6348
Epoch [3/5], Batch [370/428], Loss: 2.3438
Epoch [3/5], Batch [371/428], Loss: 1.7262
Epoch [3/5], Batch [372/428], Loss: 2.5662
Epoch [3/5], Batch [373/428], Loss: 1.9180
Epoch [3/5], Batch [374/428], Loss: 1.5066
Epoch [3/5], Batch [375/428], Loss: 2.2288
Epoch [3/5], Batch [376/428], Loss: 2.4991
Epoch [3/5], Batch [377/428], Loss: 1.4749
Epoch [3/5], Batch [378/428], Loss: 1.3552
Epoch [3/5], Batch [379/428], Loss: 1.8582
Epoch [3/5], Batch [380/428], Loss: 1.8660
Epoch [3/5], Batch [381/428], Loss: 1.7247
Epoch [3/5], Batch [382/428], Loss: 0.9877
Epoch [3/5], Batch [383/428], Loss: 1.6942
Epoch [3/5], Batch [384/428], Loss: 3.8943
Epoch [3/5], Batch [385/428], Loss: 1.6936
Epoch [3/5], Batch [386/428], Loss: 3.1673
Epoch [3/5], Batch [387/428], Loss: 1.4729
Epoch [3/5], Batch [388/428], Loss: 1.1914
Epoch [3/5], Batch [389/428], Loss: 3.4387
Epoch [3/5], Batch [390/428], Loss: 1.0425
Epoch [3/5], Batch [391/428], Loss: 3.0796
Epoch [3/5], Batch [392/428], Loss: 3.5996
Epoch [3/5], Batch [393/428], Loss: 3.1636
Epoch [3/5], Batch [394/428], Loss: 0.6611
Epoch [3/5], Batch [395/428], Loss: 2.6967
Epoch [3/5], Batch [396/428], Loss: 2.1771
Epoch [3/5], Batch [397/428], Loss: 3.2541
Epoch [3/5], Batch [398/428], Loss: 0.6129
Epoch [3/5], Batch [399/428], Loss: 2.3397
Epoch [3/5], Batch [400/428], Loss: 2.8518